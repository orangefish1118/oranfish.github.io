[{"id":"e831f129fb6325d4710907008135b5ef","title":"软件工程基础复习材料","content":"名词解释题1.软件工程将系统化、规范化、可量化的方法应用于软件的开发、运行和维护的过程，以及上述方法的研究\n软件工程是：    ①将系统化的、严格约束的、可量化的方法应用于软件的开发、运行和维护，即将工程化应用于软件；    ②在①中所述方法的研究。\n2.软件制品软件过程的每一项活动都需要人员去完成，活动实施需投入必要的成本、资源和工具，活动的完成需要时间，结束之后会产生相应的软件制品。 因此 ，软件过程将软件项目相关的人力、成本、进度、资源、制品、工具等组织在一起，不仅软件项目的实施需要软件过程的指导 ，软件项目的管理也依赖具体的软件过程 ，比如基于软件过程来制订项目实施计划、跟踪计划的开展、估算软件项目的成本等。\n①软件原型②软件用例模型③软件需求文档\n3.系统软件系统软件是指对计算资源进行管理， 为应用软件的运行提供基础服务的一类软件。\n4.支撑软件支撑软件是指用于辅助软件开发和运维，帮助软件开发入员完成软件开发和维护工作的一类软件。 \n5.软件生存周期软件生命周期指一个软件从提出开发开始，到开发完成交付用户使用，及至最后退役不再使用的全过程。 \n6.需求工程需求工程是指应用工程化的方法、技术和规格来开发和管理软件的需求。\n需求工程旨在用工程的理念和方法来指导软件需求实践。 \n它提供了一系列过程、策略、方法学和工具，帮助需求工程师加强对业务或领域问题及其环境的理解，获取和分析软件需求，指导软件需求的文档化和评审，以尽可能获得准确、一致和完整的软件需求，产生软件需求的相关软件制品。 \n7.原型所谓原型 (prototype) ，是指在产品开发前期所产生的产品雏形或仿真产品。 相较于实际产品，原型具有可直观展示产品的特性、贴近业务应用、能自然地反映产品需求等特点。\n8.强内聚低耦合内聚度是指模块内各成分间彼此结合的紧密程度，耦合度是指不同模块之间的相关程度。 高内聚度、低耦合度的原则要求模块应该设计得每个模块内部内聚度要高，不同模块之间的耦合度要低。 这两项基本原则可以用来有效指导软件模块的设计，确保得到高质量的模块设计。\n9.模块化模块化原则是指将软件系统的功能分解和实现为若干个模块，每个模块具有独立的功能，模块之间通过接口进行调用和访问。 \n10.信息隐藏原则信息隐藏原则是指模块应该设计为使其所含的信息（如内部语句、变址等）对那些不需要这些信息的模块而言不可访问，模块间仅交换实现系统功能所须交换的信息（如接口）。 \n11.系统响应时间系统响应时间指从用户执行某个控制动作（如按回车键或单击鼠标）到软件作出响应（期望的输出或动作）的时间。\n12.图形用户界面用户通过键盘和鼠标等方式来操纵图形化界面，向软件输入所需的信息，如点击按钮、选择某项信息等。软件处理完成之后，采用图形化方式向用户现实和反馈处理的结果，如通过窗口、采用图形等形式来显示处理结果。它以图形化方式向用户展示输入、输出信息，如图形、窗口、按钮、对话框、菜单等。这种方式尤其是鼠标极大促进了它的使用，方便了用户操作软件。用户无须记忆各种命令符号，只需点击菜单项或按钮可发出各种命令，通过选择或填写对话框中的各信息输入项就可以完成参数设置。\n13.软件测试用例软件测试用例的设计是软件测试的关键，它描述了对程序代码进行测试时所输入的数据以及预期的结果。一般地，一个测试用例是由以下4类元素所构成的，输入数据，前置条件，测试步骤，预期输出。\n\n输入数据。输入数据代表将交由待测试程序代码进行处理的数据，程序代码基于输入数据执行相应的业务逻辑，并产生数据输出。\n\n前置条件。当待测试的程序代码对数据进行处理是，如阿坚测试工程师需要明确程序处理输入数据的运行上下文，也即要满足的前置条件。\n\n测试步骤。在软件测试的过程中，程序代码对输入数据的处理可能设计一系列步骤，其中某些步骤需要用户的进一步输入。\n\n预期输出。根据待测试程序代码的功能及内部执行逻辑，输入不同的数据，程序代码应该有不同的预期输出结果。\n\n\n14.单元测试\\集成测试\\确认测试\n单元测试：单元测试依据软件详细设计模型和文档来设计测试用例，它主要对程序单元的接口以及内部执行逻辑进行测试。单元测试通常由程序员完成，一般采用白盒测试技术。\n\n集成测试：集成测试是将构成目标软件系统的程序单元进行逐步组装，测试它们的接口和集成是否存在缺陷。软件概要设计模型和文档(如子系统设计模型、软件体系结构设计模型等)是指导集成测试的依据，也即集成测试是要测试程序单元间的接口及其集成是否满足概要设计的相关要求。通常，集成测试在单元测试完成之后，由专门的软件测试工程师来完成，其测试用例可在软件概要设计阶段产生。集成测试通常采用黑盒测试技术。\n\n确认测试需要在集成测试完成之后，由专门的软件测试工程师在软件测试阶段来负责完成，其测试用例可在软件需求分析阶段产生。确认测试通常采用黑盒测试技术。\n\n\n15.性能测试性能测试用来测试软件在集成的系统中的性能。性能测试可发生在测试过程的所有步骤中，单元测试时主要测试一个模块的性能，软件的整体性能只有在软件集成后进行，整个计算机系统性能实在计算机系统集成后进行。 \n16.安全测试安全性测试借助工具或人工手段来模拟黑客入侵，以发现软件系统中存在的安全隐患，检查软件系统对非法侵入的防范能力。\n17.回归测试程序员修复了程序后，还需要对修复后的代码进行回归测试，以判断缺陷和错误是否已经被成功修复，或者在修复代码过程中有没有引入新的缺陷和错误。\n18.软件部署软件部署是指将目标软件系统（包括构建、配置文件、用户手册、帮助文档等）进行收集、打包、安装、配置和发布到运行环境的过程。\n19.纠正性维护\\完善性维护\\适应性维护\\预防性维护\n纠正性维护：纠正性维护是指为修复和纠正软件中缺陷而开展的维护活动。\n\n改善性维护：改善型维护是指对软件进行改造以增加新的功能、修改已有的功能等维护活动。\n\n适应性维护：适应性维护是指为实用软件运行环境变化而对软件进行的维护活动。\n\n预防性维护：预防性维护是指对软件结构进行改造，一边提高软件的可靠性和可维护性而进行的维护活动。\n\n\n20.软件演化软件演化是指针对软件的大规模功能增强和结构调整，以实现变化的软件需求或者提高软件系统的质量。\n简答题1.什么是开源软件，和其他闭源软件相比，有什么优势和不足？开源软件是一种源代码可以自由获取和传播的计算机软件，其拥有者通过开源许可证赋予被许可人对软件进行使用、修改和传播的权利。开源软件采用群体化的思想和理念，代表了一种新的软件开发方法 。\n\n优势：\n\n采购和开发成本更低\n软件质量更高、更安全\n软件研制和交付更快\n软件功能更全面、更具创新性\n\n\n不足：\n\n安装开源软件有时需要更多的技术经验，比如要有配置或编译源代码的能力。\n开源软件许可协议一般会包含类似的规定，说明作者对用户使用该软件所产生的任何问题不承担责任。由开源软件引发的损失由谁负责是个问题。\n引入或使用开源软件，发现缺陷有谁来维护也是问题，特别是原作者已经不在维护了。\n\n\n\n2.什么是软件过程模型？请列举2个进行介绍它又称软件开发模型，是软件开发技术活动和管理活动的结构框架，刻画活动间的不同次序，反映对软件开发的理解和认识，展示软件开发理念和思想。\n\n瀑布模型：瀑布模型将软件开发过程分为若干步骤和活动，包括需求分析、软件设计、编码实现、软件测试和运行维护。这些步骤严格按照先后次序和逻辑关系来组织实施。需求分析活动完成之后产生了软件需求文档，才能开展软件设计，以此类推。每个阶段的末尾需要对该阶段产生的软件制品（文档、模型和代码等）进行评审，以发现和纠正软件制品中的问题和缺陷，防止有质批问题的软件制品进入下一步骤。评审通过后意味着该阶段的开发任务完成，随后就可以进入下一个阶段的工作 因此，在瀑布模型中上一步骤的输出是下一步骤的输入，下一步骤需等到前一步骤完成之后才能实施。整个软件开发过程的步骤和实施次序与软件生存周期相一致。软件开发过程中的活动被组织为线性形状，类似于瀑布，故而因此得名。\n\n增量模型：瀑布模型要等到软件开发后期才能给用户提供可运行的软件系统，这一点往往不利于用户使用。此外，滞后的软件交付和使用必然会导致软件缺陷和问题的滞后发现，加大软件开发的成本和工作队，影响软件质乱出现这一状况的根本原因在于，获取软件需求后瀑布模型要求一次性实现所有的软件需求，这势必会导致软件设计和实现的工作址大、开发周期长，使软件交付延后针对这一问题，增量模型对瀑布模型做了适当改进，它不再要求软件开发人员，一次性实现所有的软件需求，而是在软件需求和总体设计确定好之后，采用增扯开发的模式渐进式地实现软件系统的所有功能，从而确保软件开发人员可以尽早为用户提交可运行的软件系统。增乱模型的另一个显著优点是允许软件开发人员平行地开发软件、实现软件系统的各个独立模块，从而提高软件开发效率，加快交付目标软件系统的进度。\n\n增量模型：在软件需求和总体设计确定好之后，采用增量开发的模式渐进式地实现软件系统的所有功能，从而确保软件开发人员可以尽早为用户提交可运行的软件系统。\n\n原型模型：在软件开发早期(通常在需求分析阶段)根据用户的初步需求构建软件原型并将其交给用户使用，获得用户的评价和反馈，帮助用户导出软件需求、发现开发人员与用户之间的需求认识偏差，进而有效地支持软件需求分析。这一过程模型即为原型模型。\n\n\n3.什么是计算机辅助软件工程（CASE）,请举例说明典型的CASE工具（至少写出3个）计算机辅助软件工程(computer aided software engineering, CASE)是指借助计算机软件来辅助软件开发、运行、维护和管理的过程。用于支持计算机辅助软件工程的工具称为 CASE 工具。通常每个 CASE 工具提供一个相对独立的功能，辅助软件开发人员完成某项特定的工作。 \n\nSonarQube 就是一种 CASE 工具，它可辅助软件开发人员完成代码质量分析和评估工作。\nMicrosoft Office也可视为 CASE 工具，它可辅助软件开发人员撰写软件文档。\nEclipse 也是CASE工具，用于代码编写、程序编译、程序调试等等。\nGit也是CASE工具，用于项目管理，团队合作，软件版本管理。\n\n4.软件需求是什么？包含哪些具体内容？可以从软件本身和软件利益相关者两个不同的角度来理解软件需求 (software requirements) 。\n从软件本身的角度，软件需求是指软件用千解决现实世界问题时所表现出的功能和性能等要求；\n从软件利益相关者的角度，软件需求是指软件系统的利益相关者对软件系统的功能和质量，以及软件运行环境、交付进度等方面提出的期望和要求。\n《计算机科学技术名词》将软件需求定义为：为解决用户或客户的问题或实现其目标，软件系统必须具备的能力及必须满足的约束条件。本质上，软件需求刻画了软件系统能够做什么、应表现出怎样的行为、需满足哪些方面的条件和约束等要求。\n软件需求主要表现为三种形式：功能需求、软件质量需求和软件开发约束需求。后两种形式统称为非功能需求。\n\n软件的功能需求描述了软件能做什么、具有什么功能、可提供怎样的服务，刻画了软件在具体场景下所展现的行为及效果。软件的功能需求大多来自软件的用户、客户和开发者群体。 对于一些人机物共生系统而言，目标系统的某些功能需要通过软件加以实现，因而会对软件提出特定的功能要求。\n\n软件质量需求是指软件的利益相关者对软件应具有的质蜇属性所提出的具体要求。 软件的质量属性既包括内部质量属性，也包括外部质量属性。 通常而言，软件系统的客户、用户、开发者群体或者与软件发生交互的其他系统都会对软件的外部质量属性提出要求，如运行性能、可靠性 、易用性、安全性 、私密性、可用性、持续性、可信性等。 软件系统的开发者群体还会对软 件系统的内部质扯属性提出要求 ，如软件的可扩展性、 可维护性、可理解性、可重用性 、可移植性有效性等。\n\n软件开发约束需求是指软件的利益相关者对软件系统的开发成本、交付进度、技术选型、遵循标准等方面提出的要求。 站在客户或开发者的视角，软件开发是一项工程，需要投入资源和 成本，产品交付需要时间。 为了获益，他们会对软件产品的开发成本和进度提出明确要求。\n\n\n5.写出瀑布模型的特征和不足特征：\n\n接受上一阶段的结果作为本阶段的输入\n利用这一输入实施本阶段应完成的活动\n对本阶段的工作进行评审\n将本阶段的结果作为输出，传递给下一阶段\n\n缺点：\n\n缺乏灵活性，难以适应需求不明确或需求经常变化的软件开发\n开发早期存在的问题往往要到交付使用时才发现，维护代价大\n\n6.如何选择合适的过程模型在具体的软件开发实践中，软件开发人员和管理人员需根据各个软件过程模型的特点和适用场合，结合所开发软件项目的实际情况和具体要求，合理地选择或制定软件项目的过程模型。\n\n考虑软件项目的特点：考虑软件项目的特点，尤其是所开发软件的业务特点，如业务领域是否明确、软件需求是否易于确定、用户需求是否会经常变化等。\n考虑软件项目开发的风险：如果在软件项目实施之前就可以预估到该项目可能会面临多样化的软件风险，可以考虑采用螺旋模型等过程模型。\n考虑团队的经验和水平：需要结合软件开发团队的能力和水平来选择过程模型，以防开发团队和管理人员无法掌控和驾驭过程模型。\n\n7.写出需求工程的一般过程需求工程提供了一般性过程，以指导软件需求的获取、分析和文档化。 它包含了若干与需求工程密切相关的活动，明确了每项活动的具体任务以及不同活动间的关系，以帮助需求工程师等循序渐进地开展需求工程。\n\n获取软件需求：该活动的任务是要获得软件利益相关者对软件的期望和要求，进而获取初步软件需求。\n分析软件需求：该项工作的任务是要在初步软件需求的基础上，对软件需求进行稍化、建模和分析，获得软件需求在功能、行为、特征和约束等方面更为详细的信息，发现并解决软件需求中潜在的问题，产生准确、一致和完整的软件需求及其描述。\n文档化软件需求：该项活动的任务是要在获取和分析软件需求及其成果的基础上．撰写软件需求文档，产生软件需求规格说明书。\n确认和验证软件需求：该项活动的任务是要对前面工作所产生的软件需求模型和文档进行评审，让软件系统的利益相关者确认和验证软件需求，发现其中的问题和存在的缺陷，并加以解决和纠正 ， 确保经评审后的软件需求模型和文档符合利益相关者的诉求并满足质址要求。\n管理软件需求：由于软件需求工程贯穿于整个软件生存周期，软件需求会持续发生变化，并且需求变化会对软件开发和运维产生重要的影响，因此必须对软件需求变化以及相应的软件需求制品进行有效的管理，包括明确和验证软件需求变更、追踪需求变化、分析和评估需求变化所产生的影响、 对变化后的软件需求制品进行配置管理等。\n\n8.获取软件需求的方法有哪些，请列举2个进行介绍\n从软件系统的用户和客户处导出软件需求：在获取软件需求的过程中，如果在现实世界能够找到软件系统的潜在用户和实际客户，那么需求工程师可以通过与这些用户或客户进行交互，从他们那里导出软件系统的需求。 \n分解其他系统的需求产生软件需求：多软件系统并不是独立存在的，而是作为更大系统的一个组成部分，负责完成整个系统的部分需求。\n重用已有的系统的需求：当开发一个软件系统时，如果类似的软件产品已经存在，需求工程师可通过对已有软件产品的功能和特点进行分析形成待开发软件系统的需求。\n通过软件开发者构思和创作软件需求\n激励互联网开放群体贡献软件需求\n\n9.请简述软件设计的任务软件设计的任务是根据需求工程所定义的软件需求，包括功能需求、质量需求和开发约束需求，遵循软件设计的基本原则，定义构成软件系统的各个设计元素，提供可指导软件实现的解决方案，形成高质量的软件设计模型和文档。\n10.写出软件设计的一般过程在软件设计阶段，软件设计工程师需要基千软件需求模型，通过一系列软件设计活动，产生由各种设计元素所表述的软件设计模型，以此来指导程序员编写目标软件系统的代码。 为此，软件设计工程师需要在充分理解软件需求的基础上，有序地开展一系列软件设计工作，产生支持目标软件系统的设计模型和文档。\n\n体系结构性设计：软件设计首先需要回答软件系统应具有什么样的软件体系结构，也称为软件架构。 \n用户界面设计：用户界面设计就是要明确目标软件系统有哪些用户界面（如窗口和对话框等），这些界面之间的跳转关系（如在一个窗口点击确认后将弹出另一个窗口），每个界面内部的输入输出元素及其布局，包括输入框、按钮、文本显示框、菜单项等。 所有的界面设计元素可由设计类来表示。 \n详细设计：在上述两项软件设计的基础上，软件设计工程师须进一步细化软件设计，所谓的详细设计，顾名思义就是要给出软件系统更为具体的细节性设计，需要详细到足以支待程序员的编码实现。 包括了用例设计、子系统和构件设计、类设计、数据设计。\n文档化软件设计：软件设计工程师需在上述软件设计及其成果的基础上，按照软件设计规格说明书的规范和要求撰写软件设计文档，详细记录软件设计的具体信息，并以此作为与其他人员进行交流和评审的媒介。 \n软件设计评审：软件设计工程师需要组织多方人员一起对软件设计制品进行评审，验证软件设计是否实现 了软件需求，分析软件设计的质址，发现软件设计中存在的缺陷和问题，并与多方人员 一起协商加以解决。\n软件设计管理：由于软件设计在软件生存周期中会发生变化，并且设计变化会对软件的编码、测试和运维产生重要影响，因此必须对软件设计变化以及相应的软件设计制品进行有效的管理，包括追踪软件设计变化、分析和评估软件设计变化所产生的影响、对变化后的软件设计制品进行配置管理等。\n\n11.体系结构结构设计风格有哪些，请列举两个进行介绍\n管道&#x2F;过滤器风格：\n\n管道&#x2F;过滤器风格将软件系统的功能实现为一系列处理步骤，每个步骤完成特定的子功能冰凤凰装在一个成为“过滤器”的构建中。响铃过滤器之间以“管道”相连，也即连接件，前一个过滤器的输出数据通过管道流向最后一个过滤器。整个软件系统的输入由数据源提供，它通过管道与某个过滤器项链。软件系统的最终输出由源自某个过滤器的管道流向数据宿，也称数据汇。典型的数据源和数据汇包括数据库、数据文件、其他软件系统、物理设备（如智能手机等）。\n\n层次风格：\n\n层次风格将软件系统按照抽象级别划分为若干层次,每层由若干抽象级别相同的构件组成,因而整个软件体系结构呈现出层次化的形式(见图8.6)。每层构件仅为紧邻其上的抽象别更高的层次及其构件提供服务,并且它们仅使用紧邻下层及其构件提供的服务。一般而言，处于顶层的构件直接面向用户提供软件系统的交互界面,处于底层的构件则负责提供基础性、公共性的功能和服务。相邻层次间的构件连接通常采用以下两种方式:一种是高层构件向低层构件发出服务请求,低层构件在计算完成后向请求者发送服务应答;另一种是低层构件在主动探测或被动获知计算环境的变化后,以事件的形式通知高层构件。每个层次可以采用两种方式来向上层提供服务接口:一种是层次中每个提供服务的构件对外公开其接口;另一种是将服务接口封装于层次的内部,每个层次提供统一的服务接口。\n\nMvC风格：\n\nMVC风格将软件系统划分为三类主要的构件:模型(model)、视图(view)和控制器(controller)(见图8.7)。模型构件负责存储业务数据，提供业务逻辑处理功能；视图构件负责向用户展示模型结果；控制器构件在接收模型的业务逻辑处理结果后，负责选择适当的视图作为软件系统对用户的界面动作的响应，它实际上是模型和视图之间的连接桥梁。\n\n\n12.写出用户界面设计的一般过程\n13.编写程序代码时，标识符命名应该注意什么问题（至少写出5条）I. 名字应反映所代表的实体，具有一定实际意义\nII. 选择精炼的意义明确的名字\nIII. 不用关键字作标识符\nIV. 同一个名字不要有多个含义\nV. 避免使用容易混淆的字符 \n14.写出软件调试的步骤\n15.软件设计的原则有哪些？请列举2个进行介绍\n抽象和逐步求精原则：\n\n抽象是指在认识事物、分析和解决问题时，忽略那些与当前研究目标不相关的部分及要以便将注意力集中在与当前目标相关的方面。\n\n逐步求精是指在分析问题和解决问题过程中，先建立关于问题及其解的高层次抽象，然后以此为基础，通过精化获得更多的细节，建立问题和系统的低层次抽象。\n\n模块化与高内聚度、低耦合度原则：\n\n模块化是软件工程的一项基本原则，即在开发软件时将整个软件系统设计为一个个功能单一、接口明确、相对独立的模块单元，并通过这些模块之间的交互来实现软件系统的功能。\n\n内聚度是指模块内各成分间彼此结合的紧密程度，耦合度是指不同模块之间的相关程度。高内聚度、低耦合度的原则要求模块应该设计得每个模块内部内聚度要高，不同模块之间的耦合度要低。\n\n信息隐藏原则：\n\n该原则有助于设计出高质量的软件系统其优点具体表现为以下几个方面。\n\n它使模块的独立性更好，其内部尽可能少地受其他模块的影响。\n\n由于模块的独立性好，因而有助于模块的并行开发(设计和编码)，提高了软件开发的效率。\n\n由于模块内部的信息对外不可访问，因而它可以有效地减少错误向外传播，便于软件测试，提高软件系统的可维护性。\n\n便于软件系统增加新的功能，也即新功能的增加可以通过增加相关的模块来完成，而非对已有模块的修改。\n\n将模块内部的信息隐藏起来，可以防止对模块内部的不必要访问。一旦软件模块出现问题，可以方便地寻找错误原因和定位错误源头。\n\n实际上，现有的软件设计和程序设计技术均在不同程度上支持信息隐藏。\n\n多视点及关注点分离原则：\n\n一个软件系统的设计包含多个不同的方面，需要从不同的视点对它进行设计。\n\n当然，软件设计的不同视点有其各自的独立性和关注点，或者说不同视点所关心的问题以及欲达成的设计目标是不一样的，不可将它们混为一谈。\n\n软件重用原则：\n\n软件重用是软件工程的一项基本原则，它是指在软件开发过程中要尽可能地重用已有的软件资产来实现软件系统的功能，同时要确保所开发的软件系统易于为其他软件系统所重用。\n\n软件工程提供了诸多的****技术手段*来支持软件重用，如封装、继承、信息隐藏、多态等。软件重用的*形式*也从早期基于过程和函数的细粒度重用，逐步过渡到基于类、构件、服务和镜像的粗粒度重用，以及近年来出现的基于开源软件的更大粒度重用。*重用的内容*不仅表现为源代码和可执行程序代码，而且还可以重用*体系结构风格、软件设计模式、软件开发知识*等。软件重用不仅发生在*编码实现阶段*，而且在*需求分析、软件设计、软件测试阶段****也可以进行软件重用。\n\n迭代设计原则：\n\n根据前面的阐述，软件设计极为复杂，要考虑的问题和因素很多，期望通过一次性设计就达成相关的设计任务是不现实的。软件设计需要经过多次反复迭代才能完成。每次迭代都是在前一次迭代的基础上，对产生的设计模型进行反复权衡、折中、优化等工作，以得到更为合理、高效、高质量的软件设计成果。\n\n可追踪性原则：\n\n概括而言，软件设计的目的是为软件需求的实现提供解决方案。因此，任何软件设计活动以及由此而产生的设计结果都要服务于特定的软件需求。软件设计应能通过逆向追踪找到其对应的软件需求，或者软件需求可以通过正向追踪找到其对应的设计元素。\n\n权衡抉择原则：\n\n首先，选择什么样的技术来设计和开发软件，新技术也许会让软件产品及其开发具备一定的技术优势，但是也会由于缺乏足够的实践和检验、未能熟练地掌握等因素而带来相关的技术风险，旧技术虽然老旧，但是成熟，利用它们来开发软件相对而言风险较小。为此，设计工程师需要在新旧技术之间进行合理的权衡抉择。\n\n其次，在实现软件需求时，不同软件需求项之间可能存在“负相关”的关系，尤其对于质量需求而言体现得更加明显，也即当增强某些质量需求的同时可能会导致另一些质量需求的变弱。因此，设计工程师需要在不同的设计考虑、不同的设计方案之间进行权衠抉择，以得到符合其要求和关注点的合理设计。\n\n\n16.软件测试的V模型包括哪些步骤？说明这些步骤的测试对象是什么？\n\n单元测试：模块或构件\n集成测试：集成的软件系统\n确认测试：软件需求规约\n系统测试：基于计算机的系统\n测试对象：类方法、类对象、构建、子系统、整个软件系统\n\n17.请解释什么是改善性维护，并举例说明改善性维护是指对软件进行改造以增加新的功能、修改已有的功能等维护活动。例如，“12306”软件投入使用之后，用户希望该软件能够提供车票改签、退票等功能，为此软件维护团队需要基于这些新需求，对软件进行改善性维护。\n18.为提高程序的可理解性，有哪些主要的注意事项？请至少写出3条1）易读，一看就懂\n2）易改，便于维护\n3）降低代码复杂度\n4）尽可能开展软件重用和编写可重用的程序代码\n5）要能处理异常和提高代码的容错性\n6）代码要与模型和文档相一致\n7）格式化代码的布局。尽可能使其清晰、明了\n8）进可能提供简单的代码，不要人为地增加代码的复杂度\n9）对代码辅之以适当的文档，以加强程序的理解\n10）加强程序代码的结构化组织，提高代码的可读性\n19.什么是模块化？软件设计时，模块是否应该划分越多越好？为什么？模块化原则是指将软件系统的功能分解和实现为若干个模块，每个模块具有独立的功能，模块之间通过接口进行调用和访问。每个模块内部的要素(如语句、变量等)与模块的功能相关，且相互间关系密切，即模块内部高内聚；每个模块独立性强，模块间的关系松散，即模块间松耦合。\n不是模块分得越细越好、得到的模块个数越多越好。虽然单个模块的复杂性有所降低，但是模块个数多了，组装（或集成）模块得到整个软件的复杂性和代价会增加的。其实划分每个模块的大小和得到的模块个数实际上有个合理的范围，在这个范围内复杂性和代价相对比较合理。\n20.写出测试策略（测试的V模型）中的四种测试和它们的任务\n单元测试：程序单元的接口测试、局部数据的接口测试、执行路径的接口测试、错误处理路径测试。\n集成测试：自顶向下集成测试、自底向上集成测试。\n确认测试：针对整个软件系统进行确认测试，以测试目标软件系统是否满足软件需求文档所定义的各项软件需求。\n系统测试：一旦软件系统通过了确认测试之后，它还要与相关的其他系统进行集成，以进行系统测试，发现软件系统与其他系统交互过程中是否存在缺陷。\n\n","slug":"软基-复习材料","date":"2024-06-19T07:25:12.000Z","categories_index":"Study","tags_index":"学习,软件工程基础","author_index":"Fioransh"},{"id":"db54f8ebd79c49c03d8c8d5623b2689d","title":"基础-网络模型","content":"对于同一台设备上的进程间通信，有很多种方式，比如有管道、消息队列、共享内存、信号等方式，而对于不同设备上的进程间通信，就需要网络通信，而设备是多样性的，所以要兼容多种多样的设备，就协商出了一套通用的网络协议。\n这个网络协议是分层的，每一层都有各自的作用和职责，根据「 TCP&#x2F;IP 网络模型」分别对每一层进行介绍。\n1.应用层最上层的，也是我们能直接接触到的就是应用层（Application Layer），我们电脑或手机使用的应用软件都是在应用层实现。那么，当两个不同设备的应用需要通信的时候，应用就把应用数据传给下一层，也就是传输层。\n所以，应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP等。\n应用层是不用去关心数据是如何传输的，就类似于，我们寄快递的时候，只需要把包裹交给快递员，由他负责运输快递，我们不需要关心快递是如何被运输的。\n而且应用层是工作在操作系统中的用户态，传输层及以下则工作在内核态。\n2.传输层应用层的数据包会传给传输层，传输层（Transport Layer）是为应用层提供网络支持的。\n\n\n在传输层会有两个传输协议，分别是 TCP 和 UDP。\nTCP 的全称叫传输控制协议（Transmission Control Protocol），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。\nUDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP 传输协议，也不是一件简单的事情。\n应用需要传输的数据可能会非常大，如果直接传输就不好控制，因此当传输层的数据包大小超过 MSS（TCP 最大报文段长度） ，就要将数据包分块，这样即使中途有一个分块丢失或损坏了，只需要重新发送这一个分块，而不用重新发送整个数据包。在 TCP 协议中，我们把每个分块称为一个 TCP 段（TCP Segment）。\n\n\n当设备作为接收方时，传输层则要负责把数据包传给应用，但是一台设备上可能会有很多应用在接收或者传输数据，因此需要用一个编号将应用区分开来，这个编号就是端口。\n比如 80 端口通常是 Web 服务器用的，22 端口通常是远程登录服务器用的。而对于浏览器（客户端）中的每个标签栏都是一个独立的进程，操作系统会为这些进程分配临时的端口号。\n由于传输层的报文中会携带端口号，因此接收方可以识别出该报文是发送给哪个应用。\n3.网络层传输层可能大家刚接触的时候，会认为它负责将数据从一个设备传输到另一个设备，事实上它并不负责。\n实际场景中的网络环节是错综复杂的，中间有各种各样的线路和分叉路口，如果一个设备的数据要传输给另一个设备，就需要在各种各样的路径和节点进行选择，而传输层的设计理念是简单、高效、专注，如果传输层还负责这一块功能就有点违背设计原则了。\n也就是说，我们不希望传输层协议处理太多的事情，只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是网络层（Internet Layer）。\n\n网络层最常使用的是 IP 协议（Internet Protocol），IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会再次进行分片，得到一个即将发送到网络的 IP 报文。\n\n网络层负责将数据从一个设备传输到另一个设备，世界上那么多设备，又该如何找到对方呢？因此，网络层需要有区分设备的编号。\n我们一般用 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段（比如，192.168.100.1），每段是 8 位。只有一个单纯的 IP 地址虽然做到了区分设备，但是寻址起来就特别麻烦，全世界那么多台设备，难道一个一个去匹配？这显然不科学。\n因此，需要将 IP 地址分成两种意义：\n\n一个是网络号，负责标识该 IP 地址是属于哪个「子网」的；\n一个是主机号，负责标识同一「子网」下的不同主机；\n\n怎么分的呢？这需要配合子网掩码才能算出 IP 地址 的网络号和主机号。\n举个例子，比如 10.100.122.0&#x2F;24，后面的/24表示就是 255.255.255.0 子网掩码，255.255.255.0 二进制是「11111111-11111111-11111111-00000000」，大家数数一共多少个1？不用数了，是 24 个1，为了简化子网掩码的表示，用&#x2F;24代替255.255.255.0。\n知道了子网掩码，该怎么计算出网络地址和主机地址呢？\n将 10.100.122.2 和 255.255.255.0 进行按位与运算，就可以得到网络号，如下图：\n\n将 255.255.255.0 取反后与IP地址进行进行按位与运算，就可以得到主机号。\n大家可以去搜索下子网掩码计算器，自己改变下「掩码位」的数值，就能体会到子网掩码的作用了。\n\n那么在寻址的过程中，先匹配到相同的网络号（表示要找到同一个子网），才会去找对应的主机。\n除了寻址能力， IP 协议还有另一个重要的能力就是路由。实际场景中，两台设备并不是用一条网线连接起来的，而是通过很多网关、路由器、交换机等众多网络设备连接起来的，那么就会形成很多条网络的路径，因此当数据包到达一个网络节点，就需要通过路由算法决定下一步走哪条路径。\n路由器寻址工作中，就是要找到目标地址的子网，找到后进而把数据包转发给对应的网络内。\n\n所以，IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘。\n4.网络接口层生成了 IP 头部之后，接下来要交给网络接口层（Link Layer）在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。\n\nIP 头部中的接收方 IP 地址表示网络包的目的地，通过这个地址我们就可以判断要将包发到哪里，但在以太网的世界中，这个思路是行不通的。\n什么是以太网呢？电脑上的以太网接口，Wi-Fi接口，以太网交换机、路由器上的千兆，万兆以太网口，还有网线，它们都是以太网的组成部分。以太网就是一种在「局域网」内，把附近的设备连接起来，使它们之间可以进行通讯的技术。\n以太网在判断网络包目的地时和 IP 的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而 MAC 头部就是干这个用的，所以，在以太网进行通讯要用到 MAC 地址。\nMAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。\n所以说，网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。\n5.总结综上所述，TCP&#x2F;IP 网络通常是由上到下分成 4 层，分别是应用层，传输层，网络层和网络接口层。\n\n每一层的封装格式：\n\n网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包。\n","slug":"基础-网络模型","date":"2024-06-10T07:25:12.000Z","categories_index":"Study","tags_index":"学习,计算机网络","author_index":"Fioransh"},{"id":"193fbfa2337e88e92d38c2ae6126c3d1","title":"OS-进程线程基础知识","content":"1.进程执行文件后将其装载到内存中，通过CPU执行程序中的每一条指令，那么这个运行中的程序，就被称为「进程」（Process）\n当进程要从硬盘读取数据时，CPU 不需要阻塞等待数据的返回，而是去执行另外的进程。当硬盘数据返回时，CPU 会收到个中断，于是 CPU 再继续运行这个进程。\n这种多个程序、交替执行的思想，就有 CPU 管理多个进程的初步想法。\n在 1 秒钟期间，它可能会运行多个进程，这样就产生并行的错觉，实际上这是并发。\n1.1 并发和并行的区别\n\n\n\n1.2 进程与程序的关系\nCPU 可以从一个进程（做菜）切换到另外一个进程（买可乐），在切换前必须要记录当前进程中运行的状态信息，以备下次切换回来的时候可以恢复执行。\n进程有着「运行 - 暂停 - 运行」的活动规律。\n1.3 进程的状态在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。\n\n运行状态（Running）：该时刻进程占用 CPU；\n就绪状态（Ready）：可运行，由于其他进程处于运行状态而暂时停止运行；\n阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待输入&#x2F;输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；\n\n当然，进程还有另外两个基本状态：\n\n创建状态（new）：进程正在被创建时的状态；\n结束状态（Exit）：进程正在从系统中消失时的状态；\n\n\n\n进程的状态变迁：\n\nNULL -&gt; 创建状态：一个新进程被创建时的第一个状态；\n创建状态 -&gt; 就绪状态：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；\n就绪态 -&gt; 运行状态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；\n运行状态 -&gt; 结束状态：当进程已经运行完成或出错时，会被操作系统作结束状态处理；\n运行状态 -&gt; 就绪状态：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；\n运行状态 -&gt; 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I&#x2F;O 事件；\n阻塞状态 -&gt; 就绪状态：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；\n\n在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。\n那么，就需要一个新的状态，来描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。\n另外，挂起状态可以分为两种：\n\n阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；\n就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；\n\n\n\n导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：\n\n通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。\n用户希望挂起一个程序的执行，比如在 Linux 中用 Ctrl+Z 挂起进程；\n\n1.4 进程的控制结构在操作系统中，是用进程控制块（process control block，PCB）数据结构来描述进程的。\nPCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。\n1.4.1 PCB包含的信息进程描述信息：\n\n进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；\n用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；\n\n进程控制和管理信息：\n\n进程当前状态，如 new、ready、running、waiting 或 blocked 等；\n进程优先级：进程抢占 CPU 时的优先级；\n\n资源分配清单：\n\n有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I&#x2F;O 设备信息。\n\nCPU 相关信息：\n\nCPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。\n\n1.4.2 PCB如何组织通常是通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。比如：\n\n将所有处于就绪状态的进程链在一起，称为就绪队列；\n把所有因等待某事件而处于等待状态的进程链在一起就组成各种阻塞队列；\n另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。\n\n除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。\n1.5 进程的控制进程的创建、终止、阻塞、唤醒的过程，这些过程也就是进程的控制。\n01 创建进程\n操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。\n创建进程的过程如下：\n\n申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；\n为该进程分配运行时所必需的资源，比如内存资源；\n将 PCB 插入到就绪队列，等待被调度运行；\n\n02 终止进程\n进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。\n当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。\n终止进程的过程如下：\n\n查找需要终止的进程的 PCB；\n如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；\n如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；\n将该进程所拥有的全部资源都归还给操作系统；\n将其从 PCB 所在队列中删除；\n\n03 阻塞进程\n当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。\n阻塞进程的过程如下：\n\n找到将要被阻塞进程标识号对应的 PCB；\n如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；\n将该 PCB 插入到阻塞队列中去；\n\n04 唤醒进程\n进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。\n如果某进程正在等待 I&#x2F;O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。\n唤醒进程的过程如下：\n\n在该事件的阻塞队列中找到相应进程的 PCB；\n将其从阻塞队列中移出，并置其状态为就绪状态；\n把该 PCB 插入到就绪队列中，等待调度程序调度；\n\n进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。\n1.6 进程的上下文切换各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个一个进程切换到另一个进程运行，称为进程的上下文切换。\n1.6.1 CPU上下文切换操作系统需要事先帮 CPU 设置好 CPU 寄存器和程序计数器。\nCPU 寄存器是 CPU 内部一个容量小，但是速度极快的内存（缓存）。程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。\nCPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 CPU 上下文。\nCPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。\n系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。\n上面说到所谓的「任务」，主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下文切换分成：进程上下文切换、线程上下文切换和中断上下文切换。\n1.6.2 进程上下文切换进程是由内核管理和调度的，所以进程的切换只能发生在内核态。\n进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。\n会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行\n1.6.3 发生场景\n为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；\n进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；\n当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；\n当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；\n发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；\n\n2.线程在早期的操作系统中都是以进程作为独立运行的基本单位，直到后面，计算机科学家们又提出了更小的能独立运行的基本单位，也就是线程。\n2.1 什么是线程**线程( *Thread* )**，线程之间可以并发运行且共享相同的地址空间。\n线程是进程当中的一条执行流程。\n同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。\n线程的优缺点：\n\n线程的优点：\n一个进程中可以同时存在多个线程；\n各个线程之间可以并发执行；\n各个线程之间可以共享地址空间和文件等资源；\n\n\n线程的缺点：\n当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃（这里是针对 C&#x2F;C++ 语言，Java语言中的线程奔溃不会造成进程崩溃\n\n\n\n2.2 线程与进程的比较线程与进程的比较如下：\n\n进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；\n进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；\n线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；\n线程能减少并发执行的时间和空间开销；\n\n对于，线程相比进程能减少开销，体现在：\n\n线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；\n线程的终止时间比进程快，因为线程释放的资源相比进程少很多；\n同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；\n由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；\n\n不管是时间效率，还是空间效率线程比进程都要高。\n2.3 线程的上下文切换线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。\n操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。\n\n当进程只有一个线程时，可以认为进程就等于线程；\n当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；\n\n另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。\n\n当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；\n当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；\n\n2.4 线程的实现主要有三种线程的实现方式：\n\n用户线程（*User Thread*）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；\n内核线程（*Kernel Thread*）：在内核中实现的线程，是由内核管理的线程；\n轻量级进程（*LightWeight Process*）：在内核中来支持用户线程；\n\n用户线程和内核线程对应关系：多对一、一对一、一对多\n2.4.1 用户线程概念以及优势缺陷用户线程是基于用户态的线程管理库来实现的，那么线程控制块（*Thread Control Block, TCB*） 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。\n用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。\n类似多对一关系：\n\n\n用户线程的优点：\n\n每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；\n用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；\n\n用户线程的缺点：\n\n由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。\n当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。\n由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢；\n\n2.4.2 内核线程概念以及优势缺陷内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。\n类似一对一关系：\n\n\n内核线程的优点：\n\n在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；\n分配给线程，多线程的进程获得更多的 CPU 运行时间；\n\n内核线程的缺点：\n\n在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；\n线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大；\n\n2.4.3 轻量级进程轻量级进程（*Light-weight process，LWP*）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。\n在大多数系统中，LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。\n在 LWP 之上也是可以使用用户线程的，那么 LWP 与用户线程的对应关系就有三种：\n\n1 : 1，即一个 LWP 对应 一个用户线程；\nN : 1，即一个 LWP 对应多个用户线程；\nM : N，即多个 LWP 对应多个用户线程；\n\n\n\n1 : 1 模式\n一个线程对应到一个 LWP 再对应到一个内核线程，如上图的进程 4，属于此模型。\n\n优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP；\n缺点：每一个用户线程，就产生一个内核线程，创建线程的开销较大。\n\nN : 1 模式\n多个用户线程对应一个 LWP 再对应一个内核线程，如上图的进程 2，线程管理是在用户空间完成的，此模式中用户的线程对操作系统不可见。\n\n优点：用户线程要开几个都没问题，且上下文切换发生用户空间，切换的效率较高；\n缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，是没办法充分利用 CPU 的。\n\nM : N 模式\n根据前面的两个模型混搭一起，就形成 M:N 模型，该模型提供了两级控制，首先多个用户线程对应到多个 LWP，LWP 再一一对应到内核线程，如上图的进程 3。\n\n优点：综合了前两种优点，大部分的线程上下文发生在用户空间，且多个线程又可以充分利用多核 CPU 的资源。\n\n组合模式\n如上图的进程 5，此进程结合 1:1 模型和 M:N 模型。开发人员可以针对不同的应用特点调节内核线程的数目来达到物理并行性和逻辑并行性的最佳方案。\n3.调度选择一个进程运行这一功能是在操作系统中完成的，通常称为调度程序（scheduler）。\n3.1 调度时机在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。\n比如，以下状态的变化都会触发操作系统的调度：\n\n从就绪态 -&gt; 运行态：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行；\n从运行态 -&gt; 阻塞态：当进程发生 I&#x2F;O 事件而阻塞时，操作系统必须选择另外一个进程运行；\n从运行态 -&gt; 结束态：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；\n\n这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运行，或者是否让当前进程从 CPU 上退出来而换另一个进程运行。\n如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：\n\n非抢占式调度算法挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。\n抢占式调度算法挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把 CPU 控制返回给调度程序进行调度，也就是常说的时间片机制。\n\n3.2 调度原则原则一：如果运行的程序，发生了 I&#x2F;O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回。这样的过程，势必会造成 CPU 突然的空闲。所以，为了提高 CPU 利用率，在这种发送 I&#x2F;O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。\n原则二：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以，要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。\n原则三：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越小越好，如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发生。\n原则四：处于就绪队列的进程，也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行。所以，就绪队列中进程的等待时间也是调度程序所需要考虑的原则。\n原则五：对于鼠标、键盘这种交互式比较强的应用，我们当然希望它的响应时间越快越好，否则就会影响用户体验了。所以，对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则。\n针对上面的五种调度原则，总结成如下：\n\nCPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；\n系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；\n周转时间：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；\n等待时间：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；\n响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。\n\n3.3 调度算法先来先服务FCFS、最短作业优先SJF、高响应比优先HRRN、时间片轮转RR、最高优先级调度HPF、多级反馈队列调度。具体详看另文。\n4.一个进程最多可以创建多少线程这个问题跟两个东西有关系：\n\n进程的虚拟内存空间上限，因为创建一个线程，操作系统需要为其分配一个栈空间，如果线程数量越多，所需的栈空间就要越大，那么虚拟内存就会占用的越多。\n系统参数限制，虽然 Linux 并没有内核参数来控制单个进程创建的最大线程个数，但是有系统级别的参数来控制整个系统的最大线程个数。\n\n区别于不同系统：\n\n32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。\n64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。\n\n5.线程崩溃了进程会崩溃吗为什么 C&#x2F;C++ 语言里，线程崩溃后，进程也会崩溃，而 Java 语言里却不会呢？\n5.1 线程崩溃进程一定崩溃吗一般来说如果线程是因为非法访问内存引起的崩溃，那么进程肯定会崩溃，为什么系统要让进程崩溃呢，这主要是因为在进程中，各个线程的地址空间是共享的，既然是共享，那么某个线程对地址的非法访问就会导致内存的不确定性，进而可能会影响到其他线程，这种操作是危险的，操作系统会认为这很可能导致一系列严重的后果，于是干脆让整个进程崩溃\n线程共享代码段，数据段，地址空间，文件非法访问内存有以下几种情况，我们以 C 语言举例来看看。\n1.、针对只读内存写入数据\nc   #include &lt;stdio.h&gt;\n   #include &lt;stdlib.h&gt;\n   \n   int main() &#123;\n      char *s = &quot;hello world&quot;;\n      // 向只读内存写入数据，崩溃\n      s[1] = &#39;H&#39;; \n   &#125;2、访问了进程没有权限访问的地址空间（比如内核空间）\nc   #include &lt;stdio.h&gt;\n   #include &lt;stdlib.h&gt;\n\n   int main() &#123;\n      int *p = (int *)0xC0000fff;\n      // 针对进程的内核空间写入数据，崩溃\n      *p = 10; \n   &#125;在 32 位虚拟地址空间中，p 指向的是内核空间，显然不具有写入权限，所以上述赋值操作会导致崩溃\n3、访问了不存在的内存，比如：\nc   #include &lt;stdio.h&gt;\n   #include &lt;stdlib.h&gt;\n   \n   int main() &#123;\n      int *a = NULL;\n      *a = 1;     \n   &#125;以上错误都是访问内存时的错误，所以统一会报 Segment Fault 错误（即段错误），这些都会导致进程崩溃\n5.2 进程是如何崩溃的那么线程崩溃后，进程是如何崩溃的呢，这背后的机制到底是怎样的，答案是信号。\n大家想想要干掉一个正在运行的进程是不是经常用 kill -9 pid 这样的命令，这里的 kill 其实就是给指定 pid 发送终止信号的意思，其中的 9 就是信号。\n当然了发 kill 信号必须具有一定的权限，否则任意进程都可以通过发信号来终止其他进程，那显然是不合理的，实际上 kill 执行的是系统调用，将控制权转移给了内核（操作系统），由内核来给指定的进程发送信号\n那么发个信号进程怎么就崩溃了呢，这背后的原理到底是怎样的？\n其背后的机制如下\n\nCPU 执行正常的进程指令\n调用 kill 系统调用向进程发送信号\n进程收到操作系统发的信号，CPU 暂停当前程序运行，并将控制权转交给操作系统\n调用 kill 系统调用向进程发送信号（假设为 11，即 SIGSEGV，一般非法访问内存报的都是这个错误）\n操作系统根据情况执行相应的信号处理程序（函数），一般执行完信号处理程序逻辑后会让进程退出\n\n5.3 为什么线程崩溃不会导致JVM进程崩溃在 Java 中有哪些是常见的由于非法访问内存而产生的 Exception 或 error 呢，常见的是大家熟悉的 StackoverflowError 或者 NPE（NullPointerException）,NPE 我们都了解，属于是访问了不存在的内存。\n但为什么栈溢出（Stackoverflow）也属于非法访问内存呢，这得简单聊一下进程的虚拟空间，也就是前面提到的共享地址空间。\n现代操作系统为了保护进程之间不受影响，所以使用了虚拟地址空间来隔离进程，进程的寻址都是针对虚拟地址，每个进程的虚拟空间都是一样的，而线程会共用进程的地址空间。\n进程每调用一个函数，都会分配一个栈桢，然后在栈桢里会分配函数里定义的各种局部变量。\n假设现在调用了一个无限递归的函数，那就会持续分配栈帧，但 stack 的大小是有限的（Linux 中默认为 8 M，可以通过 ulimit -a 查看），如果无限递归很快栈就会分配完了，此时再调用函数试图分配超出栈的大小内存，就会发生段错误，也就是 stackoverflowError。\nJVM 为什么不会崩溃呢？其实就是因为 JVM 自定义了自己的信号处理函数，拦截了 SIGSEGV 信号，针对这两者不让它们崩溃。\n5.4 总结为什么发生了 StackoverflowError 和 NPE 这两个非法访问内存的错误，JVM 却没有崩溃。\n原因其实就是虚拟机内部定义了信号处理函数，而在信号处理函数中对这两者做了额外的处理以让 JVM 不崩溃，另一方面也可以看出如果 JVM 不对信号做额外的处理，最后会自己退出并产生 crash 文件 hs_err_pid_xxx.log（可以通过 -XX:ErrorFile&#x3D;&#x2F;var&#x2F;*log*&#x2F;hs_err.log 这样的方式指定），这个文件记录了虚拟机崩溃的重要原因。\n所以也可以说，虚拟机是否崩溃只要看它是否会产生此崩溃日志文件\n正常情况下，操作系统为了保证系统安全，所以针对非法内存访问会发送一个 SIGSEGV 信号，而操作系统一般会调用默认的信号处理函数（一般会让相关的进程崩溃）。\n但如果进程觉得”罪不致死”，那么它也可以选择自定义一个信号处理函数，这样的话它就可以做一些自定义的逻辑，比如记录 crash 信息等有意义的事。\n回过头来看为什么虚拟机会针对 StackoverflowError 和 NullPointerException 做额外处理让线程恢复呢，针对 stackoverflow 其实它采用了一种栈回溯的方法保证线程可以一直执行下去，而捕获空指针错误主要是这个错误实在太普遍了。\n为了这一个很常见的错误而让 JVM 崩溃那线上的 JVM 要宕机多少次，所以出于工程健壮性的考虑，与其直接让 JVM 崩溃倒不如让线程起死回生，并且将这两个错误&#x2F;异常抛给用户来处理。\n","slug":"OS-进程线程基础知识","date":"2024-06-09T08:44:12.000Z","categories_index":"Study","tags_index":"学习,操作系统","author_index":"Fioransh"},{"id":"89874e71a8d4fa3b3317f544a3a17f4e","title":"OS-死锁","content":"1.死锁的概念在多线程编程中，我们为了防止多线程竞争共享资源而导致数据错乱，都会在操作共享资源之前加上互斥锁，只有成功获得到锁的线程，才能操作共享资源，获取不到锁的线程就只能等待，直到锁被释放。\n那么，当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成两个线程都在等待对方释放锁，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了死锁。\n死锁只有同时满足以下四个条件才会发生：\n\n互斥条件；\n持有并等待条件；\n不可剥夺条件；\n环路等待条件；\n\n1.1 互斥条件互斥条件是指多个线程不能同时使用同一个资源。\n如果线程 A 已经持有的资源，不能再同时被线程 B 持有，如果线程 B 请求获取线程 A 已经占用的资源，那线程 B 只能等待，直到线程 A 释放了资源。\n1.2 持有并等待条件持有并等待条件是指，当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1。\n1.3 不可剥夺条件不可剥夺条件是指，当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。\n1.4 环路等待条件环路等待条件指的是，在死锁发生的时候，两个线程获取资源的顺序构成了环形链。\n比如，线程 A 已经持有资源 2，而想请求资源 1， 线程 B 已经获取了资源 1，而想请求资源 2，这就形成资源请求等待的环形图。\n2.模拟死锁问题的产生我们用代码来模拟死锁问题的产生。\n首先，我们先创建 2 个线程，分别为线程 A 和 线程 B，然后有两个互斥锁，分别是 mutex_A 和 mutex_B，代码如下：\ncpthread_mutex_t mutex_A = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex_B = PTHREAD_MUTEX_INITIALIZER;\n\nint main()\n&#123;\n    pthread_t tidA, tidB;\n    \n    //创建两个线程\n    pthread_create(&amp;tidA, NULL, threadA_proc, NULL);\n    pthread_create(&amp;tidB, NULL, threadB_proc, NULL);\n    \n    pthread_join(tidA, NULL);\n    pthread_join(tidB, NULL);\n    \n    printf(&quot;exit\\n&quot;);\n    \n    return 0;\n&#125;接下来，我们看下线程 A 函数做了什么。\nc//线程函数 A\nvoid *threadA_proc(void *data)\n&#123;\n    printf(&quot;thread A waiting get ResourceA \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_A);\n    printf(&quot;thread A got ResourceA \\n&quot;);\n    \n    sleep(1);\n    \n    printf(&quot;thread A waiting get ResourceB \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_B);\n    printf(&quot;thread A got ResourceB \\n&quot;);\n\n    pthread_mutex_unlock(&amp;mutex_B);\n    pthread_mutex_unlock(&amp;mutex_A);\n    return (void *)0;\n&#125;可以看到，线程 A 函数的过程：\n\n先获取互斥锁 A，然后睡眠 1 秒；\n再获取互斥锁 B，然后释放互斥锁 B；\n最后释放互斥锁 A；\n\nc//线程函数 B\nvoid *threadB_proc(void *data)\n&#123;\n    printf(&quot;thread B waiting get ResourceB \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_B);\n    printf(&quot;thread B got ResourceB \\n&quot;);\n    \n    sleep(1);\n    \n    printf(&quot;thread B waiting  get ResourceA \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_A);\n    printf(&quot;thread B got ResourceA \\n&quot;);\n    \n    pthread_mutex_unlock(&amp;mutex_A);\n    pthread_mutex_unlock(&amp;mutex_B);\n    return (void *)0;\n&#125;可以看到，线程 B 函数的过程：\n\n先获取互斥锁 B，然后睡眠 1 秒；\n再获取互斥锁 A，然后释放互斥锁 A；\n最后释放互斥锁 B；\n\n然后，我们运行这个程序，运行结果如下：\nshellthread B waiting get ResourceB \nthread B got ResourceB \nthread A waiting get ResourceA \nthread A got ResourceA \nthread B waiting get ResourceA \nthread A waiting get ResourceB \n// 阻塞中。。。可以看到线程 B 在等待互斥锁 A 的释放，线程 A 在等待互斥锁 B 的释放，双方都在等待对方资源的释放，很明显，产生了死锁问题。\n3.利用工具排查死锁问题如果你想排查你的 Java 程序是否死锁，则可以使用 jstack 工具，它是 jdk 自带的线程堆栈分析工具。\n死锁代码例子是 C 写的，在 Linux 下，我们可以使用 pstack + gdb 工具来定位死锁问题。\npstack 命令可以显示每个线程的栈跟踪信息（函数调用过程），它的使用方式也很简单，只需要 pstack &lt;pid&gt; 就可以了。\n那么，在定位死锁问题时，我们可以多次执行 pstack 命令查看线程的函数调用过程，多次对比结果，确认哪几个线程一直没有变化，且是因为在等待锁，那么大概率是由于死锁问题导致的。\n我用 pstack 输出了我前面模拟死锁问题的进程的所有线程的情况，我多次执行命令后，其结果都一样，如下：\nshell$ pstack 87746\nThread 3 (Thread 0x7f60a610a700 (LWP 87747)):\n#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0\n#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0\n#3  0x0000000000400725 in threadA_proc ()\n#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0\n#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6\nThread 2 (Thread 0x7f60a5709700 (LWP 87748)):\n#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0\n#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0\n#3  0x0000000000400792 in threadB_proc ()\n#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0\n#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6\nThread 1 (Thread 0x7f60a610c700 (LWP 87746)):\n#0  0x0000003720e080e5 in pthread_join () from /lib64/libpthread.so.0\n#1  0x0000000000400806 in main ()\n\n....\n\n$ pstack 87746\nThread 3 (Thread 0x7f60a610a700 (LWP 87747)):\n#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0\n#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0\n#3  0x0000000000400725 in threadA_proc ()\n#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0\n#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6\nThread 2 (Thread 0x7f60a5709700 (LWP 87748)):\n#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0\n#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0\n#3  0x0000000000400792 in threadB_proc ()\n#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0\n#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6\nThread 1 (Thread 0x7f60a610c700 (LWP 87746)):\n#0  0x0000003720e080e5 in pthread_join () from /lib64/libpthread.so.0\n#1  0x0000000000400806 in main ()可以看到，Thread 2 和 Thread 3 一直阻塞获取锁（pthread_mutex_lock）的过程，而且 pstack 多次输出信息都没有变化，那么可能大概率发生了死锁。\n但是，还不能够确认这两个线程是在互相等待对方的锁的释放，因为我们看不到它们是等在哪个锁对象，于是我们可以使用 gdb 工具进一步确认。\n整个 gdb 调试过程，如下：\nshell// gdb 命令\n$ gdb -p 87746\n\n// 打印所有的线程信息\n(gdb) info thread\n  3 Thread 0x7f60a610a700 (LWP 87747)  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n  2 Thread 0x7f60a5709700 (LWP 87748)  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n* 1 Thread 0x7f60a610c700 (LWP 87746)  0x0000003720e080e5 in pthread_join () from /lib64/libpthread.so.0\n//最左边的 * 表示 gdb 锁定的线程，切换到第二个线程去查看\n\n// 切换到第2个线程\n(gdb) thread 2\n[Switching to thread 2 (Thread 0x7f60a5709700 (LWP 87748))]#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0 \n\n// bt 可以打印函数堆栈，却无法看到函数参数，跟 pstack 命令一样 \n(gdb) bt\n#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0\n#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0\n#3  0x0000000000400792 in threadB_proc (data=0x0) at dead_lock.c:25\n#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0\n#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6\n\n// 打印第三帧信息，每次函数调用都会有压栈的过程，而 frame 则记录栈中的帧信息\n(gdb) frame 3\n#3  0x0000000000400792 in threadB_proc (data=0x0) at dead_lock.c:25\n27    printf(&quot;thread B waiting get ResourceA \\n&quot;);\n28    pthread_mutex_lock(&amp;mutex_A);\n\n// 打印mutex_A的值 ,  __owner表示gdb中标示线程的值，即LWP\n(gdb) p mutex_A\n$1 = &#123;__data = &#123;__lock = 2, __count = 0, __owner = 87747, __nusers = 1, __kind = 0, __spins = 0, __list = &#123;__prev = 0x0, __next = 0x0&#125;&#125;, \n  __size = &quot;\\002\\000\\000\\000\\000\\000\\000\\000\\303V\\001\\000\\001&quot;, &#39;\\000&#39; &lt;repeats 26 times&gt;, __align = 2&#125;\n\n// 打印mutex_B的值 ,  __owner表示gdb中标示线程的值，即LWP\n(gdb) p mutex_B\n$2 = &#123;__data = &#123;__lock = 2, __count = 0, __owner = 87748, __nusers = 1, __kind = 0, __spins = 0, __list = &#123;__prev = 0x0, __next = 0x0&#125;&#125;, \n  __size = &quot;\\002\\000\\000\\000\\000\\000\\000\\000\\304V\\001\\000\\001&quot;, &#39;\\000&#39; &lt;repeats 26 times&gt;, __align = 2&#125;  我来解释下，上面的调试过程：\n\n通过 info thread 打印了所有的线程信息，可以看到有 3 个线程，一个是主线程（LWP 87746），另外两个都是我们自己创建的线程（LWP 87747 和 87748）；\n通过 thread 2，将切换到第 2 个线程（LWP 87748）；\n通过 bt，打印线程的调用栈信息，可以看到有 threadB_proc 函数，说明这个是线程 B 函数，也就说 LWP 87748 是线程 B;\n通过 frame 3，打印调用栈中的第三个帧的信息，可以看到线程 B 函数，在获取互斥锁 A 的时候阻塞了；\n通过 p mutex_A，打印互斥锁 A 对象信息，可以看到它被 LWP 为 87747（线程 A） 的线程持有着；\n通过 p mutex_B，打印互斥锁 B 对象信息，可以看到他被 LWP 为 87748 （线程 B） 的线程持有着；\n\n因为线程 B 在等待线程 A 所持有的 mutex_A, 而同时线程 A 又在等待线程 B 所拥有的mutex_B, 所以可以断定该程序发生了死锁。\n4.避免死锁问题的发生前面我们提到，产生死锁的四个必要条件是：互斥条件、持有并等待条件、不可剥夺条件、环路等待条件。\n那么避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是使用资源有序分配法，来破环环路等待条件。\n那什么是资源有序分配法呢？\n线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。也就是说，线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。\n我们使用资源有序分配法的方式来修改前面发生死锁的代码，我们可以不改动线程 A 的代码。\n我们先要清楚线程 A 获取资源的顺序，它是先获取互斥锁 A，然后获取互斥锁 B。\n所以我们只需将线程 B 改成以相同顺序的获取资源，就可以打破死锁了。\n线程 B 函数改进后的代码如下：\nc//线程 B 函数，同线程 A 一样，先获取互斥锁 A，然后获取互斥锁 B\nvoid *threadB_proc(void *data)\n&#123;\n    printf(&quot;thread B waiting get ResourceA \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_A);\n    printf(&quot;thread B got ResourceA \\n&quot;);\n    \n    sleep(1);\n    \n    printf(&quot;thread B waiting  get ResourceB \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_B);\n    printf(&quot;thread B got ResourceB \\n&quot;);\n    \n    pthread_mutex_unlock(&amp;mutex_B);\n    pthread_mutex_unlock(&amp;mutex_A);\n    return (void *)0;\n&#125;执行结果如下，可以看，没有发生死锁。\nshellthread B waiting get ResourceA \nthread B got ResourceA \nthread A waiting get ResourceA \nthread B waiting  get ResourceB \nthread B got ResourceB \nthread A got ResourceA \nthread A waiting get ResourceB \nthread A got ResourceB\nexit简单来说，死锁问题的产生是由两个或者以上线程并行执行的时候，争夺资源而互相等待造成的。\n死锁只有同时满足互斥、持有并等待、不可剥夺、环路等待这四个条件的时候才会发生。\n所以要避免死锁问题，就是要破坏其中一个条件即可，最常用的方法就是使用资源有序分配法来破坏环路等待条件。\n5.互斥锁与自选锁多线程访问共享资源的时候，避免不了资源竞争而导致数据错乱的问题，所以我们通常为了解决这一问题，都会在访问共享资源之前加锁。为了选择合适的锁，我们不仅需要清楚知道加锁的成本开销有多大，还需要分析业务场景中访问的共享资源的方式，再来还要考虑并发访问共享资源时的冲突概率。\n最底层的两种就是会「互斥锁和自旋锁」，有很多高级的锁都是基于它们实现的，你可以认为它们是各种锁的地基，所以我们必须清楚它俩之间的区别和应用。\n加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。\n当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：\n\n互斥锁加锁失败后，线程会释放 CPU ，给其他线程；\n自旋锁加锁失败后，线程会忙等待，直到它拿到锁；\n\n互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞。\n对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。如下图：\n\n\n所以，互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。\n那这个开销成本是什么呢？会有两次线程上下文切换的成本：\n\n当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；\n接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。\n\n线程的上下文切换的是什么？当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。\n上下切换的耗时有大佬统计过，大概在几十纳秒到几微秒之间，如果你锁住的代码执行时间比较短，那可能上下文切换的时间都比你锁住的代码执行时间还要长。\n所以，如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。\n自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。\n一般加锁的过程，包含两个步骤：\n\n第一步，查看锁的状态，如果锁是空闲的，则执行第二步；\n第二步，将锁设置为当前线程持有；\n\nCAS 函数就把这两个步骤合并成一条硬件级指令，形成原子指令，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。\n比如，设锁为变量 lock，整数 0 表示锁是空闲状态，整数 pid 表示线程 ID，那么 CAS(lock, 0, pid) 就表示自旋锁的加锁操作，CAS(lock, pid, 0) 则表示解锁操作。\n使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 while 循环等待实现，不过最好是使用 CPU 提供的 PAUSE 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。\n自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。\n自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系，我们需要清楚的知道这一点。\n自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对。\n它俩是锁的最基本处理方式，更高级的锁都会选择其中一个来实现，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现。\n6.读写锁读写锁从字面意思我们也可以知道，它由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。\n所以，读写锁适用于能明确区分读操作和写操作的场景。\n读写锁的工作原理是：\n\n当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。\n但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。\n\n所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。\n知道了读写锁的工作原理后，我们可以发现，读写锁在读多写少的场景，能发挥出优势。\n另外，根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」。\n读优先锁期望的是，读锁能被更多的线程持有，以便提高读线程的并发性，它的工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁。如下图：\n\n\n而「写优先锁」是优先服务写线程，其工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获取写锁。如下图：\n\n\n读优先锁对于读线程并发性更好，但也不是没有问题。我们试想一下，如果一直有读线程获取读锁，那么写线程将永远获取不到写锁，这就造成了写线程「饥饿」的现象。\n写优先锁可以保证写线程不会饿死，但是如果一直有写线程获取写锁，读线程也会被「饿死」。\n既然不管优先读锁还是写锁，对方可能会出现饿死问题，那么我们就不偏袒任何一方，搞个「公平读写锁」。\n公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。\n互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。\n7.乐观锁和悲观锁前面提到的互斥锁、自旋锁、读写锁，都是属于悲观锁。\n悲观锁做事比较悲观，它认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。\n那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。\n乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。\n放弃后如何重试，这跟业务场景息息相关，虽然重试的成本很高，但是冲突的概率足够低的话，还是可以接受的。\n可见，乐观锁的心态是，不管三七二十一，先改了资源再说。另外，你会发现乐观锁全程并没有加锁，所以它也叫无锁编程。\n\n\n\n\n\n\n\n\n\n这里举一个场景例子：在线文档。\n我们都知道在线文档可以同时多人编辑的，如果使用了悲观锁，那么只要有一个用户正在编辑文档，此时其他用户就无法打开相同的文档了，这用户体验当然不好了。\n那实现多人同时编辑，实际上是用了乐观锁，它允许多个用户打开同一个文档进行编辑，编辑完提交之后才验证修改的内容是否有冲突。\n怎么样才算发生冲突？这里举个例子，比如用户 A 先在浏览器编辑文档，之后用户 B 在浏览器也打开了相同的文档进行编辑，但是用户 B 比用户 A 提交早，这一过程用户 A 是不知道的，当 A 提交修改完的内容时，那么 A 和 B 之间并行修改的地方就会发生冲突。\n服务端要怎么验证是否冲突了呢？通常方案如下：\n\n由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号；\n当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号不一致则提交失败，如果版本号一致则修改成功，然后服务端版本号更新到最新的版本号。\n\n实际上，我们常见的 SVN 和 Git 也是用了乐观锁的思想，先让用户编辑代码，然后提交的时候，通过版本号来判断是否产生了冲突，发生了冲突的地方，需要我们自己修改后，再重新提交。\n乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。\n8.总结开发过程中，最常见的就是互斥锁的了，互斥锁加锁失败时，会用「线程切换」来应对，当加锁失败的线程再次加锁成功后的这一过程，会有两次线程上下文切换的成本，性能损耗比较大。\n如果我们明确知道被锁住的代码的执行时间很短，那我们应该选择开销比较小的自旋锁，因为自旋锁加锁失败时，并不会主动产生线程切换，而是一直忙等待，直到获取到锁，那么如果被锁住的代码执行时间很短，那这个忙等待的时间相对应也很短。\n如果能区分读操作和写操作的场景，那读写锁就更合适了，它允许多个读线程可以同时持有读锁，提高了读的并发性。根据偏袒读方还是写方，可以分为读优先锁和写优先锁，读优先锁并发性很强，但是写线程会被饿死，而写优先锁会优先服务写线程，读线程也可能会被饿死，那为了避免饥饿的问题，于是就有了公平读写锁，它是用队列把请求锁的线程排队，并保证先入先出的原则来对线程加锁，这样便保证了某种线程不会被饿死，通用性也更好点。\n互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。\n另外，互斥锁、自旋锁、读写锁都属于悲观锁，悲观锁认为并发访问共享资源时，冲突概率可能非常高，所以在访问共享资源前，都需要先加锁。\n相反的，如果并发访问共享资源时，冲突概率非常低的话，就可以使用乐观锁，它的工作方式是，在访问共享资源时，不用先加锁，修改完共享资源后，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。\n但是，一旦冲突概率上升，就不适合使用乐观锁了，因为它解决冲突的重试成本非常高。\n不管使用的哪种锁，我们的加锁的代码范围应该尽可能的小，也就是加锁的粒度要小，这样执行速度会比较快。再来，使用上了合适的锁，就会快上加快了。\n","slug":"OS-死锁","date":"2024-06-09T07:25:12.000Z","categories_index":"Study","tags_index":"学习,操作系统","author_index":"Fioransh"},{"id":"ab980e069c750cd15253a6b530b876d9","title":"OS-同步与互斥","content":"1.竞争与合作1.1 入门在单核 CPU 系统里，为了实现多个程序同时运行的假象，操作系统通常以时间片调度的方式，让每个进程执行每次执行一个时间片，时间片用完了，就切换下一个进程运行，由于这个时间片的时间很短，于是就造成了「并发」的现象。\n另外，操作系统也为每个进程创建巨大、私有的虚拟内存的假象，这种地址空间的抽象让每个程序好像拥有自己的内存，而实际上操作系统在背后秘密地让多个地址空间「复用」物理内存或者磁盘。\n如果一个程序只有一个执行流程，也代表它是单线程的。当然一个程序可以有多个执行流程，也就是所谓的多线程程序，线程是调度的基本单位，进程则是资源分配的基本单位。\n所以，线程之间是可以共享进程的资源，比如代码段、堆空间、数据段、打开的文件等资源，但每个线程都有自己独立的栈空间。\n那么问题就来了，多个线程如果竞争共享资源，如果不采取有效的措施，则会造成共享数据的混乱。\n\n\n\n\n\n\n\n\n\n\n1.2 互斥的概念上面展示的情况称为竞争条件（*race condition*），当多线程相互竞争操作共享变量时，由于运气不好，即在执行过程中发生了上下文切换，我们得到了错误的结果，事实上，每次运行都可能得到不同的结果，因此输出的结果存在不确定性（*indeterminate*）。\n由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为临界区（*critical section*），它是访问共享资源的代码片段，一定不能给多线程同时执行。\n我们希望这段代码是互斥（*mutualexclusion*）的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区，说白了，就是这段代码执行过程中，最多只能出现一个线程。\n互斥也并不是只针对多线程。在多进程竞争共享资源的时候，也同样是可以使用互斥的方式来避免资源竞争造成的资源混乱。\n互斥解决了并发进程&#x2F;线程对临界区的使用问题。这种基于临界区控制的交互作用是比较简单的，只要一个进程&#x2F;线程进入了临界区，其他试图想进入临界区的进程&#x2F;线程都会被阻塞着，直到第一个进程&#x2F;线程离开了临界区。\n1.3 同步的概念所谓同步，就是并发进程&#x2F;线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程&#x2F;线程同步。\n例子，线程 1 是负责读入数据的，而线程 2 是负责处理数据的，这两个线程是相互合作、相互依赖的。线程 2 在没有收到线程 1 的唤醒通知时，就会一直阻塞等待，当线程 1 读完数据需要把数据传给线程 2 时，线程 1 会唤醒线程 2，并把数据交给线程 2 处理。\n注意，同步与互斥是两种不同的概念：\n\n同步就好比：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等；\n互斥就好比：「操作 A 和操作 B 不能在同一时刻执行」；\n\n2.互斥与同步的实现与使用在进程&#x2F;线程并发执行的过程中，进程&#x2F;线程之间存在协作的关系，例如有互斥、同步的关系。\n为了实现进程&#x2F;线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：\n\n锁：加锁、解锁操作；\n信号量：P、V 操作；\n\n这两个都可以方便地实现进程&#x2F;线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程&#x2F;线程同步。\n2.1 锁使用加锁操作和解锁操作可以解决并发线程&#x2F;进程的互斥问题。\n任何想进入临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。\n根据锁的实现不同，可以分为「忙等待锁」和「无忙等待锁」。\n2.1.1 忙等待锁在说明「忙等待锁」的实现之前，先介绍现代 CPU 体系结构提供的特殊原子操作指令 —— 测试和置位（*Test-and-Set*）指令。\n如果用 C 代码表示 Test-and-Set 指令，形式如下：\n\n测试并设置指令做了下述事情:\n\n把 old_ptr 更新为 new 的新值\n返回 old_ptr 的旧值；\n\n当然，关键是这些代码是原子执行。因为既可以测试旧值，又可以设置新值，所以我们把这条指令叫作「测试并设置」。\n那什么是原子操作呢？原子操作就是要么全部执行，要么都不执行，不能出现执行到一半的中间状态\n我们可以运用 Test-and-Set 指令来实现「忙等待锁」，代码如下：\n\n我们来确保理解为什么这个锁能工作：\n\n第一个场景是，首先假设一个线程在运行，调用 lock()，没有其他线程持有锁，所以 flag 是 0。当调用 TestAndSet(flag, 1) 方法，返回 0，线程会跳出 while 循环，获取锁。同时也会原子的设置 flag 为1，标志锁已经被持有。当线程离开临界区，调用 unlock() 将 flag 清理为 0。\n第二种场景是，当某一个线程已经持有锁（即 flag 为1）。本线程调用 lock()，然后调用 TestAndSet(flag, 1)，这一次返回 1。只要另一个线程一直持有锁，TestAndSet() 会重复返回 1，本线程会一直忙等。当 flag 终于被改为 0，本线程会调用 TestAndSet()，返回 0 并且原子地设置为 1，从而获得锁，进入临界区。\n\n很明显，当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为自旋锁（*spin lock*）。\n这是最简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。\n2.1.2 无等待锁无等待锁顾明思议就是获取不到锁的时候，不用自旋。\n既然不想自旋，那当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。\n\n\n本次只是提出了两种简单锁的实现方式。在具体操作系统实现中，会更复杂，但也离不开本例子两个基本元素。\n2.2 信号量信号量是操作系统提供的一种协调共享资源访问的方法。\n通常信号量表示资源的数量，对应的变量是一个整型（sem）变量。\n另外，还有两个原子操作的系统调用函数来控制信号量的，分别是：\n\nP 操作：将 sem 减 1，相减后，如果 sem &lt; 0，则进程&#x2F;线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；\nV 操作：将 sem 加 1，相加后，如果 sem &lt;= 0，唤醒一个等待中的进程&#x2F;线程，表明 V 操作不会阻塞；\n\nP 操作是用在进入临界区之前，V 操作是用在离开临界区之后，这两个操作是必须成对出现的。\n2.2.1 PV操作如何使用信号量不仅可以实现临界区的互斥访问控制，还可以线程间的事件同步。\n我们先来说说如何使用信号量实现临界区的互斥访问。\n为每类共享资源设置一个信号量 s，其初值为 1，表示该临界资源未被占用。\n只要把进入临界区的操作置于 P(s) 和 V(s) 之间，即可实现进程&#x2F;线程互斥。\n此时，任何想进入临界区的线程，必先在互斥信号量上执行 P 操作，在完成对临界资源的访问后再执行 V 操作。由于互斥信号量的初始值为 1，故在第一个线程执行 P 操作后 s 值变为 0，表示临界资源为空闲，可分配给该线程，使之进入临界区。\n若此时又有第二个线程想进入临界区，也应先执行 P 操作，结果使 s 变为负值，这就意味着临界资源已被占用，因此，第二个线程被阻塞。\n并且，直到第一个线程执行 V 操作，释放临界资源而恢复 s 值为 0 后，才唤醒第二个线程，使之进入临界区，待它完成临界资源的访问后，又执行 V 操作，使 s 恢复到初始值 1。\n对于两个并发线程，互斥信号量的值仅取 1、0 和 -1 三个值，分别表示：\n\n如果互斥信号量为 1，表示没有线程进入临界区；\n如果互斥信号量为 0，表示有一个线程进入临界区；\n如果互斥信号量为 -1，表示一个线程进入临界区，另一个线程等待进入。\n\n通过互斥信号量的方式，就能保证临界区任何时刻只有一个线程在执行，就达到了互斥的效果。\n信号量实现事件同步。同步的方式是设置一个信号量，其初值为 0。\n2.3 生产者-消费者问题\n\n生产者-消费者问题描述：\n\n生产者在生成数据后，放在一个缓冲区中；\n消费者从缓冲区取出数据处理；\n任何时刻，只能有一个生产者或消费者可以访问缓冲区；\n\n我们对问题分析可以得出：\n\n任何时刻只能有一个线程操作缓冲区，说明操作缓冲区是临界代码，需要互斥；\n缓冲区空时，消费者必须等待生产者生成数据；缓冲区满时，生产者必须等待消费者取出数据。说明生产者和消费者需要同步。\n\n那么我们需要三个信号量，分别是：\n\n互斥信号量 mutex：用于互斥访问缓冲区，初始化值为 1；\n资源信号量 fullBuffers：用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）；\n资源信号量 emptyBuffers：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）；\n\n\n\n\n\n\n\n\n\n\n具体的实现代码：\n\n\n如果消费者线程一开始执行 P(fullBuffers)，由于信号量 fullBuffers 初始值为 0，则此时 fullBuffers 的值从 0 变为 -1，说明缓冲区里没有数据，消费者只能等待。\n接着，轮到生产者执行 P(emptyBuffers)，表示减少 1 个空槽，如果当前没有其他生产者线程在临界区执行代码，那么该生产者线程就可以把数据放到缓冲区，放完后，执行 V(fullBuffers) ，信号量 fullBuffers 从 -1 变成 0，表明有「消费者」线程正在阻塞等待数据，于是阻塞等待的消费者线程会被唤醒。\n消费者线程被唤醒后，如果此时没有其他消费者线程在读数据，那么就可以直接进入临界区，从缓冲区读取数据。最后，离开临界区后，把空槽的个数 + 1。\n3.经典同步问题3.1 哲学家就餐问题哲学家就餐的问题描述：\n\n5 个老大哥哲学家，闲着没事做，围绕着一张圆桌吃面；\n巧就巧在，这个桌子只有 5 支叉子，每两个哲学家之间放一支叉子；\n哲学家围在一起先思考，思考中途饿了就会想进餐；\n奇葩的是，这些哲学家要两支叉子才愿意吃面，也就是需要拿到左右两边的叉子才进餐；\n吃完后，会把两支叉子放回原处，继续思考；\n\n\n\n3.1.1 方案一我们用信号量的方式，也就是 PV 操作来尝试解决它\n\n\n拿起叉子用 P 操作，代表有叉子就直接用，没有叉子时就等待其他哲学家放回叉子。\n不过，这种解法存在一个极端的问题：假设五位哲学家同时拿起左边的叉子，桌面上就没有叉子了， 这样就没有人能够拿到他们右边的叉子，也就说每一位哲学家都会在 P(fork[(i + 1) % N ]) 这条语句阻塞了，很明显这发生了死锁的现象。\n3.1.2 方案二既然「方案一」会发生同时竞争左边叉子导致死锁的现象，那么我们就在拿叉子前，加个互斥信号量，代码如下：\n\n\n上面程序中的互斥信号量的作用就在于，只要有一个哲学家进入了「临界区」，也就是准备要拿叉子时，其他哲学家都不能动，只有这位哲学家用完叉子了，才能轮到下一个哲学家进餐。\n方案二虽然能让哲学家们按顺序吃饭，但是每次进餐只能有一位哲学家，而桌面上是有 5 把叉子，按道理是能可以有两个哲学家同时进餐的，所以从效率角度上，这不是最好的解决方案。\n3.1.3 方案三那既然方案二使用互斥信号量，会导致只能允许一个哲学家就餐，那么我们就不用它。\n另外，方案一的问题在于，会出现所有哲学家同时拿左边刀叉的可能性，那我们就避免哲学家可以同时拿左边的刀叉，采用分支结构，根据哲学家的编号的不同，而采取不同的动作。\n即让偶数编号的哲学家「先拿左边的叉子后拿右边的叉子」，奇数编号的哲学家「先拿右边的叉子后拿左边的叉子」。\n\n\n上面的程序，在 P 操作时，根据哲学家的编号不同，拿起左右两边叉子的顺序不同。另外，V 操作是不需要分支的，因为 V 操作是不会阻塞的。\n方案三即不会出现死锁，也可以两人同时进餐。\n3.1.4 方案四在这里再提出另外一种可行的解决方案，我们用一个数组 state 来记录每一位哲学家的三个状态，分别是在进餐状态、思考状态、饥饿状态（正在试图拿叉子）。\n那么，一个哲学家只有在两个邻居都没有进餐时，才可以进入进餐状态。\n第 i 个哲学家的左邻右舍，则由宏 LEFT 和 RIGHT 定义：\n\nLEFT : ( i + 5 - 1 ) % 5\nRIGHT : ( i + 1 ) % 5\n\n比如 i 为 2，则 LEFT 为 1，RIGHT 为 3。\n具体代码实现如下：\n\n\n上面的程序使用了一个信号量数组，每个信号量对应一位哲学家，这样在所需的叉子被占用时，想进餐的哲学家就被阻塞。\n注意，每个进程&#x2F;线程将 smart_person 函数作为主代码运行，而其他 take_forks、put_forks 和 test 只是普通的函数，而非单独的进程&#x2F;线程。\n方案四同样不会出现死锁，也可以两人同时进餐。\n3.2 读者-写者问题前面的「哲学家进餐问题」对于互斥访问有限的竞争问题（如 I&#x2F;O 设备）一类的建模过程十分有用。\n另外，还有个著名的问题是「读者-写者」，它为数据库访问建立了一个模型。\n读者只会读取数据，不会修改数据，而写者即可以读也可以修改数据。\n读者-写者的问题描述：\n\n「读-读」允许：同一时刻，允许多个读者同时读\n「读-写」互斥：没有写者时读者才能读，没有读者时写者才能写\n「写-写」互斥：没有其他写者时，写者才能写\n\n3.2.1 方案一使用信号量的方式来尝试解决：\n\n信号量 wMutex：控制写操作的互斥信号量，初始值为 1 ；\n读者计数 rCount：正在进行读操作的读者个数，初始化为 0；\n信号量 rCountMutex：控制对 rCount 读者计数器的互斥修改，初始值为 1；\n\n接下来看看代码的实现：\n\n\n上面的这种实现，是读者优先的策略，因为只要有读者正在读的状态，后来的读者都可以直接进入，如果读者持续不断进入，则写者会处于饥饿状态。\n3.2.2 方案二那既然有读者优先策略，自然也有写者优先策略：\n\n只要有写者准备要写入，写者应尽快执行写操作，后来的读者就必须阻塞；\n如果有写者持续不断写入，则读者就处于饥饿；\n\n在方案一的基础上新增如下变量：\n\n信号量 rMutex：控制读者进入的互斥信号量，初始值为 1；\n信号量 wDataMutex：控制写者写操作的互斥信号量，初始值为 1；\n写者计数 wCount：记录写者数量，初始值为 0；\n信号量 wCountMutex：控制 wCount 互斥修改，初始值为 1；\n\n具体实现如下代码：\n\n\n注意，这里 rMutex 的作用，开始有多个读者读数据，它们全部进入读者队列，此时来了一个写者，执行了 P(rMutex) 之后，后续的读者由于阻塞在 rMutex 上，都不能再进入读者队列，而写者到来，则可以全部进入写者队列，因此保证了写者优先。\n同时，第一个写者执行了 P(rMutex) 之后，也不能马上开始写，必须等到所有进入读者队列的读者都执行完读操作，通过 V(wDataMutex) 唤醒写者的写操作。\n3.2.3 方案三既然读者优先策略和写者优先策略都会造成饥饿的现象，那么我们就来实现一下公平策略。\n公平策略：\n\n优先级相同；\n写者、读者互斥访问；\n只能一个写者访问临界区；\n可以有多个读者同时访问临界资源；\n\n具体代码实现：\n\n\n看完代码不知你是否有这样的疑问，为什么加了一个信号量 flag，就实现了公平竞争？\n对比方案一的读者优先策略，可以发现，读者优先中只要后续有读者到达，读者就可以进入读者队列， 而写者必须等待，直到没有读者到达。\n没有读者到达会导致读者队列为空，即 rCount==0，此时写者才可以进入临界区执行写操作。\n而这里 flag 的作用就是阻止读者的这种特殊权限（特殊权限是只要读者到达，就可以进入读者队列）。\n比如：开始来了一些读者读数据，它们全部进入读者队列，此时来了一个写者，执行 P(falg) 操作，使得后续到来的读者都阻塞在 flag 上，不能进入读者队列，这会使得读者队列逐渐为空，即 rCount 减为 0。\n这个写者也不能立马开始写（因为此时读者队列不为空），会阻塞在信号量 wDataMutex 上，读者队列中的读者全部读取结束后，最后一个读者进程执行 V(wDataMutex)，唤醒刚才的写者，写者则继续开始进行写操作。\n","slug":"OS-同步与互斥","date":"2024-06-09T05:25:12.000Z","categories_index":"Study","tags_index":"学习,操作系统","author_index":"Fioransh"},{"id":"6c3d1454bbe7a724ef7580b6eaa23896","title":"OS-进程通信方式","content":"1.管道1.1 基础介绍每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。Linux 内核提供了不少进程间通信的机制。\nbash$ ps auxf | grep mysql上面命令行里的「|」竖线就是一个管道，它的功能是将前一个命令（ps auxf）的输出，作为后一个命令（grep mysql）的输入，从这功能描述，可以看出管道传输数据是单向的，如果想相互通信，我们需要创建两个管道才行。\n同时，我们得知上面这种管道是没有名字，所以「|」表示的管道称为匿名管道，用完了就销毁。\n管道还有另外一个类型是命名管道，也被叫做 FIFO，因为数据是先进先出的传输方式。\n在使用命名管道前，先需要通过 mkfifo 命令来创建，并且指定管道名字：\nbash$ mkfifo myPipemyPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思：\nbash$ ls -l\nprw-r--r--. 1 root    root         0 Jul 17 02:45 myPipe接下来，我们往 myPipe 这个管道写入数据：\nbash$ echo &quot;hello&quot; &gt; myPipe  // 将数据写进管道\n                         // 停住了 ...你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。\n于是，我们执行另外一个命令来读取这个管道里的数据：\nbash$ cat &lt; myPipe  // 读取管道里的数据\nhello可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。\n我们可以看出，管道这种通信方式效率低，不适合进程间频繁地交换数据。当然，它的好处，自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了。\n1.2 管道的创建与原理匿名管道的创建，需要通过下面这个系统调用：\ncint pipe(int fd[2])这里表示创建一个匿名管道，并返回了两个描述符，一个是管道的读取端描述符 fd[0]，另一个是管道的写入端描述符 fd[1]。注意，这个匿名管道是特殊的文件，只存在于内存，不存于文件系统中。\n\n\n管道，就是内核里面的一串缓存。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。\n如何使管道跨过两个进程实现通讯？\n我们可以使用 fork 创建子进程，创建的子进程会复制父进程的文件描述符，这样就做到了两个进程各有两个「 fd[0] 与 fd[1]」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。\n\n\n管道只能一端写入，另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入，也都可以读出。那么，为了避免这种情况，通常的做法是：\n\n父进程关闭读取的 fd[0]，只保留写入的 fd[1]；\n子进程关闭写入的 fd[1]，只保留读取的 fd[0]；\n\n所以说如果需要双向通信，则应该创建两个管道。\n到这里，我们仅仅解析了使用管道进行父进程与子进程之间的通信，但是在我们 shell 里面并不是这样的。\n在 shell 里面执行 A | B命令的时候，A 进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间不存在父子关系，它俩的父进程都是 shell。\n\n\n所以说，在 shell 里通过「|」匿名管道将多个命令连接在一起，实际上也就是创建了多个子进程，那么在我们编写 shell 脚本时，能使用一个管道搞定的事情，就不要多用一个管道，这样可以减少创建子进程的系统开销。\n我们可以得知，对于匿名管道，它的通信范围是存在父子关系的进程。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。\n另外，对于命名管道，它可以在不相关的进程间也能相互通信。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。\n不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。\n2.消息队列管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。\n对于这个问题，消息队列的通信模式就可以解决。\n\n\n\n\n\n\n\n\n\nA进程给B进程发送消息：A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。\n消息队列是保存在内核中的消息链表，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。\n消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。\n但邮件的通信方式存在不足的地方有两点，一是通信不及时，二是附件也有大小限制，这同样也是消息队列通信不足的点。\n消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 MSGMAX 和 MSGMNB，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。\n消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。\n3.共享内存消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那共享内存的方式，就很好的解决了这一问题。\n共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。\n4.信号量用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。\n为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，信号量就实现了这一保护机制。\n信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。\n信号量表示资源的数量，控制信号量的方式有两种原子操作：\n\n一个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;&#x3D; 0，则表明还有资源可使用，进程可正常继续执行。\n另一个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 &lt;&#x3D; 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程；\n\nP 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。\n如果要使得两个进程互斥访问共享内存，我们可以初始化信号量为 1\n具体的过程如下：\n\n进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。\n若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。\n直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。\n\n信号初始化为 1，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。\n在多进程里，每个进程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个进程能密切合作，以实现一个共同的任务。\n例如，进程 A 是负责生产数据，而进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A 必须先生产了数据，进程 B 才能读取到数据，所以执行是有前后顺序的。\n那么这时候，就可以用信号量来实现多进程同步的方式，我们可以初始化信号量为 0。\n\n\n具体过程：\n\n如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；\n接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；\n最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。\n\n可以发现，信号初始化为 0，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执行。\n5. 信号上面说的进程间通信，都是常规状态下的工作模式。对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。\n信号跟信号量虽然名字相似度 66.66%，但两者用途完全不一样，就好像 Java 和 JavaScript 的区别。\n在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 kill -l 命令，查看所有的信号：\nshell$ kill -l\n 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP\n 6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR1\n11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM\n16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP\n21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ\n26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR\n31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3\n38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8\n43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13\n48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12\n53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7\n58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2\n63) SIGRTMAX-1  64) SIGRTMAX运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如\n\nCtrl+C 产生 SIGINT 信号，表示终止该进程；\nCtrl+Z 产生 SIGTSTP 信号，表示停止该进程，但还未结束；\n\n如果进程在后台运行，可以通过 kill 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如：\n\nkill -9 1050 ，表示给 PID 为 1050 的进程发送 SIGKILL 信号，用来立即结束该进程；\n\n所以，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。\n信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。\n1.执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。\n2.捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。\n3.忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程。\n6.Socket前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。\n创建 socket 的系统调用：\ncint socket(int domain, int type, int protocal)三个参数分别代表：\n\ndomain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL&#x2F;AF_UNIX 用于本机；\ntype 参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流，对应 TCP、SOCK_DGRAM 表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字；\nprotocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可；\n\n根据创建 socket 类型的不同，通信的方式也就不同：\n\n实现 TCP 字节流通信： socket 类型是 AF_INET 和 SOCK_STREAM；\n实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；\n实现本地进程间通信： 「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket；\n\n6.1 针对 TCP 协议通信的 socket 编程模型\n\n\n服务端和客户端初始化 socket，得到文件描述符；\n服务端调用 bind，将绑定在 IP 地址和端口;\n服务端调用 listen，进行监听；\n服务端调用 accept，等待客户端连接；\n客户端调用 connect，向服务器端的地址和端口发起连接请求；\n服务端 accept 返回用于传输的 socket 的文件描述符；\n客户端调用 write 写入数据；服务端调用 read 读取数据；\n客户端断开连接时，会调用 close，那么服务端 read 读取数据的时候，就会读取到了 EOF，待处理完数据后，服务端调用 close，表示连接关闭。\n\n这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。\n所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作监听 socket，一个叫作已完成连接 socket。\n成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。\n6.2 针对 UDP 协议通信的 socket 编程模型\n\nUDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。\n对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。\n另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。\n6.3 针对本地进程间通信的 socket 编程模型本地 socket 被用于在同一台主机上进程间通信的场景：\n\n本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议；\n本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现；\n\n对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。\n对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。\n本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。\n7.总结由于每个进程的用户空间都是独立的，不能相互访问，这时就需要借助内核空间来实现进程间通信，原因很简单，每个进程都是共享一个内核空间。\nLinux 内核提供了不少进程间通信的方式，其中最简单的方式就是管道，管道分为「匿名管道」和「命名管道」。\n匿名管道顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中，shell 命令中的「|」竖线就是匿名管道，通信的数据是无格式的流并且大小受限，通信的方式是单向的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来匿名管道是只能用于存在父子关系的进程间通信，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。\n命名管道突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。\n消息队列克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。\n共享内存可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，它直接分配一个共享空间，每个进程都可以直接访问，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有最快的进程间通信方式之名。但是便捷高效的共享内存通信，带来新的问题，多进程竞争同个共享资源会造成数据的错乱。\n那么，就需要信号量来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。信号量不仅可以实现访问的互斥性，还可以实现进程间的同步，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作。\n与信号量名字很相似的叫信号，它俩名字虽然相似，但功能一点儿都不一样。信号是异步通信机制，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SIGSTOP，这是为了方便我们能在任何时候结束或停止某个进程。\n前面说到的通信机制，都是工作于同一台主机，如果要与不同主机的进程间通信，那么就需要 Socket 通信了。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。\n以上，就是进程间通信的主要机制了。你可能会问了，那线程通信间的方式呢？\n同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以对于线程间关注的不是通信方式，而是关注多线程竞争共享资源的问题，信号量也同样可以在线程间实现互斥与同步：\n\n互斥的方式，可保证任意时刻只有一个线程访问共享资源；\n同步的方式，可保证线程 A 应在线程 B 之前执行；\n\n","slug":"OS-进程通信方式","date":"2024-06-08T13:25:12.000Z","categories_index":"Study","tags_index":"学习,操作系统","author_index":"Fioransh"},{"id":"a309e6723d5eeefad0a013dac5e81168","title":"OS-文件系统","content":"1.文件系统的基本组成文件系统是操作系统中负责管理持久数据的子系统，负责把用户文件存到磁盘硬件。\n文件系统的基本数据单位是文件，它的目的是对磁盘上的文件进行组织管理，那组织的方式不同，就会形成不同的文件系统。\nLinux 最经典的一句话是：「一切皆文件」\nLinux 文件系统会为每个文件分配两个数据结构：索引节点（*index node*）和目录项（*directory entry*），它们主要用来记录文件的元信息和目录层次结构。\n\n索引节点，也就是 inode，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。\n目录项，也就是 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。\n\n索引节点唯一标识一个文件，目录项记录文件名字，目录项和索引节点关系为多对一，一个文件可以有多个别名。\n目录也是文件，也是索引节点唯一，普通文件在磁盘保存的是文件数据，目录文件保存的是子目录或文件。\n1.1 目录项和目录区别目录是文件，持久化存储在磁盘。目录项是内核一个数据结构，缓存在内存。\n如果查询目录频繁从磁盘读，效率会很低，所以内核会把已经读过的目录用目录项这个数据结构缓存在内存，下次再次读到相同的目录时，只需从内存读就可以，大大提高了文件系统的效率。\n目录项这个数据结构不只是表示目录，也是可以表示文件的。\n1.2 文件数据如何存储在磁盘磁盘读写最小单位是扇区，扇区大小为521B\n文件系统把多个扇区组成一个逻辑块，每次读写的最小单位就是逻辑块。\nLinux中逻辑块大小为4KB，也就是一次性读写8个扇区，提高读写效率。\n\n\n索引节点是存储在硬盘上的数据，那么为了加速文件的访问，通常会把索引节点加载到内存中\n磁盘进行格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。\n\n超级块，用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。\n索引节点区，用来存储索引节点；\n数据块区，用来存储文件或目录数据；\n\n当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：\n\n超级块：当文件系统挂载时进入内存；\n索引节点区：当文件被访问时进入内存；\n\n2.虚拟文件系统文件系统的种类众多，而操作系统希望对用户提供一个统一的接口，于是在用户层与文件系统层引入了中间层，这个中间层就称为虚拟文件系统（*Virtual File System，VFS*）。\nVFS 定义了一组所有文件系统都支持的数据结构和标准接口。\n\n\nLinux 支持的文件系统根据存储位置的不同，可以把文件系统分为三类：\n\n磁盘的文件系统：直接把数据存储在磁盘中，比如 Ext 2&#x2F;3&#x2F;4、XFS 等都是这类文件系统。\n内存的文件系统：这类文件系统的数据不是存储在硬盘的，而是占用内存空间，我们经常用到的 /proc 和 /sys 文件系统都属于这一类，读写这类文件，实际上是读写内核中相关的数据。\n网络的文件系统：用来访问其他计算机主机数据的文件系统，比如 NFS、SMB 等等。\n\n文件系统首先要先挂载到某个目录才可以正常使用，比如 Linux 系统在启动时，会把文件系统挂载到根目录。\n3.文件的使用文件打开过程：\n\n首先用 open 系统调用打开文件，open 的参数中包含文件的路径名和文件名。\n使用 write 写数据，其中 write 使用 open 所返回的文件描述符，并不使用文件名作为参数。\n使用完文件后，要用 close 系统调用关闭文件，避免资源的泄露。\n\n打开文件后，系统会跟踪打开的所有文件，所谓跟踪即是操作系统为每个进程维护一个打开文件表，文件表里的每一项代表「文件描述符」，所以说文件描述符是打开文件的标识。\n操作系统在打开文件表中维护着打开文件的状态和信息：\n\n文件指针：系统跟踪上次读写位置作为当前文件位置指针，这种指针对打开文件的某个进程来说是唯一的；\n文件打开计数器：文件关闭时，操作系统必须重用其打开文件表条目，否则表内空间不够用。因为多个进程可能打开同一个文件，所以系统在删除打开文件条目之前，必须等待最后一个进程关闭文件，该计数器跟踪打开和关闭的数量，当该计数为 0 时，系统关闭文件，删除该条目；\n文件磁盘位置：绝大多数文件操作都要求系统修改文件数据，该信息保存在内存中，以免每个操作都从磁盘中读取；\n访问权限：每个进程打开文件都需要有一个访问模式（创建、只读、读写、添加等），该信息保存在进程的打开文件表中，以便操作系统能允许或拒绝之后的 I&#x2F;O 请求；\n\n在用户视角里，文件就是一个持久化的数据结构，但操作系统并不会关心你想存在磁盘上的任何的数据结构，操作系统的视角是如何把文件数据和磁盘块对应起来。\n所以，用户和操作系统对文件的读写操作是有差异的，用户习惯以字节的方式读写文件，而操作系统则是以数据块来读写文件，那屏蔽掉这种差异的工作就是文件系统了。\n我们来分别看一下，读文件和写文件的过程：\n\n当用户进程从文件读取 1 个字节大小的数据时，文件系统则需要获取字节所在的数据块，再返回数据块对应的用户进程所需的数据部分。\n当用户进程把 1 个字节大小的数据写进文件时，文件系统则找到需要写入数据的数据块的位置，然后修改数据块中对应的部分，最后再把数据块写回磁盘。\n\n所以说，文件系统的基本操作单位是数据块。\n4.文件的存储文件的数据存储在硬盘上，数据在磁盘上的存放方式有以下两种：\n\n连续空间存放方式\n非连续空间存放方式\n\n其中，非连续空间存放方式又可以分为「链表方式」和「索引方式」，重点分析它们的存储效率和读写性能。\n4.1 连续空间存放方式文件存放在磁盘「连续的」物理空间中。这种模式下，文件的数据都是紧密相连，读写效率很高，因为一次磁盘寻道就可以读出整个文件。\n使用连续存放方式前提：必须知道文件的大小。\n文件头里需要指定「起始块的位置」和「长度」，有了这两个信息就可以很好的表示文件存放方式是一块连续的磁盘空间。\n注意，此处说的文件头，就类似于 Linux 的 inode。\n\n\n连续空间存放的方式虽然读写效率高，但是有「磁盘空间碎片」和「文件长度不易扩展」的缺陷。\n磁盘空间碎片与之前的内部存储碎片相似，文件存放小于空间空缺可以存放，存放后的剩余空间为碎片，大于则不能存放。\n文件长度扩展不方便，唯一的方式也是挪动，效率低下。\n使用非连续空间存放方式可以来解决这些缺陷。\n4.2 非连续空间存放方式非连续空间存放方式分为「链表方式」和「索引方式」。\n4.2.1 链表方式链表的方式存放是离散的，不用连续的，于是就可以消除磁盘碎片，可大大提高磁盘空间的利用率，同时文件的长度可以动态扩展。根据实现的方式的不同，链表可分为「隐式链表」和「显式链接」两种形式。\n隐式链表：\n文件要以「隐式链表」的方式存放的话，实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置，这样一个数据块连着一个数据块，从链头开始就可以顺着指针找到所有的数据块，所以存放的方式可以是不连续的。\n\n\n隐式链表的存放方式的缺点在于无法直接访问数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间。隐式链接分配的稳定性较差，系统在运行过程中由于软件或者硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失。\n显式链表：\n如果取出每个磁盘块的指针，把它放在内存的一个表中，就可以解决上述隐式链表的两个不足。这种实现方式是「显式链接」，它指把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中，该表在整个磁盘仅设置一张，每个表项中存放链接指针，指向下一个数据块号。\n内存中的这样一个表格称为文件分配表（*File Allocation Table，FAT*）。\n\n\n由于查找记录的过程是在内存中进行的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。但也正是整个表都存放在内存中的关系，它的主要的缺点是不适用于大磁盘。\n4.2.2 索引方式索引的实现是为每个文件创建一个「索引数据块」，里面存放的是指向文件数据块的指针列表，说白了就像书的目录一样，要找哪个章节的内容，看目录查就可以。\n文件头需要包含指向「索引数据块」的指针，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。\n创建文件时，索引块的所有指针都设为空。当首次写入第 i 块时，先从空闲空间中取得一个块，再将其地址写到索引块的第 i 个条目。\n\n\n索引的方式优点在于：\n\n文件的创建、增大、缩小很方便；\n不会有碎片的问题；\n支持顺序读写和随机读写；\n\n由于索引数据也是存放在磁盘块的，如果文件很小，明明只需一块就可以存放的下，但还是需要额外分配一块来存放索引数据，所以缺陷之一就是存储索引带来的开销。\n如何处理过大文件（大于一个索引数据块）：\n链表 + 索引的组合，这种组合称为「链式索引块」，它的实现方式是在索引数据块留出一个存放下一个索引数据块的指针，于是当一个索引数据块的索引信息用完了，就可以通过指针的方式，找到下一个索引数据块的信息。那这种方式也会出现前面提到的链表方式的问题，万一某个指针损坏了，后面的数据也就会无法读取了。\n\n\n还有另外一种组合方式是索引 + 索引的方式，这种组合称为「多级索引块」，实现方式是通过一个索引块来存放多个索引数据块，一层套一层索引。\n\n\n\n\n4.3 Unix文件的实现方式\n\n那早期 Unix 文件系统是组合了前面的文件存放方式的优点\n\n\n它是根据文件的大小，存放的方式会有所变化：\n\n如果存放文件所需的数据块小于 10 块，则采用直接查找的方式；\n如果存放文件所需的数据块超过 10 块，则采用一级间接索引方式；\n如果前面两种方式都不够存放大文件，则采用二级间接索引方式；\n如果二级间接索引也不够存放大文件，这采用三级间接索引方式；\n\n那么，文件头（Inode）就需要包含 13 个指针：\n\n10 个指向数据块的指针；\n第 11 个指向索引块的指针；\n第 12 个指向二级索引块的指针；\n第 13 个指向三级索引块的指针；\n\n所以，这种方式能很灵活地支持小文件和大文件的存放：\n\n对于小文件使用直接查找的方式可减少索引数据块的开销；\n对于大文件则以多级索引的方式来支持，所以大文件在访问数据块时需要大量查询；\n\n5.空闲空间管理针对磁盘的空闲空间也是要引入管理的机制，接下来介绍几种常见的方法：\n\n空闲表法\n空闲链表法\n位图法\n\n5.1 空闲表法空闲表法就是为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数，注意，这个方式是连续分配的。\n当请求分配磁盘空间时，系统依次扫描空闲表里的内容，直到找到一个合适的空闲区域为止。当用户撤销一个文件时，系统回收文件空间。这时，也需顺序扫描空闲表，寻找一个空闲表条目并将释放空间的第一个物理块号及它占用的块数填到这个条目中。\n这种方法仅当有少量的空闲区时才有较好的效果。因为，如果存储空间中有着大量的小的空闲区，则空闲表变得很大，这样查询效率会很低。另外，这种分配技术适用于建立连续文件。\n\n\n\n\n5.2 空闲链表法我们也可以使用「链表」的方式来管理空闲空间，每一个空闲块里有一个指针指向下一个空闲块，这样也能很方便的找到空闲块并管理起来。\n当创建文件需要一块或几块时，就从链头上依次取下一块或几块。反之，当回收空间时，把这些空闲块依次接到链头上。\n这种技术只要在主存中保存一个指针，令它指向第一个空闲块。其特点是简单，但不能随机访问，工作效率低，因为每当在链上增加或移动空闲块时需要做很多 I&#x2F;O 操作，同时数据块的指针消耗了一定的存储空间。\n空闲表法和空闲链表法都不适合用于大型文件系统，因为这会使空闲表或空闲链表太大。\n\n\n\n\n5.3 位图法位图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。\n当值为 0 时，表示对应的盘块空闲，值为 1 时，表示对应的盘块已分配。它形式如下：\ntxt1111110011111110001110110111111100111 ...在 Linux 文件系统就采用了位图的方式来管理空闲空间，不仅用于数据空闲块的管理，还用于 inode 空闲块的管理，因为 inode 也是存储在磁盘的，自然也要有对其管理。\n6.文件系统的结构前面提到 Linux 是用位图的方式管理空闲空间，用户在创建一个新文件时，Linux 内核会通过 inode 的位图找到空闲可用的 inode，并进行分配。要存储数据时，会通过块的位图找到空闲的块，并分配，但仔细计算一下还是有问题的。\n数据块的位图是放在磁盘块里的，假设是放在一个块里，一个块 4K，每位表示一个数据块，共可以表示 4 * 1024 * 8 = 2^15 个空闲块，由于 1 个数据块是 4K 大小，那么最大可以表示的空间为 2^15 * 4 * 1024 = 2^27 个 byte，也就是 128M。\n也就是说按照上面的结构，如果采用「一个块的位图 + 一系列的块」，外加「一个块的 inode 的位图 + 一系列的 inode 的结构」能表示的最大空间也就 128M，这太少了，现在很多文件都比这个大。\n在 Linux 文件系统，把这个结构称为一个块组，那么有 N 多的块组，就能够表示 N 大的文件。\n下图给出了 Linux Ext2 整个文件系统的结构和块组的内容，文件系统都由大量块组组成，在硬盘上相继排布：\n\n最前面的第一个块是引导块，在系统启动时用于启用引导，接着后面就是一个一个连续的块组了，块组的内容如下：\n\n超级块，包含的是文件系统的重要信息，比如 inode 总个数、块总个数、每个块组的 inode 个数、每个块组的块个数等等。\n块组描述符，包含文件系统中各个块组的状态，比如块组中空闲块和 inode 的数目等，每个块组都包含了文件系统中「所有块组的组描述符信息」。\n数据位图和 inode 位图， 用于表示对应的数据块或 inode 是空闲的，还是被使用中。\ninode 列表，包含了块组中所有的 inode，inode 用于保存文件系统中与各个文件和目录相关的所有元数据。\n数据块，包含文件的有用数据。\n\n你可以会发现每个块组里有很多重复的信息，比如超级块和块组描述符表，这两个都是全局信息，而且非常的重要，这么做是有两个原因：\n\n如果系统崩溃破坏了超级块或块组描述符，有关文件系统结构和内容的所有信息都会丢失。如果有冗余的副本，该信息是可能恢复的。\n通过使文件和管理数据尽可能接近，减少了磁头寻道和旋转，这可以提高文件系统的性能。\n\n不过，Ext2 的后续版本采用了稀疏技术。该做法是，超级块和块组描述符表不再存储到文件系统的每个块组中，而是只写入到块组 0、块组 1 和其他 ID 可以表示为 3、 5、7 的幂的块组中。\n7.目录的存储基于 Linux 一切皆文件的设计思想，目录其实也是个文件，你甚至可以通过 vim 打开它，它也有 inode，inode 里面也是指向一些块。\n和普通文件不同的是，普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息。\n在目录文件的块中，最简单的保存格式就是列表，就是一项一项地将目录下的文件信息（如文件名、文件 inode、文件类型等）列在表里。\n列表中每一项就代表该目录下的文件的文件名和对应的 inode，通过这个 inode，就可以找到真正的文件。\n\n\n如果一个目录有超级多的文件，我们要想在这个目录下找文件，按照列表一项一项的找，效率就不高了。\n于是，保存目录的格式改成哈希表，对文件名进行哈希计算，把哈希值保存起来，如果我们要查找一个目录下面的文件名，可以通过名称取哈希。如果哈希能够匹配上，就说明这个文件的信息在相应的块里面。\nLinux 系统的 ext 文件系统就是采用了哈希表，来保存目录的内容，这种方法的优点是查找非常迅速，插入和删除也较简单，不过需要一些预备措施来避免哈希冲突。\n目录查询是通过在磁盘上反复搜索完成，需要不断地进行 I&#x2F;O 操作，开销较大。所以，为了减少 I&#x2F;O 操作，把当前使用的文件目录缓存在内存，以后要使用该文件时只要在内存中操作，从而降低了磁盘操作次数，提高了文件系统的访问速度。\n8.软链接和硬链接有时候我们希望给某个文件取个别名，那么在 Linux 中可以通过硬链接（*Hard Link*） 和软链接（*Symbolic Link*） 的方式来实现，它们都是比较特殊的文件，但是实现方式也是不相同的。\n硬链接是多个目录项中的「索引节点」指向一个文件，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表，所以硬链接是不可用于跨文件系统的。由于多个目录项都是指向一个 inode，那么只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。\n\n\n软链接相当于重新创建一个文件，这个文件有独立的 inode，但是这个文件的内容是另外一个文件的路径，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以软链接是可以跨文件系统的，甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。\n\n\n\n\n9.文件I&#x2F;O9.1 缓存与非缓存I&#x2F;O文件操作的标准库是可以实现数据的缓存，那么根据「是否利用标准库缓冲」，可以把文件 I&#x2F;O 分为缓冲 I&#x2F;O 和非缓冲 I&#x2F;O：\n\n缓冲 I&#x2F;O，利用的是标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件。\n非缓冲 I&#x2F;O，直接通过系统调用访问文件，不经过标准库缓存。\n\n这里所说的「缓冲」特指标准库内部实现的缓冲。\n比方说，很多程序遇到换行时才真正输出，而换行前的内容，其实就是被标准库暂时缓存了起来，这样做的目的是，减少系统调用的次数，毕竟系统调用是有 CPU 上下文切换的开销的。\n9.2 直接与非直接I&#x2F;OLinux 内核为了减少磁盘 I&#x2F;O 次数，在系统调用后，会把用户数据拷贝到内核中缓存起来，这个内核缓存空间也就是「页缓存」，只有当缓存满足某些条件的时候，才发起磁盘 I&#x2F;O 的请求。\n根据是「否利用操作系统的缓存」，可以把文件 I&#x2F;O 分为直接 I&#x2F;O 与非直接 I&#x2F;O：\n\n直接 I&#x2F;O，不会发生内核缓存和用户程序之间数据复制，而是直接经过文件系统访问磁盘。\n非直接 I&#x2F;O，读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写入数据到磁盘。\n\n如果你在使用文件操作类的系统调用函数时，指定了 O_DIRECT 标志，则表示使用直接 I&#x2F;O。如果没有设置过，默认使用的是非直接 I&#x2F;O。\n以下几种场景会触发内核缓存的数据写入磁盘：\n\n在调用 write 的最后，当发现内核缓存的数据太多的时候，内核会把数据写到磁盘上；\n用户主动调用 sync，内核缓存会刷到磁盘上；\n当内存十分紧张，无法再分配页面时，也会把内核缓存的数据刷到磁盘上；\n内核缓存的数据的缓存时间超过某个时间时，也会把数据刷到磁盘上；\n\n9.3 阻塞与非阻塞I&#x2F;O VS  同步与异步I&#x2F;O阻塞 I&#x2F;O，当用户程序执行 read ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，read 才会返回。\n注意，阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程。\n\n\n非阻塞 I&#x2F;O，非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，read 调用才可以获取到结果。\n\n\n注意，这里最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。\n为了解决程序每次轮询内核的I&#x2F;O上是否准备好的问题，产生了I&#x2F;O多路复用技术，如 select、poll，它是通过 I&#x2F;O 事件分发，当内核数据准备好时，再以事件通知应用程序进行操作。\n这个做法大大改善了 CPU 的利用率，因为当调用了 I&#x2F;O 多路复用接口，如果没有事件发生，那么当前线程就会发生阻塞，这时 CPU 会切换其他线程执行任务，等内核发现有事件到来的时候，会唤醒阻塞在 I&#x2F;O 多路复用接口的线程，然后用户可以进行后续的事件处理。\n整个流程要比阻塞 IO 要复杂，似乎也更浪费性能。但 I&#x2F;O 多路复用接口最大的优势在于，用户可以在一个线程内同时处理多个 socket 的 IO 请求。\n用户可以注册多个 socket，然后不断地调用 I&#x2F;O 多路复用接口读取被激活的 socket，即可达到在同一个线程内同时处理多个 IO 请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。\n下图是使用 select I&#x2F;O 多路复用过程。注意，read 获取数据的过程（数据从内核态拷贝到用户态的过程），也是一个同步的过程，需要等待：\n\n\n实际上，无论是阻塞 I&#x2F;O、非阻塞 I&#x2F;O，还是基于非阻塞 I&#x2F;O 的多路复用都是同步调用。因为它们在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。\n而真正的异步 I&#x2F;O 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。\n当我们发起 aio_read 之后，就立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。过程如下图：\n\n\n下面这张图，总结了以上几种 I&#x2F;O 模型：\n\n\n在前面我们知道了，I&#x2F;O 是分为两个过程的：\n\n数据准备的过程\n数据从内核空间拷贝到用户进程缓冲区的过程\n\n阻塞 I&#x2F;O 会阻塞在「过程 1 」和「过程 2」，而非阻塞 I&#x2F;O 和基于非阻塞 I&#x2F;O 的多路复用只会阻塞在「过程 2」，所以这三个都可以认为是同步 I&#x2F;O。\n异步 I&#x2F;O 则不同，「过程 1 」和「过程 2 」都不会阻塞。\n\n\n\n\n\n\n\n\n\n用故事去理解这几种 I&#x2F;O 模型\n举个你去饭堂吃饭的例子，你好比用户程序，饭堂好比操作系统。\n阻塞 I&#x2F;O 好比，你去饭堂吃饭，但是饭堂的菜还没做好，然后你就一直在那里等啊等，等了好长一段时间终于等到饭堂阿姨把菜端了出来（数据准备的过程），但是你还得继续等阿姨把菜（内核空间）打到你的饭盒里（用户空间），经历完这两个过程，你才可以离开。\n非阻塞 I&#x2F;O 好比，你去了饭堂，问阿姨菜做好了没有，阿姨告诉你没，你就离开了，过几十分钟，你又来饭堂问阿姨，阿姨说做好了，于是阿姨帮你把菜打到你的饭盒里，这个过程你是得等待的。\n基于非阻塞的 I&#x2F;O 多路复用好比，你去饭堂吃饭，发现有一排窗口，饭堂阿姨告诉你这些窗口都还没做好菜，等做好了再通知你，于是等啊等（select 调用中），过了一会阿姨通知你菜做好了，但是不知道哪个窗口的菜做好了，你自己看吧。于是你只能一个一个窗口去确认，后面发现 5 号窗口菜做好了，于是你让 5 号窗口的阿姨帮你打菜到饭盒里，这个打菜的过程你是要等待的，虽然时间不长。打完菜后，你自然就可以离开了。\n异步 I&#x2F;O 好比，你让饭堂阿姨将菜做好并把菜打到饭盒里后，把饭盒送到你面前，整个过程你都不需要任何等待。\n","slug":"OS-文件系统","date":"2024-06-07T06:25:12.000Z","categories_index":"Study","tags_index":"学习,操作系统","author_index":"Fioransh"},{"id":"1074313276193b1539ba5882aa8b135e","title":"OS-调度算法","content":"1.进程调度算法当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。\n非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。\n抢占式调度，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。\n什么时候会发生 CPU 调度呢？通常有以下情况：\n\n当进程从运行状态转到等待状态；\n当进程从运行状态转到就绪状态；\n当进程从等待状态转到就绪状态；\n当进程从运行状态转到终止状态；\n\n其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。\n1.1 先来先服务算法FCFS最简单的一个调度算法，就是非抢占式的先来先服务（*First Come First Severd, FCFS*）算法了。\n\n顾名思义，先来后到，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。\n这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。\nFCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I&#x2F;O 繁忙型作业的系统。\n\n1.2 最短作业优先调度算法SJF&#x2F;SPN最短作业优先（*Shortest Job First, SJF*）调度算法同样也是顾名思义，它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。\n\n这显然对长作业不利，很容易造成一种极端现象。\n比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。\n\n1.3 高响应比优先调度算法HRRN前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。\n那么，高响应比优先 （*Highest Response Ratio Next, HRRN*）调度算法主要是权衡了短作业和长作业。\n每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：\n\n\n从上面的公式，可以发现：\n\n如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；\n如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；\n\n\n1.4 时间片轮转调度算法RR最古老、最简单、最公平且使用最广的算法就是时间片轮转（*Round Robin, RR*）调度算法。\n\n每个进程被分配一个时间段，称为时间片（*Quantum*），即允许该进程在该时间段中运行。\n\n如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；\n如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；\n\n另外，时间片的长度就是一个很关键的点：\n\n如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；\n如果设得太长又可能引起对短作业进程的响应时间变长。将\n\n通常时间片设为 20ms~50ms 通常是一个比较合理的折中值。\n\n1.5 最高优先级调度算法HPF前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。\n但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（*Highest Priority First，HPF*）调度算法。\n进程的优先级可以分为，静态优先级或动态优先级：\n\n静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；\n动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。\n\n该算法也有两种处理优先级高的方法，非抢占式和抢占式：\n\n非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。\n抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。\n\n但是依然有缺点，可能会导致低优先级的进程永远不会运行。\n\n\n1.6 多级反馈队列调度算法MFQ多级反馈队列（*Multilevel Feedback Queue*）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。\n顾名思义：\n\n「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。\n「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；\n\n\n来看看，它是如何工作的：\n\n设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短；\n新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；\n当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；\n\n可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。\n\n2.内存页面置换算法缺页异常（缺页中断）\n当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：\n\n缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。\n缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。\n\n我们来看一下缺页中断的处理流程，如下图：\n\n\n找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。\n这里提一下，页表项通常有如下图的字段：\n\n那其中：\n\n状态位：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。\n访问字段：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。\n修改位：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。\n硬盘地址：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。\n\n虚拟内存的管理整个流程：\n\n\n所以，页面置换算法的功能是，当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。\n2.1 最佳页面置换算法OPT最佳页面置换算法基本思路是，置换在「未来」最长时间不访问的页面。\n所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。\n这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。\n所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。\n\n2.2 先进先出置换算法FIFO既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以选择在内存驻留时间很长的页面进行中置换，这个就是「先进先出置换」算法的思想。\n\n2.3 最近最久未使用的置换算法LRU最近最久未使用（LRU）的置换算法的基本思路是，发生缺页时，选择最长时间没有被访问的页面进行置换，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。\n这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。\n虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。\n困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。\n所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。\n\n2.4 时钟页面置换算法时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。\n该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。\n当发生缺页中断时，算法首先检查表针指向的页面：\n\n如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；\n如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；\n\n我画了一副时钟页面置换算法的工作流程图，你可以在下方看到：\n\n2.5 最不常用算法LFU最不常用（LFU）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。\n它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。\n看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。\n要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。\n但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。\n那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。\n3.磁盘调度算法磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。\n寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。\n3.1 先来先服务FCFS先来先服务（First-Come，First-Served，FCFS），顾名思义，先到来的请求，先被服务。\n这种算法，比较简单粗暴，但是如果大量进程竞争使用磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过长。\n\n3.2 最短寻道时间优先SSTF最短寻道时间优先（Shortest Seek First，SSF）算法的工作方式是，优先选择从当前磁头位置所需寻道时间最短的请求\n\n但这个算法可能存在某些请求的饥饿，因为本次例子我们是静态的序列，看不出问题，假设是一个动态的请求，如果后续来的请求都是小于 183 磁道的，那么 183 磁道可能永远不会被响应，于是就产生了饥饿现象，这里产生饥饿的原因是磁头在一小块区域来回移动。\n3.3 扫描算法SCAN最短寻道时间优先算法会产生饥饿的原因在于：磁头有可能再一个小区域内来回得移动。\n为了防止这个问题，可以规定：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向，这就是扫描（*Scan*）算法。\n这种算法也叫做电梯算法，比如电梯保持按一个方向移动，直到在那个方向上没有请求为止，然后改变方向。\n磁头先响应左边的请求，直到到达最左端（ 0 磁道）后，才开始反向移动，响应右边的请求。\n扫描调度算法性能较好，不会产生饥饿现象，但是存在这样的问题，中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。\n\n3.4 循环扫描算法C-SCAN扫描算法使得每个磁道响应的频率存在差异，那么要优化这个问题的话，可以总是按相同的方向进行扫描，使得每个磁道的响应频率基本一致。\n循环扫描（Circular Scan, CSCAN ）规定：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。\n\n磁头先响应了右边的请求，直到碰到了最右端的磁道 199，就立即回到磁盘的开始处（磁道 0），但这个返回的途中是不响应任何请求的，直到到达最开始的磁道后，才继续顺序响应右边的请求。\n循环扫描算法相比于扫描算法，对于各个位置磁道响应频率相对比较平均。\n3.5 LOOK和C-LOOK算法我们前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。\n那这其实是可以优化的，优化的思路就是磁头在移动到「最远的请求」位置，然后立即反向移动。\n那针对 SCAN 算法的优化则叫 LOOK 算法，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中会响应请求。\n\n\n而针 C-SCAN 算法的优化则叫 C-LOOK，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中不会响应请求。\n","slug":"OS-调度算法","date":"2024-06-04T14:25:12.000Z","categories_index":"Study","tags_index":"学习,操作系统","author_index":"Fioransh"},{"id":"a8e53f71d8296af4285fe02496a3f129","title":"OS-虚拟内存","content":"1.虚拟内存1.1 引入单片机的CPU是直接操作内存的 [物理地址]\n此时不能同时在内存运行两个程序，如何解决？\n1.2 操作系统如何解决这个问题问题在于两个程序都引用了绝对物理地址，要避免。\n因此操作系统把进程所使用的地址隔离开，为每个进程都分配独立的一套**[虚拟地址]**，互不干涉，每个进程都不能访问物理地址。\n操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。\n如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。\n于是，这里就引出了两种地址的概念：\n\n我们程序所使用的内存地址叫做虚拟内存地址（Virtual Memory Address）\n实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address）。\n\n操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：\n\n\n\n\n1.3 OS如何管理虚拟地址和物理地址之间的关系主要通过内存分段和内存分页来管理。\n2.内存分段程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段（*Segmentation*）的形式把这些段分离出来。\n2.1 分段机制下，虚拟地址和物理地址如何映射分段机制下的虚拟地址由两部分组成，段选择因子和段内偏移量。\n\n\n段选择因子和段内偏移量：\n\n段选择子就保存在段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。\n虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。\n\n在上面，知道了虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址。\n\n如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 &#x3D; 7500。\n分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：\n\n第一个就是内存碎片的问题。\n第二个就是内存交换的效率低的问题。\n\n2.2 分段产生内存碎片问题如图\n\n2.3 内存分段会出现内存碎片吗内存碎片主要分为，内部内存碎片和外部内存碎片。\n内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以不会出现内部内存碎片。\n但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以会出现外部内存碎片的问题。\n解决「外部内存碎片」的问题就是内存交换。\n\n\n\n\n\n\n\n\n\n可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。\n这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。\n2.4 分段为什么导致内存交换效率低硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。\n如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。\n为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页。\n3.内存分页当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是内存分页（Paging）。\n分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。\n虚拟地址与物理地址之间通过页表来映射，如下图：\n\n\n页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。\n而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。\n3.1 分页如何解决「外部内存碎片和内存交换效率低」的问题内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。\n但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有内部内存碎片的现象。\n如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。\n\n更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。\n3.2 分页机制下，虚拟地址和物理地址都是如何映射在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。\n\n总结一下，对于一个内存地址转换，其实就是这样三个步骤：\n\n把虚拟内存地址，切分成页号和偏移量；\n根据页号，从页表里面，查询对应的物理页号；\n直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。\n\n3.3 简单分页的缺陷有空间上的缺陷。\n因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。\n3.4 多级页表要解决上面的问题，就需要采用一种叫作多级页表（Multi-Level Page Table）的解决方案。\n\n\n\n\n页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表\n把二级分页再推广到多级页表，就会发现页表占用的内存空间更少了，这一切都要归功于对局部性原理的充分应用。\n对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是：\n\n全局页目录项 PGD（Page Global Directory）；\n上层页目录项 PUD（Page Upper Directory）；\n中间页目录项 PMD（Page Middle Directory）；\n页表项 PTE（Page Table Entry）；\n\n\n\n\n\n3.5 TLB多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。\n我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为页表缓存、转址旁路缓存、快表等。\n在 CPU 芯片里面，封装了内存管理单元（Memory Management Unit）芯片，它用来完成地址转换和 TLB 的访问与交互。\n有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。\nTLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。\n4.段页式内存管理内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理。\n段页式内存管理实现的方式：\n\n先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；\n接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；\n\n这样，地址结构就由段号、段内页号和页内位移三部分组成。\n用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号\n\n段页式地址变换中要得到物理地址须经过三次内存访问：\n\n第一次访问段表，得到页表起始地址；\n第二次访问页表，得到物理页号；\n第三次将物理页号与页内位移组合，得到物理地址。\n\n可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。\n5.Linux内存管理页式内存管理的作用是在由段式内存管理所映射而成的地址上再加上一层地址映射。\n由于此时由段式内存管理映射而成的地址不再是“物理地址”了，Intel 就称之为“线性地址”（也称虚拟地址）。于是，段式内存管理先将逻辑地址映射成线性地址，然后再由页式内存管理将线性地址映射成物理地址。\nLinux 内存主要采用的是页式内存管理，但同时也不可避免地涉及了段机制。\nLinux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。\n在 Linux 操作系统中，虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示：\n\n通过这里可以看出：\n\n32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间；\n64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。\n\n再来说说，内核空间与用户空间的区别：\n\n进程在用户态时，只能访问用户空间内存；\n只有进入内核态后，才可以访问内核空间的内存；\n\n虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。\n\n接下来，进一步了解虚拟空间的划分情况，用户空间和内核空间划分的方式是不同的，内核空间的分布情况就不多说了。\n我们看看用户空间分布的情况，以 32 位系统为例，我画了一张图来表示它们的关系：\n\n通过这张图你可以看到，用户空间内存，从低到高分别是 6 种不同的内存段：\n\n代码段，包括二进制可执行代码；\n数据段，包括已初始化的静态常量和全局变量；\nBSS 段，包括未初始化的静态变量和全局变量；\n堆段，包括动态分配的内存，从低地址开始向上增长；\n文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 (opens new window)）；\n栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；\n\n上图中的内存布局可以看到，代码段下面还有一段内存空间的（灰色部分），这一块区域是「保留区」，之所以要有保留区这是因为在大多数的系统里，我们认为比较小数值的地址不是一个合法地址，例如，我们通常在 C 的代码里会将无效的指针赋值为 NULL。因此，这里会出现一段不可访问的内存保留区，防止程序因为出现 bug，导致读或写了一些小内存地址的数据，而使得程序跑飞。\n在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap() ，就可以分别在堆和文件映射段动态分配内存。\n6.总结为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套虚拟地址空间，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。\n每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过内存交换技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。\n那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。\n那么对于虚拟地址与物理地址的映射关系，可以有分段和分页的方式，同时两者结合都是可以的。\n内存分段是根据程序的逻辑角度，分成了栈段、堆段、数据段、代码段等，这样可以分离出不同属性的段，同时是一块连续的空间。但是每个段的大小都不是统一的，这就会导致外部内存碎片和内存交换效率低的问题。\n于是，就出现了内存分页，把虚拟空间和物理空间分成大小固定的页，如在 Linux 系统中，每一页的大小为 4KB。由于分了页后，就不会产生细小的内存碎片，解决了内存分段的外部内存碎片问题。同时在内存交换的时候，写入硬盘也就一个页或几个页，这就大大提高了内存交换的效率。\n再来，为了解决简单分页产生的页表过大的问题，就有了多级页表，它解决了空间上的问题，但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加大了时间上的开销。于是根据程序的局部性原理，在 CPU 芯片中加入了 TLB，负责缓存最近常被访问的页表项，大大提高了地址的转换速度。\nLinux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理。于是 Linux 就把所有段的基地址设为 0，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。\n另外，Linux 系统中虚拟空间分布可分为用户态和内核态两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。\n6.1 虚拟内存有什么作用\n第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。\n第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。\n第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。\n\n","slug":"OS-虚拟内存","date":"2024-06-04T12:25:12.000Z","categories_index":"Study","tags_index":"学习,操作系统","author_index":"Fioransh"},{"id":"77c1bfd730d0b976f5020ec70d93bbca","title":"OS-课后作业题目总结","content":"第一章1.一台计算机包括高速缓存、内存和磁盘，如果要存取的字在高速缓存中，从高速缓存存取需要20ns；如果该字不在高速缓存中而在内存中，先把它从内存载入高速缓存需要60ns，然后再从高速缓存存取；如果该字不在内存中，则先需要花费12ms从磁盘中取到内存，接着从内存复制到高速缓存中，再从高速缓存存取。高速缓存的命中率为0.9，内存的命中率为0.6，则该系统中一个字的平均存取时间是多少ns？\n解答：\n\n平均存取时间为：0.9×20 + 0.06×80 + 0.04×12000080 &#x3D; 480026 ns\n2.假设系统中有两个程序A和B待执行，设以A、B的先后顺序运行，不能互相抢占CPU。程序A的访问流程是：处理器10秒，设备甲5秒，处理器5秒，设备乙10秒，处理器10秒；程序B的访问流程是：设备甲10秒，处理器10秒，设备乙5秒，处理器5秒，设备乙10秒。在单道程序环境下和多道程序环境下执行，处理器的利用率是分别是多少？\n解答：\n单道CPU利用率：(10+5+10+10+5)\\80＝50％\n\n多道CPU利用率：(10+5+10+10+5)\\45＝88.9％ \n\n第二章1.假设在时间5时，系统资源只有处理器和内存被使用。考虑如下事件：时间5：P1执行对磁盘单元3的读操作。时间15：P5的时间片结束。时间18：P7执行对磁盘单元3的写操作。时间20：P3执行对磁盘单元2的读操作。时间24：P5执行对磁盘单元3的写操作。时间28：P5被换出。时间33：P3读磁盘单元2操作完成，产生中断。时间36：P1读磁盘单元3操作完成，产生中断。时间38：P8结束。时间40：P5写磁盘单元3操作完成，产生中断。时间44：P5被调入。时间48：P7写磁盘单元3操作完成，产生中断。请分别写出时间22、37和47时每个进程的状态。如果一个进程在阻塞态，写出其等待的事件。\n解答：\n\n注：47时刻，P1、P3、P5中有两个就绪，另一个运行\n2.某分时系统中的进程可能出现如下图所示的状态变化，请把图中每个状态变化以及变化的可能原因填写在下表中。\n\n解答：\n\n3.写出信号量定义，semWait和semSignal原语，以及用信号量实现互斥的伪代码。\n解答：\n\n\n4.假设一个阅览室有100个座位，没有座位时读者在阅览室外等待；每个读者进入阅览室时都必须在阅览室门口的一个登记本上登记座位号和姓名，然后阅览，离开阅览室时要去掉登记项。每次只允许一个人登记或去掉登记。用信号量操作描述读者的行为。\n解答：\ncppsemaphore seatcount=100;  //空座位数\nsemaphore mutex=1;            //互斥操作登记本\nvoid readeri()&#123;                             \n  while(true)&#123;\n      semWait(seatcount);\n      semWait (mutex)；\n            登记；\n      semSignal (mutex);\n         进入阅览室坐下读书；\n      semWait (mutex);\n           取消登记；\n      semSignal(mutex);\n      semSignal(seatcount);\n          离开阅览室；\n&#125;&#125;5.6个进程：P0…P5；4种资源：A(15)、B(6)、C(9)、D(10)； T0时刻状态如图所示。问题：（1）验证可用资源向量的正确性。（2）计算需求矩阵。（3）指出一个安全的进程序列来证明当前状态的安全性。同时指出每个进程结束时可用资源向量的变化情况。（4）假设P5请求资源（3, 2, 3, 3），该请求应该被允许吗？请说明理由。\n\n解答：\n\n2+0+4+1+1+1+6&#x3D;150+1+1+0+1+0+3&#x3D;62+1+0+0+0+1+5&#x3D;91+1+2+1+0+1+4&#x3D;10因此，可用资源向量正确。\n\n\n\n\n6.如下的代码涉及3个进程竞争6种资源（A~F）。（1）使用资源分配图来指出这种实现中可能存在的死锁。（2）改变某些请求的顺序来预防死锁。注意不能跨函数移动请求，只能在函数内部调整请求的顺序。\n\n解答：\n\n\n\n\n第三章1.假设使用动态分区，下图是经过数次放置和换出操作后的内存格局。内存地址从左到右增长；灰色区域是分配给进程的内存块；白色区域是可用内存块。空闲块分配总是从左到右（从低地址端到高地址端）。最后一个放置的进程A大小为2MB，用X标记。此后仅换出了一个进程B。（1）换出的进程B最大是多少？（2）从一个空闲块K中，分配2MB给进程A，那么分配之前，这个空闲块K的大小是多少？（3）下一个内存需求大小为3MB。在使用最佳适配&#x2F;首次适配&#x2F;下次适配&#x2F;最差适配的情况下，分别在图上标记出分配的内存区域。\n\n解答：\n（1）换出的最大进程大小是多少？1M（2）创建分区并分配给X之前，空闲块的大小是多少？7M（3）下一个内存需求大小为3MB。在使用最佳适配&#x2F;首次适配&#x2F;下次适配&#x2F;最差适配的情况下，分别在图上标记出分配的内存区域\n\n2.一个1MB的内存块使用伙伴系统来分配内存。请画出类似图3.5的图来表示如下序列的结果：A:请求70；B:请求35；C:请求80；释放A；D:请求60；释放B；释放D；释放C。\n解答：\n\n3.在一个简单分段系统中，包含如下图所示段表，对下面的每一个逻辑地址，确定其对应的物理地址或者说明段错误是否会发生。(1) 0,198      (2)  2,156      (3)  1,530      (4)  3,444      (5)  0,222\n\n解答：\n（1）660+198&#x3D;858（2）222+156&#x3D;378（3）段错误，因为530&gt;422（4）996+444&#x3D;1440（5）660+222&#x3D;882\n4.页式存储管理系统中，某进程页表如下。已知页面大小为1024字节，问逻辑地址600，2700，4000所对应的物理地址各是多少？\n\n解答：\n600&#x2F;1024&#x3D;0…600    71024+600&#x3D;77682700&#x2F;1024&#x3D;2…652   51024+652&#x3D;57724000&#x2F;1024&#x3D;3…928   非法地址\n5.考虑如下的页访问序列:7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2，请画图说明FIFO、LRU、最佳置换算法（假设后续页面访问序列 1, 2, 0, 1, 7, 0, 1）这三种算法的页框的分配情况（假设该进程分配三个物理块）；对每种情况计算缺页中断次数和缺页率。\n解答：\nFIFO算法：共缺页10次，缺页率 p&#x3D;10&#x2F;13&#x3D;76.9%\n\n LRU算法：共缺页9次，缺页率 p&#x3D;9&#x2F;13&#x3D;69.2%\n\n OPT算法：共缺页7次，缺页率 p&#x3D;7&#x2F;13&#x3D;53.8%\n\n6.考虑一个使用单级页表的分页系统。假设所需的页表总在内存中。（1）如果一次物理内存访问耗时200ns，那么一次逻辑内存访问耗时多少？\n（2）现在添加一个MMU，对每次命中或缺页MMU造成20ns开销。假设85%的内存访问都命中MMU TLB。有效访问时间（EMAT）是多少？\n（3）解释TLB命中率是如何影响EMAT的？\n解答：\n\n200 * 2&#x3D;400（ns）\n（20+200）* 85%+（20+200+200）* 15%&#x3D;250（ns）\nTLB的命中率越大，有效访问时间越小。\n\n第四章1.从A到E的5个进程同时到达计算中心，它们的估计运行时间分别为15、9、3、6和12分钟，优先级分别为6、3、7、9和4（值越小，表示的优先级越高），所有进程都完全是处理器密集型的。对下面的每种调度算法，确定所有作业的平均周转时间和平均带权周转时间（忽略进程切换的开销）。（1）时间片为1分钟的轮转法。（2）优先级调度。（3）FCFS（按A到E的顺序）。（4）最短进程优先。（5）最高响应比优先。\n解答：\n\n\n\n\n\n\n\n\n\n\n\n\n2.在一个三道批处理系统中（N道批处理是指至多允许N个作业进入内存，内存中至多允许N个进程存在，不能进入内存的作业将在后备作业队列中等待），作业调度采用最短作业优先调度算法，进程调度采用以优先级为基础的抢占式调度算法。在下表所示的序列中，所有进程都完全是处理器密集型的，优先数表示进程优先级，此题中优先数越小则优先级越高。试填充表中空白部分。\n解答：\n\n\n3.考虑一组周期任务，执行简表如下，给出100个单位时间内，基于最早完成期限调度算法的调度图。\n\n解答：\n\n4.考虑5个非周期任务，执行简表如下，给出调度这5个任务，基于有自愿空闲时间的最早最后期限调度算法的调度图。\n\n解答：\n\n第五章1.分析下列磁道请求序列：27，129，110，186，147，41，10，64，120。假设磁头当前定位在磁道100处。对以下两种移动方向，分别应用FCFS、SSTF、SCAN、C-SCAN算法，求磁道访问顺序及平均寻道长度。（1）沿着磁道号减小的方向移动。（2）沿着磁道号增大的方向移动。\n解答：\nFCFS平均寻道长度：556&#x2F;9&#x3D;61.8\n\nSSTF平均寻道长度：262&#x2F;9&#x3D;29.1\n\n小方向SCAN平均寻道长度：266&#x2F;9&#x3D;29.6\n\n小方向C-SCAN平均寻道长度：342&#x2F;9&#x3D;38\n\n大方向SCAN平均寻道长度：262&#x2F;9&#x3D;29.1\n\n大方向C-SCAN平均寻道长度：316&#x2F;9&#x3D;35.1\n\n2.现有一个RAID磁盘阵列，包含4个磁盘，每个磁盘大小都是200GB。请给出RAID级别分别是0、1、3、4、5、6时，该磁盘阵列的有效存储容量是多少。RAID0：800GB；RAID1：400GB；RAID3：600GB；RAID4：600GB；RAID5：600GB；RAID6：400GB。\n解答：\n\nRAID0：4个盘均存储数据，4200&#x3D;800；\nRAID1：2个盘存储，2个盘备份，2200&#x3D;400；\nRAID3-5：3个盘存储，1个盘校验，3200&#x3D;600；\nRAID6：2个盘存储，2个盘校验，2200&#x3D;400。\n\n\n","slug":"OS-课后作业题目","date":"2024-05-12T10:25:12.000Z","categories_index":"Study","tags_index":"学习,操作系统","author_index":"Fioransh"},{"id":"5ace535680a97380947dc34f832b3150","title":"OS-期末简答题复习","content":"OS简答题第一章3.简述中断技术工作原理\n中断是指处理器对系统中发生的异步事件的响应。异步事件是指随机发生的、非预期的事件，处理器不能预知这些事件发生的时刻，但当这些事件发生时必须对事件及时处理。\n\n在程序执行过程中，当发生异步事件时，处理器将收到一个中断请求信号，于是处理器将暂停当前程序的运行而转去处理该事件（执行相应的中断处理程序），处理完毕后又返回到原程序的断点继续执行或调度新的程序运行。\n\n\n4.多中断的处理方案包括哪些顺序处理多个中断\n\n当正在处理一个中断时，禁止中断，顺序处理所发生的各个中断。\n\n嵌套处理多个中断\n\n定义中断优先级，允许高优先级中断打断低优先级中断的处理过程。\n\n6.简述高速缓存的工作原理\n高速缓冲存储器是比主存小而快的存储器，用于解决CPU处理速率和主存访问速率差异过大的问题。CPU将内存中的数据读到高速缓存时，会根据局部性原理，除了读取本次要访问的数据，还会预取本次数据的周边数据到高速缓存里；如果CPU后续读取的数据已经在高速缓存，将会有效提升数据传输性能。\n\n8.什么是多道程序设计\n多道批处理系统把多个作业同时放入内存，并允许它们在处理器上交替运行，共享系统中的各项硬件资源和软件资源。当某个作业因I&#x2F;O请求而暂停运行时，处理器便可以转向运行另外一个等待运行的作业，以提高处理器利用率。这种处理方式称为多道程序设计。\n\n第二章1.简要定义五状态进程模型中的每种状态\n新建态：刚刚创建的进程。\n\n就绪态：进程做好了准备，只要有机会就可执行。\n\n运行态：正在执行。\n\n阻塞态：进程在某些事件发生前不能执行。\n\n退出态：操作系统从可执行进程组中释放出的进程，自身停止或者因为某种原因被取消。\n\n\n3.模式切换和进程切换有何种区别\n发生模式切换可以不改变正处于运行态的进程状态，这种情况下，保存上下文环境和以后恢复上下文环境只需要很少的开销。\n\n发生进程切换时，正在运行的进程被转换到另一个状态（就绪或阻塞等），操作系统必须使其环境产生实质性的变化，比模式切换需要做更多的工作。\n\n\n5.列出用户级线程相对于内核线程的三个优点（1）线程切换不需要内核态特权，节省了两次状态转换的开销。\n（2）调度可以是应用程序相关的。\n（3）用户级线程可以在任何操作系统中运行，不需要对底层内核进行修改以支持用户级线程。\n6.列出用户级线程相对于内核线程的三个优点（1）用户级线程执行一个系统调用时，进程中的所有线程都会被阻塞。\n（2）不能利用多处理器结构。\n8.列出互斥的要求（1）必须强制实施互斥。在与相同资源或共享对象的临界区有关的所有进程中，一次只允许一个进程进入临界区。\n（2）不允许出现需要访问临界区的进程被无限延迟的情况，即不会死锁或饥饿。\n（3）当没有进程在临界区时，任何需要进入临界区的进程必须能够立即进入。\n（4）一个进程驻留在临界区中的时间必须是有限的。\n9.产生死锁的四个条件是什么\n互斥\n\n占有且等待\n\n不可抢占\n\n循环等待\n\n\n10.死锁避免、检测和预防之间的区别是什么死锁避免通过限制进程启动或资源分配，预防通过运用某种策略来消除产生死锁的四个条件之一，来保证不让死锁状态出现；而检测允许死锁出现，定期检测死锁的存在并从死锁中恢复出来。\n第三章1.为什么需要重定位进程的能力首先，程序员并不能事先知道在某个程序执行期间会有其他哪些程序驻留在内存中。其次，为了提高处理器的利用率，允许进程换入或换出内存，当被换出内存的进程下一次被换入时，没必要也很那做到放在换出前的位置。因此，需要重定位技术。\n2.页和页框之间有什么区别内存被划分成大小固定相等的小块，称为页框，每个进程被分成同样大小的小块，称为页。因此，页是逻辑上的划分，而页框是物理内存的划分，一页匹配一个页框。\n3.解释什么是抖动抖动是虚存管理方案中可能出现的一种现象，处理器花费在交换上的时间多于执行指令的时间。\n4.转换检测缓冲区的目的是什么TLB是一个缓冲，包含最近一段时间频繁用到的页表项，目的是减少数据访问需要的时间。\n5.驻留集和工作集有什么区别驻留集是指进程当前在内存里的页面集合，而工作集是指进程最近被引用过的页面集合。\n第四章1.简要描述三种类型的处理器调度\n长程调度：其调度对象是作业，主要功能是决定将后备作业队列中的哪几个作业调入内存，为它们创建进程，并放入就绪进程队列。\n\n中程调度：根据系统并发度的要求，完成外存和内存中的进程对换；\n\n短程调度：其调度对象是进程，调度程序根据调度算法来选择一个新的就绪进程，使之占用处理器运行。\n\n\n2.抢占式调度和非抢占式调度有何区别\n非抢占式：一旦调度某个进程到处理器上执行，则当前进程将一直运行下去，直至其运行完毕或发生某事件而阻塞不能继续运行时，才再次调度并分配处理器。\n\n抢占式：当前进程正在处理器上执行，操作系统中的调度器可以根据实际需求和既定原则，剥夺其处理器所有权并将其转换为就绪态，然后调度另外一个就绪进程到处理器上运行。\n\n\n第五章1.说明中断驱动I&#x2F;O方式与DMA方式有什么不同？控制方式及其主要优缺点。在中断控制方式中，当外部设备准备好数据或发生错误后，主动向CPU发出中断请求；CPU调用相应的中断处理程序，完成CPU与外部设备之间的一次数据交换。\n\n优缺点：CPU与外部设备可并行工作，仅当输入完一个数据时，才需要CPU花费极短的时间去做一次中断处理，这样可提高整个系统的资源利用率和吞吐率。但中断次数急剧增加时，CPU负担很重。\n\nDMA方式直接通过系统总线在DMA控制器的缓冲区和内存之间进行双向数据传送。\n\n优缺点：在设备和内存之间直接传输数据块；一个数据块全部传送完毕后，才发出一次中断，大大减少了CPU进行中断处理的次数。提高了传输速率和CPU利用率。\n\n5.缓冲技术有什么作用？缓和CPU与I&#x2F;O设备间速度不匹配的矛盾，提高CPU和I&#x2F;O设备间的并行性。协调逻辑记录和物理记录大小不一致的问题。减少I&#x2F;O中断次数，放宽对CPU中断响应时间的要求。\n第六章4.简单定义三种记录组块的方法。\n固定组块：使用固定长度的记录，并且若干条完整的记录被保存在一个块中。在每个块的末尾可能会有一些未使用的空间，称为内部碎片。\n可变长度跨越式组块：使用长度可变的记录，并且紧缩到块中，使得块中没有未使用空间。因此，某些记录可能会跨越两个块，通过一个指向后继块的指针连接。\n可变长度非跨越式组块：使用可变长度的记录，但并不采用跨越的方式。如果下一条记录比块中剩余的未使用空间大，则无法使用这一部分，因此在大多数块中都会有未使用的空间。\n\n5.简单定义三种文件分配方法。\n连续分配：是指在创建文件时，给文件分配一组连续的块。\n链式分配：基于单个的块，链中的每一块都包含指向下一块的指针。\n索引分配：每个文件在文件分配表中有一个一级索引，分配给该文件的每个分区在索引中都有一个表项。\n\n","slug":"OS-简答题","date":"2024-05-10T10:25:12.000Z","categories_index":"Study","tags_index":"学习,操作系统","author_index":"Fioransh"},{"id":"dd1d0aeec4afc2eb6977d05e1c00c07e","title":"Linux基础总结","content":"1.Linux入门1.1 操作系统概述操作系统是计算机软件的一种，它主要负责：\n作为用户和计算机硬件之间的桥梁，调度和管理计算机硬件进行工作。\n常见的操作系统：\nPC端：Windows、Linux、MacOS\n移动端：Android、IOS、鸿蒙系统\n1.2 初识LinuxLinux创始人: 林纳斯 托瓦兹     开发于1991年\nLinux系统的组成：Linux系统内核+系统级应用程序\n\n内核：提供系统最核心的功能，如：调度CPU、调度内存、调度文件系统、调度网络通讯、调度IO等。\n\n系统级应用程序：可以理解为出厂自带程序，可供用户快速上手操作系统，如：文件管理器、任务管理器、图片查看、音乐播放等。\n\n\nLinux内核是免费开源的，任何人都可以下载内核源码并查看且修改。\n可以通过：https://www.kernel.org  去下载Linux内核\n内核是免费、开源的，这也就代表了：\n\n任何人都可以获得并修改内核，并且自行集成系统级程序\n\n提供了内核+系统级程序的完整封装，称之为Linux发行版\n\n\n任何人都可以封装Linux，目前市面上由非常多的Linux发行版，常用的、知名的如下：CentOS、Ubuntu等\n1.3 虚拟机介绍借助虚拟化技术，我们可以在系统中，通过软件：模拟计算机硬件，并给虚拟硬件安装真实的操作系统。\n我们不能给自己电脑重装系统为Linux，所以通过虚拟机的形式，得到可以用的Linux系统环境，供后续学习使用。\n1.4 VMware安装Linux系统省略\n1.5 远程连接Linux系统我们使用VMware可以得到Linux虚拟机，但是在VMware中操作Linux的命令行页面不太方便。可以通过第三方软件，FinalShell，远程连接到Linux操作系统。\nFinalShell的下载地址为：\nWindows: http://www.hostbuf.com/downloads/finalshell_install.exe\nMac: http://www.hostbuf.com/downloads/finalshell_install.pkg\n首先，先查询到Linux系统的IP地址\n\n打开Finshell软件，配置到Linux系统的连接 \n\n\n打开连接管理器，双击刚刚配置好的连接，点击接受并保存\n\n1.6 WSLWSL：Windows Subsystem for Linux，是用于Windows系统之上的Linux子系统。\n作用很简单，可以在Windows系统中获得Linux系统环境，并完全直连计算机硬件，无需通过虚拟机虚拟硬件。\nWSL是Windows10自带功能，需要开启，无需下载，点击确定开启后会自动部署\n打开Windows应用商店，选择Ubuntu并获取安装，然后点击启动\n\n\nUbuntu自带的终端窗口软件不太好用，我们可以使用微软推出的：Windows Terminal软件\n1.7 虚拟机快照的制作和还原如果损坏了Linux系统的话，重新安装一个Linux操作系统就会十分麻烦。\nVMware虚拟机（Workstation和Funsion）支持为虚拟机制作快照。\n通过快照将当前虚拟机的状态保存下来，在以后可以通过快照恢复虚拟机到保存的状态。\n\n2.Linux基础2.1 Linux的目录结构Linux的目录结构是一个树型结构\nLinux没有盘符这个概念, 只有一个根目录 &#x2F;, 所有文件都在它下\n在Linux系统中，路径之间的层级关系，使用：&#x2F; 来表示\n2.2 Linux命令入门无论是什么命令，用于什么用途，在Linux中，命令有其通用的格式：\ncommand： 命令本身\n-options：[可选，非必填]命令的一些选项，可以通过选项控制命令的行为细节\nparameter：[可选，非必填]命令的参数，多数用于命令的指向目标等\n2.3 ls命令ls命令的作用是列出目录下的内容，语法细节如下：\nls [-a -l -h] [Linux路径]\n\n-a -l -h 是可选的选项\n\n-a选项，表示：all的意思，即列出全部文件（包含隐藏的文件&#x2F;文件夹）\n-l选项，表示：以列表（竖向排列）的形式展示内容，并展示更多信息\n语法中的选项是可以组合使用的，比如学习的-a和-l可以组合应用\n-h 表示以易于阅读的形式，列出文件大小，如K、M、G，必须要搭配 -l 一起使用\n\n\nLinux路径是此命令可选的参数\n\n\n当不使用选项和参数，直接使用ls命令本体，表示：以平铺形式，列出当前工作目录下的内容\n2.4 目录切换命令cd&#x2F;pwdcd：\n当Linux终端（命令行）打开的时候，会默认以用户的HOME目录作为当前的工作目录\n我们可以通过cd命令，更改当前所在的工作目录。\ncd命令来自英文：Change Directory\n语法： cd [Linux路径]\n\ncd命令无需选项，只有参数，表示要切换到哪个目录下\ncd命令直接执行，不写参数，表示回到用户的HOME目录\n\npwd:\n通过ls来验证当前的工作目录，其实是不恰当的。\n我们可以通过pwd命令，来查看当前所在的工作目录。\npwd命令来自：Print Work Directory\n语法：pwd\n\npwd命令，无选项，无参数，直接输入pwd即可\n\n2.5 相对、绝对路径和特殊路径符绝对路径：以根目录为起点，描述路径的一种写法，路径描述以&#x2F;开头\n相对路径：以当前目录为起点，描述路径的一种写法，路径描述无需以&#x2F;开头\n特殊路径符：\n\n表示当前目录，比如cd ./Desktop表示切换到当前目录下的Desktop目录内，和cd Desktop效果一致\n表示上一级目录，比如：cd ..  即可切换到上一级目录，cd ..&#x2F;.. 切换到上二级的目录\n表示HOME目录，比如：cd ~  即可切换到HOME目录或cd ~&#x2F;Desktop，切换到HOME内的Desktop目录\n\n2.6 创建目录命令mkdir通过mkdir命令可以创建新的目录（文件夹）\nmkdir来自英文：Make Directory\n语法：mkdir [-p] Linux路径\n\n参数必填，表示Linux路径，即要创建的文件夹的路径，相对路径或绝对路径均可（路径所写的即是包名）\n-p选项可选，表示自动创建不存在的父目录，适用于创建连续多层级的目录\n\n2.7 文件操作命令touch：\n可以通过touch命令创建文件\n语法：touch Linux路径\n\ntouch命令无选项，参数必填，表示要创建的文件路径，相对、绝对、特殊路径符均可以使用\n\ncat：\n准备好文件内容后，可以通过cat查看内容。\n语法：cat Linux路径\n\ncat同样没有选项，只有必填参数，参数表示：被查看的文件路径，相对、绝对、特殊路径符都可以使用\n\nmore：\nmore命令同样可以查看文件内容，同cat不同的是：\n\ncat是直接将内容全部显示出来\nmore支持翻页，如果文件内容过多，可以一页页的展示\n\n语法：more Linux路径\n\n同样没有选项，只有必填参数，参数表示：被查看的文件路径，相对、绝对、特殊路径符都可以使用\n在查看的过程中，通过空格翻页\n通过q退出查看\n\ncp：\ncp命令可以用于复制文件\\文件夹，cp命令来自英文单词：copy\n语法：cp [-r] 参数1 参数2\n\n-r选项，可选，用于复制文件夹使用，表示递归\n参数1，Linux路径，表示被复制的文件或文件夹\n参数2，Linux路径，表示要复制去的地方\n复制文件夹，必须使用-r选项，否则不会生效\n\nmv：\nmv命令可以用于移动文件\\文件夹，mv命令来自英文单词：move\n语法：mv 参数1 参数2\n\n参数1，Linux路径，表示被移动的文件或文件夹\n参数2，Linux路径，表示要移动去的地方，如果目标不存在，则进行改名，确保目标存在\n\nrm：\nrm命令可用于删除文件、文件夹\nrm命令来自英文单词：remove\n语法：rm [-r -f] 参数1 参数2 ...... 参数N\n\n同cp命令一样，-r选项用于删除文件夹\n-f表示force，强制删除（不会弹出提示确认信息）\n普通用户删除内容不会弹出提示，只有root管理员用户删除内容会有提示\n所以一般普通用户用不到-f选项\n\n\n参数1、参数2、……、参数N 表示要删除的文件或文件夹路径，按照空格隔开\nrm命令支持通配符 *，用来做模糊匹配\n\nrm是一个危险的命令，特别是在处于root（超级管理员）用户的时候。请谨慎使用。\n如下命令，请千万千万不要在root管理员用户下执行：\nrm -rf /\nrm -rf /*\n效果等同于在Windows上执行C盘格式化。\n2.8 查找命令which&#x2F;findwhich：\n通过which命令，查看所使用的一系列命令的程序文件存放在哪里\n语法：which 要查找的命令\nfind：\n通过find命令去搜索指定的文件。\n语法：find 起始路径 -name &quot;被查找文件名&quot;\n\n被查找文件名，支持使用通配符 * 来做模糊查询。\n\n语法：find 起始路径 -size +|=n[kMG]\n\n+、- 表示大于和小于\nn表示大小数字\nkMG表示大小单位，k(小写字母)表示kb，M表示MB，G表示GB\n\n2.9 grep、wc和管道符grep：\n可以通过grep命令，从文件中通过关键字过滤文件行。\n语法：grep [-n] 关键字 文件路径\n\n选项-n，可选，表示在结果中显示匹配的行的行号。\n参数，关键字，必填，表示过滤的关键字，带有空格或其它特殊符号，建议使用””将关键字包围起来\n参数，文件路径，必填，表示要过滤内容的文件路径，可作为内容输入端口\n\nwc：\n可以通过wc命令统计文件的行数、单词数量等\n语法：wc [-c -m -l -w] 文件路径\n\n选项，-c，统计bytes数量\n选项，-m，统计字符数量\n选项，-l，统计行数\n选项，-w，统计单词数量\n\n参数，文件路径，被统计的文件，可作为内容输入端口\n管道符：\n管道符：|\n管道符的含义是：将管道符左边命令的结果，作为右边命令的输入\n2.10 echo、tail和重定向符echo：\n可以使用echo命令在命令行内输出指定内容\n语法：echo 输出的内容\n\n无需选项，只有一个参数，表示要输出的内容，复杂内容可以用””包围\n\n反引号：\n看一下如下命令：echo pwd\n本意是想，输出当前的工作路径，但是pwd被作为普通字符输出了。\n我们可以通过将命令用反引号（通常也称之为飘号）&#96;将其包围\n被&#96;包围的内容，会被作为命令执行，而非普通字符\n重定向符：\n重定向符：&gt;和&gt;&gt;\n\n&gt;，将左侧命令的结果，覆盖写入到符号右侧指定的文件中\n&gt;&gt;，将左侧命令的结果，追加写入到符号右侧指定的文件中\n\ntail：\n使用tail命令，可以查看文件尾部内容，跟踪文件的最新更改。\n语法如下：tail [-f -num] Linux路径\n\n参数，Linux路径，表示被跟踪的文件路径\n\n选项，-f，可以持续跟踪文件更改\n\n选项, -num，表示，查看尾部多少行，不填默认10行\n\n\n2.11 vi编辑器vi\\vim是visual interface的简称, 是Linux中最经典的文本编辑器\n同图形化界面中的 文本编辑器一样，vi是命令行下对文本文件进行编辑的绝佳选择。\nvim 是 vi 的加强版本，兼容 vi 的所有指令，不仅能编辑文本，而且还具有 shell 程序编辑的功能，可以不同颜色的字体来辨别语法的正确性，极大方便了程序的设计和编辑性。\n\n命令模式（Command mode）\n\n命令模式下，所敲的按键编辑器都理解为命令，以命令驱动执行不同的功能。\n此模型下，不能自由进行文本编辑。\n\n\n输入模式（Insert mode）\n\n也就是所谓的编辑模式、插入模式。\n此模式下，可以对文件内容进行自由编辑。\n\n\n底线命令模式（Last line mode）\n\n以：开始，通常用于文件的保存、退出。\n\n\n\n\n\n\n2.12 其他任何命令都支持：–help 选项， 可以通过这个选项，查看命令的帮助。\n如果想要查看命令的详细手册，可以通过man（manual， 手册）命令查看。\n大多数手册都是全英文的，如果阅读吃力，可以通过重定向符：man ls &gt; ls-man.txt，输出手册到文件，然后通过翻译软件翻译内容查看。\n3.Linux用户和权限3.1 root用户无论是Windows、MacOS、Linux均采用多用户的管理模式进行权限管理。\n\n在Linux系统中，拥有最大权限的账户名为：root（超级管理员）\n\nroot用户拥有最大的系统操作权限，而普通用户在许多地方的权限是受限的。\n\n普通用户的权限，一般在其HOME目录内是不受限的\n\n一旦出了HOME目录，大多数地方，普通用户仅有只读和执行权限，无修改权限\n\n\n3.2 su和exit命令su命令就是用于账户切换的系统命令，其来源英文单词：Switch User\n语法：su [-] [用户名]\n\n符号是可选的，表示是否在切换用户后加载环境变量（后续讲解），建议带上\n\n参数：用户名，表示要切换的用户，用户名也可以省略，省略表示切换到root\n\n切换用户后，可以通过exit命令退回上一个用户，也可以使用快捷键：ctrl + d\n\n使用普通用户，切换到其它用户需要输入密码，如切换到root用户\n\n使用root用户切换到其它用户，无需密码，可以直接切换\n\n\n3.3 sudo命令我们可以使用sudo命令，为普通的命令授权，临时以root身份执行。\n语法：sudo 其他命令\n\n在其它命令之前，带上sudo，即可为这一条命令临时赋予root授权\n但是并不是所有的用户，都有权利使用sudo，我们需要为普通用户配置sudo认证\n\n为普通用户配置sudo：\n\n切换到root用户，执行visudo命令，会自动通过vi编辑器打开：&#x2F;etc&#x2F;sudoers\n\n\n\n最后通过 wq 保存\n\n3.4 用户管理Linux系统中可以：\n\n配置多个用户\n配置多个用户组\n用户可以加入多个用户组中\n\nLinux中关于权限的管控级别有2个级别，分别是：\n\n针对用户的权限控制\n针对用户组的权限控制\n\n比如，针对某文件，可以控制用户的权限，也可以控制用户组的权限。\n以下命令需root用户执行：\n\n创建用户\n\nuseradd [-g -d] 用户名\n\n选项：-g指定用户的组，不指定-g，会创建同名组并自动加入，指定-g需要组已经存在，如已存在同名组，必须使用-g\n\n选项：-d指定用户HOME路径，不指定，HOME目录默认在：&#x2F;home&#x2F;用户名\n\n删除用户\n\n\nuserdel [-r] 用户名\n\n选项：-r，删除用户的HOME目录，不使用-r，删除用户时，HOME目录保留\n\n查看用户所属组\n\n\nid [用户名]\n\n参数：用户名，被查看的用户，如果不提供则查看自身\n\n修改用户所属组\n\n\nusermod -aG 用户组 用户名\n\n将指定用户加入指定用户组\n\n3.5 用户组管理以下命令需root用户执行\n\n创建用户组\n\ngroupadd 用户组名\n\n删除用户组\n\ngroupdel 用户组名\n3.6 getent命令使用getent命令，可以查看当前系统中有哪些用户\n语法： getent passwd\n使用getent命令，同样可以查看当前系统中有哪些用户组\n语法：getent group\n3.7 查看权限控制通过ls -l 可以以列表形式查看内容，并显示权限细节\n\n序号1，表示文件、文件夹的权限控制信息\n序号2，表示文件、文件夹所属用户\n序号3，表示文件、文件夹所属用户组\n\n\n权限细节总共分为10个槽位\n\nrwx：\n\nr表示读权限\nw表示写权限\nx表示执行权限\n\n针对文件、文件夹的不同，rwx的含义有细微差别\n\nr，针对文件可以查看文件内容\n\n针对文件夹，可以查看文件夹内容，如ls命令\n\n\nw，针对文件表示可以修改此文件\n\n针对文件夹，可以在文件夹内：创建、删除、改名等操作\n\n\nx，针对文件表示可以将文件作为程序执行\n\n针对文件夹，表示可以更改工作目录到此文件夹，即cd进入\n\n\n\n3.8 修改权限控制chmod我们可以使用chmod命令，修改文件、文件夹的权限信息。\n注意，只有文件、文件夹的所属用户或root用户可以修改。\n语法：chmod [-R] 权限 文件或文件夹\n\n选项：-R，对文件夹内的全部内容应用同样的操作\n\n权限可以用3位数字来代表，第一位数字表示用户权限，第二位表示用户组权限，第三位表示其它用户权限。\n数字的细节如下：r记为4，w记为2，x记为1，可以有：\n\n0：无任何权限， 即 —\n1：仅有x权限， 即 –x\n2：仅有w权限 即 -w-\n3：有w和x权限 即 -wx\n4：仅有r权限 即 r–\n5：有r和x权限 即 r-x\n6：有r和w权限 即 rw-\n7：有全部权限 即 rwx\n\n3.9 修改权限控制chown使用chown命令，可以修改文件、文件夹的所属用户和用户组\n普通用户无法修改所属为其它用户或组，所以此命令只适用于root用户执行\n语法：chown [-R] [用户][:][用户组] 文件或文件夹\n\n选项，-R，同chmod，对文件夹内全部内容应用相同规则\n选项，用户，修改所属用户\n选项，用户组，修改所属用户组\n用于分隔用户和用户组\n\n4.Linux实用操作4.1 各类技巧快捷键\nLinux某些程序的运行，如果想要强制停止它，可以使用快捷键ctrl + c\n\n可以通过快捷键：ctrl + d，退出账户的登录\n\n或者退出某些特定程序的专属页面\n不能用于退出vi&#x2F;vim\n\n\n可以通过history命令，查看历史输入过的命令\n\n可以通过：**!**命令前缀，自动执行上一次匹配前缀的命令\n\n可以通过快捷键：ctrl + r，输入内容去匹配历史命令\n\n如果搜索到的内容是你需要的，那么：\n\n回车键可以直接执行\n\n键盘左右键，可以得到此命令（不执行）\n\n\n\n\n\nctrl + a，跳到命令开头\n\nctrl + e，跳到命令结尾\n\nctrl + 键盘左键，向左跳一个单词\n\nctrl + 键盘右键，向右跳一个单词\n\n通过快捷键ctrl + l，可以清空终端内容\n\n或通过命令clear得到同样效果\n\n\n4.2 软件安装yum命令：（CentOS）\nRPM包软件管理器，用于自动化安装配置Linux软件，并可以自动解决依赖问题。\n语法：yum [-y] [install | remove | search] 软件名称\n\n选项：-y，自动确认，无需手动确认安装或卸载过程\ninstall：安装\nremove：卸载\nsearch：搜索\n\n\n\n\n\n\n\n\n\n\n yum命令需要root权限哦，可以su切换到root，或使用sudo提权。\nyum命令需要联网\napt命令：（Ubuntu）\nCentOS使用yum管理器，Ubuntu使用apt管理器\n通过前面学习的WSL环境，我们可以得到Ubuntu运行环境。\n语法：apt [-y] [install | remove | search] 软件名称\n用法和yum一致，同样需要root权限\n4.3 systemctlLinux系统很多软件（内置或第三方）均支持使用systemctl命令控制：启动、停止、开机自启\n能够被systemctl管理的软件，一般也称之为：服务\n语法：systemctl start| stop | status | enable | disable 服务名\n\nstart 启动 stop关闭 status查看状态 enable 开启开机自启 disable 关闭开机自启\n\n\n\n\n\n\n\n\n\n\n系统内置的服务比较多，比如：\nNetworkManager，主网络服务\nnetwork，副网络服务\nfirewalld，防火墙服务\nsshd，ssh服务（FinalShell远程登录Linux使用的就是这个服务）\n除了内置的服务以外，部分第三方软件安装后也可以以systemctl进行控制。\nyum install -y ntp，安装ntp软件，可以通过ntpd服务名，配合systemctl进行控制。\nyum install -y httpd，安装apache服务器软件，可以通过httpd服务名，配合systemctl进行控制。\n部分软件安装后没有自动集成到systemctl中，我们可以手动添加。\n4.4 软连接ln在系统中创建软链接，可以将文件、文件夹链接到其它位置。\n类似Windows系统中的《快捷方式》\n语法：ln -s 参数1 参数2\n\n-s选项，创建软连接\n参数1：被链接的文件或文件夹\n参数2：要链接去的目的地\n\n4.5 日期、时区date：\n通过date命令可以在命令行中查看系统的时间\n语法：date [-d] [+格式化字符串]\n\n-d 按照给定的字符串显示日期，一般用于日期计算\n格式化字符串：通过特定的字符串标记，来控制显示的日期格式\n\n\n修改Linux时区：\n系统默认时区非中国的东八区。使用root权限，执行如下命令，修改时区为东八区时区\nshellrm -f /etc/localtime\nsudo ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime将系统自带的localtime文件删除，并将/usr/share/zoneinfo/Asia/Shanghai文件链接为localtime文件即可\nntp：\n我们可以通过ntp程序自动校准系统时间\n安装ntp：yum -y install ntp\n启动并设置开机自启：\nshellsystemctl start ntpd\nsystemctl enable ntpd当ntpd启动后会定期的帮助我们联网校准系统的时间\n也可以手动校准（需root权限）：ntpdate -u ntp.aliyun.com\n通过阿里云提供的服务网址配合ntpdate（安装ntp后会附带这个命令）命令自动校准。\n4.6 IP地址、主机名IP地址：\n每一台联网的电脑都会有一个地址，用于和其它计算机进行通讯\nIP地址主要有2个版本，V4版本和V6版本（V6很少用，课程暂不涉及）\nIPv4版本的地址格式是：a.b.c.d，其中abcd表示0~255的数字，如192.168.88.101就是一个标准的IP地址\n可以通过命令：ifconfig，查看本机的ip地址\n如无法使用ifconfig命令，可以安装：yum -y install net-tools\n特殊IP地址：\n除了标准的IP地址以外，还有几个特殊的IP地址需要我们了解：\n\n127.0.0.1，这个IP地址用于指代本机\n\n0.0.0.0，用于指代本机\n\n可以在端口绑定中用来确定绑定关系（后续讲解）\n\n在一些IP地址限制中，表示所有IP的意思，如放行规则设置为0.0.0.0，表示允许任意IP访问\n\n\n\n\n主机名：\n每一台电脑除了对外联络地址（IP地址）以外，也可以有一个名字，称之为主机名\n无论是Windows或Linux系统，都可以给系统设置主机名\n\n可以使用命令：hostname查看主机名\n可以使用命令：hostnamectl set-hostname 主机名，修改主机名（需root）\n\n域名解析：\n可以通过主机名找到对应计算机的IP地址，这就是主机名映射（域名解析）\n先通过系统本地的记录去查找，如果找不到就联网去公开DNS服务器去查找\n配置主机名映射：\n在Windows系统的：C:\\Windows\\System32\\drivers\\etc\\hosts文件中配置记录即可\n\n\n\n\n4.7 虚拟机配置固定IP为什么需要固定IP：\n当前我们虚拟机的Linux操作系统，其IP地址是通过DHCP服务获取的。\nDHCP：动态获取IP地址，即每次重启设备后都会获取一次，可能导致IP地址频繁变更\n原因1：办公电脑IP地址变化无所谓，但是我们要远程连接到Linux系统，如果IP地址经常变化我们就要频繁修改适配很麻烦\n原因2：在刚刚我们配置了虚拟机IP地址和主机名的映射，如果IP频繁更改，我们也需要频繁更新映射关系\n在VMware Workstation中配置固定IP：\n配置固定IP需要2个大步骤：\n1.在VMware Workstation（或Fusion）中配置IP地址网关和网段（IP地址的范围）\n2.在Linux系统中手动修改配置文件，固定IP\n\n\n\n现在进行第二步，在Linux系统中修改固定IP\n\n使用vim编辑&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens33文件，填入如下内容\n执行：systemctl restart network 重启网卡，执行ifconfig即可看到ip地址固定为192.168.88.130了\n\n\n4.8 网络传输ping&#x2F;wget&#x2F;curlping命令：\n可以通过ping命令，检查指定的网络服务器是否是可联通状态\n语法：ping [-c num] ip或主机名\n\n选项：-c，检查的次数，不使用-c选项，将无限次数持续检查\n参数：ip或主机名，被检查的服务器的ip地址或主机名地址\n\nwget命令：\nwget是非交互式的文件下载器，可以在命令行内下载网络文件\n语法：wget [-b] url\n\n选项：-b，可选，后台下载，会将日志写入到当前工作目录的wget-log文件\n参数：url，下载链接\n\ncurl命令：\ncurl可以发送http网络请求，可用于：下载文件、获取信息等\n语法：curl [-O] url\n\n选项：-O，用于下载文件，当url是下载链接时，可以使用此选项保存文件\n参数：url，要发起请求的网络地址\n\n4.9 端口端口，是设备与外界通讯交流的出入口。端口可以分为：物理端口和虚拟端口两类\n\n物理端口：又可称之为接口，是可见的端口，如USB接口，RJ45网口，HDMI端口等\n虚拟端口：是指计算机内部的端口，是不可见的，是用来操作系统和外部进行交互使用的\n\n虚拟端口：计算机程序之间的通讯，通过IP只能锁定计算机，但是无法锁定具体的程序。通过端口可以锁定计算机上具体的程序，确保程序之间进行沟通。\nLinux系统是一个超大号小区，可以支持65535个端口，这6万多个端口分为3类进行使用：\n\n公认端口：1~1023，通常用于一些系统内置或知名程序的预留使用，如SSH服务的22端口，HTTPS服务的443端口\n\n非特殊需要，不要占用这个范围的端口\n\n\n注册端口：1024~49151，通常可以随意使用，用于松散的绑定一些程序\\服务\n\n动态端口：49152~65535，通常不会固定绑定程序，而是当程序对外进行网络链接时，用于临时使用。\n\n\n可以通过Linux命令去查看端口的占用情况\n使用nmap命令，安装nmap：yum -y install nmap\n语法：nmap 被查看的IP地址\n可以通过netstat命令，查看指定端口的占用情况\n安装netstat：yum -y install net-tools\n语法：netstat -anp | grep 端口号\n4.10 进程管理进程：\n程序运行在操作系统中，是被操作系统所管理的。\n为管理运行的程序，每一个程序在运行的时候，便被操作系统注册为系统中的一个：进程\n并会为每一个进程都分配一个独有的：进程ID（进程号）\n查看进程：\n可以通过ps命令查看Linux系统中的进程信息\n语法：ps [-e -f]\n选项：-e，显示出全部的进程\n选项：-f，以完全格式化的形式展示信息（展示全部信息）\n一般来说，固定用法就是： ps -ef 列出全部进程的全部信息\n\n查看指定进程：\n使用管道符配合grep来进行过滤，如：\nps -ef | grep tail，即可准确的找到tail命令的信息\n过滤不仅仅过滤名称，进程号，用户ID等等，都可以被grep过滤\n关闭进程：\n在Linux中，可以通过kill命令关闭进程。\n语法：kill [-9] 进程ID\n选项：-9，表示强制关闭进程。不使用此选项会向进程发送信号要求其关闭，但是否关闭看进程自身的处理机制。\n4.11 主机状态查看系统资源占用：\n可以通过top命令查看CPU、内存使用情况，类似Windows的任务管理器\n\n默认每5秒刷新一次，语法：直接输入top即可，按q或ctrl + c退出\n\ntop命令内容详解：\n\n\ntop命令也支持选项：\n\ntop交互式选项：\n当top以交互式运行（非-b选项启动），可以用以下交互式命令进行控制\n\n磁盘信息监控：\n使用df命令，可以查看硬盘的使用情况\n语法：df [-h]\n\n选项：-h，以更加人性化的单位显示\n\n可以使用iostat查看CPU、磁盘的相关信息\n语法：iostat [-x] [num1] [num2]\n\n选项：-x，显示更多信息\nnum1：数字，刷新间隔，num2：数字，刷新几次\n\n\n\n\n\n\n\n\n\n\ntps：该设备每秒的传输次数（Indicate the number of transfers per second that were issued to the device.）。”一次传输”意思是”一次I&#x2F;O请求”。多个逻辑请求可能会被合并为”一次I&#x2F;O请求”。”一次传输”请求的大小是未知的。\n\n使用iostat的-x选项，可以显示更多信息\n\n\n网络状态监控：\n可以使用sar命令查看网络的相关统计（sar命令非常复杂，这里仅简单用于统计网络）\n语法：sar -n DEV num1 num2\n\n选项：-n，查看网络，DEV表示查看网络接口\nnum1：刷新间隔（不填就查看一次结束），num2：查看次数（不填无限次数）\n\n\n4.12 环境变量环境变量是操作系统（Windows、Linux、Mac）在运行的时候，记录的一些关键性信息，用以辅助系统运行。\n在Linux系统中执行：env命令即可查看当前系统中记录的环境变量\n环境变量是一种KeyValue型结构，即名称和值\n环境变量：PATH\n在前面提出的问题中，我们说无论当前工作目录是什么，都能执行&#x2F;usr&#x2F;bin&#x2F;cd这个程序，这个就是借助环境变量中：PATH这个项目的值来做到的。\nPATH记录了系统执行任何命令的搜索路径。当执行任何命令，都会按照顺序，从上述路径中搜索要执行的程序的本体。\n$符号：\n在Linux系统中，$符号被用于取”变量”的值。\n环境变量记录的信息，除了给操作系统自己使用外，如果我们想要取用，也可以使用。\n取得环境变量的值就可以通过语法：**$环境变量名** 来取得\n自行设置环境变量：\nLinux环境变量可以用户自行设置，其中分为：\n\n临时设置，语法：export 变量名&#x3D;变量值\n永久生效\n针对当前用户生效，配置在当前用户的： ~&#x2F;.bashrc文件中\n针对所有用户生效，配置在系统的： &#x2F;etc&#x2F;profile文件中\n并通过语法：source 配置文件，进行立刻生效，或重新登录FinalShell生效\n\n\n\n自定义环境变量PATH：\n环境变量PATH这个项目里面记录了系统执行命令的搜索路径。\n这些搜索路径我们也可以自行添加到PATH中去。\n4.13 上传、下载我们可以通过FinalShell工具，方便的和虚拟机进行数据交换。\n在FinalShell软件的下方窗体中，提供了Linux的文件系统视图，可以方便的：\n\n浏览文件系统，找到合适的文件，右键点击下载，即可传输到本地电脑\n\n浏览文件系统，找到合适的目录，将本地电脑的文件拓展进入，即可方便的上传数据到Linux中\n\n\nrz、sz命令：\n可以通过rz、sz命令进行文件传输。\nrz、sz命令需要安装，可以通过：yum -y install lrzsz，即可安装。\n\nrz命令，进行上传，语法：直接输入rz即可\nsz命令进行下载，语法：sz 要下载的文件\n\n4.14 压缩、解压tar命令：\nLinux和Mac系统常用有2种压缩格式，后缀名分别是：\n\n.tar，称之为tarball，归档文件，即简单的将文件组装到一个.tar的文件内，并没有太多文件体积的减少，仅仅是简单的封装\n\n.gz，也常见为.tar.gz，gzip格式压缩文件，即使用gzip压缩算法将文件压缩到一个文件内，可以极大的减少压缩后的体积\n\n\n针对这两种格式，使用tar命令均可以进行压缩和解压缩的操作\n语法：tar [-c -v -x -f -z -C] \n\n-c，创建压缩文件，用于压缩模式\n-v，显示压缩、解压过程，用于查看进度\n-x，解压模式\n-f，要创建的文件，或要解压的文件，-f选项必须在所有选项中位置处于最后一个\n-z，gzip模式，不使用-z就是普通的tarball格式\n-C，选择解压的目的地，用于解压模式\n\ntar命令压缩：\ntar的常用组合为：\n\ntar -cvf test.tar 1.txt 2.txt 3.txt\n\n将1.txt 2.txt 3.txt 压缩到test.tar文件内\n\ntar -zcvf test.tar.gz 1.txt 2.txt 3.txt\n\n将1.txt 2.txt 3.txt 压缩到test.tar.gz文件内，使用gzip模式\n注意：\n\n-z选项如果使用的话，一般处于选项位第一个\n-f选项，必须在选项位最后一个\n\ntar解压：\n常用的tar解压组合有\n\ntar -xvf test.tar\n\n解压test.tar，将文件解压至当前目录\n\ntar -xvf test.tar -C &#x2F;home&#x2F;itheima\n\n解压test.tar，将文件解压至指定目录（&#x2F;home&#x2F;itheima）\n\ntar -zxvf test.tar.gz -C &#x2F;home&#x2F;itheima\n\n以Gzip模式解压test.tar.gz，将文件解压至指定目录（&#x2F;home&#x2F;itheima）\n注意：\n\n-f选项，必须在选项组合体的最后一位\n-z选项，建议在开头位置\n-C选项单独使用，和解压所需的其它参数分开\n\nzip命令压缩文件：\n可以使用zip命令，压缩文件为zip压缩包\n语法：zip [-r] 参数1 参数2 ... 参数N\n\n-r，被压缩的包含文件夹的时候，需要使用-r选项，和rm、cp等命令的-r效果一致\n\nunzip命令解压文件：\n使用unzip命令，可以方便的解压zip压缩包\n语法：unzip [-d] 参数\n\n-d，指定要解压去的位置，同tar的-C选项\n参数，被解压的zip压缩包文件\n\n","slug":"Linux基础总结","date":"2024-05-07T08:40:12.000Z","categories_index":"Study","tags_index":"开发工具,Linux","author_index":"Fioransh"},{"id":"902b00dac8e53459d584ad64422345db","title":"汇编语言指令","content":"1.通用寄存器简单指令1.1 简单传送指令1.1.1 传送指令MOVMOV  DEST,SRC\n将源操作数SRC送至目的操作数DEST，即：\nDEST &lt;&#x3D; SRC\n1.1.2 交换指令XCHGXCHG   OPRD1,OPRD2\n将操作数OPRD1的内容与操作数OPRD2的内容交换，即：\nOPRD1 &lt;&#x3D;&gt; OPRD2\n1.1.3 取地址LEALEA   OPRD1,OPRD2\n取地址至寄存器\n1.2  简单加减指令1.2.1 加法指令ADD ADD   DEST,SRC\n此指令完成两个操作数相加，结果送到目的操作数DEST，即：\nDEST &lt;&#x3D; DEST + SRC\n1.2.2 减法指令SUBSUB   DEST,SRC\n此指令完成两个操作数相减，结果送到目的操作数DEST，即：\nDEST &lt;&#x3D; DEST - SRC\n1.2.3 加1指令INCINC   DEST\n此指令完成对操作数DEST加1，然后把结果送回DEST，即：DEST &lt;&#x3D; DEST + 1\n1.2.4 减1指令DECDEC  DEST\n此指令完成对操作数DEST减1，然后把结果送回DEST，即：DEST &lt;&#x3D; DEST - 1\n1.2.5 取补指令NEGNEG  OPRD\n此指令对操作数取补，就是用0减去操作数OPRD，再把结果送回OPRD，即：OPRD &lt;&#x3D; 0 - OPRD\n2.标志寄存器的标志及指令2.1 状态标志2.1.1 进位标志CF进位标志主要反映算数运算是否产生进位或借位。\n如果运算结果的最高位产生一个进位或借位，则CF被置1，否则CF被清0。\n2.1.2 零标志ZF零标志反映运算结果是否为0。\n如果运算结果为0，则ZF被置1，否则ZF被清零。\n2.1.3 符号标志SF符号标志反映运算结果的符号位。\nSF与运算结果的最高位相同，如果运算结果最高位为1，则SF被置1，否则SF被清0。\n2.1.4 溢出标志OF溢出标志反映有符号数加减运算是否引起溢出。\n如果运算结果超出了8位、16位或32位有符号数的表示范围，则OF被置1，否则OF被清0。\n2.1.5 奇偶标志PF奇偶标志反映运算结果的最低字节中含有“1”的位数是偶数还是奇数。\n如果“1”的位数是偶数，则PF被置1，否则PF被清0。\n2.1.6 辅助进位标志AF辅助进位标志反映算术运算中第3位是否产生进位或借位，或者最低的4位是否有进位或借位。\n如果产生进位或借位，则AF被置1，否则AF被清0。\n2.2 状态标志操作指令2.2.1 清进位标志指令CLC这条指令使进位标志CF为0。\n2.2.2 置进位标志指令STR这条指令使进位标志CF为1。\n2.2.3 进位标志取反指令CMC这条指令使进位标志CF取反。\n如CF为1，则使CF为0；如CF为0，则使CF为1。\n上述 3 条进位标志操作指令仅影响CF，对其他标志没有影响。\n2.2.4 获取状态标志操作指令LAHF这条指令把标志寄存器的低8位，送到通用寄存器AH中。\n2.2.5 设置状态标志操作指令SAHF这条指令对标志寄存器中低8位的状态标志产生影响，使得状态标志SF、ZF、AF、PF和CF分别成为来自寄存器AH中对应位的值，但保留位不受影响。\n2.3 带进位加减指令2.3.1 带进位加法指令ADCADC  DEST,SRC\n这条指令与ADD指令类似，完成两个操作数相加，但还要把进位标志CF的当前值加上，把结果送至目的操作数DEST，即：\nDEST &lt;&#x3D; DEST + SRC + CF\n2.3.2 带借位减法指令SBBSBB  DEST,SRC\n这条指令与SUB指令类似，完成两个操作数相减，但还要把借位标志CF的当前值减去，把结果送至目的操作数DEST，即：\nDEST &lt;&#x3D; DEST - SRC - CF\n3.堆栈和堆栈操作3.1 堆栈操作指令3.1.1 进栈指令PUSHPUSH  SRC\n该指令把源操作数SRC压入堆栈。\n3.1.2 出栈指令POPPOP  DEST\n该指令从栈顶弹出一个双字或者字数据到目的操作数DEST。\n注意：出栈指令的操作数不同于进栈指令，它不能是立即数和代码段寄存器CS！\n3.2 通用寄存器全进栈指令和全出栈指令3.2.1 16位通用寄存器全进栈和全出栈指令\nPUSHA\n\n将8个16位通用寄存器的内容压入堆栈，压入顺序为AX，CX，DX，BX，SP，BP，SI，DI，然后堆栈指针寄存器SP的值减16。\n\nPOPA\n\n从堆栈弹出内容，以PUSHA相反的顺序送到这些通用寄存器，从而恢复PUSHA之前的寄存器内容。然后SP的值通过增加16来恢复。\n3.2.2 32位通用寄存器全进栈和全出栈指令\nPUSHAD\n\n将8个32位通用寄存器的内容压入堆栈，压入顺序为EAX，ECX，EDX，EBX，ESP，EBP，ESI，EDI，然后堆栈指针寄存器SP的值减32。\n\nPOPAD\n\n从堆栈弹出内容，以PUSHAD相反的顺序送到这些通用寄存器，从而恢复PUSHAD之前的寄存器内容。然后SP的值通过增加32来恢复。\n3.3 子程序3.3.1 过程调用指令CALLCALL   LABEL（标号 LABEL 可以是程序中的一个标号，也可以是一个过程名）\n此指令是段内直接调用指令，此指令的具体操作是：先把返回地址偏移压入堆栈，使得EIP的内容为目标地址偏移，从而实现转移。\n3.3.2 过程返回指令RETRET\n该指令从堆栈弹出地址偏移，送到指令指针寄存器EIP。\n4.算数逻辑运算指令4.1 乘除运算指令4.1.1 无符号数乘法指令MULMUL   OPRD\n此指令实现两个无符号操作数的乘法运算。\n指令看似只有一个操作数OPRD，实际上，另一个操作数是隐含的，位于寄存器AL、AX或者EAX中（这取决于OPRD的尺寸）：\n\n如果OPRD是字节操作数（8位），则把AL中的无符号数与OPRD相乘，16位结果送到AX中。\n如果OPRD是字操作数（16位）则把AX中的无符号数与OPRD相乘，32位结果送到寄存器对DX：AX中，DX含高 16 位，AX含低 16 位。\n如果OPRD是双字操作数（32位），则把EAX中的无符号数与OPRD相乘，64位结果送到寄存器对EDX：EAX中，EDX含高 32 位，EAX含低 32 位。\n\n4.1.2 有符号数乘法指令IMULIMUL   OPRD\n单操作数形式。单操作数乘法指令实际上有一个隐含的操作数，位于寄存器AL、AX或者EAX中（这取决于操作数OPRD的尺寸）。\nIMUL   DEST,SRC\n双操作数形式。即：DEST &lt;&#x3D; DEST * SRC\nIMUL   DEST,SRC1,SRC2\n三操作数形式。即：DEST &lt;&#x3D; SRC1 * SRC2\n4.1.3 无符号数除法指令DIVDIV   OPRD\n此指令实行两个无符号操作数的除法运算。指令看似只有一个操作数OPRD（作为除数），实际上，另一个操作数（作为被除数）是隐含的，位于寄存器AX、寄存器对DX：AX或者寄存器对EDX：EAX中（DX含有被除数的高16位，或者EDX含有被除数的高32位）。\n\n如果OPRD是字节操作数（8位），则把AX中的无符号数除以OPRD，所得商送到AL中，余数送到AH中；\n如果OPRD是字操作数（16位），则把寄存器对DX：AX中的无符号数除以OPRD，所得商送到AX，余数送到DX中；\n如果OPRD是双字操作数（32位），则把寄存器对EDX：EAX中的无符号数除以OPRD，所得商送到EAX中，余数送到EDX中。\n\n4.1.4 有符号数除法指令IDIVIDIV   OPRD\n此指令实现两个有符号操作数的除法运算。指令看似只有一个作为除数的操作数OPRD，实际上，作为被除数的另一个操作数是隐含的，位于寄存器AX、寄存器对DX：AX或者寄存器对EDX：EAX中（取决于操作数OPRD的尺寸）。\n4.1.5 符号扩展指令\n字节转换字指令（CBW）CBW此指令把寄存器AL中的符号拓展到寄存器AH。\n\n字转换为双字指令（CWD）CWD此指令把寄存器AX中的符号扩展到寄存器DX。\n\n双字转换为四字指令（CDQ）CDQ此指令把寄存器EAX中的符号扩展到寄存器EDX。\n\n另一条字转换为双字指令（CWDE）CWDX此指令把寄存器AX中的符号扩展到寄存器EAX的高16位。\n\n\n4.1.6 扩展传送指令\n符号扩展传送指令（MOVSX）MOVSX    DEST，SRC此指令把源操作数SRC符号扩展后送至目的操作数DEST。\n零扩展传送指令（MOVZX）MOVZX    DEST，SRC此指令把源操作数SRC零扩展后送至目的操作数DEST。\n\n4.2 逻辑运算指令4.2.1 否运算指令NOTNOT   OPRD\n此指令把操作数OPRD按位“取反”，然后送回OPRD；按位“取反”是指把为 0 的位设置为 1，把为 1 的位清为 0。\n4.2.2 与运算指令ANDAND   DEST,SRC\n此指令对两个操作数进行按位的逻辑“与”运算，结果送到目的操作数DEST。按位“与”是指当两个操作数对应位都为 1 时，把结果的对应位设置成 1 ，否则清成 0。\n4.2.3 或运算指令OROR   DEST,SRC\n此指令对两个操作数进行按位的逻辑“或”运算，结果送到目的操作数DEST。\n4.2.4 异或运算指令XORXOR   DEST,SRC\n此指令对两个操作数进行按位的逻辑“异或”运算，结果送到目的操作数DEST。\n4.2.5 测试指令TESTTEST   DEST,SRC\n此指令和AND指令类似，也是把两个操作数进行按位“与”，但结果不送回目的操作数DEST，仅仅影响状态标志。该指令执行后，标志ZF、PF和SF反映运算结果，标志CF和OF被清为0。\n4.3 移位指令4.3.1 移位指令\n算数左移指令（同逻辑左移指令）SAL（SHL）\nSAL   OPRD,COUNT\nSHL   OPRD,COUNT\n\n算数右移指令SAR\nSAR   OPRD,COUNT\n\n逻辑右移指令SHR\nSHR   OPRD,COUNT\n\n\n4.3.2 循环移位指令\n左循环移位指令ROL\nROL   OPRD,COUNT\n\n右循环移位指令ROR\nROR   OPRD,COUNT\n\n带进位左循环移位指令RCL\nRCL   OPRD,COUNT\n\n带进位右循环移位指令RCR\nRCR  OPRD,COUNT\n\n\n4.3.3 双精度移位指令\n双精度左移指令SHLD\nSHLD   OPRD1,OPRD2,COUNT\n\n双精度右移指令SHRD\nSHRD  OPRD1,OPRD2,COUNT\n\n\n5.转移指令5.1 条件转移指令\n\n\n大于（G）\n等于（E）\n小于（L）\n\n\n\n高于（A）\n等于（E）\n低于（B）\n\n\n\n5.2 无条件转移指令5.2.1 无条件段内直接转移指令JMP   LABEL\n标号 LABEL 用于表示转移的目标位置，或者说转移目的地。\n5.2.2 无条件段内间接转移指令JMP  OPRD\n此指令使控制无条件转移到操作数 OPRD 的内容给定的目标地址处。\n6.循环指令6.1 循环指令6.1.1 计数循环指令LOOPLOOP   LABEL\n此指令使寄存器ECX的值减 1，如果结果不等于 0，则转移到标号 LABEL 处，否则顺序执行LOOP指令后的指令。\n6.1.2 等于&#x2F;全零循环指令LOOPE&#x2F;LOOPZLOOPE   LABEL\nLOOPZ   LABEL\n此指令使寄存器 ECX 的值减 1，如果结果不等于 0，并且零标志 ZF 等于 1（表示相等），那么就转移到标号 LABEL 处，否则顺序执行。\n6.1.3 不等于&#x2F;非零循环指令LOOPNE&#x2F;LOOPNZLOOPEN    JABEL\nLOOPNZ    JABEL\n此指令使寄存器 ECX 的值减 1，如果结果不等于 0，并且零标志 ZF 等于 0（表示不相等），那么就转移到标号 LABEL 处，否则顺序执行。\n6.2 计数器转移指令6.2.1 计数器转移指令JECXZJECXZ   LABEL\n此指令实现当寄存器 ECX 的值等于 0 时转移到标号 LABEL 处，否则顺序执行。\n7.字符串操作7.1 串操作指令字符串操作的方向由标志寄存器中的方向标志 DF 控制。\n\n清方向标志 DF 的指令（CLD）\n设置方向标志 DF 的指令（STD）\n\n利用这两条指令可以根据需要调整字符串操作指令处理字符串的方向。\n7.1.1 字符串装入指令LOAD\nLODSB    ；装入字节    \nLODSW    ；装入字\nLODSD    ；装入双字\n\n7.1.2 字符串存储指令STO\nSTOSB    ；存储字节    \nSTOSW    ；存储字\nSTOSD    ；存储双字\n\n7.1.3 字符串传送指令MOV\nMOVSB    ；字节传送   \nMOVSW    ；字传送\nMOVSD    ；双字传送\n\n7.1.4 字符串扫描指令SCA\nSCASB    ；串字节扫描    \nSCASW    ；串字扫描\nSCASD    ；串双字扫描\n\n7.1.5 字符串比较指令CMP\nCMPSB    ；串字节比较 \nCMPSW    ；串字比较\nCMPSD    ；串双字比较\n\n7.2 重复操作前缀7.2.1 重复前缀REP它重复其后的串操作指令动作；每一次重复都先判断寄存器 ECX 是否为 0，如果为 0 就结束重复，否则 ECX 的值减 1，重复其后的串操作指令。\n（它类似于 LOOP 指令，但 LOOP 指令使先把 ECX 的值减 1 后再判断是否为 0）\n7.2.2 重复前缀REPE&#x2F;REPZREPE 和 REPZ 是一个前缀的两个助记符，下面以 REPE 为代表进行说明。REPE 重复其后的串操作指令动作。每重复一次，ECX 的值减 1，重复一直进行到 ECX 为 0 或串操作指令使零标志 ZF 为 0 时为止。\n7.2.3 重复前缀REPNE&#x2F;REPNZREPNE 和 REPNZ 是一个前缀的两个助记符，下面以 REPNE 为代表进行说明。\nREPNE 与 REPE 类似，所不同的是重复一直进行到 ECX 为 0 或串操作指令使零标志 ZF 为 1 时止。\n8.位操作8.1 位操作指令8.1.1 位测试及设置指令组\n位测试指令BTBT        OPRD1，OPRD2\n\n功能是把被测试位的值送到进位标志 CF。\n\n位测试并取反指令BTCBTC        OPRD1，OPRD2\n\n功能是把被测试位的值送到进位标志 CF，并且把被测试位取反。\n\n位测试并复位指令BTR BTR        OPRD1，OPRD2\n\n功能是把被测试位的值送到进位标志 CF，并且把被测试位复位，即清 0。\n\n位测试并置位指令BTSBTS        OPRD1，OPRD2\n\n功能是把被测试位的值送到进位标志 CF，并且把被测试位置位，即置 1。\n8.1.2 位扫描指令组\n顺向位扫描指令BSFBSF        OPRD1,OPRD2\n\n功能是从右往左（位 0 至位 15 或位 31）扫描字或者双字操作数 OPRD2 中的第一个含“1”的位，并把扫描到的第一个含“1”的位的位号送至操作数 OPRD1。\n\n逆向位扫描指令BSRBSR        OPRD1,OPRD2\n\n功能是从左往右（位 15 至位 31 或位 0）扫描字或者双字操作数 OPRD2 中的第一个含“1”的位，并把扫描到的第一个含“1”的位的位号送至操作数 OPRD1。\n8.2 条件设置字节指令SET\n\n9.常用DOS功能9.1 键盘输入单字符功能号1，输入字符以ASCII码的形式存放在累加器AL中同时显示出来。\nbashMOV AH 01\nINT 21H9.2 屏幕显示单字符功能号2，屏幕显示存放在DL寄存器中的字符。\nbashMOV AH 02\nMOV DL 待显示字符\nINT 21H9.3 屏幕显示字符串功能号9，用于在显示器上显示一个存放在寄存器DX中的字符串，被显示的字符串必须以’$’作为结束符。\nbashMOV AH 09\nMOV DX 待显示字符串首地址\nINT 21H9.4 退出一个程序执行完成后使得程序正常退出并返回DOS的功能，功能号为4CH。\nbashMOV AH 4CH\nINT 21H10.其他数据长度：8086CPU指令中，可以处理两种尺寸的数据，byte和word。\n通过寄存器名指明要处理的数据的尺寸。\n在没有寄存器名存在的情况下，用操作符X PTR指明内存单元的长度，X在汇编语言中可以为WORD或者BYTE。例如 MOV WORD PTR ds:[0] , 1\n有些指令默认了访问的是字单元还是字节单元，比如PUSH指令只进行字操作。\n除数：有8位和16位两种，在一个reg或者内存单元中。\n被除数：默认放在AX或DX和AX中，如果除数为8位，被除数为16位，默认在AX中存放；如果除数为16位，被除数为32位，在DX和AX中存放，DX存放高16位，AX存放低16位。\n结果：如果除数为8位，则AL存储除法操作的商，AH存储除法操作的余数；如果除数为16位，则AX存储除法操作的商，DX存储除法操作的余数。\n伪指令dd：DB（define byte）定义字节型数据，DW（define word）定义字型数据，DD（double word双字）定义双字型数据。\ndup是一个操作符，在汇编语言中通db、dw、dd一样，也是由编译器是被处理的符号。它是和db、dw、dd等数据定义伪指令配合使用的，用来进行数据的重复。\n\ndb 3 dup (0)       定义了3个字节，它们的值都是0，相当于db 0   0   0\ndb 3 dup(0,1,2)  定义了9个字节，它们是0、1、2、0、1、2、0、1、2，相当于db 0,1,2,0,1,2,0,1,2\ndup的使用格式如下：DB 重复的次数  DUP  （重复的字节型数据）DW 重复的次数  DUP  （重复 的字型数据）DD 重复的次数  DUP （重复 的双字型数据）\n\npush指令的执行步骤:①SP&#x3D;SP-2:②向SS:SP指向的字单元中送入数据。\npop指令的执行步骤:①从SS:SP指向的字单元中读取数据;②SP&#x3D;SP+2。\n用栈来暂存以后需要恢复的寄存器的内容时,寄存器出栈的顺序要和入栈的顺序相反。\nOFFSET是保留字，表示取出后面变量的偏移地址\n间接寻址寄存器只能是BX BP SI DI中的一个。如果没有另外说明，那么使用BX、SI和DI时自动以DS中的内容作为段基址，使用BP时自动使用SS的值作为段基址。\n","slug":"汇编语言指令","date":"2024-04-26T07:25:12.000Z","categories_index":"Study","tags_index":"学习,汇编","author_index":"Fioransh"},{"id":"06d1fc8de80210c7c2d63f6de4354843","title":"Docker使用学习","content":"1.Docker安装前置条件：配置好本地虚拟机或者云端虚拟机并安装好CentOS7版本的Linux系统。\n1.1 卸载旧版首先如果系统中已经存在旧的Docker，则先卸载：\nshellyum remove docker \\\n    docker-client \\\n    docker-client-latest \\\n    docker-common \\\n    docker-latest \\\n    docker-latest-logrotate \\\n    docker-logrotate \\\n    docker-engine1.2 配置Docker的yum库首先要安装一个yum工具\nbashyum install -y yum-utils安装成功后，执行命令，配置Docker的yum源：\nbashyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo1.3 安装Docker最后，执行命令，安装Docker\nbashyum install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin1.4 启动和校验bash# 启动Docker\nsystemctl start docker\n\n# 停止Docker\nsystemctl stop docker\n\n# 重启\nsystemctl restart docker\n\n# 设置开机自启\nsystemctl enable docker\n\n# 执行docker ps命令，如果不报错，说明安装启动成功\ndocker ps1.5 配置镜像加速这里以阿里云镜像加速为例。\n1.5.1 注册阿里云账号首先访问阿里云网站:\nhttps://www.aliyun.com/\n注册一个账号。\n1.5.2 开通镜像服务在首页的产品中，找到阿里云的容器镜像服务：\n\n点击后进入控制台：\n\n首次可能需要选择立刻开通，然后进入控制台。\n1.5.3 配置镜像加速找到镜像工具下的镜像加速器：\n\n页面向下滚动，即可找到配置的文档说明：\n\n具体命令如下：\nbash# 创建目录\nmkdir -p /etc/docker\n\n# 复制内容，注意把其中的镜像加速地址改成你自己的\ntee /etc/docker/daemon.json &lt;&lt;-&#39;EOF&#39;\n&#123;\n  &quot;registry-mirrors&quot;: [&quot;https://xxxx.mirror.aliyuncs.com&quot;]\n&#125;\nEOF\n\n# 重新加载配置\nsystemctl daemon-reload\n\n# 重启Docker\nsystemctl restart docker\n\n\n\n\n\n\n\n\n注：遇到多行命令的时候可以使用反斜杠进行换行，然后继续输入命令。\n若要结束命令则可以输入EOF或者done终止多行\n2.Docker快速入门2.1 Docker引入Linux原生安装环境缺点核心体现在三点：\n\n命令太多了，记不住\n软件安装包名字复杂，不知道去哪里找\n安装和部署步骤复杂，容易出错\n\n其实上述问题不仅仅是新手，即便是运维在安装、部署的时候一样会觉得麻烦、容易出错。\n特别是我们即将进入微服务阶段学习，微服务项目动辄就是几十台、上百台服务需要部署，有些大型项目甚至达到数万台服务。而由于每台服务器的运行环境不同，你写好的安装流程、部署脚本并不一定在每个服务器都能正常运行，经常会出错。这就给系统的部署运维带来了很多困难。\n那么，有没有一种技术能够避免部署对服务器环境的依赖，减少复杂的部署流程呢？\n答案是肯定的，这就是Docker技术。你会发现，有了Docker以后项目的部署如丝般顺滑，大大减少了运维工作量。\n即便你对Linux不熟悉，你也能轻松部署各种常见软件、Java项目。\n2.2 部署MySQL例首先，我们利用Docker来安装一个MySQL软件，大家可以对比一下之前传统的安装方式，看看哪个效率更高一些。\n如果是利用传统方式部署MySQL，大概的步骤有：\n\n搜索并下载MySQL安装包\n上传至Linux环境\n编译和配置环境\n安装\n\n而使用Docker安装，仅仅需要一步即可，在命令行输入下面的命令：\npowershelldocker run -d \\\n  --name mysql \\\n  -p 3306:3306 \\\n  -e TZ=Asia/Shanghai \\\n  -e MYSQL_ROOT_PASSWORD=123 \\\n  mysql运行效果如图：\n\nMySQL安装完毕，通过任意客户端工具即可连接到MySQL.\n我们执行命令后，Docker做的第一件事情，是去自动搜索并下载了MySQL，然后会自动运行MySQL\n这种安装方式你完全不用考虑运行的操作系统环境，它不仅仅在CentOS系统是这样，在Ubuntu系统、macOS系统、甚至是装了WSL的Windows下，都可以使用这条命令来安装MySQL。\n要知道，不同操作系统下其安装包、运行环境是都不相同的！如果是手动安装，必须手动解决安装包不同、环境不同的、配置不同的问题！\n而使用Docker，这些完全不用考虑。就是因为Docker会自动搜索并下载MySQL。注意：这里下载的不是安装包，而是镜像。镜像中不仅包含了MySQL本身，还包含了其运行所需要的环境、配置、系统级函数库。因此它在运行时就有自己独立的环境，就可以跨系统运行，也不需要手动再次配置环境了。这套独立运行的隔离环境我们称为容器。\n说明：\n\n镜像：英文是image\n容器：英文是container\n\n\n\n\n\n\n\n\n\n\n因此，Docker安装软件的过程，就是自动搜索下载镜像，然后创建并运行容器的过程。\nDocker官方提供了一个专门管理、存储镜像的网站，并对外开放了镜像上传、下载的权利。Docker官方提供了一些基础镜像，然后各大软件公司又在基础镜像基础上，制作了自家软件的镜像，全部都存放在这个网站。这个网站就成了Docker镜像交流的社区：\nhttps://hub.docker.com/\n基本上我们常用的各种软件都能在这个网站上找到，我们甚至可以自己制作镜像上传上去。\n像这种提供存储、管理Docker镜像的服务器，被称为DockerRegistry，可以翻译为镜像仓库。DockerHub网站是官方仓库，阿里云、华为云会提供一些第三方仓库，我们也可以自己搭建私有的镜像仓库。\n官方仓库在国外，下载速度较慢，一般我们都会使用第三方仓库提供的镜像加速功能，提高下载速度。而企业内部的机密项目，往往会采用私有镜像仓库。\n总之，镜像的来源有两种：\n\n基于官方基础镜像自己制作\n直接去DockerRegistry下载\n\n总结：\nDocker本身包含一个后台服务，我们可以利用Docker命令告诉Docker服务，帮助我们快速部署指定的应用。Docker服务部署应用时，首先要去搜索并下载应用对应的镜像，然后根据镜像创建并允许容器，应用就部署完成了。\n用一幅图标示如下：\n\n2.3 命令解读powershelldocker run -d \\\n  --name mysql \\\n  -p 3306:3306 \\\n  -e TZ=Asia/Shanghai \\\n  -e MYSQL_ROOT_PASSWORD=123 \\\n  mysql\n\n\n\n\n\n\n\n\n解读：\n\ndocker run -d ：创建并运行一个容器，-d则是让容器以后台进程运行\n--name mysql  : 给容器起个名字叫mysql，你可以叫别的\n-p 3306:3306 : 设置端口映射。\n容器是隔离环境，外界不可访问。但是可以将宿主机端口****映射容器内到端口，当访问宿主机指定端口时，就是在访问容器内的端口了。\n容器内端口往往是由容器内的进程决定，例如MySQL进程默认端口是3306，因此容器内端口一定是3306；而宿主机端口则可以任意指定，一般与容器内保持一致。\n格式： -p 宿主机端口:容器内端口，示例中就是将宿主机的3306映射到容器内的3306端口\n\n\n-e TZ=Asia/Shanghai : 配置容器内进程运行时的一些参数\n格式：-e KEY=VALUE，KEY和VALUE都由容器内进程决定\n案例中，TZ=Asia/Shanghai是设置时区；MYSQL_ROOT_PASSWORD=123是设置MySQL默认密码\n\n\nmysql : 设置镜像名称，Docker会根据这个名字搜索并下载镜像\n格式：REPOSITORY:TAG，例如mysql:8.0，其中REPOSITORY可以理解为镜像名，TAG是版本号\n在未指定TAG的情况下，默认是最新版本，也就是mysql:latest\n\n\n\n镜像的名称不是随意的，而是要到DockerRegistry中寻找，镜像运行时的配置也不是随意的，要参考镜像的帮助文档，这些在DockerHub网站或者软件的官方网站中都能找到。\n如果我们要安装其它软件，也可以到DockerRegistry中寻找对应的镜像名称和版本，阅读相关配置即可。\n3.Docker基础3.1 常见命令可以参考官方文档：\nhttps://docs.docker.com/engine/reference/commandline/cli/\n3.1.1 命令介绍\n\n\n命令\n说明\n文档地址\n\n\n\ndocker pull\n拉取镜像\ndocker pull\n\n\ndocker push\n推送镜像到DockerRegistry\ndocker push\n\n\ndocker images\n查看本地镜像\ndocker images\n\n\ndocker rmi\n删除本地镜像\ndocker rmi\n\n\ndocker run\n创建并运行容器（不能重复创建）\ndocker run\n\n\ndocker stop\n停止指定容器\ndocker stop\n\n\ndocker start\n启动指定容器\ndocker start\n\n\ndocker restart\n重新启动容器\ndocker restart\n\n\ndocker rm\n删除指定容器\ndocs.docker.com\n\n\ndocker ps\n查看容器\ndocker ps\n\n\ndocker logs\n查看容器运行日志\ndocker logs\n\n\ndocker exec\n进入容器\ndocker exec\n\n\ndocker save\n保存镜像到本地压缩文件\ndocker save\n\n\ndocker load\n加载本地压缩文件到镜像\ndocker load\n\n\ndocker inspect\n查看容器详细信息\ndocker inspect\n\n\n用一副图来表示这些命令的关系：\n\n注：docker run每次执行都会创建一个新的容器，如果我们原本就已经执行过创建了一个容器，然后在下次启动的时候直接使用docker start就能够启动容器，在关闭的时候使用docker stop即可停止，无需再输入docker run来启动容器，否则每次都会创建新容器，导致内存占用等一系列问题。\n补充：\n默认情况下，每次重启虚拟机我们都需要手动启动Docker和Docker中的容器。通过命令可以实现开机自启：\npowershell# Docker开机自启\nsystemctl enable docker\n\n# Docker容器开机自启\ndocker update --restart=always [容器名/容器id]3.1.2 演示教学环节说明：我们以Nginx为例给大家演示上述命令。\npowershell# 第1步，去DockerHub查看nginx镜像仓库及相关信息\n\n# 第2步，拉取Nginx镜像\ndocker pull nginx\n\n# 第3步，查看镜像\ndocker images\n# 结果如下：\nREPOSITORY   TAG       IMAGE ID       CREATED         SIZE\nnginx        latest    605c77e624dd   16 months ago   141MB\nmysql        latest    3218b38490ce   17 months ago   516MB\n\n# 第4步，创建并允许Nginx容器\ndocker run -d --name nginx -p 80:80 nginx\n\n# 第5步，查看运行中容器\ndocker ps\n# 也可以加格式化方式访问，格式会更加清爽\ndocker ps --format &quot;table &#123;&#123;.ID&#125;&#125;\\t&#123;&#123;.Image&#125;&#125;\\t&#123;&#123;.Ports&#125;&#125;\\t&#123;&#123;.Status&#125;&#125;\\t&#123;&#123;.Names&#125;&#125;&quot;\n\n# 第6步，访问网页，地址：http://虚拟机地址\n\n# 第7步，停止容器\ndocker stop nginx\n\n# 第8步，查看所有容器\ndocker ps -a --format &quot;table &#123;&#123;.ID&#125;&#125;\\t&#123;&#123;.Image&#125;&#125;\\t&#123;&#123;.Ports&#125;&#125;\\t&#123;&#123;.Status&#125;&#125;\\t&#123;&#123;.Names&#125;&#125;&quot;\n\n# 第9步，再次启动nginx容器\ndocker start nginx\n\n# 第10步，再次查看容器\ndocker ps --format &quot;table &#123;&#123;.ID&#125;&#125;\\t&#123;&#123;.Image&#125;&#125;\\t&#123;&#123;.Ports&#125;&#125;\\t&#123;&#123;.Status&#125;&#125;\\t&#123;&#123;.Names&#125;&#125;&quot;\n\n# 第11步，查看容器详细信息\ndocker inspect nginx\n\n# 第12步，进入容器,查看容器内目录\ndocker exec -it nginx bash\n# 或者，可以进入MySQL\ndocker exec -it mysql mysql -uroot -p\n\n# 第13步，删除容器\ndocker rm nginx\n# 发现无法删除，因为容器运行中，强制删除容器\ndocker rm -f nginx3.1.3 命令别名给常用Docker命令起别名，方便我们访问：\npowershell# 修改/root/.bashrc文件\nvi /root/.bashrc\n内容如下：\n# .bashrc\n\n# User specific aliases and functions\n//在此处添加别名代表的命令\nalias rm=&#39;rm -i&#39;\nalias cp=&#39;cp -i&#39;\nalias mv=&#39;mv -i&#39;\nalias dps=&#39;docker ps --format &quot;table &#123;&#123;.ID&#125;&#125;\\t&#123;&#123;.Image&#125;&#125;\\t&#123;&#123;.Ports&#125;&#125;\\t&#123;&#123;.Status&#125;&#125;\\t&#123;&#123;.Names&#125;&#125;&quot;&#39;\nalias dis=&#39;docker images&#39;\n\n# Source global definitions\nif [ -f /etc/bashrc ]; then\n        . /etc/bashrc\nfi然后，执行命令使别名生效\npowershellsource /root/.bashrc\n或 source ~/.bashrc3.2 数据卷容器是隔离环境，容器内程序的文件、配置、运行时产生的容器都在容器内部，我们要读写容器内的文件非常不方便。大家思考几个问题：\n\n如果要升级MySQL版本，需要销毁旧容器，那么数据岂不是跟着被销毁了？\nMySQL、Nginx容器运行后，如果我要修改其中的某些配置该怎么办？\n我想要让Nginx代理我的静态资源怎么办？\n\n因此，容器提供程序的运行环境，但是程序运行产生的数据、程序运行依赖的配置都应该与容器解耦。\n3.2.1 什么是数据卷数据卷（volume）是一个虚拟目录，是容器内目录与宿主机目录之间映射的桥梁。\n以Nginx为例，我们知道Nginx中有两个关键的目录： \n\nhtml：放置一些静态资源\nconf：放置配置文件\n\n如果我们要让Nginx代理我们的静态资源，最好是放到html目录；如果我们要修改Nginx的配置，最好是找到conf下的nginx.conf文件。\n但遗憾的是，容器运行的Nginx所有的文件都在容器内部。所以我们必须利用数据卷将两个目录与宿主机目录关联，方便我们操作。如图：\n\n在上图中：\n\n我们创建了两个数据卷：conf、html\nNginx容器内部的conf目录和html目录分别与两个数据卷关联。\n而数据卷conf和html分别指向了宿主机的/var/lib/docker/volumes/conf/_data目录和/var/lib/docker/volumes/html/_data目录\n\n这样以来，容器内的conf和html目录就 与宿主机的conf和html目录关联起来，我们称为挂载。此时，我们操作宿主机的/var/lib/docker/volumes/html/_data就是在操作容器内的/usr/share/nginx/html/_data目录。只要我们将静态资源放入宿主机对应目录，就可以被Nginx代理了。\n\n\n\n\n\n\n\n\n\n小提示：\n/var/lib/docker/volumes这个目录就是默认的存放所有容器数据卷的目录，其下再根据数据卷名称创建新目录，格式为/数据卷名/_data。\n为什么不让容器目录直接指向宿主机目录呢？\n\n因为直接指向宿主机目录就与宿主机强耦合了，如果切换了环境，宿主机目录就可能发生改变了。由于容器一旦创建，目录挂载就无法修改，这样容器就无法正常工作了。\n但是容器指向数据卷，一个逻辑名称，而数据卷再指向宿主机目录，就不存在强耦合。如果宿主机目录发生改变，只要改变数据卷与宿主机目录之间的映射关系即可。\n\n不过，我们通过由于数据卷目录比较深，不好寻找，通常我们也**允许让容器直接与宿主机目录挂载而不使用数据卷。\n3.2.2 数据卷命令数据卷的相关命令有：\n\n\n\n命令\n说明\n文档地址\n\n\n\ndocker volume create\n创建数据卷\ndocker volume create\n\n\ndocker volume ls\n查看所有数据卷\ndocs.docker.com\n\n\ndocker volume rm\n删除指定数据卷\ndocs.docker.com\n\n\ndocker volume inspect\n查看某个数据卷的详情\ndocs.docker.com\n\n\ndocker volume prune\n清除数据卷\ndocker volume prune\n\n\n注意：容器与数据卷的挂载要在创建容器时配置，对于创建好的容器，是不能设置数据卷的。而且创建容器的过程中如果挂载了数据卷且数据卷不存在，数据卷会自动创建。\n在docker run命令的时候，使用**-v数据卷：容器内**目录可以完成挂载\n演示nginx的html目录挂载\npowershell# 1.首先创建容器并指定数据卷，注意通过 -v 参数来指定数据卷\ndocker run -d --name nginx -p 80:80 -v html:/usr/share/nginx/html nginx\n\n# 2.然后查看数据卷\ndocker volume ls\n# 结果\nDRIVER    VOLUME NAME\nlocal     29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f\nlocal     html\n\n# 3.查看数据卷详情\ndocker volume inspect html\n# 结果\n[\n    &#123;\n        &quot;CreatedAt&quot;: &quot;2024-05-17T19:57:08+08:00&quot;,\n        &quot;Driver&quot;: &quot;local&quot;,\n        &quot;Labels&quot;: null,\n        &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/html/_data&quot;,\n        &quot;Name&quot;: &quot;html&quot;,\n        &quot;Options&quot;: null,\n        &quot;Scope&quot;: &quot;local&quot;\n    &#125;\n]\n\n# 4.查看/var/lib/docker/volumes/html/_data目录\nll /var/lib/docker/volumes/html/_data\n# 可以看到与nginx的html目录内容一样，结果如下：\n总用量 8\n-rw-r--r--. 1 root root 497 12月 28 2021 50x.html\n-rw-r--r--. 1 root root 615 12月 28 2021 index.html\n\n# 5.进入该目录，并随意修改index.html内容\ncd /var/lib/docker/volumes/html/_data\nvi index.html\n\n# 6.打开页面，查看效果\n\n# 7.进入容器内部，查看/usr/share/nginx/html目录内的文件是否变化\ndocker exec -it nginx bash演示MySQL的匿名数据卷\npowershell# 1.查看MySQL容器详细信息\ndocker inspect mysql\n# 关注其中.Config.Volumes部分和.Mounts部分我们关注两部分内容，第一是.Config.Volumes部分：\njson&#123;\n  &quot;Config&quot;: &#123;\n    // ... 略\n    &quot;Volumes&quot;: &#123;\n      &quot;/var/lib/mysql&quot;: &#123;&#125;\n    &#125;\n    // ... 略\n  &#125;\n&#125;可以发现这个容器声明了一个本地目录，需要挂载数据卷，但是数据卷未定义。这就是匿名卷。\n然后，我们再看结果中的.Mounts部分：\njson&#123;\n  &quot;Mounts&quot;: [\n    &#123;\n      &quot;Type&quot;: &quot;volume&quot;,\n      &quot;Name&quot;: &quot;29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f&quot;,\n      &quot;Source&quot;: &quot;/var/lib/docker/volumes/29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f/_data&quot;,\n      &quot;Destination&quot;: &quot;/var/lib/mysql&quot;,\n      &quot;Driver&quot;: &quot;local&quot;,\n    &#125;\n  ]\n&#125;可以发现，其中有几个关键属性：\n\nName：数据卷名称。由于定义容器未设置容器名，这里的就是匿名卷自动生成的名字，一串hash值。\nSource：宿主机目录\nDestination : 容器内的目录\n\n上述配置是将容器内的/var/lib/mysql这个目录，与数据卷29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f挂载。于是在宿主机中就有了/var/lib/docker/volumes/29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f/_data这个目录。这就是匿名数据卷对应的目录，其使用方式与普通数据卷没有差别。\n接下来，可以查看该目录下的MySQL的data文件：\nbashls -l /var/lib/docker/volumes/29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f/_data注意：每一个不同的镜像，将来创建容器后内部有哪些目录可以挂载，可以参考DockerHub对应的页面\n3.2.3 挂载本地目录或文件可以发现，数据卷的目录结构较深，如果我们去操作数据卷目录会不太方便。在很多情况下，我们会直接将容器目录与宿主机指定目录挂载。挂载语法与数据卷类似：\nbash# 挂载本地目录\n-v 本地目录:容器内目录\n# 挂载本地文件\n-v 本地文件:容器内文件注意：本地目录或文件必须以 / 或 ./开头，如果直接以名字开头，会被识别为数据卷名而非本地目录名。\n例如：\nbash-v mysql:/var/lib/mysql # 会被识别为一个数据卷叫mysql，运行时会自动创建这个数据卷\n-v ./mysql:/var/lib/mysql # 会被识别为当前目录下的mysql目录，运行时如果不存在会创建目录演示，删除并重新创建mysql容器，并完成本地目录挂载：\n\n挂载/root/mysql/data到容器内的/var/lib/mysql目录\n挂载/root/mysql/init到容器内的/docker-entrypoint-initdb.d目录（初始化的SQL脚本目录）\n挂载/root/mysql/conf到容器内的/etc/mysql/conf.d目录（这个是MySQL配置文件目录）\n\nmysql的init目录和conf目录：\n\n以及对应的初始化SQL脚本和配置文件：\n\n\n其中，hm.cnf主要是配置了MySQL的默认编码，改为utf8mb4；而hmall.sql是初始化SQL脚本。\n我们直接将整个mysql目录上传至虚拟机的/root目录下：\n\n接下来，我们演示本地目录挂载：\nbash# 1.删除原来的MySQL容器\ndocker rm -f mysql\n\n# 2.进入root目录\ncd ~\n\n# 3.创建并运行新mysql容器，挂载本地目录\ndocker run -d \\\n  --name mysql \\\n  -p 3306:3306 \\\n  -e TZ=Asia/Shanghai \\\n  -e MYSQL_ROOT_PASSWORD=123 \\\n  -v ./mysql/data:/var/lib/mysql \\\n  -v ./mysql/conf:/etc/mysql/conf.d \\\n  -v ./mysql/init:/docker-entrypoint-initdb.d \\\n  mysql\n\n# 4.查看root目录，可以发现~/mysql/data目录已经自动创建好了\nls -l mysql\n# 结果：\n总用量 4\ndrwxr-xr-x. 2 root    root   20 5月  19 15:11 conf\ndrwxr-xr-x. 7 polkitd root 4096 5月  19 15:11 data\ndrwxr-xr-x. 2 root    root   23 5月  19 15:11 init\n\n# 查看data目录，会发现里面有大量数据库数据，说明数据库完成了初始化\nls -l data\n\n# 5.查看MySQL容器内数据\n# 5.1.进入MySQL\ndocker exec -it mysql mysql -uroot -p123\n# 5.2.查看编码表\nshow variables like &quot;%char%&quot;;\n# 5.3.结果，发现编码是utf8mb4没有问题\n+--------------------------+--------------------------------+\n| Variable_name            | Value                          |\n+--------------------------+--------------------------------+\n| character_set_client     | utf8mb4                        |\n| character_set_connection | utf8mb4                        |\n| character_set_database   | utf8mb4                        |\n| character_set_filesystem | binary                         |\n| character_set_results    | utf8mb4                        |\n| character_set_server     | utf8mb4                        |\n| character_set_system     | utf8mb3                        |\n| character_sets_dir       | /usr/share/mysql-8.0/charsets/ |\n+--------------------------+--------------------------------+\n\n# 6.查看数据\n# 6.1.查看数据库\nshow databases;\n# 结果，hmall是黑马商城数据库\n+--------------------+\n| Database           |\n+--------------------+\n| hmall              |\n| information_schema |\n| mysql              |\n| performance_schema |\n| sys                |\n+--------------------+\n5 rows in set (0.00 sec)\n# 6.2.切换到hmall数据库\nuse hmall;\n# 6.3.查看表\nshow tables;\n# 结果：\n+-----------------+\n| Tables_in_hmall |\n+-----------------+\n| address         |\n| cart            |\n| item            |\n| order           |\n| order_detail    |\n| order_logistics |\n| pay_order       |\n| user            |\n+-----------------+\n# 6.4.查看address表数据\n+----+---------+----------+--------+----------+-------------+---------------+-----------+------------+-------+\n| id | user_id | province | city   | town     | mobile      | street        | contact   | is_default | notes |\n+----+---------+----------+--------+----------+-------------+---------------+-----------+------------+-------+\n| 59 |       1 | 北京     | 北京   | 朝阳区    | 13900112222 | 金燕龙办公楼   | 李佳诚    | 0          | NULL  |\n| 60 |       1 | 北京     | 北京   | 朝阳区    | 13700221122 | 修正大厦       | 李佳红    | 0          | NULL  |\n| 61 |       1 | 上海     | 上海   | 浦东新区  | 13301212233 | 航头镇航头路   | 李佳星    | 1          | NULL  |\n| 63 |       1 | 广东     | 佛山   | 永春      | 13301212233 | 永春武馆       | 李晓龙    | 0          | NULL  |\n+----+---------+----------+--------+----------+-------------+---------------+-----------+------------+-------+\n4 rows in set (0.00 sec)3.3 镜像前面我们一直在使用别人准备好的镜像，那如果我要部署一个Java项目，把它打包为一个镜像该怎么做呢？\n3.3.1 镜像结构镜像之所以能让我们快速跨操作系统部署应用而忽略其运行环境、配置，就是因为镜像中包含了程序运行需要的系统函数库、环境、配置、依赖。\n因此，自定义镜像本质就是依次准备好程序运行的基础环境、依赖、应用本身、运行配置等文件，并且打包而成。\n我们要从0部署一个Java应用，大概流程是这样：\n\n准备一个linux服务（CentOS或者Ubuntu均可）\n安装并配置JDK\n上传Jar包\n运行jar包\n\n我们打包镜像也是分成这么几步：\n\n准备Linux运行环境（java项目并不需要完整的操作系统，仅仅是基础运行环境即可）\n安装并配置JDK\n拷贝jar包\n配置启动脚本\n\n上述步骤中的每一次操作其实都是在生产一些文件（系统运行环境、函数库、配置最终都是磁盘文件），所以镜像就是一堆文件的集合。\n但需要注意的是，镜像文件不是随意堆放的，而是按照操作的步骤分层叠加而成，每一层形成的文件都会单独打包并标记一个唯一id，称为Layer（层）。这样，如果我们构建时用到的某些层其他人已经制作过，就可以直接拷贝使用这些层，而不用重复制作。\n例如，第一步中需要的Linux运行环境，通用性就很强，所以Docker官方就制作了这样的只包含Linux运行环境的镜像。我们在制作java镜像时，就无需重复制作，直接使用Docker官方提供的CentOS或Ubuntu镜像作为基础镜像。然后再搭建其它层即可，这样逐层搭建，最终整个Java项目的镜像结构如图所示：\n\n3.3.2 Dockerfile由于制作镜像的过程中，需要逐层处理和打包，比较复杂，所以Docker就提供了自动打包镜像的功能。我们只需要将打包的过程，每一层要做的事情用固定的语法写下来，交给Docker去执行即可。\n而这种记录镜像结构的文件就称为Dockerfile，其对应的语法可以参考官方文档：\nhttps://docs.docker.com/engine/reference/builder/\n其中的语法比较多，比较常用的有：\n\n\n\n指令\n说明\n示例\n\n\n\nFROM\n指定基础镜像\nFROM centos:6\n\n\nENV\n设置环境变量，可在后面指令使用\nENV key value\n\n\nCOPY\n拷贝本地文件到镜像的指定目录\nCOPY ./xx.jar /tmp/app.jar\n\n\nRUN\n执行Linux的shell命令，一般是安装过程的命令\nRUN yum install gcc\n\n\nEXPOSE\n指定容器运行时监听的端口，是给镜像使用者看的\nEXPOSE 8080\n\n\nENTRYPOINT\n镜像中应用的启动命令，容器运行时调用\nENTRYPOINT java -jar xx.jar\n\n\n例如，要基于Ubuntu镜像来构建一个Java应用，其Dockerfile内容如下：\ndockerfile# 指定基础镜像\nFROM ubuntu:16.04\n# 配置环境变量，JDK的安装目录、容器内时区\nENV JAVA_DIR=/usr/local\nENV TZ=Asia/Shanghai\n# 拷贝jdk和java项目的包\nCOPY ./jdk8.tar.gz $JAVA_DIR/\nCOPY ./docker-demo.jar /tmp/app.jar\n# 设定时区\nRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezone\n# 安装JDK\nRUN cd $JAVA_DIR \\\n &amp;&amp; tar -xf ./jdk8.tar.gz \\\n &amp;&amp; mv ./jdk1.8.0_144 ./java8\n# 配置环境变量\nENV JAVA_HOME=$JAVA_DIR/java8\nENV PATH=$PATH:$JAVA_HOME/bin\n# 指定项目监听的端口\nEXPOSE 8080\n# 入口，java项目的启动命令\nENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;/app.jar&quot;]会有很多java项目需要打包为镜像，他们都需要Linux系统环境、JDK环境这两层，只有上面的3层不同（因为jar包不同）。如果每次制作java镜像都重复制作前两层镜像会很麻烦。 \n所以，就有人提供了基础的系统加JDK环境，我们在此基础上制作java镜像，就可以省去JDK的配置了：\ndockerfile# 基础镜像\nFROM openjdk:11.0-jre-buster\n# 设定时区\nENV TZ=Asia/Shanghai\nRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezone\n# 拷贝jar包\nCOPY docker-demo.jar /app.jar\n# 入口\nENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;/app.jar&quot;]3.3.3 构建镜像当Dockerfile文件写好以后，就可以利用命令来构建镜像了。\n首先，将docker-demo.jar包以及Dockerfile拷贝到虚拟机的/root/demo目录：\n\n然后，执行命令，构建镜像：\nbash# 进入镜像目录\ncd /root/demo\n# 开始构建\ndocker build -t docker-demo:1.0 .命令说明：\n\ndocker build : 就是构建一个docker镜像\n-t docker-demo:1.0 ：-t参数是指定镜像的名称（repository和tag）\n. : 最后的点是指构建时Dockerfile所在路径，由于我们进入了demo目录，所以指定的是.代表当前目录，也可以直接指定Dockerfile目录：\nbash# 直接指定Dockerfile目录\ndocker build -t docker-demo:1.0 /root/demo\n\n\n\n结果：\n\n查看镜像列表：\nbash# 查看镜像列表：\ndocker images\n# 结果\nREPOSITORY    TAG       IMAGE ID       CREATED          SIZE\ndocker-demo   1.0       d6ab0b9e64b9   27 minutes ago   327MB\nnginx         latest    605c77e624dd   16 months ago    141MB\nmysql         latest    3218b38490ce   17 months ago    516MB然后尝试运行该镜像：\nbash# 1.创建并运行容器\ndocker run -d --name dd -p 8080:8080 docker-demo:1.0\n# 2.查看容器\ndps\n# 结果\nCONTAINER ID   IMAGE             PORTS                                                  STATUS         NAMES\n78a000447b49   docker-demo:1.0   0.0.0.0:8080-&gt;8080/tcp, :::8090-&gt;8090/tcp              Up 2 seconds   dd\nf63cfead8502   mysql             0.0.0.0:3306-&gt;3306/tcp, :::3306-&gt;3306/tcp, 33060/tcp   Up 2 hours     mysql\n\n# 3.访问\ncurl localhost:8080/hello/count\n# 结果：\n&lt;h5&gt;欢迎访问黑马商城, 这是您第1次访问&lt;h5&gt;3.4 网络上我们创建了一个Java项目的容器，而Java项目往往需要访问其它各种中间件，例如MySQL、Redis等。现在，我们的容器之间能否互相访问？我们来测试一下\n首先，我们查看下MySQL容器的详细信息，重点关注其中的网络IP地址：\nbash# 1.用基本命令，寻找Networks.bridge.IPAddress属性\ndocker inspect mysql\n# 也可以使用format过滤结果\ndocker inspect --format=&#39;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;println .IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#39; mysql\n# 得到IP地址如下：\n172.17.0.2\n\n# 2.然后通过命令进入dd容器\ndocker exec -it dd bash\n\n# 3.在容器内，通过ping命令测试网络\nping 172.17.0.2\n# 结果\nPING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.\n64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.053 ms\n64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.059 ms\n64 bytes from 172.17.0.2: icmp_seq=3 ttl=64 time=0.058 ms发现可以互联，没有问题。\n但是，容器的网络IP其实是一个虚拟的IP，其值并不固定与某一个容器绑定，如果我们在开发时写死某个IP，而在部署时很可能MySQL容器的IP会发生变化，连接会失败。\n所以，我们必须借助于docker的网络功能来解决这个问题，官方文档：\nhttps://docs.docker.com/engine/reference/commandline/network/\n常见命令有：\n\n\n\n命令\n说明\n文档地址\n\n\n\ndocker network create\n创建一个网络\ndocker network create\n\n\ndocker network ls\n查看所有网络\ndocs.docker.com\n\n\ndocker network rm\n删除指定网络\ndocs.docker.com\n\n\ndocker network prune\n清除未使用的网络\ndocs.docker.com\n\n\ndocker network connect\n使指定容器连接加入某网络\ndocs.docker.com\n\n\ndocker network disconnect\n使指定容器连接离开某网络\ndocker network disconnect\n\n\ndocker network inspect\n查看网络详细信息\ndocker network inspect\n\n\n演示：自定义网络\nbash# 1.首先通过命令创建一个网络\ndocker network create hmall\n\n# 2.然后查看网络\ndocker network ls\n# 结果：\nNETWORK ID     NAME      DRIVER    SCOPE\n639bc44d0a87   bridge    bridge    local\n403f16ec62a2   hmall     bridge    local\n0dc0f72a0fbb   host      host      local\ncd8d3e8df47b   none      null      local\n# 其中，除了hmall以外，其它都是默认的网络\n\n# 3.让dd和mysql都加入该网络，注意，在加入网络时可以通过--alias给容器起别名\n# 这样该网络内的其它容器可以用别名互相访问！\n# 3.1.mysql容器，指定别名为db，另外每一个容器都有一个别名是容器名\ndocker network connect hmall mysql --alias db\n# 3.2.db容器，也就是我们的java项目\ndocker network connect hmall dd\n\n# 4.进入dd容器，尝试利用别名访问db\n# 4.1.进入容器\ndocker exec -it dd bash\n# 4.2.用db别名访问\nping db\n# 结果\nPING db (172.18.0.2) 56(84) bytes of data.\n64 bytes from mysql.hmall (172.18.0.2): icmp_seq=1 ttl=64 time=0.070 ms\n64 bytes from mysql.hmall (172.18.0.2): icmp_seq=2 ttl=64 time=0.056 ms\n# 4.3.用容器名访问\nping mysql\n# 结果：\nPING mysql (172.18.0.2) 56(84) bytes of data.\n64 bytes from mysql.hmall (172.18.0.2): icmp_seq=1 ttl=64 time=0.044 ms\n64 bytes from mysql.hmall (172.18.0.2): icmp_seq=2 ttl=64 time=0.054 ms现在无需记住IP地址也可以实现容器互联了。\n总结：\n\n在自定义网络中，可以给容器起多个别名，默认的别名是容器名本身\n在同一个自定义网络中的容器，可以通过别名互相访问\n\n4.项目部署演示好了，我们已经熟悉了Docker的基本用法，接下来可以尝试部署项目了。\n演示项目说明：\n\nhmall：商城的后端代码\nhmall-portal：商城用户端的前端代码\nhmall-admin：商城管理端的前端代码\n\n部署的容器及端口说明：\n\n\n\n项目\n容器名\n端口\n备注\n\n\n\nhmall\nhmall\n8080\n商城后端API入口\n\n\nhmall-portal\nnginx\n18080\n商城用户端入口\n\n\nhmall-admin\n18081\n商城管理端入口\n\n\n\nmysql\nmysql\n3306\n数据库\n\n\n在正式部署前，我们先删除之前的nginx、dd两个容器：\nbashdocker rm -f nginx ddmysql容器中已经准备好了商城的数据，所以就不再删除了。\n4.1 部署Java项目hmall项目是一个maven聚合项目，使用IDEA打开hmall项目，查看项目结构如图：\n\n我们要部署的就是其中的hm-service，其中的配置文件采用了多环境的方式：\n\n其中的application-dev.yaml是部署到开发环境的配置，application-local.yaml是本地运行时的配置。\n查看application.yaml，你会发现其中的JDBC地址并未写死，而是读取变量：\n\n这两个变量在application-dev.yaml和application-local.yaml中并不相同：\n\n在dev开发环境（也就是Docker部署时）采用了mysql作为地址，刚好是我们的mysql容器名，只要两者在一个网络，就一定能互相访问。\n我们将项目打包：\n\n结果：\n\n将hm-service目录下的Dockerfile和hm-service/target目录下的hm-service.jar一起上传到虚拟机的root目录：\n\n部署项目：\nbash# 1.构建项目镜像，不指定tag，则默认为latest\ndocker build -t hmall .\n\n# 2.查看镜像\ndocker images\n# 结果\nREPOSITORY    TAG       IMAGE ID       CREATED          SIZE\nhmall         latest    0bb07b2c34b9   43 seconds ago   362MB\ndocker-demo   1.0       49743484da68   24 hours ago     327MB\nnginx         latest    605c77e624dd   16 months ago    141MB\nmysql         latest    3218b38490ce   17 months ago    516MB\n\n# 3.创建并运行容器，并通过--network将其加入hmall网络，这样才能通过容器名访问mysql\ndocker run -d --name hmall --network hmall -p 8080:8080 hmall测试，通过浏览器访问：http:&#x2F;&#x2F;你的虚拟机地址:8080&#x2F;search&#x2F;list\n4.2 部署前端hmall-portal和hmall-admin是前端代码，需要基于nginx部署。nginx的部署目录：\n\n其中：\n\nhtml是静态资源目录，我们需要把hmall-portal以及hmall-admin都复制进去\nnginx.conf是nginx的配置文件，主要是完成对html下的两个静态资源目录做代理，注意api的修改容器名称的对应。\n\n把整个nginx目录上传到虚拟机的/root目录下：\n\n然后创建nginx容器并完成两个挂载：\n\n把/root/nginx/nginx.conf挂载到/etc/nginx/nginx.conf\n把/root/nginx/html挂载到/usr/share/nginx/html\n\n由于需要让nginx同时代理hmall-portal和hmall-admin两套前端资源，因此我们需要暴露两个端口：\n\n18080：对应hmall-portal\n18081：对应hmall-admin\n\n命令如下：\nbashdocker run -d \\\n  --name nginx \\\n  -p 18080:18080 \\\n  -p 18081:18081 \\\n  -v /root/nginx/html:/usr/share/nginx/html \\\n  -v /root/nginx/nginx.conf:/etc/nginx/nginx.conf \\\n  --network hmall \\\n  nginx测试，通过浏览器访问：http:&#x2F;&#x2F;你的虚拟机ip:18080\n4.3 DockerCompose大家可以看到，我们部署一个简单的java项目，其中包含3个容器：\n\nMySQL\nNginx\nJava项目\n\n而稍微复杂的项目，其中还会有各种各样的其它中间件，需要部署的东西远不止3个。如果还像之前那样手动的逐一部署，就太麻烦了。\n而Docker Compose就可以帮助我们实现多个相互关联的Docker容器的快速部署。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器。\n4.3.1 基本语法docker-compose.yml文件的基本语法可以参考官方文档：\nhttps://docs.docker.com/compose/compose-file/compose-file-v3/\ndocker-compose文件中可以定义多个相互关联的应用容器，每一个应用容器被称为一个服务（service）。由于service就是在定义某个应用的运行时参数，因此与docker run参数非常相似。\n举例来说，用docker run部署MySQL的命令如下：\nbashdocker run -d \\\n  --name mysql \\\n  -p 3306:3306 \\\n  -e TZ=Asia/Shanghai \\\n  -e MYSQL_ROOT_PASSWORD=123 \\\n  -v ./mysql/data:/var/lib/mysql \\\n  -v ./mysql/conf:/etc/mysql/conf.d \\\n  -v ./mysql/init:/docker-entrypoint-initdb.d \\\n  --network hmall\n  mysql如果用docker-compose.yml文件来定义，就是这样：\nyamlversion: &quot;3.8&quot;\n\nservices:\n  mysql:\n    image: mysql\n    container_name: mysql\n    ports:\n      - &quot;3306:3306&quot;\n    environment:\n      TZ: Asia/Shanghai\n      MYSQL_ROOT_PASSWORD: 123\n    volumes:\n      - &quot;./mysql/conf:/etc/mysql/conf.d&quot;\n      - &quot;./mysql/data:/var/lib/mysql&quot;\n    networks:\n      - new\nnetworks:\n  new:\n    name: hmall对比如下：\n\n\n\ndocker run 参数\ndocker compose 指令\n说明\n\n\n\n–name\ncontainer_name\n容器名称\n\n\n-p\nports\n端口映射\n\n\n-e\nenvironment\n环境变量\n\n\n-v\nvolumes\n数据卷配置\n\n\n–network\nnetworks\n网络\n\n\n明白了其中的对应关系，相信编写docker-compose文件应该难不倒大家。\n演示商城部署文件：\nyamlversion: &quot;3.8&quot;\n\nservices:\n  mysql:\n    image: mysql\n    container_name: mysql\n    ports:\n      - &quot;3306:3306&quot;\n    environment:\n      TZ: Asia/Shanghai\n      MYSQL_ROOT_PASSWORD: 123\n    volumes:\n      - &quot;./mysql/conf:/etc/mysql/conf.d&quot;\n      - &quot;./mysql/data:/var/lib/mysql&quot;\n      - &quot;./mysql/init:/docker-entrypoint-initdb.d&quot;\n    networks:\n      - hm-net\n  hmall:\n    build: \n      context: .\n      dockerfile: Dockerfile\n    container_name: hmall\n    ports:\n      - &quot;8080:8080&quot;\n    networks:\n      - hm-net\n    depends_on:\n      - mysql\n  nginx:\n    image: nginx\n    container_name: nginx\n    ports:\n      - &quot;18080:18080&quot;\n      - &quot;18081:18081&quot;\n    volumes:\n      - &quot;./nginx/nginx.conf:/etc/nginx/nginx.conf&quot;\n      - &quot;./nginx/html:/usr/share/nginx/html&quot;\n    depends_on:\n      - hmall\n    networks:\n      - hm-net\nnetworks:\n  hm-net:\n    name: hmall4.3.2 基础命令编写好docker-compose.yml文件，就可以部署项目了。常见的命令：\nhttps://docs.docker.com/compose/reference/\n基本语法如下：\nbashdocker compose [OPTIONS] [COMMAND]其中，OPTIONS和COMMAND都是可选参数，比较常见的有：\n\n\n\n类型\n参数或指令\n说明\n\n\n\nOptions\n-f\n指定compose文件的路径和名称\n\n\n-p\n指定project名称。project就是当前compose文件中设置的多个service的集合，是逻辑概念\n\n\n\nCommands\nup\n创建并启动所有service容器\n\n\ndown\n停止并移除所有容器、网络\n\n\n\nps\n列出所有启动的容器\n\n\n\nlogs\n查看指定容器的日志\n\n\n\nstop\n停止容器\n\n\n\nstart\n启动容器\n\n\n\nrestart\n重启容器\n\n\n\ntop\n查看运行的进程\n\n\n\nexec\n在指定的运行中容器中执行命令\n\n\n\n教学演示：\nbash# 1.进入root目录\ncd /root\n\n# 2.删除旧容器\ndocker rm -f $(docker ps -qa)\n\n# 3.删除hmall镜像\ndocker rmi hmall\n\n# 4.清空MySQL数据\nrm -rf mysql/data\n\n# 5.启动所有, -d 参数是后台启动\ndocker compose up -d\n# 结果：\n[+] Building 15.5s (8/8) FINISHED\n =&gt; [internal] load build definition from Dockerfile                                    0.0s\n =&gt; =&gt; transferring dockerfile: 358B                                                    0.0s\n =&gt; [internal] load .dockerignore                                                       0.0s\n =&gt; =&gt; transferring context: 2B                                                         0.0s\n =&gt; [internal] load metadata for docker.io/library/openjdk:11.0-jre-buster             15.4s\n =&gt; [1/3] FROM docker.io/library/openjdk:11.0-jre-buster@sha256:3546a17e6fb4ff4fa681c3  0.0s\n =&gt; [internal] load build context                                                       0.0s\n =&gt; =&gt; transferring context: 98B                                                        0.0s\n =&gt; CACHED [2/3] RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo   0.0s\n =&gt; CACHED [3/3] COPY hm-service.jar /app.jar                                           0.0s\n =&gt; exporting to image                                                                  0.0s\n =&gt; =&gt; exporting layers                                                                 0.0s\n =&gt; =&gt; writing image sha256:32eebee16acde22550232f2eb80c69d2ce813ed099640e4cfed2193f71  0.0s\n =&gt; =&gt; naming to docker.io/library/root-hmall                                           0.0s\n[+] Running 4/4\n ✔ Network hmall    Created                                                             0.2s\n ✔ Container mysql  Started                                                             0.5s\n ✔ Container hmall  Started                                                             0.9s\n ✔ Container nginx  Started                                                             1.5s\n\n# 6.查看镜像\ndocker compose images\n# 结果\nCONTAINER           REPOSITORY          TAG                 IMAGE ID            SIZE\nhmall               root-hmall          latest              32eebee16acd        362MB\nmysql               mysql               latest              3218b38490ce        516MB\nnginx               nginx               latest              605c77e624dd        141MB\n\n# 7.查看容器\ndocker compose ps\n# 结果\nNAME                IMAGE               COMMAND                  SERVICE             CREATED             STATUS              PORTS\nhmall               root-hmall          &quot;java -jar /app.jar&quot;     hmall               54 seconds ago      Up 52 seconds       0.0.0.0:8080-&gt;8080/tcp, :::8080-&gt;8080/tcp\nmysql               mysql               &quot;docker-entrypoint.s…&quot;   mysql               54 seconds ago      Up 53 seconds       0.0.0.0:3306-&gt;3306/tcp, :::3306-&gt;3306/tcp, 33060/tcp\nnginx               nginx               &quot;/docker-entrypoint.…&quot;   nginx               54 seconds ago      Up 52 seconds       80/tcp, 0.0.0.0:18080-18081-&gt;18080-18081/tcp, :::18080-18081-&gt;18080-18081/tcp打开浏览器，访问：http://yourIp:8080\n","slug":"Docker总结","date":"2024-04-12T02:51:12.000Z","categories_index":"Study","tags_index":"Docker,开发工具","author_index":"Fioransh"},{"id":"da5c5f9dfe8d5fb0dab3c41b63c9c534","title":"VMware部署Redis","content":"1.VMware安装CentOS71.1 CentOS7的下载官网下载地址：Download。\n\n点进去后选择阿里云镜像源下载\n\n选择iso镜像文件下载\n\n1.2 CentOS7的配置1.2.1 VMware安装vmware官网下载：vmware官网\n下载文件：安装之后是这样的界面\n\n如果你点击下一步出现了这个页面的话，那就证明你电脑里面已经有vmware了，就可以直接用了，如果你想重新安装，直接删除就好，再重新打开安装程序继续安装。\n\n到选择位置的时候可以更改一下安装位置，防止c盘爆掉…\n\n继续点击下一步\n到下面图片中的这一个步骤，可以点击许可证，输入密钥就可以使用了，\n密钥可以去某度或者其他地方搜索一个拿来用就好！！\n如果直接点击完成的话，可以有试用的时间，也可以使用\n\n1.2.2 新建虚拟机打开“VMware Workstation”软件，选择“创建新的虚拟机”。\n\n点击下一步选择稍后安装操作系统。\n\n选择Linux，版本为CentOS 7 64位。\n\n选择虚拟机安装的位置，也可以更改虚拟机名称。\n\n磁盘大小默认即可，虚拟磁盘存储为单个文件。\n\n点击下一步后选择自定义硬件，找到镜像文件。\n\n\n返回点击完成后即可成功创建虚拟机。\n\n1.2.3 CentOS7安装选中刚刚配置的CentOS7，然后点击“开启此虚拟机”。\n\n虚拟机启动之后会出现如下界面（白色表示选中），默认选中的是Test this media &amp; install CentOS 7。\n\n\n\n\n\n\n\n\n\n\n注意： 在虚拟机中的操作，鼠标必须要移入到虚拟机中，否则虚拟机感应不到，无法对其进行操作。\n​       鼠标移动到虚拟机内部单击或者按下Ctrl + G，鼠标即可移入到虚拟机中。\n​       按下Ctrl + Alt，鼠标即可移出虚拟机。\n按下Enter进行安装，等待系统加载完成\n\n选择使用哪种语言，推荐使用英文。 在这里我选择中文安装\n\n【本地化】只配置日期和时间，键盘和语言支持没有特殊情况默认就好。中国范围内都选择为上海（因为只有上海可选），并选择为24小时制，设置完成后单击完成按钮。\n【软件】中只配置软件选择，安装源系统会自动识别，所以不用。\n若出现感叹号则需要点击进入设置后再点击一次完成即可自动配置好。\n然后我们选择安装的系统是否含有界面，界面一般对于我们来说用处不大，而且CentOS的界面不好操作，所以这里选择最小安装。\n【系统】中只配置安装位置，指的是系统如何分区，其它的都默认就好。\n分区选择自动分区即可，如需手动配置分区请网络搜索教程。\n\n回到界面，点击开始安装。\n接下来配置用户设置。\n设置管理员ROOT密码，这是最高权限root用户的密码（默认账号为root，密码为现在要设置的）。在实际中root密码越复杂越好，因为这里只是演示，所以密码就没有那么复杂了。\n提示：这个密码非常重要，请务必牢记！！！\n\n\n创建用户可以随意创建，密码可以随意\n\n用户设置好了之后，等待CentOS安装完成，然后点击完成配置，然后点击重启。\n\nCentOS的启动之后的界面如下，登录CentOS，使用默认账号为root，密码为你在前面安装时设置的root密码。\n注意：在输入密码时，linux为了安全起见，是看不到你输入的密码。并且输入密码的时候光标不会移动，确保输入完密码后点击enter键就会进入系统。同时，如果是使用的是键盘右边的数字键盘输入密码的话，建议查看一下num lock键是否开启。\n\n至此，CentOS7的安装全部完成了。\n1.2.4 CentOS7网络配置因为前面在设置CentOS7的网络适配器的时候，设置是NAT模式。\n\n在VMware界面（管理员方式启动）点击“编辑”里面的“虚拟网络编辑器”，然后勾选DHCP服务将IP地址分配给虚拟机，并设置子网IP(默认就好)。\n\n\n点击NAT模式旁边的“NAT设置”，然后修改与子网IP同网段下的网关IP，就是前三位必须相同， 即192.168.30要相同，最后一位数不相同即可（其实已经自动设置好了，默认），最后点击“确认”保存设置。\n\n然后启动虚拟机，进入网络配置文件目录：cd &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;，并且用 ls 命令查看是否有ifcfg-xxx名称的配置文件（ifcfg-lo除外），如果没有则说明网卡没有被识别，这种只能重装或者换个CentOS的版本。\n\n编辑ifcfg-ens33文件：vi ifcfg-ens33。按 i 进入insert编辑模式，\n将BOOTPROTO设为dhcp，将ONBOOT设为yes，\n按下Esc进入命令模式输入:wq保存并退出，如果没有反应则shift+q后输入wq保存并退出。\n配置完成之后输入：service network restart，重启网卡让网卡设置生效，之后就可以上网了。\n\n输入ip addr检查一下动态分配的IP，可以发现分配的动态IP为192.168.30.128。\n\n最后验证是否可以访问外网。\n\n重点：以上方式配置后可能仍然不能联网，请看下文\n若不能联网则修改NAT模式为桥接模式，设置虚拟机为桥接模式，以及虚拟网络设置也改为桥接模式，并且选择自己电脑相对应的网卡进行桥接。\n\n\n2.Redis配置2.1 安装wgetCentOS系统:\nxmlyum install wget -y2.2 安装gcc进入到/usr/local目录下\nxmlcd /usr/local\nredis是c语言开发，安装redis需要先将官网下载的源码进行编译，编译依赖gcc环境\n输入命令进行安装\nxmlyum install gcc-c++\n询问则回答y直至安装完成显示Complete\n2.3 下载Redisxmlwget http://download.redis.io/releases/redis-4.0.2.tar.gz下载时如果遇到卡住进度下不动了，首先用 ctrl+z 结束下载,注意不要用 ctrl+c.如果用了ctrl+c就是直接结束，因为wget是单线程的。用 wget -c url 重新下载\n\n下载完成。输入ll查看是否有redis压缩包\n\n解压\nxmltar -zxvf redis-4.0.2.tar.gz解压后再次输入ll查看是否有解压好的redis\n2.4 安装Redis进入redis目录并执行make命令编译\nxmlcd redis-4.0.2\nmake编译完成出现以下内容\n\n执行安装命令\nxmlmake PREFIX=/usr/local/redis install\n安装完成后进入/usr/local/redis/bin目录 这个redis目录(redis的安装目录)是上一步命令安装自动创建的（不是redis-4.0.2目录(reids解压后的文件目录)）\nxmlcd ../redis/bin\n可以看到有一些可执行文件。redis-server 是redis服务器redis-cli 是redis客户端返回/usr/local目录后进入redis-4.0.2\n此目录下有个redis.conf文件\n将该文件移动到/usr/local/redis/bin目录下\nxmlcp ./redis.conf /usr/local/redis/bin/\n进入/usr/local/redis/bin目录\nxmlcd /usr/local/redis/bin\n可以看到redis.conf已经移动到/usr/local/redis/bin目录下\n3.Redis启动3.1 启动服务器xml./redis.server redis.conf\n出现这个表示服务器启动成功\n按下ctrl+alt+F1&#x2F;F2&#x2F;F3切换一个新命令行窗口，登录后进入&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin\nxmlcd /usr/local/redis/bin3.2 启动Redis客户端输入命令\nxml./redis-cli\n连接客户端成功进行简单测试\n\n至此，Redis已经安装完成了。\n","slug":"VMware部署Redis","date":"2024-04-05T15:48:12.000Z","categories_index":"Study","tags_index":"Redis,VMware","author_index":"Fioransh"},{"id":"9d6afd20d8190b4b550aed150e5e2779","title":"Redis入门","content":"1.初始RedisRedis是一种键值型的NoSql数据库，这里有两个关键字：\n\n键值型\n\nNoSql\n\n\n其中键值型，是指Redis中存储的数据都是以key、value对的形式存储，而value的形式多种多样，可以是字符串、数值、甚至json：\n\n而NoSql则是相对于传统关系型数据库而言，有很大差异的一种数据库。\n1.1 认识NoSQLNoSql可以翻译做Not Only Sql（不仅仅是SQL），或者是No Sql（非Sql的）数据库。是相对于传统关系型数据库而言，有很大差异的一种特殊的数据库，因此也称之为非关系型数据库。\n1.1.1 结构化和非结构化传统关系型数据库是结构化数据，每一张表都有严格的约束信息：字段名、字段数据类型、字段约束等等信息，插入的数据必须遵守这些约束。\n\n而NoSql则对数据库格式没有严格约束，往往形式松散，自由。\n可以是键值型：\n\n也可以是文档型：\n\n甚至可以是图格式：\n\n1.1.2 关联和非关联传统数据库的表与表之间往往存在关联，例如外键。\n而非关系型数据库不存在关联关系，要维护关系要么靠代码中的业务逻辑，要么靠数据之间的耦合：\njson&#123;\n  id: 1,\n  name: &quot;张三&quot;,\n  orders: [\n    &#123;\n       id: 1,\n       item: &#123;\n     id: 10, title: &quot;荣耀6&quot;, price: 4999\n       &#125;\n    &#125;,\n    &#123;\n       id: 2,\n       item: &#123;\n     id: 20, title: &quot;小米11&quot;, price: 3999\n       &#125;\n    &#125;\n  ]\n&#125;1.1.3 查询方式传统关系型数据库会基于Sql语句做查询，语法有统一标准；\n而不同的非关系数据库查询语法差异极大，五花八门各种各样。\n\n1.1.4 事务传统关系型数据库能满足事务ACID的原则。\n而非关系型数据库往往不支持事务，或者不能严格保证ACID的特性，只能实现基本的一致性。\n1.1.5 总结除了上述四点以外，在存储方式、扩展性、查询性能上关系型与非关系型也都有着显著差异，总结如下：\n\n\n存储方式\n关系型数据库基于磁盘进行存储，会有大量的磁盘IO，对性能有一定影响\n非关系型数据库，他们的操作更多的是依赖于内存来操作，内存的读写速度会非常快，性能自然会好一些\n\n\n\n\n扩展性\n关系型数据库集群模式一般是主从，主从数据一致，起到数据备份的作用，称为垂直扩展。\n非关系型数据库可以将数据拆分，存储在不同机器上，可以保存海量数据，解决内存大小有限的问题。称为水平扩展。\n关系型数据库因为表之间存在关联关系，如果做水平扩展会给数据查询带来很多麻烦\n\n\n\n1.2 认识RedisRedis诞生于2009年全称是Remote  Dictionary Server 远程词典服务器，是一个基于内存的键值型NoSQL数据库。\n特征：\n\n键值（key-value）型，value支持多种不同数据结构，功能丰富\n单线程，每个命令具备原子性\n低延迟，速度快（基于内存、IO多路复用、良好的编码）。\n支持数据持久化\n支持主从集群、分片集群\n支持多语言客户端\n\nRedis的官方网站地址：https://redis.io/\n1.3 安装Redisps：可看VMware部署Redis文档学习以下内容。\n本安装教程基于Linux系统来安装Redis，此处选择的Linux版本为CentOS 7。\n1.3.1 依赖库Redis是基于C语言编写的，因此首先需要安装Redis所需要的gcc依赖：\nshyum install -y gcc tcl1.3.2 上传安装包并解压ps：此处需学习使用Xftp进行虚拟机上传Redis安装包\n然后将课前资料提供的Redis安装包上传到虚拟机的任意目录：\n\n例如，我放到了&#x2F;usr&#x2F;local&#x2F;src 目录：\n\n解压缩：\nshtar -xzf redis-6.2.6.tar.gz解压后：\n\n进入redis目录：\nshcd redis-6.2.6运行编译命令：\nshmake &amp;&amp; make install如果没有出错，应该就安装成功了。\n默认的安装路径是在 /usr/local/bin目录下\n该目录已经默认配置到环境变量，因此可以在任意目录下运行这些命令。其中：\n\nredis-cli：是redis提供的命令行客户端\nredis-server：是redis的服务端启动脚本\nredis-sentinel：是redis的哨兵启动脚本\n\n1.3.3 启动redis的启动方式有很多种，例如：\n\n默认启动\n指定配置启动\n开机自启\n\n1.3.4 默认启动安装完成后，在任意目录输入redis-server命令即可启动Redis：\ntxtredis-server如图：\n\n这种启动属于前台启动，会阻塞整个会话窗口，窗口关闭或者按下CTRL + C则Redis停止。不推荐使用。\n1.3.5 指定配置启动如果要让Redis以后台方式启动，则必须修改Redis配置文件，就在我们之前解压的redis安装包下（/usr/local/src/redis-6.2.6），名字叫redis.conf：\n\n我们先将这个配置文件备份一份：\ntxtcp redis.conf redis.conf.bckas然后修改redis.conf文件中的一些配置：\nproperties# 允许访问的地址，默认是127.0.0.1，会导致只能在本地访问。修改为0.0.0.0则可以在任意IP访问，生产环境不要设置为0.0.0.0\nbind 0.0.0.0\n# 守护进程，修改为yes后即可后台运行\ndaemonize yes \n# 密码，设置后访问Redis必须输入密码\nrequirepass 123321Redis的其它常见配置：\nproperties# 监听的端口\nport 6379\n# 工作目录，默认是当前目录，也就是运行redis-server时的命令，日志、持久化等文件会保存在这个目录\ndir .\n# 数据库数量，设置为1，代表只使用1个库，默认有16个库，编号0~15\ndatabases 1\n# 设置redis能够使用的最大内存\nmaxmemory 512mb\n# 日志文件，默认为空，不记录日志，可以指定日志文件名\nlogfile &quot;redis.log&quot;启动Redis：\nsh# 进入redis安装目录 \ncd /usr/local/src/redis-6.2.6\n# 启动\nredis-server redis.conf停止服务：\nsh# 利用redis-cli来执行 shutdown 命令，即可停止 Redis 服务，\n# 因为之前配置了密码，因此需要通过 -u 来指定密码\nredis-cli -u 123321 shutdown1.3.6 开机自启我们也可以通过配置来实现开机自启。\n首先，新建一个系统服务文件：\nshvi /etc/systemd/system/redis.service内容如下：\ntxt[Unit]\nDescription=redis-server\nAfter=network.target\n\n[Service]\nType=forking\nExecStart=/usr/local/bin/redis-server /usr/local/src/redis-6.2.6/redis.conf\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target然后重载系统服务：\nshsystemctl daemon-reload现在，我们可以用下面这组命令来操作redis了：\nsh# 启动\nsystemctl start redis\n# 停止\nsystemctl stop redis\n# 重启\nsystemctl restart redis\n# 查看状态\nsystemctl status redis执行下面的命令，可以让redis开机自启：\nshsystemctl enable redis1.4 Redis桌面客户端安装完成Redis，我们就可以操作Redis，实现数据的CRUD了。这需要用到Redis客户端，包括：\n\n命令行客户端\n图形化桌面客户端\n编程客户端\n\n1.4.1 Redis命令行客户端Redis安装完成后就自带了命令行客户端：redis-cli，使用方式如下：\nshredis-cli [options] [commonds]其中常见的options有：\n\n-h 127.0.0.1：指定要连接的redis节点的IP地址，默认是127.0.0.1\n-p 6379：指定要连接的redis节点的端口，默认是6379\n-a 123321：指定redis的访问密码\n\n其中的commonds就是Redis的操作命令，例如：\n\nping：与redis服务端做心跳测试，服务端正常会返回pong\n\n不指定commond时，会进入redis-cli的交互控制台：\n\n1.4.2 图形化桌面客户端GitHub上的大神编写了Redis的图形化桌面客户端，地址：https://github.com/uglide/RedisDesktopManager\n不过该仓库提供的是RedisDesktopManager的源码，并未提供windows安装包。\n在下面这个仓库可以找到安装包：https://github.com/lework/RedisDesktopManager-Windows/releases\n请灵活搜索。\n1.4.3 安装解压缩后，运行安装程序即可安装：\n\n安装完成后，在安装目录下找到rdm.exe文件：\n\n双击即可运行：\n\n1.4.4 建立连接点击左上角的连接到Redis服务器按钮：\n\n在弹出的窗口中填写Redis服务信息：\n\n点击确定后，在左侧菜单会出现这个链接：\n\n点击即可建立连接了。\n\nRedis默认有16个仓库，编号从0至15.  通过配置文件可以设置仓库数量，但是不超过16，并且不能自定义仓库名称。\n如果是基于redis-cli连接Redis服务，可以通过select命令来选择数据库：\nsh# 选择 0号库\nselect 02.Redis常见命令Redis是典型的key-value数据库，key一般是字符串，而value包含很多不同的数据类型：\n\nRedis为了方便我们学习，将操作不同数据类型的命令也做了分组，在官网（ https://redis.io/commands ）可以查看到不同的命令。\n不同类型的命令称为一个group，我们也可以通过help命令来查看各种不同group的命令：\n\n2.1 Redis通用命令通用指令是部分数据类型的，都可以使用的指令，常见的有：\n\nKEYS：查看符合模板的所有key\nDEL：删除一个指定的key\nEXISTS：判断key是否存在\nEXPIRE：给一个key设置有效期，有效期到期时该key会被自动删除\nTTL：查看一个KEY的剩余有效期\n\n通过help [command] 可以查看一个命令的具体用法，例如：\nsh# 查看keys命令的帮助信息：\n127.0.0.1:6379&gt; help keys\n\nKEYS pattern\nsummary: Find all keys matching the given pattern\nsince: 1.0.0\ngroup: generic2.2 String类型String类型，也就是字符串类型，是Redis中最简单的存储类型。\n其value是字符串，不过根据字符串的格式不同，又可以分为3类：\n\nstring：普通字符串\nint：整数类型，可以做自增、自减操作\nfloat：浮点类型，可以做自增、自减操作\n\n不管是哪种格式，底层都是字节数组形式存储，只不过是编码方式不同。字符串类型的最大空间不能超过512m.\n\n2.2.1 String的常见命令String的常见命令有：\n\nSET：添加或者修改已经存在的一个String类型的键值对\nGET：根据key获取String类型的value\nMSET：批量添加多个String类型的键值对\nMGET：根据多个key获取多个String类型的value\nINCR：让一个整型的key自增1\nINCRBY:让一个整型的key自增并指定步长，例如：incrby num 2 让num值自增2\nINCRBYFLOAT：让一个浮点类型的数字自增并指定步长\nSETNX：添加一个String类型的键值对，前提是这个key不存在，否则不执行\nSETEX：添加一个String类型的键值对，并且指定有效期\n\n2.2.2 Key结构Redis没有类似MySQL中的Table的概念，我们该如何区分不同类型的key呢？\n我们可以通过给key添加前缀加以区分，不过这个前缀不是随便加的，有一定的规范：\nRedis的key允许有多个单词形成层级结构，多个单词之间用’:’隔开，格式如下：\ntxt    项目名:业务名:类型:id这个格式并非固定，也可以根据自己的需求来删除或添加词条。这样以来，我们就可以把不同类型的数据区分开了。从而避免了key的冲突问题。\n例如我们的项目名称叫 heima，有user和product两种不同类型的数据，我们可以这样定义key：\n\nuser相关的key：heima:user:1\n\nproduct相关的key：heima:product:1\n\n\n如果Value是一个Java对象，例如一个User对象，则可以将对象序列化为JSON字符串后存储：\n\n\n\nKEY\nVALUE\n\n\n\nheima:user:1\n{“id”:1,  “name”: “Jack”, “age”: 21}\n\n\nheima:product:1\n{“id”:1,  “name”: “小米11”, “price”: 4999}\n\n\n并且，在Redis的桌面客户端中，还会以相同前缀作为层级结构，让数据看起来层次分明，关系清晰：\n\n2.3 Hash类型Hash类型，也叫散列，其value是一个无序字典，类似于Java中的HashMap结构。\nString结构是将对象序列化为JSON字符串后存储，当需要修改对象某个字段时很不方便：\n\nHash结构可以将对象中的每个字段独立存储，可以针对单个字段做CRUD：\n\nHash的常见命令有：\n\nHSET key field value：添加或者修改hash类型key的field的值\n\nHGET key field：获取一个hash类型key的field的值\n\nHMSET：批量添加多个hash类型key的field的值\n\nHMGET：批量获取多个hash类型key的field的值\n\nHGETALL：获取一个hash类型的key中的所有的field和value\n\nHKEYS：获取一个hash类型的key中的所有的field\n\nHINCRBY:让一个hash类型key的字段值自增并指定步长\n\nHSETNX：添加一个hash类型的key的field值，前提是这个field不存在，否则不执行\n\n\n2.4 List类型Redis中的List类型与Java中的LinkedList类似，可以看做是一个双向链表结构。既可以支持正向检索和也可以支持反向检索。\n特征也与LinkedList类似：\n\n有序\n元素可以重复\n插入和删除快\n查询速度一般\n\n常用来存储一个有序数据，例如：朋友圈点赞列表，评论列表等。\nList的常见命令有：\n\nLPUSH key element … ：向列表左侧插入一个或多个元素\nLPOP key：移除并返回列表左侧的第一个元素，没有则返回nil\nRPUSH key element … ：向列表右侧插入一个或多个元素\nRPOP key：移除并返回列表右侧的第一个元素\nLRANGE key star end：返回一段角标范围内的所有元素\nBLPOP和BRPOP：与LPOP和RPOP类似，只不过在没有元素时等待指定时间，而不是直接返回nil\n\n2.5 Set类型Redis的Set结构与Java中的HashSet类似，可以看做是一个value为null的HashMap。因为也是一个hash表，因此具备与HashSet类似的特征：\n\n无序\n\n元素不可重复\n\n查找快\n\n支持交集、并集、差集等功能\n\n\nSet的常见命令有：\n\nSADD key member … ：向set中添加一个或多个元素\nSREM key member … : 移除set中的指定元素\nSCARD key： 返回set中元素的个数\nSISMEMBER key member：判断一个元素是否存在于set中\nSMEMBERS：获取set中的所有元素\nSINTER key1 key2 … ：求key1与key2的交集\nSDIFF key1 key2 … ：求key1与key2的不同\n\n2.6 SortedSet类型Redis的SortedSet是一个可排序的set集合，与Java中的TreeSet有些类似，但底层数据结构却差别很大。SortedSet中的每一个元素都带有一个score属性，可以基于score属性对元素排序，底层的实现是一个跳表（SkipList）加 hash表。\nSortedSet具备下列特性：\n\n可排序\n元素不重复\n查询速度快\n\n因为SortedSet的可排序特性，经常被用来实现排行榜这样的功能。\nSortedSet的常见命令有：\n\nZADD key score member：添加一个或多个元素到sorted set ，如果已经存在则更新其score值\nZREM key member：删除sorted set中的一个指定元素\nZSCORE key member : 获取sorted set中的指定元素的score值\nZRANK key member：获取sorted set 中的指定元素的排名\nZCARD key：获取sorted set中的元素个数\nZCOUNT key min max：统计score值在给定范围内的所有元素的个数\nZINCRBY key increment member：让sorted set中的指定元素自增，步长为指定的increment值\nZRANGE key min max：按照score排序后，获取指定排名范围内的元素\nZRANGEBYSCORE key min max：按照score排序后，获取指定score范围内的元素\nZDIFF、ZINTER、ZUNION：求差集、交集、并集\n\n\n\n\n\n\n\n\n\n\n注意：所有的排名默认都是升序，如果要降序则在命令的Z后面添加REV即可，例如：\n\n升序获取sorted set 中的指定元素的排名：ZRANK key member\n\n降序获取sorted set 中的指定元素的排名：ZREVRANK key memeber\n\n\n3.Redis的Java客户端在Redis官网中提供了各种语言的客户端，地址：https://redis.io/docs/clients/\n标记为*的就是推荐使用的java客户端，包括：\n\nJedis和Lettuce：这两个主要是提供了Redis命令对应的API，方便我们操作Redis，而SpringDataRedis又对这两种做了抽象和封装，因此我们后期会直接以SpringDataRedis来学习。\nRedisson：是在Redis基础上实现了分布式的可伸缩的java数据结构，例如Map、Queue等，而且支持跨进程的同步机制：Lock、Semaphore等待，比较适合用来实现特殊的功能需求。\n\n3.1 Jedis客户端Jedis的官网地址： https://github.com/redis/jedis\n3.1.1 快速入门1）引入依赖：\nxml&lt;!--jedis--&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;redis.clients&lt;/groupId&gt;\n    &lt;artifactId&gt;jedis&lt;/artifactId&gt;\n    &lt;version&gt;3.7.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;!--单元测试--&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt;\n    &lt;artifactId&gt;junit-jupiter&lt;/artifactId&gt;\n    &lt;version&gt;5.7.0&lt;/version&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;2）建立连接\n新建一个单元测试类，内容如下：\njavaprivate Jedis jedis;\n\n@BeforeEach\nvoid setUp() &#123;\n    // 1.建立连接\n    // jedis = new Jedis(&quot;192.168.150.101&quot;, 6379);\n    jedis = JedisConnectionFactory.getJedis();\n    // 2.设置密码\n    jedis.auth(&quot;123321&quot;);\n    // 3.选择库\n    jedis.select(0);\n&#125;3）测试：\njava@Test\nvoid testString() &#123;\n    // 存入数据\n    String result = jedis.set(&quot;name&quot;, &quot;虎哥&quot;);\n    System.out.println(&quot;result = &quot; + result);\n    // 获取数据\n    String name = jedis.get(&quot;name&quot;);\n    System.out.println(&quot;name = &quot; + name);\n&#125;\n\n@Test\nvoid testHash() &#123;\n    // 插入hash数据\n    jedis.hset(&quot;user:1&quot;, &quot;name&quot;, &quot;Jack&quot;);\n    jedis.hset(&quot;user:1&quot;, &quot;age&quot;, &quot;21&quot;);\n\n    // 获取\n    Map&lt;String, String&gt; map = jedis.hgetAll(&quot;user:1&quot;);\n    System.out.println(map);\n&#125;4）释放资源\njava@AfterEach\nvoid tearDown() &#123;\n    if (jedis != null) &#123;\n        jedis.close();\n    &#125;\n&#125;3.1.2 连接池Jedis本身是线程不安全的，并且频繁的创建和销毁连接会有性能损耗，因此我们推荐大家使用Jedis连接池代替Jedis的直连方式。\njavapackage com.heima.jedis.util;\n\nimport redis.clients.jedis.*;\n\npublic class JedisConnectionFactory &#123;\n\n    private static JedisPool jedisPool;\n\n    static &#123;\n        // 配置连接池\n        JedisPoolConfig poolConfig = new JedisPoolConfig();\n        poolConfig.setMaxTotal(8);\n        poolConfig.setMaxIdle(8);\n        poolConfig.setMinIdle(0);\n        poolConfig.setMaxWaitMillis(1000);\n        // 创建连接池对象，参数：连接池配置、服务端ip、服务端端口、超时时间、密码\n        jedisPool = new JedisPool(poolConfig, &quot;192.168.150.101&quot;, 6379, 1000, &quot;123321&quot;);\n    &#125;\n\n    public static Jedis getJedis()&#123;\n        return jedisPool.getResource();\n    &#125;\n&#125;3.2 SpringDataRedis客户端SpringData是Spring中数据操作的模块，包含对各种数据库的集成，其中对Redis的集成模块就叫做SpringDataRedis，官网地址：https://spring.io/projects/spring-data-redis\n\n提供了对不同Redis客户端的整合（Lettuce和Jedis）\n提供了RedisTemplate统一API来操作Redis\n支持Redis的发布订阅模型\n支持Redis哨兵和Redis集群\n支持基于Lettuce的响应式编程\n支持基于JDK、JSON、字符串、Spring对象的数据序列化及反序列化\n支持基于Redis的JDKCollection实现\n\nSpringDataRedis中提供了RedisTemplate工具类，其中封装了各种对Redis的操作。并且将不同数据类型的操作API封装到了不同的类型中：\n\n3.2.1 快速入门SpringBoot已经提供了对SpringDataRedis的支持，使用非常简单。\n首先，新建一个maven项目，然后按照下面步骤执行：\n1）引入依赖\nxml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;parent&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n        &lt;version&gt;2.5.7&lt;/version&gt;\n        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;\n    &lt;/parent&gt;\n    &lt;groupId&gt;com.heima&lt;/groupId&gt;\n    &lt;artifactId&gt;redis-demo&lt;/artifactId&gt;\n    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\n    &lt;name&gt;redis-demo&lt;/name&gt;\n    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;\n    &lt;properties&gt;\n        &lt;java.version&gt;1.8&lt;/java.version&gt;\n    &lt;/properties&gt;\n    &lt;dependencies&gt;\n        &lt;!--redis依赖--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;!--common-pool--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;\n            &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;!--Jackson依赖--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;\n            &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n            &lt;optional&gt;true&lt;/optional&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;excludes&gt;\n                        &lt;exclude&gt;\n                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n                        &lt;/exclude&gt;\n                    &lt;/excludes&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n\n&lt;/project&gt;2）配置Redis\nyamlspring:\n  redis:\n    host: 192.168.150.101\n    port: 6379\n    password: 123321\n    lettuce:\n      pool:\n        max-active: 8\n        max-idle: 8\n        min-idle: 0\n        max-wait: 100ms3）注入RedisTemplate\n因为有了SpringBoot的自动装配，我们可以拿来就用：\njava@SpringBootTest\nclass RedisStringTests &#123;\n\n    @Autowired\n    private RedisTemplate redisTemplate;\n&#125;4）编写测试\njava@SpringBootTest\nclass RedisStringTests &#123;\n\n    @Autowired\n    private RedisTemplate edisTemplate;\n\n    @Test\n    void testString() &#123;\n        // 写入一条String数据\n        redisTemplate.opsForValue().set(&quot;name&quot;, &quot;虎哥&quot;);\n        // 获取string数据\n        Object name = stringRedisTemplate.opsForValue().get(&quot;name&quot;);\n        System.out.println(&quot;name = &quot; + name);\n    &#125;\n&#125;3.2.2 自定义序列化RedisTemplate可以接收任意Object作为值写入Redis：\n\n只不过写入前会把Object序列化为字节形式，默认是采用JDK序列化，得到的结果是这样的：\n\n缺点：\n\n可读性差\n内存占用较大\n\n我们可以自定义RedisTemplate的序列化方式，代码如下：\njava@Configuration\npublic class RedisConfig &#123;\n\n    @Bean\n    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory connectionFactory)&#123;\n        // 创建RedisTemplate对象\n        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;();\n        // 设置连接工厂\n        template.setConnectionFactory(connectionFactory);\n        // 创建JSON序列化工具\n        GenericJackson2JsonRedisSerializer jsonRedisSerializer = \n                                        new GenericJackson2JsonRedisSerializer();\n        // 设置Key的序列化\n        template.setKeySerializer(RedisSerializer.string());\n        template.setHashKeySerializer(RedisSerializer.string());\n        // 设置Value的序列化\n        template.setValueSerializer(jsonRedisSerializer);\n        template.setHashValueSerializer(jsonRedisSerializer);\n        // 返回\n        return template;\n    &#125;\n&#125;这里采用了JSON序列化来代替默认的JDK序列化方式。最终结果如图：\n\n整体可读性有了很大提升，并且能将Java对象自动的序列化为JSON字符串，并且查询时能自动把JSON反序列化为Java对象。不过，其中记录了序列化时对应的class名称，目的是为了查询时实现自动反序列化。这会带来额外的内存开销。\n3.2.3 StringRedisTemplate为了节省内存空间，我们可以不使用JSON序列化器来处理value，而是统一使用String序列化器，要求只能存储String类型的key和value。当需要存储Java对象时，手动完成对象的序列化和反序列化。\n\n因为存入和读取时的序列化及反序列化都是我们自己实现的，SpringDataRedis就不会将class信息写入Redis了。\n这种用法比较普遍，因此SpringDataRedis就提供了RedisTemplate的子类：StringRedisTemplate，它的key和value的序列化方式默认就是String方式。\n\n省去了我们自定义RedisTemplate的序列化方式的步骤，而是直接使用：\njava@Autowired\nprivate StringRedisTemplate stringRedisTemplate;\n// JSON序列化工具\nprivate static final ObjectMapper mapper = new ObjectMapper();\n\n@Test\nvoid testSaveUser() throws JsonProcessingException &#123;\n    // 创建对象\n    User user = new User(&quot;虎哥&quot;, 21);\n    // 手动序列化\n    String json = mapper.writeValueAsString(user);\n    // 写入数据\n    stringRedisTemplate.opsForValue().set(&quot;user:200&quot;, json);\n\n    // 获取数据\n    String jsonUser = stringRedisTemplate.opsForValue().get(&quot;user:200&quot;);\n    // 手动反序列化\n    User user1 = mapper.readValue(jsonUser, User.class);\n    System.out.println(&quot;user1 = &quot; + user1);\n&#125;\nRedisTemplate的两种序列化实践方案：\n\n方案一：\n\n自定义RedisTemplate\n修改RedisTemplate的序列化器为GenericJackson2JsonRedisSerializer\n\n\n方案二：\n\n使用StringRedisTemplate\n写入Redis时，手动把对象序列化为JSON\n读取Redis时，手动把读取到的JSON反序列化为对象\n\n\n\n3.2.4 Hash结构操作java@SpringBootTest\nclass RedisStringTests &#123;\n\n    @Autowired\n    private StringRedisTemplate stringRedisTemplate;\n\n\n    @Test\n    void testHash() &#123;\n        stringRedisTemplate.opsForHash().put(&quot;user:400&quot;, &quot;name&quot;, &quot;虎哥&quot;);\n        stringRedisTemplate.opsForHash().put(&quot;user:400&quot;, &quot;age&quot;, &quot;21&quot;);\n\n        Map&lt;Object, Object&gt; entries = stringRedisTemplate.opsForHash().entries(&quot;user:400&quot;);\n        System.out.println(&quot;entries = &quot; + entries);\n    &#125;\n&#125;","slug":"Redis入门","date":"2024-04-04T13:25:12.000Z","categories_index":"Study","tags_index":"Redis","author_index":"Fioransh"},{"id":"af7adfb1aa53297139dec65c56a65de6","title":"算竞常用STL","content":"1 前言**C++ 标准模板库 (STL, Standard Template Library)**：包含一些常用数据结构与算法的模板的 C++ 软件库。其包含四个组件——算法 (Algorithms)、容器 (Containers)、仿函数 (Functors)、迭代器 (Iterators).\n\n\n示例：\n\n算法：sort(a.begin(), a.end())\n容器：priority_queue&lt;int&gt; pque\n仿函数：greater&lt;int&gt;()\n迭代器：vector&lt;int&gt;::iterator it = a.begin()\n\nSTL 作为一个封装良好，性能合格的 C++ 标准库，在算法竞赛中运用极其常见。灵活且正确使用 STL 可以节省非常多解题时间，这一点不仅是由于可以直接调用，还是因为它封装良好，可以让代码的可读性变高，解题思路更清晰，调试过程 往往 更顺利。\n不过 STL 毕竟使用了很多复杂的结构来实现丰富的功能，它的效率往往是比不上自己手搓针对特定题目的数据结构与算法的。因此，STL 的使用相当于使用更长的运行时间换取更高的编程效率。因此，在实际比赛中要权衡 STL 的利弊，不过这一点就得靠经验了。\n接下来，我会分享在算法竞赛中常用的 STL 容器和算法，对于函数和迭代器，就不着重展开讲了。\n2 常用容器2.1 内容总览打勾的是本次将会详细讲解的，加粗的是算法竞赛中有必要学习的。\n\n顺序容器\n\n \narray\n\n \nvector\n\n \ndeque\n\n \nforward_list\n\n \nlist\n\n\n\n关联容器\n\n set\n map\n multiset\n multimap\n\n\n无序关联容器\n\n unordered_set\n unordered_map\n unordered_multiset\n unordered_multimap\n\n\n容器适配器\n\n stack\n queue\n priority_queue\n flat_set\n flat_map\n flat_multiset\n flat_multimap\n\n\n字符串\n\n string (basic_string&lt;char&gt;)\n\n\n对与元组\n\n pair\n tuple\n\n\n\n2.2 向量 vector#include &lt;vector&gt;\n连续的顺序的储存结构（和数组一样的类别），但是有长度可变的特性。\n2.2.1 常用方法构造vector&lt;类型&gt; arr(长度, [初值])\n时间复杂度：$O(n)$\n常用的一维和二维数组构造示例，高维也是一样的（就是会有点长）.\ncppvector&lt;int&gt; arr;         // 构造int数组\nvector&lt;int&gt; arr(100);    // 构造初始长100的int数组\nvector&lt;int&gt; arr(100, 1); // 构造初始长100的int数组，初值为1\n\nvector&lt;vector&lt;int&gt;&gt; mat(100, vector&lt;int&gt; ());       // 构造初始100行，不指定列数的二维数组\nvector&lt;vector&lt;int&gt;&gt; mat(100, vector&lt;int&gt; (666, -1)) // 构造初始100行，初始666列的二维数组，初值为-1构造二维数组的奇葩写法，千万别用：\ncppvector&lt;int&gt; arr[100];         // 正确，构造初始100行，不指定列数的二维数组，可用于链式前向星存图\nvector&lt;int&gt; arr[100](100, 1); // 语法错误！\nvector&lt;int&gt; arr(100, 1)[100]; // 语法错误！\nvector&lt;int&gt; arr[100] &lt;!--swig￼0--&gt;; // 正确但奇葩，使用列表初始化尾接 &amp; 尾删\n**.push_back(元素)**：在 vector 尾接一个元素，数组长度 $+1$.\n**.pop_back()**：删除 vector 尾部的一个元素，数组长度 $-1$\n\n时间复杂度：均摊 $O(1)$\ncpp// init: arr = []\narr.push_back(1);\n// after: arr = [1]\narr.push_back(2);\n// after: arr = [1, 2]\narr.pop_back();\n// after: arr = [1]\narr.pop_back();\n// after: arr = []中括号运算符和一般数组一样的作用\n时间复杂度：$O(1)$\n获取长度.size()\n获取当前 vector 的长度\n时间复杂度：$O(1)$\ncppfor (int i = 0; i &lt; arr.size(); i++)\n    cout &lt;&lt; a[i] &lt;&lt; endl;清空.clear()\n清空 vector\n时间复杂度：$O(n)$\n判空.empty()\n如果是空返回 true 反之返回 false.\n时间复杂度：$O(1)$\n改变长度.resize(新长度, [默认值])\n修改 vector 的长度\n\n如果是缩短，则删除多余的值\n如果是扩大，且指定了默认值，则新元素均为默认值（旧元素不变）\n\n时间复杂度：$O(n)$\n2.2.2 适用情形一般情况 vector 可以替换掉普通数组，除非该题卡常。\n有些情况普通数组没法解决：$n\\times m$ 的矩阵，$1\\leq n,m\\leq 10^6$ 且 $n\\times m \\leq 10^6$\n\n如果用普通数组 int mat[1000010][1000010]，浪费内存，会导致 MLE。\n如果使用 vector&lt;vector&lt;int&gt;&gt; mat(n + 10, vector&lt;int&gt; (m + 10))，完美解决该问题。\n\n另外，vector 的数据储存在堆空间中，不会爆栈。\n2.2.3 注意事项提前指定长度如果长度已经确定，那么应当直接在构造函数指定长度，而不是一个一个 .push_back(). 因为 vector 额外内存耗尽后的重分配是有时间开销的，直接指定长度就不会出现重分配了。\ncpp// 优化前: 522ms\nvector&lt;int&gt; a;\nfor (int i = 0; i &lt; 1e8; i++)\n    a.push_back(i);\n// 优化后: 259ms\nvector&lt;int&gt; a(1e8);\nfor (int i = 0; i &lt; a.size(); i++)\n    a[i] = i;当心 size_t 溢出vector 获取长度的方法 .size() 返回值类型为 size_t，通常 OJ 平台使用的是 32 位编译器（有些平台例如 cf 可选 64 位），那么该类型范围为 $[0,2^{32})$.\ncppvector&lt;int&gt; a(65536);\nlong long a = a.size() * a.size(); // 直接溢出变成0了2.3 栈 stack#include &lt;stack&gt;\n通过二次封装双端队列 (deque) 容器，实现先进后出的栈数据结构。\n2.3.1 常用方法\n\n\n作用\n用法\n示例\n\n\n\n构造\nstack&lt;类型&gt; stk\nstack&lt;int&gt; stk;\n\n\n进栈\n.push(元素)\nstk.push(1);\n\n\n出栈\n.pop()\nstk.pop();\n\n\n取栈顶\n.top()\nint a = stk.top();\n\n\n查看大小 &#x2F; 清空 &#x2F; 判空\n略\n略\n\n\n2.3.2 适用情形如果不卡常的话，就可以直接用它而不需要手写栈了。\n另外，vector 也可以当栈用，vector 的 .back() 取尾部元素，就相当于取栈顶，.push_back() 相当于进栈，.pop_back() 相当于出栈。\n2.3.3 注意事项不可访问内部元素！下面都是错误用法\ncppfor (int i = 0; i &lt; stk.size(); i++)\n    cout &lt;&lt; stk[i] &lt;&lt; endl;\nfor (auto ele : stk)\n    cout &lt;&lt; stk &lt;&lt; endl;2.4 队列 queue#include &lt;queue&gt;\n通过二次封装双端队列 (deque) 容器，实现先进先出的队列数据结构。\n2.4.1 常用方法\n\n\n作用\n用法\n示例\n\n\n\n构造\nqueue&lt;类型&gt; que\nqueue&lt;int&gt; que;\n\n\n进队\n.push(元素)\nque.push(1);\n\n\n出队\n.pop()\nque.pop();\n\n\n取队首\n.front()\nint a = que.front();\n\n\n取队尾\n.back()\nint a = que.back();\n\n\n查看大小 &#x2F; 清空 &#x2F; 判空\n略\n略\n\n\n2.4.2 适用情形如果不卡常的话，就可以直接用它而不需要手写队列了。\n2.4.3 注意事项不可访问内部元素！下面都是错误用法\ncppfor (int i = 0; i &lt; que.size(); i++)\n    cout &lt;&lt; que[i] &lt;&lt; endl;\nfor (auto ele : que)\n    cout &lt;&lt; ele &lt;&lt; endl;2.5 优先队列 priority_queue#include &lt;queue&gt;\n提供常数时间的最大元素查找，对数时间的插入与提取，底层原理是二叉堆。\n2.5.1 常用方法构造priority_queue&lt;类型, 容器, 比较器&gt; pque\n\n类型：要储存的数据类型\n容器：储存数据的底层容器，默认为 vector&lt;类型&gt;，竞赛中保持默认即可\n比较器：比较大小使用的比较器，默认为 less&lt;类型&gt;，可自定义\n\ncpppriority_queue&lt;int&gt; pque1;                            // 储存int的大顶堆\npriority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; pque2; // 储存int的小顶堆\n\n\n\n\n\n\n\n\n对于需要自定义比较器的情况，涉及一些初学时容易看迷糊的语法（重载小括号运算符 &#x2F; lambda 表达式），在此就不展开讲了。如果想要了解，可以查阅 cppreference 中的代码示例。\n其他\n\n\n作用\n用法\n示例\n\n\n\n进堆\n.push(元素)\nque.push(1);\n\n\n出堆\n.pop()\nque.pop();\n\n\n取堆顶\n.top()\nint a = que.top();\n\n\n查看大小 &#x2F; 判空\n略\n略\n\n\n进出队复杂度 $O(\\log n)$，取堆顶 $O(1)$.\n2.5.2 适用情形持续维护元素的有序性：每次向队列插入大小不定的元素，或者每次从队列里取出大小最小&#x2F;最大的元素，元素数量 $n$，插入操作数量 $k$.\n\n每次插入后进行快速排序：$k\\cdot n\\log n$\n使用优先队列维护：$k\\cdot\\log n$\n\n2.5.3 注意事项仅堆顶可读只可访问堆顶，其他元素都无法读取到。下面是错误用法：\ncppcout &lt;&lt; pque[1] &lt;&lt; endl;所有元素不可写堆中所有元素是不可修改的。下面是错误用法：\ncpppque[1] = 2;\npque.top() = 1;如果你恰好要修改的是堆顶元素，那么是可以完成的：\ncppint tp = pque.top();\npque.pop();\npque.push(tp + 1);2.6 集合 set#include &lt;set&gt;\n提供对数时间的插入、删除、查找的集合数据结构。底层原理是红黑树。\n\n\n\n集合三要素\n解释\nset\nmultiset\nunordered_set\n\n\n\n确定性\n一个元素要么在集合中，要么不在\n✔\n✔\n✔\n\n\n互异性\n一个元素仅可以在集合中出现一次\n✔\n❌（任意次）\n✔\n\n\n无序性\n集合中的元素是没有顺序的\n❌（从小到大）\n❌（从小到大）\n✔\n\n\n2.6.1 常用方法构造set&lt;类型, 比较器&gt; st\n\n类型：要储存的数据类型\n比较器：比较大小使用的比较器，默认为 less&lt;类型&gt;，可自定义\n\ncppset&lt;int&gt; st1;               // 储存int的集合（从小到大）\nset&lt;int, greater&lt;int&gt;&gt; st2; // 储存int的集合（从大到小）\n\n\n\n\n\n\n\n\n对于需要自定义比较器的情况，涉及一些初学时容易看迷糊的语法（重载小括号运算符 &#x2F; lambda 表达式），在此就不展开讲了。\n遍历可使用迭代器进行遍历：\ncppfor (set&lt;int&gt;::iterator it = st.begin(); it != st.end(); ++it)\n    cout &lt;&lt; *it &lt;&lt; endl;基于范围的循环（C++ 11）：\ncppfor (auto &amp;ele : st)\n    cout &lt;&lt; ele &lt;&lt; endl;其他\n\n\n作用\n用法\n示例\n\n\n\n插入元素\n.insert(元素)\nst.insert(1);\n\n\n删除元素\n.erase(元素)\nst.erase(2);\n\n\n查找元素\n.find(元素)\nauto it = st.find(1);\n\n\n判断元素是否存在\n.count(元素)\nst.count(3);\n\n\n查看大小 &#x2F; 清空 &#x2F; 判空\n略\n略\n\n\n增删查时间复杂度均为 $O(\\log n)$\n2.6.2 适用情形\n元素去重：$[1,1,3,2,4,4]\\to[1,2,3,4]$\n维护顺序：$[1,5,3,7,9]\\to[1,3,5,7,9]$\n元素是否出现过：元素大小 $[-10^{18},10^{18}]$，元素数量 $10^6$，vis 数组无法实现，通过 set 可以完成。\n\n2.6.3 注意事项不存在下标索引set 虽说可遍历，但仅可使用迭代器进行遍历，它不存在下标这一概念，无法通过下标访问到数据。下面是错误用法：\ncppcout &lt;&lt; st[0] &lt;&lt; endl;元素只读set 的迭代器取到的元素是只读的（因为是 const 迭代器），不可修改其值。如果要改，需要先 erase 再 insert. 下面是错误用法：\ncppcout &lt;&lt; *st.begin() &lt;&lt; endl; // 正确。可读。\n*st.begin() = 1;             // 错误！不可写！不可用迭代器计算下标set 的迭代器不能像 vector 一样相减得到下标。下面是错误用法：\ncppauto it = st.find(2);      // 正确，返回2所在位置的迭代器。\nint idx = it - st.begin(); // 错误！不可相减得到下标。2.7 映射 map#include &lt;map&gt;\n提供对数时间的有序键值对结构。底层原理是红黑树。\n映射：$$\\begin{matrix}1&amp;\\to&amp;2\\2&amp;\\to&amp;2\\3&amp;\\to&amp;1\\4&amp;\\to&amp;5\\&amp;\\vdots\\end{matrix}$$\n\n\n\n性质\n解释\nmap\nmultimap\nunordered_map\n\n\n\n互异性\n一个键仅可以在映射中出现一次\n✔\n❌（任意次）\n✔\n\n\n无序性\n键是没有顺序的\n❌（从小到大）\n❌（从小到大）\n✔\n\n\n2.7.1 常用方法构造map&lt;键类型, 值类型, 比较器&gt; mp\n\n键类型：要储存键的数据类型\n值类型：要储存值的数据类型\n比较器：键比较大小使用的比较器，默认为 less&lt;类型&gt;，可自定义\n\ncppmap&lt;int, int&gt; mp1;               // int-&gt;int 的映射（键从小到大）\nmap&lt;int, int, greater&lt;int&gt;&gt; st2; // int-&gt;int 的映射（键从大到小）\n\n\n\n\n\n\n\n\n对于需要自定义比较器的情况，涉及一些初学时容易看迷糊的语法（重载小括号运算符 &#x2F; lambda 表达式），在此就不展开讲了。\n遍历可使用迭代器进行遍历：\ncppfor (map&lt;int, int&gt;::iterator it = mp.begin(); it != mp.end(); ++it)\n    cout &lt;&lt; it-&gt;first &lt;&lt; &#39; &#39; &lt;&lt; it-&gt;second &lt;&lt; endl;基于范围的循环（C++ 11）：\ncppfor (auto &amp;pr : mp)\n    cout &lt;&lt; pr.first &lt;&lt; &#39; &#39; &lt;&lt; pr.second &lt;&lt; endl;结构化绑定 + 基于范围的循环（C++17）：\ncppfor (auto &amp;[key, val] : mp)\n    cout &lt;&lt; key &lt;&lt; &#39; &#39; &lt;&lt; val &lt;&lt; endl;其他\n\n\n作用\n用法\n示例\n\n\n\n增 &#x2F; 改 &#x2F; 查元素\n中括号\nmp[1] = 2;\n\n\n查元素（返回迭代器）\n.find(元素)\nauto it = mp.find(1);\n\n\n删除元素\n.erase(元素)\nmp.erase(2);\n\n\n判断元素是否存在\n.count(元素)\nmp.count(3);\n\n\n查看大小 &#x2F; 清空 &#x2F; 判空\n略\n略\n\n\n增删改查时间复杂度均为 $O(\\log n)$\n2.7.2 适用情形需要维护映射的场景可以使用：输入若干字符串，统计每种字符串的出现次数。(map&lt;string, int&gt; mp)\n2.7.3 注意事项中括号访问时默认值如果使用中括号访问 map 时对应的键不存在，那么会新增这个键，并且值为默认值，因此中括号会影响键的存在性。\ncppmap&lt;char, int&gt; mp;\ncout &lt;&lt; mp.count(&#39;a&#39;) &lt;&lt; endl; // 0\nmp[&#39;a&#39;];                       // 即使什么都没做，此时mp[&#39;a&#39;]=0已经插入了\ncout &lt;&lt; mp.count(&#39;a&#39;) &lt;&lt; endl; // 1\ncout &lt;&lt; mp[&#39;a&#39;] &lt;&lt; endl;       // 0不可用迭代器计算下标map 的迭代器不能像 vector 一样相减得到下标。下面是错误用法：\ncppauto it = mp.find(&#39;a&#39;);      // 正确，返回2所在位置的迭代器。\nint idx = it - mp.begin();   // 错误！不可相减得到下标。2.8 字符串 string#include &lt;string&gt;\n顾名思义，就是储存字符串的。\n2.8.1 常用方法构造构造函数：string(长度, 初值)\ncppstring s1;           // 构造字符串，为空\nstring s2 = &quot;awa!&quot;;  // 构造字符串，并赋值awa!\nstring s3(10, &#39;6&#39;);  // 构造字符串，通过构造函数构造为6666666666输入输出C++\ncppstring s;\ncin &gt;&gt; s;\ncout &lt;&lt; s;C\ncppstring s;\nchar buf[100];\nscanf(&quot;%s&quot;, &amp;buf);\ns = buf;\nprintf(&quot;%s&quot;, s.c_str());其他\n\n\n作用\n用法\n示例\n\n\n\n修改、查询指定下标字符\n[]\ns[1] = &#39;a&#39;;\n\n\n是否相同\n==\nif (s1 == s2) ...\n\n\n字符串连接\n+\nstring s = s1 + s2;\n\n\n尾接字符串\n+=\ns += &quot;awa&quot;;\n\n\n取子串\n.substr(起始下标, 子串长度)\nstring sub = s.substr(2, 10);\n\n\n查找字符串\n.find(字符串, 起始下标)\nint pos = s.find(&quot;awa&quot;);\n\n\n数值与字符串互转（C++11）\n\n\n源\n目的\n函数\n\n\n\nint &#x2F; long long &#x2F; float &#x2F; double &#x2F; long double\nstring\nto_string()\n\n\nstring\nint\nstoi()\n\n\nstring\nlong long\nstoll()\n\n\nstring\nfloat\nstof()\n\n\nstring\ndouble\nstod()\n\n\nstring\nlong double\nstold()\n\n\n2.8.2 适用情形非常好用！建议直接把字符数组扔了，赶快投入 string 的怀抱。\n2.8.3 注意事项尾接字符串一定要用 +=string 的 +&#x3D; 运算符，将会在原字符串原地尾接字符串。而 + 了再 &#x3D; 赋值，会先生成一个临时变量，在复制给 string.\n通常字符串长度可以很长，如果使用 + 字符串很容易就 TLE 了。\ncpp// 优化前: 15139ms\nstring s;\nfor (int i = 0; i &lt; 5e5; i++)\n    s = s + &quot;a&quot;;\n\n// 优化后: &lt; 1ms (计时器显示0)\nstring s;\nfor (int i = 0; i &lt; 5e5; i++)\n    s += &quot;a&quot;;.substr() 方法的奇葩参数一定要注意，C++ string 的取子串的第一个参数是子串起点下标，第二个参数是子串长度。\n第二个参数不是子串终点！不是子串终点！要与 java 等其他语言区分开来。\n.find() 方法的复杂度该方法实现为暴力实现，时间复杂度为 $O(n^2)$.\n不要幻想 STL 内置了个 $O(n)$ 的 KMP 算法\n2.9 二元组 pair#include &lt;utility&gt;\n顾名思义，就是储存二元组的。\n2.9.1 常用方法构造pair&lt;第一个值类型, 第二个值类型&gt; pr\n\n第一个值类型：要储存的第一个值的数据类型\n第二个值类型：要储存的第二个值的数据类型\n\ncpppair&lt;int, int&gt; p1;\npair&lt;int, long long&gt; p2;\npair&lt;char, int&gt; p3;\n// ...赋值老式\ncpppair&lt;int, char&gt; pr = make_pair(1, &#39;a&#39;);列表构造 C++11\ncpppair&lt;int, char&gt; pr = &#123;1, &#39;a&#39;&#125;;取值直接取值\n\n取第一个值：.first\n取第二个值：.second\n\ncpppair&lt;int, char&gt; pr = &#123;1, &#39;a&#39;&#125;;\nint awa = pr.first;\nchar bwb = pr.second;结构化绑定 C++17\ncpppair&lt;int, char&gt; pr = &#123;1, &#39;a&#39;&#125;;\nauto &amp;[awa, bwb] = pr;判同直接用 == 运算符\ncpppair&lt;int, int&gt; p1 = &#123;1, 2&#125;;\npair&lt;int, int&gt; p2 = &#123;1, 3&#125;;\nif (p1 == p2) &#123; ... &#125; // false2.9.2 适用场景所有需要二元组的场景均可使用，效率和自己定义结构体差不多。\n2.9.3 注意事项无\n3 迭代器简介3.1 迭代器是什么？不搞抽象，直接举例。\n对于一个 vector，我们可以用下标遍历：\ncppfor (int i = 0; i &lt; a.size(); i++)\n    cout &lt;&lt; a[i] &lt;&lt; endl;我们同时也可以用迭代器来遍历：\ncppfor (vector&lt;int&gt;::iterator it = a.begin(); it != a.end(); ++it)\n    cout &lt;&lt; *it &lt;&lt; endl;\na.begin() 是一个迭代器，指向的是第一个元素\na.end() 是一个迭代器，指向的是最后一个元素再后面一位\n上述迭代器具有自增运算符，自增则迭代器向下一个元素移动\n迭代器与指针相似，如果对它使用解引用运算符，即 *it，就能取到对应值了\n\n3.2 为何需要迭代器？很多数据结构并不是线性的（例如红黑树），对于非线性数据结构，下标是无意义的。无法使用下标来遍历整个数据结构。\n迭代器的作用就是定义某个数据结构的遍历方式，通过迭代器的增减，代表遍历到的位置，通过迭代器便能成功遍历非线性结构了。\n例如，set 的实现是红黑树，我们是没法用下标来访问元素的。但是通过迭代器，我们就能遍历 set 中的元素了：\ncppfor (set&lt;int&gt;::iterator it = st.begin(); it != st.end(); ++it)\n    cout &lt;&lt; *it &lt;&lt; endl;3.3 迭代器用法对于 vector 容器，它的迭代器功能比较完整，以它举例：\n\n.begin()：头迭代器\n.end()：尾迭代器\n.rbegin()：反向头迭代器\n.rend()：反向尾迭代器\n迭代器 + 整型：将迭代器向后移动\n迭代器 - 整型：将迭代器向前移动\n迭代器 ++：将迭代器向后移动 1 位\n迭代器 --：将迭代器向前移动 1 位\n迭代器 - 迭代器：两个迭代器的距离\nprev(it)：返回 it 的前一个迭代器\nnext(it)：返回 it 的后一个迭代器\n\n对于其他容器，由于其结构特性，上面的功能不一定都有（例如 set 的迭代器是不能相减求距离的）\n3.4 常见问题.end() 和 .rend() 指向的位置是无意义的值\n对于一个长度为 10 的数组：for (int i = 0; i &lt; 10; i++)，第 10 位是不可访问的\n对于一个长度为 10 的容器：for (auto it = a.begin(); it != a.end(); ++it)，.end 是不可访问的\n不同容器的迭代器功能可能不一样\n迭代器细化的话有正向、反向、双向，每个容器的迭代器支持的运算符也可能不同，因此不同容器的迭代器细节很有可能是不一样的。\n删除操作时需要警惕\n为什么 3 没删掉？\ncppvector&lt;int&gt; a&#123;1, 2, 3, 4&#125;;\nfor (auto it = a.begin(); it != a.end(); ++it)\n    if (*it == 2 || *it == 3)\n        a.erase(it);\n// a = [1, 3, 4]为啥 RE 了？\ncppvector&lt;int&gt; a&#123;1, 2, 3, 4&#125;;\nfor (auto it = a.begin(); it != a.end(); ++it)\n    if (*it == 4)\n        a.erase(it);建议：如无必要，别用迭代器操作容器。（遍历与访问没关系）\n\n\n\n4 常用算法4.1 内容总览打勾的是本次将会详细讲解的，其他的是算法竞赛中建议学习的，不在下表列出的在比赛中基本用不到。\n（很多函数的功能很简单，自己都能快速写出来，但是使用函数可以让代码可读性变得更高，这在比赛中是至关紧要的）\n\n算法库 Algorithm\n\n count()\n find()\n fill()\n swap()\n reverse()\n shuffle() C++11\n unique()\n sort()\n lower_bound() &#x2F; upper_bound()\n max() &#x2F; min()\n max_element() &#x2F; min_element()\n prev_permutation() &#x2F; next_permutation()\n\n\n数学函数 cmath\n\n abs()\n exp()\n log() &#x2F; log10() &#x2F; log2()\n pow()\n sqrt()\n sin() &#x2F; cos() &#x2F; tan()\n asin() &#x2F; acos() &#x2F; atan()\n sinh() &#x2F; cosh() &#x2F; tanh()\n asinh() &#x2F; acosh() &#x2F; atanh() C++11\n ceil() &#x2F; floor()\n round() C++11\n\n\n数值算法 numeric\n\n iota() C++11\n accumulate()\n gcd() C++17\n lcm() C++17\n\n\n伪随机数生成 random\n\n mt19937\n random_device()\n\n\n\n4.2 swap()交换两个变量的值\n用法示例\ncpptemplate&lt; class T &gt;\nvoid swap( T&amp; a, T&amp; b );cppint a = 0, b = 1;\nswap(a, b);\n// now a = 1, b = 0\n\nint arr[10] &#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125;;\nswap(arr[4], arr[6]);\n// now arr = &#123;0, 1, 2, 3, 6, 5, 4, 7, 8, 9&#125;注意事项\n这个 swap 参数是引用的，不需要像 C 语言一样取地址。\n4.3 sort()使用快速排序给一个可迭代对象排序\n用法示例\ncpptemplate&lt; class RandomIt, class Compare &gt;\nvoid sort( RandomIt first, RandomIt last, Compare comp );默认排序从小到大\ncppvector&lt;int&gt; arr&#123;1, 9, 1, 9, 8, 1, 0&#125;;\nsort(arr.begin(), arr.end());\n// arr = [0, 1, 1, 1, 8, 9, 9]如果要从大到小，则需要传比较器进去。\ncppvector&lt;int&gt; arr&#123;1, 9, 1, 9, 8, 1, 0&#125;;\nsort(arr.begin(), arr.end(), greater&lt;int&gt;());\n// arr = [9, 9, 8, 1, 1, 1, 0]如果需要完成特殊比较，则需要手写比较器。\n比较器函数返回值是 bool 类型，传参是需要比较的两个元素。记我们定义的该比较操作为 $\\star$：\n\n若 $a\\star b$，则比较器函数应当返回 true\n若 $a\\not\\star b$，则比较器函数应当返回 false\n\n注意：如果 $a&#x3D;b$，比较器函数必须返回 false\ncppbool cmp(pair&lt;int, int&gt; a, pair&lt;int, int&gt; b)\n&#123;\n    if (a.second != b.second)\n        return a.second &lt; b.second;\n    return a.first &gt; b.first;\n&#125;\n\nint main()\n&#123;\n    vector&lt;pair&lt;int, int&gt;&gt; arr&lt;!--swig￼1--&gt;;\n    sort(arr.begin(), arr.end(), cmp);\n    // arr = [(0, 0), (8, 1), (2, 9), (1, 9)]\n&#125;4.4 lower_bound() &#x2F; upper_bound()在已升序排序的元素中，应用二分查找检索指定元素，返回对应元素迭代器位置。找不到则返回尾迭代器。\n\nlower_bound(): 寻找 $\\geq x$ 的第一个元素的位置\nupper_bound(): 寻找 $&gt;x$ 的第一个元素的位置\n\n怎么找 $\\leq x$ &#x2F; $&lt; x$ 的第一个元素呢？\n\n$&gt;x$ 的第一个元素的前一个元素（如果有）便是 $\\leq x$ 的第一个元素\n$\\geq x$ 的第一个元素的前一个元素（如果有）便是 $&lt;x$ 的第一个元素\n\n返回的是迭代器，如何转成下标索引呢？减去头迭代器即可。\n用法示例\ncpptemplate&lt; class ForwardIt, class T &gt;\nForwardIt lower_bound( ForwardIt first, ForwardIt last, const T&amp; value );cppvector&lt;int&gt; arr&#123;0, 1, 1, 1, 8, 9, 9&#125;;\nvector&lt;int&gt;::iterator it = lower_bound(arr.begin(), arr.end(), 7);\nint idx = it - arr.begin();\n// idx = 4我们通常写成一行：\ncppvector&lt;int&gt; arr&#123;0, 1, 1, 1, 8, 9, 9&#125;;\nidx = lower_bound(arr.begin(), arr.end(), 7) - arr.begin(); // 4\nidx = lower_bound(arr.begin(), arr.end(), 8) - arr.begin(); // 4\nidx = upper_bound(arr.begin(), arr.end(), 7) - arr.begin(); // 4\nidx = upper_bound(arr.begin(), arr.end(), 8) - arr.begin(); // 54.5 reverse()反转一个可迭代对象的元素顺序\n用法示例\ncpptemplate&lt; class BidirIt &gt;\nvoid reverse( BidirIt first, BidirIt last );cppvector&lt;int&gt; arr(10);\niota(arr.begin(), arr.end(), 1);\n// 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\nreverse(arr.begin(), arr.end());\n// 10, 9, 8, 7, 6, 5, 4, 3, 2, 14.6 max() &#x2F; min()返回最大值 &#x2F; 最小值的数值\n用法示例\ncppint mx = max(1, 2); // 2\nint mn = min(1, 2); // 1在 C++11 之后，可以使用列表构造语法传入一个列表，这样就能一次性给多个元素找最大值而不用套娃了：\ncpp// Before C++11\nint mx = max(max(1, 2), max(3, 4)); // 4\nint mn = min(min(1, 2), min(3, 4)); // 1\n\n// After C++11\nint mx = max(&#123;1, 2, 3, 4&#125;); // 4\nint mn = min(&#123;1, 2, 3, 4&#125;); // 14.7 unique()消除数组的重复相邻元素，数组长度不变，但是有效数据缩短，返回的是有效数据位置的结尾迭代器。\n例如：$[1,1,4,5,1,4]\\to[1,4,5,1,4,\\underline?]$，下划线位置为返回的迭代器指向。\ncpptemplate&lt; class ForwardIt &gt;\nForwardIt unique( ForwardIt first, ForwardIt last );用法示例\n单独使用 unique 并不能达成去重效果，因为它只消除相邻的重复元素。但是如果序列有序，那么它就能去重了。\n但是它去重后，序列尾部会产生一些无效数据：$[1,1,2,4,4,4,5]\\to[1,2,4,5,\\underline?,?,?]$，为了删掉这些无效数据，我们需要结合 erase.\n最终，给 vector 去重的写法便是：\ncppvector&lt;int&gt; arr&#123;1, 2, 1, 4, 5, 4, 4&#125;;\nsort(arr.begin(), arr.end());\narr.erase(unique(arr.begin(), arr.end()), arr.end());4.8 数学函数所有函数参数均支持 int &#x2F; long long &#x2F; float &#x2F; double &#x2F; long double\n\n\n\n公式\n示例\n\n\n\n$f(x)&#x3D;\\lvert x\\rvert$\nabs(-1.0)\n\n\n$f(x)&#x3D;e^x$\nexp(2)\n\n\n$f(x)&#x3D;\\ln x$\nlog(3)\n\n\n$f(x,y)&#x3D;x^y$\npow(2, 3)\n\n\n$f(x)&#x3D;\\sqrt x$\nsqrt(2)\n\n\n$f(x)&#x3D;\\lceil x\\rceil$\nceil(2.1)\n\n\n$f(x)&#x3D;\\lfloor x\\rfloor$\nfloor(2.1)\n\n\n$f(x)&#x3D;\\left&lt;x\\right&gt;$\nrount(2.1)\n\n\n注意事项\n由于浮点误差，有些的数学函数的行为可能与预期不符，导致 WA。如果你的操作数都是整型，那么用下面的写法会更稳妥。\n\n\n\n\n\n\n\n\n\n原文地址：https://codeforces.com/blog/entry/107717\n\n$\\lfloor\\frac{a}{b}\\rfloor$\n别用：floor(1.0 * a / b)\n要用：a / b\n\n\n$\\lceil\\frac{a}{b}\\rceil$\n别用：ceil(1.0 * a / b)\n要用：(a + b - 1) / b  （$\\lceil\\frac{a}{b}\\rceil&#x3D;\\lfloor\\frac{a+b-1}{b}\\rfloor$）\n\n\n$\\lfloor\\sqrt a\\rfloor$\n别用：(int) sqrt(a)\n要用：二分查找 https://io.zouht.com/7.html\n\n\n$a^b$\n别用：pow(a, b)\n要用：快速幂 https://io.zouht.com/18.html\n\n\n$\\lfloor\\log_2 a\\rfloor$\n别用：log2(a)\n要用：__lg （不规范，但是这是竞赛）&#x2F; bit_width（C++20 可用）\n\n\n\n4.9 gcd() &#x2F; lcm()（C++17）返回最大公因数 &#x2F; 最小公倍数\ncppint x = gcd(8, 12); // 4\nint y = lcm(8, 12); // 24如果不是 C++17，但是是 GNU 编译器（g++），那么可以用内置函数 __gcd().\n当然，gcd &#x2F; lcm 函数也挺好写，直接写也行（欧几里得算法）：\ncppint gcd(int a, int b)\n&#123;\n    if (!b)\n        return a;\n    return gcd(b, a % b);\n&#125;\n\nint lcm(int a, int b)\n&#123;\n    return a / gcd(a, b) * b;\n&#125;","slug":"算竞常用STL","date":"2024-02-14T12:01:12.000Z","categories_index":"Study","tags_index":"学习,算法","author_index":"Fioransh"},{"id":"70c70d32e8bb29f6d69b3478fcb4a7ae","title":"SpringBoot知识点总结（三）","content":"11.事务管理11.1 事务回顾在数据库阶段我们已学习过事务了，我们讲到：\n事务是一组操作的集合，它是一个不可分割的工作单位。事务会把所有的操作作为一个整体，一起向数据库提交或者是撤销操作请求。所以这组操作要么同时成功，要么同时失败。\n怎么样来控制这组操作，让这组操作同时成功或同时失败呢？此时就要涉及到事务的具体操作了。\n事务的操作主要有三步：\n\n开启事务（一组操作开始前，开启事务）：start transaction &#x2F; begin ;\n提交事务（这组操作全部成功后，提交事务）：commit ;\n回滚事务（中间任何一个操作出现异常，回滚事务）：rollback ;\n\n11.2 Spring事务管理简单的回顾了事务的概念以及事务的基本操作之后，接下来我们看一个事务管理案例：解散部门 （解散部门就是删除部门）\n需求：当部门解散了不仅需要把部门信息删除了，还需要把该部门下的员工数据也删除了。\n步骤：\n\n根据ID删除部门数据\n根据部门ID删除该部门下的员工\n\n重启SpringBoot服务，使用postman测试部门删除：\n代码正常情况下，dept表和Em表中的数据已删除\n修改DeptServiceImpl类中代码，添加可能出现异常的代码：\n重启SpringBoot服务，使用postman测试部门删除：\n查看数据库表：\n\n删除了2号部门\n\n2号部门下的员工数据没有删除\n\n\n以上程序出现的问题：即使程序运行抛出了异常，部门依然删除了，但是部门下的员工却没有删除，造成了数据的不一致。\n原因：\n\n先执行根据id删除部门的操作，这步执行完毕，数据库表 dept 中的数据就已经删除了。\n执行 1&#x2F;0 操作，抛出异常\n抛出异常之前，下面所有的代码都不会执行了，根据部门ID删除该部门下的员工，这个操作也不会执行 。\n\n此时就出现问题了，部门删除了，部门下的员工还在，业务操作前后数据不一致。\n而要想保证操作前后，数据的一致性，就需要让解散部门中涉及到的两个业务操作，要么全部成功，要么全部失败 。 那我们如何，让这两个操作要么全部成功，要么全部失败呢 ？\n那就可以通过事务来实现，因为一个事务中的多个业务操作，要么全部成功，要么全部失败。\n此时，我们就需要在delete删除业务功能中添加事务。\n\n在方法运行之前，开启事务，如果方法成功执行，就提交事务，如果方法执行的过程当中出现异常了，就回滚事务。\n思考：开发中所有的业务操作，一旦我们要进行控制事务，是不是都是这样的套路？\n答案：是的。\n所以在spring框架当中就已经把事务控制的代码都已经封装好了，并不需要我们手动实现。我们使用了spring框架，我们只需要通过一个简单的注解@Transactional就搞定了。\n\n\n\n\n\n\n\n\n\n@Transactional作用：就是在当前这个方法执行开始之前来开启事务，方法执行完毕之后提交事务。如果在这个方法执行的过程当中出现了异常，就会进行事务的回滚操作。\n@Transactional注解：我们一般会在业务层当中来控制事务，因为在业务层当中，一个业务功能可能会包含多个数据访问的操作。在业务层来控制事务，我们就可以将多个数据访问操作控制在一个事务范围内。\n@Transactional注解书写位置：\n\n方法\n当前方法交给spring进行事务管理\n\n\n类\n当前类中所有的方法都交由spring进行事务管理\n\n\n接口\n接口下所有的实现类当中所有的方法都交给spring 进行事务管理\n\n\n\n接下来，我们就可以在业务方法delete上加上 @Transactional 来控制事务 。\njava@Slf4j\n@Service\npublic class DeptServiceImpl implements DeptService &#123;\n    @Autowired\n    private DeptMapper deptMapper;\n\n    @Autowired\n    private EmpMapper empMapper;\n\n    \n    @Override\n    @Transactional  //当前方法添加了事务管理\n    public void delete(Integer id)&#123;\n        //根据部门id删除部门信息\n        deptMapper.deleteById(id);\n        \n        //模拟：异常发生\n        int i = 1/0;\n\n        //删除部门下的所有员工信息\n        empMapper.deleteByDeptId(id);   \n    &#125;\n&#125;在业务功能上添加@Transactional注解进行事务管理后，我们重启SpringBoot服务，使用postman测试：\n\n添加Spring事务管理后，由于服务端程序引发了异常，所以事务进行回滚。\n\n\n说明：可以在application.yml配置文件中开启事务管理日志，这样就可以在控制看到和事务相关的日志信息了\nyaml#spring事务管理日志\nlogging:\n  level:\n    org.springframework.jdbc.support.JdbcTransactionManager: debug11.3 事务进阶前面我们通过spring事务管理注解@Transactional已经控制了业务层方法的事务。接下来我们要来详细的介绍一下@Transactional事务管理注解的使用细节。我们这里主要介绍@Transactional注解当中的两个常见的属性：\n\n异常回滚的属性：rollbackFor \n事务传播行为：propagation\n\n我们先来学习下rollbackFor属性。\n11.3.1 rollbackFor我们在之前编写的业务方法上添加了@Transactional注解，来实现事务管理。\njava@Transactional\npublic void delete(Integer id)&#123;\n        //根据部门id删除部门信息\n        deptMapper.deleteById(id);\n        \n        //模拟：异常发生\n        int i = 1/0;\n\n        //删除部门下的所有员工信息\n        empMapper.deleteByDeptId(id);   \n&#125;以上业务功能delete()方法在运行时，会引发除0的算数运算异常(运行时异常)，出现异常之后，由于我们在方法上加了@Transactional注解进行事务管理，所以发生异常会执行rollback回滚操作，从而保证事务操作前后数据是一致的。\n下面我们在做一个测试，我们修改业务功能代码，在模拟异常的位置上直接抛出Exception异常（编译时异常）\njava@Transactional\npublic void delete(Integer id) throws Exception &#123;\n        //根据部门id删除部门信息\n        deptMapper.deleteById(id);\n        \n        //模拟：异常发生\n        if(true)&#123;\n            throw new Exception(&quot;出现异常了~~~&quot;);\n        &#125;\n\n        //删除部门下的所有员工信息\n        empMapper.deleteByDeptId(id);   \n&#125;\n\n\n\n\n\n\n\n\n说明：在service中向上抛出一个Exception编译时异常之后，由于是controller调用service，所以在controller中要有异常处理代码，此时我们选择在controller中继续把异常向上抛。\njava@DeleteMapping(&quot;/depts/&#123;id&#125;&quot;)\npublic Result delete(@PathVariable Integer id) throws Exception &#123;\n  //日志记录\n  log.info(&quot;根据id删除部门&quot;);\n  //调用service层功能\n  deptService.delete(id);\n  //响应\n  return Result.success();\n&#125;\n重新启动服务后测试：\n抛出异常之后事务会不会回滚\n\n现有表中数据：\n\n使用postman测试，删除5号部门\n\n发生了Exception异常，但事务依然提交了\n\n\n\n\n\n\n\n\n\n\ndept表中数据：\n\n通过以上测试可以得出一个结论：默认情况下，只有出现RuntimeException(运行时异常)才会回滚事务。\n假如我们想让所有的异常都回滚，需要来配置@Transactional注解当中的rollbackFor属性，通过rollbackFor这个属性可以指定出现何种异常类型回滚事务。\njava@Slf4j\n@Service\npublic class DeptServiceImpl implements DeptService &#123;\n    @Autowired\n    private DeptMapper deptMapper;\n\n    @Autowired\n    private EmpMapper empMapper;\n\n    \n    @Override\n    @Transactional(rollbackFor=Exception.class)\n    public void delete(Integer id)&#123;\n        //根据部门id删除部门信息\n        deptMapper.deleteById(id);\n        \n        //模拟：异常发生\n        int num = id/0;\n\n        //删除部门下的所有员工信息\n        empMapper.deleteByDeptId(id);   \n    &#125;\n&#125;接下来我们重新启动服务，测试删除部门的操作：\n\n控制台日志：执行了删除3号部门的操作， 因为异常又进行了事务回滚\n\n数据表：3号部门没有删除\n\n\n\n\n\n\n\n\n\n\n结论：\n\n在Spring的事务管理中，默认只有运行时异常 RuntimeException才会回滚。\n如果还需要回滚指定类型的异常，可以通过rollbackFor属性来指定。\n\n11.3.2 propagation我们接着继续学习@Transactional注解当中的第二个属性propagation，这个属性是用来配置事务的传播行为的。\n什么是事务的传播行为呢？\n\n就是当一个事务方法被另一个事务方法调用时，这个事务方法应该如何进行事务控制。\n\n例如：两个事务方法，一个A方法，一个B方法。在这两个方法上都添加了@Transactional注解，就代表这两个方法都具有事务，而在A方法当中又去调用了B方法。\n \n所谓事务的传播行为，指的就是在A方法运行的时候，首先会开启一个事务，在A方法当中又调用了B方法， B方法自身也具有事务，那么B方法在运行的时候，到底是加入到A方法的事务当中来，还是B方法在运行的时候新建一个事务？这个就涉及到了事务的传播行为。\n我们要想控制事务的传播行为，在@Transactional注解的后面指定一个属性propagation，通过 propagation 属性来指定传播行为。接下来我们就来介绍一下常见的事务传播行为。\n\n\n\n属性值\n含义\n\n\n\nREQUIRED\n【默认值】需要事务，有则加入，无则创建新事务\n\n\nREQUIRES_NEW\n需要新事务，无论有无，总是创建新事务\n\n\nSUPPORTS\n支持事务，有则加入，无则在无事务状态中运行\n\n\nNOT_SUPPORTED\n不支持事务，在无事务状态下运行,如果当前存在已有事务,则挂起当前事务\n\n\nMANDATORY\n必须有事务，否则抛异常\n\n\nNEVER\n必须没事务，否则抛异常\n\n\n…\n\n\n\n\n\n\n\n\n\n\n\n\n对于这些事务传播行为，我们只需要关注以下两个就可以了：\n\nREQUIRED（默认值）\nREQUIRES_NEW\n\n接下来我们就通过一个案例来演示下事务传播行为propagation属性的使用。\n需求：解散部门时需要记录操作日志\n​\t\t\t由于解散部门是一个非常重要而且非常危险的操作，所以在业务当中要求每一次执行解散部门的操作都需要留下痕迹，就是要记录操作日志。而且还要求无论是执行成功了还是执行失败了，都需要留下痕迹。\n步骤：\n\n执行解散部门的业务：先删除部门，再删除部门下的员工（前面已实现）\n记录解散部门的日志，到日志表（未实现）\n\n准备工作：\n\n创建数据库表 dept_log 日志表：\n\ntxtcreate table dept_log(\n       id int auto_increment comment &#39;主键ID&#39; primary key,\n    create_time datetime null comment &#39;操作时间&#39;,\n    description varchar(300) null comment &#39;操作描述&#39;\n)comment &#39;部门操作日志表&#39;;\n引入资料中提供的实体类：DeptLog\n\njava@Data\n@NoArgsConstructor\n@AllArgsConstructor\npublic class DeptLog &#123;\n    private Integer id;\n    private LocalDateTime createTime;\n    private String description;\n&#125;\n引入资料中提供的Mapper接口：DeptLogMapper\n\njava@Mapper\npublic interface DeptLogMapper &#123;\n\n    @Insert(&quot;insert into dept_log(create_time,description) values(#&#123;createTime&#125;,#&#123;description&#125;)&quot;)\n    void insert(DeptLog log);\n\n&#125;\n引入资料中提供的业务接口：DeptLogService\n\njavapublic interface DeptLogService &#123;\n    void insert(DeptLog deptLog);\n&#125;\n引入资料中提供的业务实现类：DeptLogServiceImpl\n\njava@Service\npublic class DeptLogServiceImpl implements DeptLogService &#123;\n\n    @Autowired\n    private DeptLogMapper deptLogMapper;\n\n    @Transactional //事务传播行为：有事务就加入、没有事务就新建事务\n    @Override\n    public void insert(DeptLog deptLog) &#123;\n        deptLogMapper.insert(deptLog);\n    &#125;\n&#125;\n代码实现:\n业务实现类：DeptServiceImpl\njava@Slf4j\n@Service\n//@Transactional //当前业务实现类中的所有的方法，都添加了spring事务管理机制\npublic class DeptServiceImpl implements DeptService &#123;\n    @Autowired\n    private DeptMapper deptMapper;\n    \n    @Autowired\n    private EmpMapper empMapper;\n\n    @Autowired\n    private DeptLogService deptLogService;\n\n\n    //根据部门id，删除部门信息及部门下的所有员工\n    @Override\n    @Log\n    @Transactional(rollbackFor = Exception.class) \n    public void delete(Integer id) throws Exception &#123;\n        try &#123;\n            //根据部门id删除部门信息\n            deptMapper.deleteById(id);\n            //模拟：异常\n            if(true)&#123;\n                throw new Exception(&quot;出现异常了~~~&quot;);\n            &#125;\n            //删除部门下的所有员工信息\n            empMapper.deleteByDeptId(id);\n        &#125;finally &#123;\n            //不论是否有异常，最终都要执行的代码：记录日志\n            DeptLog deptLog = new DeptLog();\n            deptLog.setCreateTime(LocalDateTime.now());\n            deptLog.setDescription(&quot;执行了解散部门的操作，此时解散的是&quot;+id+&quot;号部门&quot;);\n            //调用其他业务类中的方法\n            deptLogService.insert(deptLog);\n        &#125;\n    &#125;\n    \n    //省略其他代码...\n&#125;测试:\n重新启动SpringBoot服务，测试删除3号部门后会发生什么？\n\n执行了删除3号部门操作\n执行了插入部门日志操作\n程序发生Exception异常\n执行事务回滚（删除、插入操作因为在一个事务范围内，两个操作都会被回滚）\n\n\n然后在dept_log表中没有记录日志数据\n \n原因分析:\n接下来我们就需要来分析一下具体是什么原因导致的日志没有成功的记录。\n\n在执行delete操作时开启了一个事务\n\n当执行insert操作时，insert设置的事务传播行是默认值REQUIRED，表示有事务就加入，没有则新建事务\n\n此时：delete和insert操作使用了同一个事务，同一个事务中的多个操作，要么同时成功，要么同时失败，所以当异常发生时进行事务回滚，就会回滚delete和insert操作\n\n\n\n解决方案：\n在DeptLogServiceImpl类中insert方法上，添加@Transactional(propagation &#x3D; Propagation.REQUIRES_NEW)\n\n\n\n\n\n\n\n\n\nPropagation.REQUIRES_NEW  ：不论是否有事务，都创建新事务  ，运行在一个独立的事务中。\njava@Service\npublic class DeptLogServiceImpl implements DeptLogService &#123;\n\n    @Autowired\n    private DeptLogMapper deptLogMapper;\n\n    @Transactional(propagation = Propagation.REQUIRES_NEW)//事务传播行为：不论是否有事务，都新建事务\n    @Override\n    public void insert(DeptLog deptLog) &#123;\n        deptLogMapper.insert(deptLog);\n    &#125;\n&#125;重启SpringBoot服务，再次测试删除3号部门：\n\n那此时，DeptServiceImpl中的delete方法运行时，会开启一个事务。 当调用  deptLogService.insert(deptLog)  时，也会创建一个新的事务，那此时，当insert方法运行完毕之后，事务就已经提交了。 即使外部的事务出现异常，内部已经提交的事务，也不会回滚了，因为是两个独立的事务。\n到此事务传播行为已演示完成，事务的传播行为我们只需要掌握两个：REQUIRED、REQUIRES_NEW。\n\n\n\n\n\n\n\n\n\n\nREQUIRED ：大部分情况下都是用该传播行为即可。\n\nREQUIRES_NEW ：当我们不希望事务之间相互影响时，可以使用该传播行为。比如：下订单前需要记录日志，不论订单保存成功与否，都需要保证日志记录能够记录成功。\n\n\n12.AOP基础12.1 AOP概述什么是AOP？\n\nAOP英文全称：Aspect Oriented Programming（面向切面编程、面向方面编程），其实说白了，面向切面编程就是面向特定方法编程。\n\n那什么又是面向方法编程呢，为什么又需要面向方法编程呢？来我们举个例子做一个说明：\n比如，我们这里有一个项目，项目中开发了很多的业务功能。\n \n然而有一些业务功能执行效率比较低，执行耗时较长，我们需要针对于这些业务方法进行优化。 那首先第一步就需要定位出执行耗时比较长的业务方法，再针对于业务方法再来进行优化。\n此时我们就需要统计当前这个项目当中每一个业务方法的执行耗时。那么统计每一个业务方法的执行耗时该怎么实现？\n可能多数人首先想到的就是在每一个业务方法运行之前，记录这个方法运行的开始时间。在这个方法运行完毕之后，再来记录这个方法运行的结束时间。拿结束时间减去开始时间，不就是这个方法的执行耗时吗？\n \n\n\n\n以上分析的实现方式是可以解决需求问题的。但是对于一个项目来讲，里面会包含很多的业务模块，每个业务模块又包含很多增删改查的方法，如果我们要在每一个模块下的业务方法中，添加记录开始时间、结束时间、计算执行耗时的代码，就会让程序员的工作变得非常繁琐。\n \n\n\n\n而AOP面向方法编程，就可以做到在不改动这些原始方法的基础上，针对特定的方法进行功能的增强。\n\n\n\n\n\n\n\n\n\nAOP的作用：在程序运行期间在不修改源代码的基础上对已有方法进行增强（无侵入性: 解耦）\n我们要想完成统计各个业务方法执行耗时的需求，我们只需要定义一个模板方法，将记录方法执行耗时这一部分公共的逻辑代码，定义在模板方法当中，在这个方法开始运行之前，来记录这个方法运行的开始时间，在方法结束运行的时候，再来记录方法运行的结束时间，中间就来运行原始的业务方法。\n \n\n\n\n而中间运行的原始业务方法，可能是其中的一个业务方法，比如：我们只想通过 部门管理的 list 方法的执行耗时，那就只有这一个方法是原始业务方法。  而如果，我们是先想统计所有部门管理的业务方法执行耗时，那此时，所有的部门管理的业务方法都是 原始业务方法。 那面向这样的指定的一个或多个方法进行编程，我们就称之为 面向切面编程。\n那此时，当我们再调用部门管理的 list 业务方法时啊，并不会直接执行 list 方法的逻辑，而是会执行我们所定义的 模板方法 ， 然后再模板方法中：\n\n记录方法运行开始时间\n运行原始的业务方法（那此时原始的业务方法，就是 list 方法）\n记录方法运行结束时间，计算方法执行耗时\n\n \n\n不论，我们运行的是那个业务方法，最后其实运行的就是我们定义的模板方法，而在模板方法中，就完成了原始方法执行耗时的统计操作 。(那这样呢，我们就通过一个模板方法就完成了指定的一个或多个业务方法执行耗时的统计)\n而大家会发现，这个流程，我们是不是似曾相识啊？ \n对了，就是和我们之前所学习的动态代理技术是非常类似的。 我们所说的模板方法，其实就是代理对象中所定义的方法，那代理对象中的方法以及根据对应的业务需要， 完成了对应的业务功能，当运行原始业务方法时，就会运行代理对象中的方法，从而实现统计业务方法执行耗时的操作。\n其实，AOP面向切面编程和OOP面向对象编程一样，它们都仅仅是一种编程思想，而动态代理技术是这种思想最主流的实现方式。而Spring的AOP是Spring框架的高级技术，旨在管理bean对象的过程中底层使用动态代理机制，对特定的方法进行编程(功能增强)。\n\n\n\n\n\n\n\n\n\nAOP的优势：\n\n减少重复代码\n提高开发效率\n维护方便\n\n12.2 AOP快速入门在了解了什么是AOP后，我们下面通过一个快速入门程序，体验下AOP的开发，并掌握Spring中AOP的开发步骤。\n需求：统计各个业务层方法执行耗时。\n实现步骤：\n\n导入依赖：在pom.xml中导入AOP的依赖\n编写AOP程序：针对于特定方法根据业务需要进行编程\n\n\n\n\n\n\n\n\n\n\n为演示方便，可以自建新项目或导入提供的springboot-aop-quickstart项目工程\npom.xml\nxml&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;\n&lt;/dependency&gt;AOP程序：TimeAspect\njava@Component\n@Aspect //当前类为切面类\n@Slf4j\npublic class TimeAspect &#123;\n\n    @Around(&quot;execution(* com.itheima.service.*.*(..))&quot;) \n    public Object recordTime(ProceedingJoinPoint pjp) throws Throwable &#123;\n        //记录方法执行开始时间\n        long begin = System.currentTimeMillis();\n\n        //执行原始方法\n        Object result = pjp.proceed();\n\n        //记录方法执行结束时间\n        long end = System.currentTimeMillis();\n\n        //计算方法执行耗时\n        log.info(pjp.getSignature()+&quot;执行耗时: &#123;&#125;毫秒&quot;,end-begin);\n\n        return result;\n    &#125;\n&#125;重新启动SpringBoot服务测试程序：\n\n查询3号部门信息\n\n\n\n\n\n\n\n\n\n\n\n\n我们可以再测试下：查询所有部门信息（同样执行AOP程序）\n\n我们通过AOP入门程序完成了业务方法执行耗时的统计，那其实AOP的功能远不止于此，常见的应用场景如下：\n\n记录系统的操作日志\n权限控制\n事务管理：我们前面所讲解的Spring事务管理，底层其实也是通过AOP来实现的，只要添加@Transactional注解之后，AOP程序自动会在原始方法运行前先来开启事务，在原始方法运行完毕之后提交或回滚事务\n\n这些都是AOP应用的典型场景。\n通过入门程序，我们也应该感受到了AOP面向切面编程的一些优势：\n\n代码无侵入：没有修改原始的业务方法，就已经对原始的业务方法进行了功能的增强或者是功能的改变\n\n减少了重复代码\n\n提高开发效率\n\n维护方便\n\n\n12.3 AOP核心概念通过SpringAOP的快速入门，感受了一下AOP面向切面编程的开发方式。下面我们再来学习AOP当中涉及到的一些核心概念。\n1. 连接点：JoinPoint，可以被AOP控制的方法（暗含方法执行时的相关信息）\n​\t连接点指的是可以被aop控制的方法。例如：入门程序当中所有的业务方法都是可以被aop控制的方法。\n​\t \n​\t在SpringAOP提供的JoinPoint当中，封装了连接点方法在执行时的相关信息。（后面会有具体的讲解）\n2. 通知：Advice，指哪些重复的逻辑，也就是共性功能（最终体现为一个方法）\n​\t在入门程序中是需要统计各个业务方法的执行耗时的，此时我们就需要在这些业务方法运行开始之前，先记录这个方法运行的开始时间，在每一个业务方法运行结束的时候，再来记录这个方法运行的结束时间。\n​\t但是在AOP面向切面编程当中，我们只需要将这部分重复的代码逻辑抽取出来单独定义。抽取出来的这一部分重复的逻辑，也就是共性的功能。\n​\t \n​\t\n3. 切入点：PointCut，匹配连接点的条件，通知仅会在切入点方法执行时被应用\n​\t在通知当中，我们所定义的共性功能到底要应用在哪些方法上？此时就涉及到了切入点pointcut概念。切入点指的是匹配连接点的条件。通知仅会在切入点方法运行时才会被应用。\n​\t在aop的开发当中，我们通常会通过一个切入点表达式来描述切入点(后面会有详解)。\n​\t \n​\t假如：切入点表达式改为DeptServiceImpl.list()，此时就代表仅仅只有list这一个方法是切入点。只有list()方法在运行的时候才会应用通知。\n​\t\n4. 切面：Aspect，描述通知与切入点的对应关系（通知+切入点）\n​\t当通知和切入点结合在一起，就形成了一个切面。通过切面就能够描述当前aop程序需要针对于哪个原始方法，在什么时候执行什么样的操作。\n​\t \n​\t切面所在的类，我们一般称为切面类（被@Aspect注解标识的类）\n​\t\n5. 目标对象：Target，通知所应用的对象\n​\t目标对象指的就是通知所应用的对象，我们就称之为目标对象。\n​\t \nAOP的核心概念我们介绍完毕之后，接下来我们再来分析一下我们所定义的通知是如何与目标对象结合在一起，对目标对象当中的方法进行功能增强的。\n \n\nSpring的AOP底层是基于动态代理技术来实现的，也就是说在程序运行的时候，会自动的基于动态代理技术为目标对象生成一个对应的代理对象。在代理对象当中就会对目标对象当中的原始方法进行功能的增强。\n13.AOP进阶AOP的基础知识学习完之后，下面我们对AOP当中的各个细节进行详细的学习。主要分为4个部分：\n\n通知类型\n通知顺序\n切入点表达式\n连接点\n\n我们先来学习第一部分通知类型。\n13.1 通知顺序在入门程序当中，我们已经使用了一种功能最为强大的通知类型：Around环绕通知。\njava@Around(&quot;execution(* com.itheima.service.*.*(..))&quot;)\npublic Object recordTime(ProceedingJoinPoint pjp) throws Throwable &#123;\n    //记录方法执行开始时间\n    long begin = System.currentTimeMillis();\n    //执行原始方法\n    Object result = pjp.proceed();\n    //记录方法执行结束时间\n    long end = System.currentTimeMillis();\n    //计算方法执行耗时\n    log.info(pjp.getSignature()+&quot;执行耗时: &#123;&#125;毫秒&quot;,end-begin);\n    return result;\n&#125;\n\n\n\n\n\n\n\n\n只要我们在通知方法上加上了@Around注解，就代表当前通知是一个环绕通知。\nSpring中AOP的通知类型：\n\n@Around：环绕通知，此注解标注的通知方法在目标方法前、后都被执行\n@Before：前置通知，此注解标注的通知方法在目标方法前被执行\n@After ：后置通知，此注解标注的通知方法在目标方法后被执行，无论是否有异常都会执行\n@AfterReturning ： 返回后通知，此注解标注的通知方法在目标方法后被执行，有异常不会执行\n@AfterThrowing ： 异常后通知，此注解标注的通知方法发生异常后执行\n\n下面我们通过代码演示，来加深对于不同通知类型的理解：\njava@Slf4j\n@Component\n@Aspect\npublic class MyAspect1 &#123;\n    //前置通知\n    @Before(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void before(JoinPoint joinPoint)&#123;\n        log.info(&quot;before ...&quot;);\n\n    &#125;\n\n    //环绕通知\n    @Around(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public Object around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123;\n        log.info(&quot;around before ...&quot;);\n\n        //调用目标对象的原始方法执行\n        Object result = proceedingJoinPoint.proceed();\n        \n        //原始方法如果执行时有异常，环绕通知中的后置代码不会在执行了\n        \n        log.info(&quot;around after ...&quot;);\n        return result;\n    &#125;\n\n    //后置通知\n    @After(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void after(JoinPoint joinPoint)&#123;\n        log.info(&quot;after ...&quot;);\n    &#125;\n\n    //返回后通知（程序在正常执行的情况下，会执行的后置通知）\n    @AfterReturning(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void afterReturning(JoinPoint joinPoint)&#123;\n        log.info(&quot;afterReturning ...&quot;);\n    &#125;\n\n    //异常通知（程序在出现异常的情况下，执行的后置通知）\n    @AfterThrowing(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void afterThrowing(JoinPoint joinPoint)&#123;\n        log.info(&quot;afterThrowing ...&quot;);\n    &#125;\n&#125;\n重新启动SpringBoot服务，进行测试：\n1. 没有异常情况下：\n\n使用postman测试查询所有部门数据\n\n\n\n查看idea中控制台日志输出\n\n\n\n\n\n\n\n\n\n\n\n程序没有发生异常的情况下，@AfterThrowing标识的通知方法不会执行。\n2. 出现异常情况下：\n修改DeptServiceImpl业务实现类中的代码： 添加异常\njava@Slf4j\n@Service\npublic class DeptServiceImpl implements DeptService &#123;\n    @Autowired\n    private DeptMapper deptMapper;\n\n    @Override\n    public List&lt;Dept&gt; list() &#123;\n\n        List&lt;Dept&gt; deptList = deptMapper.list();\n\n        //模拟异常\n        int num = 10/0;\n\n        return deptList;\n    &#125;\n    \n    //省略其他代码...\n&#125;重新启动SpringBoot服务，测试发生异常情况下通知的执行：\n\n查看idea中控制台日志输出\n\n\n\n\n\n\n\n\n\n\n\n程序发生异常的情况下：\n\n@AfterReturning标识的通知方法不会执行，@AfterThrowing标识的通知方法执行了\n\n@Around环绕通知中原始方法调用时有异常，通知中的环绕后的代码逻辑也不会在执行了 （因为原始方法调用已经出异常了）\n\n\n在使用通知时的注意事项：\n\n@Around环绕通知需要自己调用 ProceedingJoinPoint.proceed() 来让原始方法执行，其他通知不需要考虑目标方法执行\n@Around环绕通知方法的返回值，必须指定为Object，来接收原始方法的返回值，否则原始方法执行完毕，是获取不到返回值的。\n\n五种常见的通知类型，我们已经测试完毕了，此时我们再来看一下刚才所编写的代码，有什么问题吗？\njava//前置通知\n@Before(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n\n//环绕通知\n@Around(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n  \n//后置通知\n@After(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n\n//返回后通知（程序在正常执行的情况下，会执行的后置通知）\n@AfterReturning(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n\n//异常通知（程序在出现异常的情况下，执行的后置通知）\n@AfterThrowing(&quot;execution(* com.itheima.service.*.*(..))&quot;)我们发现啊，每一个注解里面都指定了切入点表达式，而且这些切入点表达式都一模一样。此时我们的代码当中就存在了大量的重复性的切入点表达式，假如此时切入点表达式需要变动，就需要将所有的切入点表达式一个一个的来改动，就变得非常繁琐了。\n怎么来解决这个切入点表达式重复的问题？ 答案就是：抽取\nSpring提供了@PointCut注解，该注解的作用是将公共的切入点表达式抽取出来，需要用到时引用该切入点表达式即可。\njava@Slf4j\n@Component\n@Aspect\npublic class MyAspect1 &#123;\n\n    //切入点方法（公共的切入点表达式）\n    @Pointcut(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    private void pt()&#123;\n\n    &#125;\n\n    //前置通知（引用切入点）\n    @Before(&quot;pt()&quot;)\n    public void before(JoinPoint joinPoint)&#123;\n        log.info(&quot;before ...&quot;);\n\n    &#125;\n\n    //环绕通知\n    @Around(&quot;pt()&quot;)\n    public Object around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123;\n        log.info(&quot;around before ...&quot;);\n\n        //调用目标对象的原始方法执行\n        Object result = proceedingJoinPoint.proceed();\n        //原始方法在执行时：发生异常\n        //后续代码不在执行\n\n        log.info(&quot;around after ...&quot;);\n        return result;\n    &#125;\n\n    //后置通知\n    @After(&quot;pt()&quot;)\n    public void after(JoinPoint joinPoint)&#123;\n        log.info(&quot;after ...&quot;);\n    &#125;\n\n    //返回后通知（程序在正常执行的情况下，会执行的后置通知）\n    @AfterReturning(&quot;pt()&quot;)\n    public void afterReturning(JoinPoint joinPoint)&#123;\n        log.info(&quot;afterReturning ...&quot;);\n    &#125;\n\n    //异常通知（程序在出现异常的情况下，执行的后置通知）\n    @AfterThrowing(&quot;pt()&quot;)\n    public void afterThrowing(JoinPoint joinPoint)&#123;\n        log.info(&quot;afterThrowing ...&quot;);\n    &#125;\n&#125;需要注意的是：当切入点方法使用private修饰时，仅能在当前切面类中引用该表达式， 当外部其他切面类中也要引用当前类中的切入点表达式，就需要把private改为public，而在引用的时候，具体的语法为：\n全类名.方法名()，具体形式如下：\njava@Slf4j\n@Component\n@Aspect\npublic class MyAspect2 &#123;\n    //引用MyAspect1切面类中的切入点表达式\n    @Before(&quot;com.itheima.aspect.MyAspect1.pt()&quot;)\n    public void before()&#123;\n        log.info(&quot;MyAspect2 -&gt; before ...&quot;);\n    &#125;\n&#125;13.2 通知顺序讲解完了Spring中AOP所支持的5种通知类型之后，接下来我们再来研究通知的执行顺序。\n当在项目开发当中，我们定义了多个切面类，而多个切面类中多个切入点都匹配到了同一个目标方法。此时当目标方法在运行的时候，这多个切面类当中的这些通知方法都会运行。\n此时我们就有一个疑问，这多个通知方法到底哪个先运行，哪个后运行？ 下面我们通过程序来验证（这里呢，我们就定义两种类型的通知进行测试，一种是前置通知@Before，一种是后置通知@After）\n定义多个切面类：\njava@Slf4j\n@Component\n@Aspect\npublic class MyAspect2 &#123;\n    //前置通知\n    @Before(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void before()&#123;\n        log.info(&quot;MyAspect2 -&gt; before ...&quot;);\n    &#125;\n\n    //后置通知\n    @After(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void after()&#123;\n        log.info(&quot;MyAspect2 -&gt; after ...&quot;);\n    &#125;\n&#125;\njava@Slf4j\n@Component\n@Aspect\npublic class MyAspect3 &#123;\n    //前置通知\n    @Before(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void before()&#123;\n        log.info(&quot;MyAspect3 -&gt; before ...&quot;);\n    &#125;\n\n    //后置通知\n    @After(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void after()&#123;\n        log.info(&quot;MyAspect3 -&gt;  after ...&quot;);\n    &#125;\n&#125;java@Slf4j\n@Component\n@Aspect\npublic class MyAspect4 &#123;\n    //前置通知\n    @Before(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void before()&#123;\n        log.info(&quot;MyAspect4 -&gt; before ...&quot;);\n    &#125;\n\n    //后置通知\n    @After(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void after()&#123;\n        log.info(&quot;MyAspect4 -&gt; after ...&quot;);\n    &#125;\n&#125;\n重新启动SpringBoot服务，测试通知的执行顺序：\n\n\n\n\n\n\n\n\n\n备注：\n\n把DeptServiceImpl实现类中模拟异常的代码删除或注释掉。\n\n注释掉其他切面类(把@Aspect注释即可)，仅保留MyAspect2、MyAspect3、MyAspect4 ，这样就可以清晰看到执行的结果，而不被其他切面类干扰。\n\n\n\n使用postman测试查询所有部门数据\n\n\n\n查看idea中控制台日志输出\n\n\n通过以上程序运行可以看出在不同切面类中，默认按照切面类的类名字母排序：\n\n目标方法前的通知方法：字母排名靠前的先执行\n目标方法后的通知方法：字母排名靠前的后执行\n\n如果我们想控制通知的执行顺序有两种方式：\n\n修改切面类的类名（这种方式非常繁琐、而且不便管理）\n使用Spring提供的@Order注解\n\n使用@Order注解，控制通知的执行顺序：\njava@Slf4j\n@Component\n@Aspect\n@Order(2)  //切面类的执行顺序（前置通知：数字越小先执行; 后置通知：数字越小越后执行）\npublic class MyAspect2 &#123;\n    //前置通知\n    @Before(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void before()&#123;\n        log.info(&quot;MyAspect2 -&gt; before ...&quot;);\n    &#125;\n\n    //后置通知 \n    @After(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void after()&#123;\n        log.info(&quot;MyAspect2 -&gt; after ...&quot;);\n    &#125;\n&#125;java@Slf4j\n@Component\n@Aspect\n@Order(3)  //切面类的执行顺序（前置通知：数字越小先执行; 后置通知：数字越小越后执行）\npublic class MyAspect3 &#123;\n    //前置通知\n    @Before(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void before()&#123;\n        log.info(&quot;MyAspect3 -&gt; before ...&quot;);\n    &#125;\n\n    //后置通知\n    @After(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void after()&#123;\n        log.info(&quot;MyAspect3 -&gt;  after ...&quot;);\n    &#125;\n&#125;java@Slf4j\n@Component\n@Aspect\n@Order(1) //切面类的执行顺序（前置通知：数字越小先执行; 后置通知：数字越小越后执行）\npublic class MyAspect4 &#123;\n    //前置通知\n    @Before(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void before()&#123;\n        log.info(&quot;MyAspect4 -&gt; before ...&quot;);\n    &#125;\n\n    //后置通知\n    @After(&quot;execution(* com.itheima.service.*.*(..))&quot;)\n    public void after()&#123;\n        log.info(&quot;MyAspect4 -&gt; after ...&quot;);\n    &#125;\n&#125;重新启动SpringBoot服务，测试通知执行顺序：\n\n\n\n\n\n\n\n\n\n\n通知的执行顺序大家主要知道两点即可：\n\n不同的切面类当中，默认情况下通知的执行顺序是与切面类的类名字母排序是有关系的\n可以在切面类上面加上@Order注解，来控制不同的切面类通知的执行顺序\n\n13.3 切入点表示式从AOP的入门程序到现在，我们一直都在使用切入点表达式来描述切入点。下面我们就来详细的介绍一下切入点表达式的具体写法。\n切入点表达式：\n\n描述切入点方法的一种表达式\n\n作用：主要用来决定项目中的哪些方法需要加入通知\n\n常见形式：\n\nexecution(……)：根据方法的签名来匹配\n\n\n\n@annotation(……) ：根据注解匹配\n\n\n\n\n首先我们先学习第一种最为常见的execution切入点表达式。\n13.3.1 executionexecution主要根据方法的返回值、包名、类名、方法名、方法参数等信息来匹配，语法为：\ntxtexecution(访问修饰符?  返回值  包名.类名.?方法名(方法参数) throws 异常?)其中带?的表示可以省略的部分\n\n访问修饰符：可省略（比如: public、protected）\n\n包名.类名： 可省略\n\nthrows 异常：可省略（注意是方法上声明抛出的异常，不是实际抛出的异常）\n\n\n示例：\njava@Before(&quot;execution(void com.itheima.service.impl.DeptServiceImpl.delete(java.lang.Integer))&quot;)可以使用通配符描述切入点\n\n* ：单个独立的任意符号，可以通配任意返回值、包名、类名、方法名、任意类型的一个参数，也可以通配包、类、方法名的一部分\n\n.. ：多个连续的任意符号，可以通配任意层级的包，或任意类型、任意个数的参数\n\n\n切入点表达式的语法规则：\n\n方法的访问修饰符可以省略\n返回值可以使用*号代替（任意返回值类型）\n包名可以使用*号代替，代表任意包（一层包使用一个*）\n使用..配置包名，标识此包以及此包下的所有子包\n类名可以使用*号代替，标识任意类\n方法名可以使用*号代替，表示任意方法\n可以使用 *  配置参数，一个任意类型的参数\n可以使用.. 配置参数，任意个任意类型的参数\n\n切入点表达式示例\n\n省略方法的修饰符号 \njavaexecution(void com.itheima.service.impl.DeptServiceImpl.delete(java.lang.Integer))\n使用*代替返回值类型\njavaexecution(* com.itheima.service.impl.DeptServiceImpl.delete(java.lang.Integer))\n使用*代替包名（一层包使用一个*）\njavaexecution(* com.itheima.*.*.DeptServiceImpl.delete(java.lang.Integer))\n使用..省略包名\njavaexecution(* com..DeptServiceImpl.delete(java.lang.Integer))    \n使用*代替类名\njavaexecution(* com..*.delete(java.lang.Integer))   \n使用*代替方法名\njavaexecution(* com..*.*(java.lang.Integer))   \n使用 * 代替参数\njavaexecution(* com.itheima.service.impl.DeptServiceImpl.delete(*))\n使用..省略参数\njavaexecution(* com..*.*(..))\n\n​\t\n注意事项：\n\n根据业务需要，可以使用 且（&amp;&amp;）、或（||）、非（!） 来组合比较复杂的切入点表达式。\njavaexecution(* com.itheima.service.DeptService.list(..)) || execution(* com.itheima.service.DeptService.delete(..))\n\n切入点表达式的书写建议：\n\n所有业务方法名在命名时尽量规范，方便切入点表达式快速匹配。如：查询类方法都是 find 开头，更新类方法都是update开头\njava//业务类\n@Service\npublic class DeptServiceImpl implements DeptService &#123;\n    \n    public List&lt;Dept&gt; findAllDept() &#123;\n       //省略代码...\n    &#125;\n    \n    public Dept findDeptById(Integer id) &#123;\n       //省略代码...\n    &#125;\n    \n    public void updateDeptById(Integer id) &#123;\n       //省略代码...\n    &#125;\n    \n    public void updateDeptByMoreCondition(Dept dept) &#123;\n       //省略代码...\n    &#125;\n    //其他代码...\n&#125;java//匹配DeptServiceImpl类中以find开头的方法\nexecution(* com.itheima.service.impl.DeptServiceImpl.find*(..))\n描述切入点方法通常基于接口描述，而不是直接描述实现类，增强拓展性\njavaexecution(* com.itheima.service.DeptService.*(..))\n在满足业务需要的前提下，尽量缩小切入点的匹配范围。如：包名匹配尽量不使用 ..，使用 * 匹配单个包\njavaexecution(* com.itheima.*.*.DeptServiceImpl.find*(..))\n\n13.3.2 @annotation已经学习了execution切入点表达式的语法。那么如果我们要匹配多个无规则的方法，比如：list()和 delete()这两个方法。这个时候我们基于execution这种切入点表达式来描述就不是很方便了。而在之前我们是将两个切入点表达式组合在了一起完成的需求，这个是比较繁琐的。\n我们可以借助于另一种切入点表达式annotation来描述这一类的切入点，从而来简化切入点表达式的书写。\n实现步骤：\n\n编写自定义注解\n\n在业务类要做为连接点的方法上添加自定义注解\n\n\n自定义注解：MyLog\njava@Target(ElementType.METHOD)\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface MyLog &#123;\n&#125;业务类：DeptServiceImpl\njava@Slf4j\n@Service\npublic class DeptServiceImpl implements DeptService &#123;\n    @Autowired\n    private DeptMapper deptMapper;\n\n    @Override\n    @MyLog //自定义注解（表示：当前方法属于目标方法）\n    public List&lt;Dept&gt; list() &#123;\n        List&lt;Dept&gt; deptList = deptMapper.list();\n        //模拟异常\n        //int num = 10/0;\n        return deptList;\n    &#125;\n\n    @Override\n    @MyLog  //自定义注解（表示：当前方法属于目标方法）\n    public void delete(Integer id) &#123;\n        //1. 删除部门\n        deptMapper.delete(id);\n    &#125;\n\n\n    @Override\n    public void save(Dept dept) &#123;\n        dept.setCreateTime(LocalDateTime.now());\n        dept.setUpdateTime(LocalDateTime.now());\n        deptMapper.save(dept);\n    &#125;\n\n    @Override\n    public Dept getById(Integer id) &#123;\n        return deptMapper.getById(id);\n    &#125;\n\n    @Override\n    public void update(Dept dept) &#123;\n        dept.setUpdateTime(LocalDateTime.now());\n        deptMapper.update(dept);\n    &#125;\n&#125;切面类\njava@Slf4j\n@Component\n@Aspect\npublic class MyAspect6 &#123;\n    //针对list方法、delete方法进行前置通知和后置通知\n\n    //前置通知\n    @Before(&quot;@annotation(com.itheima.anno.MyLog)&quot;)\n    public void before()&#123;\n        log.info(&quot;MyAspect6 -&gt; before ...&quot;);\n    &#125;\n\n    //后置通知\n    @After(&quot;@annotation(com.itheima.anno.MyLog)&quot;)\n    public void after()&#123;\n        log.info(&quot;MyAspect6 -&gt; after ...&quot;);\n    &#125;\n&#125;重启SpringBoot服务，测试查询所有部门数据，查看控制台日志：\n\n到此我们两种常见的切入点表达式我已经介绍完了。\n\nexecution切入点表达式\n根据我们所指定的方法的描述信息来匹配切入点方法，这种方式也是最为常用的一种方式\n如果我们要匹配的切入点方法的方法名不规则，或者有一些比较特殊的需求，通过execution切入点表达式描述比较繁琐\n\n\nannotation 切入点表达式\n基于注解的方式来匹配切入点方法。这种方式虽然多一步操作，我们需要自定义一个注解，但是相对来比较灵活。我们需要匹配哪个方法，就在方法上加上对应的注解就可以了\n\n\n\n13.4 连接点讲解完了切入点表达式之后，接下来我们再来讲解最后一个部分连接点。我们前面在讲解AOP核心概念的时候，我们提到过什么是连接点，连接点可以简单理解为可以被AOP控制的方法。\n我们目标对象当中所有的方法是不是都是可以被AOP控制的方法。而在SpringAOP当中，连接点又特指方法的执行。\n在Spring中用JoinPoint抽象了连接点，用它可以获得方法执行时的相关信息，如目标类名、方法名、方法参数等。\n\n对于@Around通知，获取连接点信息只能使用ProceedingJoinPoint类型\n\n对于其他四种通知，获取连接点信息只能使用JoinPoint，它是ProceedingJoinPoint的父类型\n\n\n14.配置优先级在我们前面的课程当中，我们已经讲解了SpringBoot项目当中支持的三类配置文件：\n\napplication.properties\napplication.yml\napplication.yaml\n\n在SpringBoot项目当中，我们要想配置一个属性，可以通过这三种方式当中的任意一种来配置都可以，那么如果项目中同时存在这三种配置文件，且都配置了同一个属性，如：Tomcat端口号，到底哪一份配置文件生效呢？\n\napplication.properties\n\npropertiesserver.port=8081\napplication.yml\n\nyamlserver:\n   port: 8082\napplication.yaml\n\nyamlserver:\n   port: 8082我们启动SpringBoot程序，测试下三个配置文件中哪个Tomcat端口号生效：\n\nproperties、yaml、yml三种配置文件同时存在\n\n\n\n\n\n\n\n\n\n\n\nproperties、yaml、yml三种配置文件，优先级最高的是properties\n\nyaml、yml两种配置文件同时存在\n\n\n\n\n\n\n\n\n\n\n\n配置文件优先级排名（从高到低）：\n\nproperties配置文件\nyml配置文件\nyaml配置文件\n\n注意事项：虽然springboot支持多种格式配置文件，但是在项目开发时，推荐统一使用一种格式的配置。（yml是主流）\n在SpringBoot项目当中除了以上3种配置文件外，SpringBoot为了增强程序的扩展性，除了支持配置文件的配置方式以外，还支持另外两种常见的配置方式：\n\nJava系统属性配置 （格式： -Dkey&#x3D;value）\nshell-Dserver.port=9000\n命令行参数 （格式：–key&#x3D;value）\nshell--server.port=10010\n\n那在idea当中运行程序时，如何来指定Java系统属性和命令行参数呢？\n\n编辑启动程序的配置信息\n\n\n\n重启服务，同时配置Tomcat端口(三种配置文件、系统属性、命令行参数)，测试哪个Tomcat端口号生效：\n\n删除命令行参数配置，重启SpringBoot服务：\n\n\n\n\n\n\n\n\n\n\n优先级： 命令行参数 &gt;  系统属性参数 &gt; properties参数 &gt; yml参数 &gt; yaml参数\n思考：如果项目已经打包上线了，这个时候我们又如何来设置Java系统属性和命令行参数呢？\nshelljava -Dserver.port=9000 -jar XXXXX.jar --server.port=10010下面我们来演示下打包程序运行时指定Java系统属性和命令行参数：\n\n执行maven打包指令package，把项目打成jar文件\n使用命令：java -jar 方式运行jar文件程序\n\n项目打包：\n\n\n运行jar程序：\n\n同时设置Java系统属性和命令行参数\n\n\n\n仅设置Java系统属性\n\n\n\n\n\n\n\n\n\n\n\n注意事项：\n\nSpringboot项目进行打包时，需要引入插件 spring-boot-maven-plugin (基于官网骨架创建项目，会自动添加该插件)\n\n在SpringBoot项目当中，常见的属性配置方式有5种， 3种配置文件，加上2种外部属性的配置(Java系统属性、命令行参数)。通过以上的测试，我们也得出了优先级(从低到高)：\n\napplication.yaml（忽略）\napplication.yml\napplication.properties\njava系统属性（-Dxxx&#x3D;xxx）\n命令行参数（–xxx&#x3D;xxx）\n\n15.Bean管理15.1 获取Bean默认情况下，SpringBoot项目在启动的时候会自动的创建IOC容器(也称为Spring容器)，并且在启动的过程当中会自动的将bean对象都创建好，存放在IOC容器当中。应用程序在运行时需要依赖什么bean对象，就直接进行依赖注入就可以了。\n而在Spring容器中提供了一些方法，可以主动从IOC容器中获取到bean对象，下面介绍3种常用方式：\n\n根据name获取bean\njavaObject getBean(String name)\n根据类型获取bean\njava&lt;T&gt; T getBean(Class&lt;T&gt; requiredType)\n根据name获取bean（带类型转换）\njava&lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType)\n\n思考：要从IOC容器当中来获取到bean对象，需要先拿到IOC容器对象，怎么样才能拿到IOC容器呢？\n\n想获取到IOC容器，直接将IOC容器对象注入进来就可以了\n\n控制器：DeptController\njava@RestController\n@RequestMapping(&quot;/depts&quot;)\npublic class DeptController &#123;\n\n    @Autowired\n    private DeptService deptService;\n\n    public DeptController()&#123;\n        System.out.println(&quot;DeptController constructor ....&quot;);\n    &#125;\n\n    @GetMapping\n    public Result list()&#123;\n        List&lt;Dept&gt; deptList = deptService.list();\n        return Result.success(deptList);\n    &#125;\n\n    @DeleteMapping(&quot;/&#123;id&#125;&quot;)\n    public Result delete(@PathVariable Integer id)  &#123;\n        deptService.delete(id);\n        return Result.success();\n    &#125;\n\n    @PostMapping\n    public Result save(@RequestBody Dept dept)&#123;\n        deptService.save(dept);\n        return Result.success();\n    &#125;\n&#125;业务实现类：DeptServiceImpl\njava@Slf4j\n@Service\npublic class DeptServiceImpl implements DeptService &#123;\n    @Autowired\n    private DeptMapper deptMapper;\n\n    @Override\n    public List&lt;Dept&gt; list() &#123;\n        List&lt;Dept&gt; deptList = deptMapper.list();\n        return deptList;\n    &#125;\n\n    @Override\n    public void delete(Integer id) &#123;\n        deptMapper.delete(id);\n    &#125;\n\n    @Override\n    public void save(Dept dept) &#123;\n        dept.setCreateTime(LocalDateTime.now());\n        dept.setUpdateTime(LocalDateTime.now());\n        deptMapper.save(dept);\n    &#125;\n&#125;Mapper接口：\njava@Mapper\npublic interface DeptMapper &#123;\n    //查询全部部门数据\n    @Select(&quot;select * from dept&quot;)\n    List&lt;Dept&gt; list();\n\n    //删除部门\n    @Delete(&quot;delete from dept where id = #&#123;id&#125;&quot;)\n    void delete(Integer id);\n\n    //新增部门\n    @Insert(&quot;insert into dept(name, create_time, update_time) values (#&#123;name&#125;,#&#123;createTime&#125;,#&#123;updateTime&#125;)&quot;)\n    void save(Dept dept);\n&#125;\n测试类：\njava@SpringBootTest\nclass SpringbootWebConfig2ApplicationTests &#123;\n\n    @Autowired\n    private ApplicationContext applicationContext; //IOC容器对象\n\n    //获取bean对象\n    @Test\n    public void testGetBean()&#123;\n        //根据bean的名称获取\n        DeptController bean1 = (DeptController) applicationContext.getBean(&quot;deptController&quot;);\n        System.out.println(bean1);\n\n        //根据bean的类型获取\n        DeptController bean2 = applicationContext.getBean(DeptController.class);\n        System.out.println(bean2);\n\n        //根据bean的名称 及 类型获取\n        DeptController bean3 = applicationContext.getBean(&quot;deptController&quot;, DeptController.class);\n        System.out.println(bean3);\n    &#125;\n&#125;程序运行后控制台日志：\n\n\n\n\n\n\n\n\n\n\n问题：输出的bean对象地址值是一样的，说明IOC容器当中的bean对象有几个？\n答案：只有一个。        （默认情况下，IOC中的bean对象是单例）\n那么能不能将bean对象设置为非单例的(每次获取的bean都是一个新对象)？\n可以，在下一个知识点(bean作用域)中讲解。\n注意事项：\n\n上述所说的 【Spring项目启动时，会把其中的bean都创建好】还会受到作用域及延迟初始化影响，这里主要针对于默认的单例非延迟加载的bean而言。\n\n15.2 Bean作用域在前面我们提到的IOC容器当中，默认bean对象是单例模式(只有一个实例对象)。那么如何设置bean对象为非单例呢？需要设置bean的作用域。\n在Spring中支持五种作用域，后三种在web环境才生效：\n\n\n\n作用域\n说明\n\n\n\nsingleton\n容器内同名称的bean只有一个实例（单例）（默认）\n\n\nprototype\n每次使用该bean时会创建新的实例（非单例）\n\n\nrequest\n每个请求范围内会创建新的实例（web环境中，了解）\n\n\nsession\n每个会话范围内会创建新的实例（web环境中，了解）\n\n\napplication\n每个应用范围内会创建新的实例（web环境中，了解）\n\n\n知道了bean的5种作用域了，我们要怎么去设置一个bean的作用域呢？\n\n可以借助Spring中的@Scope注解来进行配置作用域\n\n\n1). 测试一\n\n控制器\n\njava//默认bean的作用域为：singleton (单例)\n@Lazy //延迟加载（第一次使用bean对象时，才会创建bean对象并交给ioc容器管理）\n@RestController\n@RequestMapping(&quot;/depts&quot;)\npublic class DeptController &#123;\n\n    @Autowired\n    private DeptService deptService;\n\n    public DeptController()&#123;\n        System.out.println(&quot;DeptController constructor ....&quot;);\n    &#125;\n\n    //省略其他代码...\n&#125;\n测试类\n\njava@SpringBootTest\nclass SpringbootWebConfig2ApplicationTests &#123;\n\n    @Autowired\n    private ApplicationContext applicationContext; //IOC容器对象\n\n    //bean的作用域\n    @Test\n    public void testScope()&#123;\n        for (int i = 0; i &lt; 10; i++) &#123;\n            DeptController deptController = applicationContext.getBean(DeptController.class);\n            System.out.println(deptController);\n        &#125;\n    &#125;\n&#125;重启SpringBoot服务，运行测试方法，查看控制台打印的日志：\n\n\n\n\n\n\n\n\n\n\n注意事项：\n\nIOC容器中的bean默认使用的作用域：singleton (单例)\n\n默认singleton的bean，在容器启动时被创建，可以使用@Lazy注解来延迟初始化(延迟到第一次使用时)\n\n\n2). 测试二\n修改控制器DeptController代码：\njava@Scope(&quot;prototype&quot;) //bean作用域为非单例\n@Lazy //延迟加载\n@RestController\n@RequestMapping(&quot;/depts&quot;)\npublic class DeptController &#123;\n\n    @Autowired\n    private DeptService deptService;\n\n    public DeptController()&#123;\n        System.out.println(&quot;DeptController constructor ....&quot;);\n    &#125;\n\n    //省略其他代码...\n&#125;重启SpringBoot服务，再次执行测试方法，查看控制吧打印的日志：\n\n\n\n\n\n\n\n\n\n\n注意事项：\n\nprototype的bean，每一次使用该bean的时候都会创建一个新的实例\n实际开发当中，绝大部分的Bean是单例的，也就是说绝大部分Bean不需要配置scope属性\n\n15.3 第三方Bean学习完bean的获取、bean的作用域之后，接下来我们再来学习第三方bean的配置。\n之前我们所配置的bean，像controller、service，dao三层体系下编写的类，这些类都是我们在项目当中自己定义的类(自定义类)。当我们要声明这些bean，也非常简单，我们只需要在类上加上@Component以及它的这三个衍生注解（@Controller、@Service、@Repository），就可以来声明这个bean对象了。但是在我们项目开发当中，还有一种情况就是这个类它不是我们自己编写的，而是我们引入的第三方依赖当中提供的。\n在pom.xml文件中，引入dom4j：\nxml&lt;!--Dom4j--&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.dom4j&lt;/groupId&gt;\n    &lt;artifactId&gt;dom4j&lt;/artifactId&gt;\n    &lt;version&gt;2.1.3&lt;/version&gt;\n&lt;/dependency&gt;\n\n\n\n\n\n\n\n\ndom4j就是第三方组织提供的。 dom4j中的SAXReader类就是第三方编写的。\n当我们需要使用到SAXReader对象时，直接进行依赖注入是不是就可以了呢？\n\n按照我们之前的做法，需要在SAXReader类上添加一个注解@Component（将当前类交给IOC容器管理）\n\n\n\n\n\n\n\n\n\n\n\n结论：第三方提供的类是只读的。无法在第三方类上添加@Component注解或衍生注解。\n那么我们应该怎样使用并定义第三方的bean呢？\n\n如果要管理的bean对象来自于第三方（不是自定义的），是无法用@Component 及衍生注解声明bean的，就需要用到**@Bean**注解。\n\n解决方案1：在启动类上添加@Bean标识的方法\njava@SpringBootApplication\npublic class SpringbootWebConfig2Application &#123;\n\n    public static void main(String[] args) &#123;\n        SpringApplication.run(SpringbootWebConfig2Application.class, args);\n    &#125;\n\n    //声明第三方bean\n    @Bean //将当前方法的返回值对象交给IOC容器管理, 成为IOC容器bean\n    public SAXReader saxReader()&#123;\n        return new SAXReader();\n    &#125;\n&#125;\nxml文件：\nxml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;emp&gt;\n    &lt;name&gt;Tom&lt;/name&gt;\n    &lt;age&gt;18&lt;/age&gt;\n&lt;/emp&gt;\n测试类：\njava@SpringBootTest\nclass SpringbootWebConfig2ApplicationTests &#123;\n\n    @Autowired\n    private SAXReader saxReader;\n\n    //第三方bean的管理\n    @Test\n    public void testThirdBean() throws Exception &#123;\n        Document document = saxReader.read(this.getClass().getClassLoader().getResource(&quot;1.xml&quot;));\n        Element rootElement = document.getRootElement();\n        String name = rootElement.element(&quot;name&quot;).getText();\n        String age = rootElement.element(&quot;age&quot;).getText();\n\n        System.out.println(name + &quot; : &quot; + age);\n    &#125;\n\n    //省略其他代码...\n&#125;\n重启SpringBoot服务，执行测试方法后，控制台输出日志：\ntxtTom : 18\n\n\n\n\n\n\n\n\n说明：以上在启动类中声明第三方Bean的作法，不建议使用（项目中要保证启动类的纯粹性）\n解决方案2：在配置类中定义@Bean标识的方法\n\n如果需要定义第三方Bean时， 通常会单独定义一个配置类\n\njava@Configuration //配置类  (在配置类当中对第三方bean进行集中的配置管理)\npublic class CommonConfig &#123;\n\n    //声明第三方bean\n    @Bean //将当前方法的返回值对象交给IOC容器管理, 成为IOC容器bean\n          //通过@Bean注解的name/value属性指定bean名称, 如果未指定, 默认是方法名\n    public SAXReader reader(DeptService deptService)&#123;\n        System.out.println(deptService);\n        return new SAXReader();\n    &#125;\n\n&#125;\n注释掉SpringBoot启动类中创建第三方bean对象的代码，重启服务，执行测试方法，查看控制台日志：\ntxtTom : 18在方法上加上一个@Bean注解，Spring 容器在启动的时候，它会自动的调用这个方法，并将方法的返回值声明为Spring容器当中的Bean对象。\n\n\n\n\n\n\n\n\n\n注意事项 ：\n\n通过@Bean注解的name或value属性可以声明bean的名称，如果不指定，默认bean的名称就是方法名。\n\n如果第三方bean需要依赖其它bean对象，直接在bean定义方法中设置形参即可，容器会根据类型自动装配。\n\n\n关于Bean大家只需要保持一个原则：\n\n如果是在项目当中我们自己定义的类，想将这些类交给IOC容器管理，我们直接使用@Component以及它的衍生注解来声明就可以。\n如果这个类它不是我们自己定义的，而是引入的第三方依赖当中提供的类，而且我们还想将这个类交给IOC容器管理。此时我们就需要在配置类中定义一个方法，在方法上加上一个@Bean注解，通过这种方式来声明第三方的bean对象。\n\n16.SpringBoot原理SpringBoot使我们能够集中精力地去关注业务功能的开发，而不用过多地关注框架本身的配置使用。而我们前面所讲解的都是面向应用层面的技术，接下来我们开始学习SpringBoot的原理，这部分内容偏向于底层的原理分析。\n在剖析SpringBoot的原理之前，我们先来快速回顾一下我们前面所讲解的Spring家族的框架。\n\nSpring是目前世界上最流行的Java框架，它可以帮助我们更加快速、更加容易的来构建Java项目。而在Spring家族当中提供了很多优秀的框架，而所有的框架都是基于一个基础框架的SpringFramework(也就是Spring框架)。而前面我们也提到，如果我们直接基于Spring框架进行项目的开发，会比较繁琐。\n这个繁琐主要体现在两个地方：\n\n在pom.xml中依赖配置比较繁琐，在项目开发时，需要自己去找到对应的依赖，还需要找到依赖它所配套的依赖以及对应版本，否则就会出现版本冲突问题。\n在使用Spring框架进行项目开发时，需要在Spring的配置文件中做大量的配置，这就造成Spring框架入门难度较大，学习成本较高。\n\n\n\n\n\n\n\n\n\n\n\n基于Spring存在的问题，官方在Spring框架4.0版本之后，又推出了一个全新的框架：SpringBoot。\n通过 SpringBoot来简化Spring框架的开发(是简化不是替代)。我们直接基于SpringBoot来构建Java项目，会让我们的项目开发更加简单，更加快捷。\nSpringBoot框架之所以使用起来更简单更快捷，是因为SpringBoot框架底层提供了两个非常重要的功能：一个是起步依赖，一个是自动配置。\n\n\n\n\n\n\n\n\n\n\n通过SpringBoot所提供的起步依赖，就可以大大的简化pom文件当中依赖的配置，从而解决了Spring框架当中依赖配置繁琐的问题。\n通过自动配置的功能就可以大大的简化框架在使用时bean的声明以及bean的配置。我们只需要引入程序开发时所需要的起步依赖，项目开发时所用到常见的配置都已经有了，我们直接使用就可以了。\n简单回顾之后，接下来我们来学习下SpringBoot的原理。其实学习SpringBoot的原理就是来解析SpringBoot当中的起步依赖与自动配置的原理。我们首先来学习SpringBoot当中起步依赖的原理。\n16.1 起步依赖假如我们没有使用SpringBoot，用的是Spring框架进行web程序的开发，此时我们就需要引入web程序开发所需要的一些依赖。\n\n\n\n\n\n\n\n\n\n\nspring-webmvc依赖：这是Spring框架进行web程序开发所需要的依赖\nservlet-api依赖：Servlet基础依赖\njackson-databind依赖：JSON处理工具包\n如果要使用AOP，还需要引入aop依赖、aspect依赖\n项目中所引入的这些依赖，还需要保证版本匹配，否则就可能会出现版本冲突问题。\n如果我们使用了SpringBoot，就不需要像上面这么繁琐的引入依赖了。我们只需要引入一个依赖就可以了，那就是web开发的起步依赖：springboot-starter-web。\n\n为什么我们只需要引入一个web开发的起步依赖，web开发所需要的所有的依赖都有了呢？\n\n因为Maven的依赖传递。\n\n\n\n\n\n\n\n\n\n\n\n在SpringBoot给我们提供的这些起步依赖当中，已提供了当前程序开发所需要的所有的常见依赖(官网地址：https://docs.spring.io/spring-boot/docs/2.7.7/reference/htmlsingle/#using.build-systems.starters)。\n\n比如：springboot-starter-web，这是web开发的起步依赖，在web开发的起步依赖当中，就集成了web开发中常见的依赖：json、web、webmvc、tomcat等。我们只需要引入这一个起步依赖，其他的依赖都会自动的通过Maven的依赖传递进来。\n\n\n结论：起步依赖的原理就是Maven的依赖传递。\n16.2 自动配置我们讲解了SpringBoot当中起步依赖的原理，就是Maven的依赖传递。接下来我们解析下自动配置的原理，我们要分析自动配置的原理，首先要知道什么是自动配置。\n16.2.1 概述SpringBoot的自动配置就是当Spring容器启动后，一些配置类、bean对象就自动存入到了IOC容器中，不需要我们手动去声明，从而简化了开发，省去了繁琐的配置操作。\n\n\n\n\n\n\n\n\n\n比如：我们要进行事务管理、要进行AOP程序的开发，此时就不需要我们再去手动的声明这些bean对象了，我们直接使用就可以从而大大的简化程序的开发，省去了繁琐的配置操作。\n下面我们打开idea，一起来看下自动配置的效果：\n\n运行SpringBoot启动类\n\n\n\n\n大家会看到有两个CommonConfig，在第一个CommonConfig类中定义了一个bean对象，bean对象的名字叫reader。\n在第二个CommonConfig中它的bean名字叫commonConfig，为什么还会有这样一个bean对象呢？原因是在CommonConfig配置类上添加了一个注解@Configuration，而@Configuration底层就是@Component\n\n\n\n\n\n\n\n\n\n\n所以配置类最终也是SpringIOC容器当中的一个bean对象\n在IOC容器中除了我们自己定义的bean以外，还有很多配置类，这些配置类都是SpringBoot在启动的时候加载进来的配置类。这些配置类加载进来之后，它也会生成很多的bean对象。\n\n\n\n\n\n\n\n\n\n\n比如：配置类GsonAutoConfiguration里面有一个bean，bean的名字叫gson，它的类型是Gson。 \ncom.google.gson.Gson是谷歌包中提供的用来处理JSON格式数据的。\n当我们想要使用这些配置类中生成的bean对象时，可以使用@Autowired就自动注入了：\njavaimport com.google.gson.Gson;\nimport com.itheima.pojo.Result;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.context.SpringBootTest;\n\n@SpringBootTest\npublic class AutoConfigurationTests &#123;\n\n    @Autowired\n    private Gson gson;\n\n\n    @Test\n    public void testJson()&#123;\n        String json = gson.toJson(Result.success());\n        System.out.println(json);\n    &#125;\n&#125;添加断点，使用debug模式运行测试类程序：\n\n问题：在当前项目中我们并没有声明谷歌提供的Gson这么一个bean对象，然后我们却可以通过@Autowired从Spring容器中注入bean对象，那么这个bean对象怎么来的？\n答案：SpringBoot项目在启动时通过自动配置完成了bean对象的创建。\n体验了SpringBoot的自动配置了，下面我们就来分析自动配置的原理。其实分析自动配置原理就是来解析在SpringBoot项目中，在引入依赖之后是如何将依赖jar包当中所定义的配置类以及bean加载到SpringIOC容器中的。\n16.2.2 常见方案我们知道了什么是自动配置之后，接下来我们就要来剖析自动配置的原理。解析自动配置的原理就是分析在 SpringBoot项目当中，我们引入对应的依赖之后，是如何将依赖jar包当中所提供的bean以及配置类直接加载到当前项目的SpringIOC容器当中的。\n接下来，我们就直接通过代码来分析自动配置原理。\n\n\n\n\n\n\n\n\n\n准备工作：在Idea中导入”资料\\03. 自动配置原理”下的itheima-utils工程\n1、在SpringBoot项目 spring-boot-web-config2 工程中，通过坐标引入itheima-utils依赖\n\njava@Component\npublic class TokenParser &#123;\n    public void parse()&#123;\n        System.out.println(&quot;TokenParser ... parse ...&quot;);\n    &#125;\n&#125;2、在测试类中，添加测试方法\njava@SpringBootTest\npublic class AutoConfigurationTests &#123;\n\n    @Autowired\n    private ApplicationContext applicationContext;\n\n\n    @Test\n    public void testTokenParse()&#123;\n        System.out.println(applicationContext.getBean(TokenParser.class));\n    &#125;\n\n    //省略其他代码...\n&#125;3、执行测试方法\n\n\n\n\n\n\n\n\n\n\n异常信息描述： 没有com.example.TokenParse类型的bean\n说明：在Spring容器中没有找到com.example.TokenParse类型的bean对象\n思考：引入进来的第三方依赖当中的bean以及配置类为什么没有生效？\n\n原因在我们之前讲解IOC的时候有提到过，在类上添加@Component注解来声明bean对象时，还需要保证@Component注解能被Spring的组件扫描到。\nSpringBoot项目中的@SpringBootApplication注解，具有包扫描的作用，但是它只会扫描启动类所在的当前包以及子包。 \n当前包：com.itheima， 第三方依赖中提供的包：com.example（扫描不到）\n\n那么如何解决以上问题的呢？\n\n方案1：@ComponentScan 组件扫描\n方案2：@Import 导入（使用@Import导入的类会被Spring加载到IOC容器中）\n\n@ComponentScan组件扫描\njava@SpringBootApplication\n@ComponentScan(&#123;&quot;com.itheima&quot;,&quot;com.example&quot;&#125;) //指定要扫描的包\npublic class SpringbootWebConfig2Application &#123;\n    public static void main(String[] args) &#123;\n        SpringApplication.run(SpringbootWebConfig2Application.class, args);\n    &#125;\n&#125;\n重新执行测试方法，控制台日志输出：\n\n\n\n\n\n\n\n\n\n\n大家可以想象一下，如果采用以上这种方式来完成自动配置，那我们进行项目开发时，当需要引入大量的第三方的依赖，就需要在启动类上配置N多要扫描的包，这种方式会很繁琐。而且这种大面积的扫描性能也比较低。\n缺点：\n\n使用繁琐\n性能低\n\n结论：SpringBoot中并没有采用以上这种方案。\n@Import导入\n\n导入形式主要有以下几种：\n导入普通类\n导入配置类\n导入ImportSelector接口实现类\n\n\n\n1). 使用@Import导入普通类：\njava@Import(TokenParser.class) //导入的类会被Spring加载到IOC容器中\n@SpringBootApplication\npublic class SpringbootWebConfig2Application &#123;\n    public static void main(String[] args) &#123;\n        SpringApplication.run(SpringbootWebConfig2Application.class, args);\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n重新执行测试方法，控制台日志输出：\n\n2). 使用@Import导入配置类：\n\n配置类\n\njava@Configuration\npublic class HeaderConfig &#123;\n    @Bean\n    public HeaderParser headerParser()&#123;\n        return new HeaderParser();\n    &#125;\n\n    @Bean\n    public HeaderGenerator headerGenerator()&#123;\n        return new HeaderGenerator();\n    &#125;\n&#125;\n启动类\n\njava@Import(HeaderConfig.class) //导入配置类\n@SpringBootApplication\npublic class SpringbootWebConfig2Application &#123;\n    public static void main(String[] args) &#123;\n        SpringApplication.run(SpringbootWebConfig2Application.class, args);\n    &#125;\n&#125;\n测试类\n\njava@SpringBootTest\npublic class AutoConfigurationTests &#123;\n    @Autowired\n    private ApplicationContext applicationContext;\n\n    @Test\n    public void testHeaderParser()&#123;\n        System.out.println(applicationContext.getBean(HeaderParser.class));\n    &#125;\n\n    @Test\n    public void testHeaderGenerator()&#123;\n        System.out.println(applicationContext.getBean(HeaderGenerator.class));\n    &#125;\n    \n    //省略其他代码...\n&#125;\n\n\n\n\n\n\n\n\n执行测试方法：\n\n3). 使用@Import导入ImportSelector接口实现类：\n\nImportSelector接口实现类\n\njavapublic class MyImportSelector implements ImportSelector &#123;\n    public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123;\n        //返回值字符串数组（数组中封装了全限定名称的类）\n        return new String[]&#123;&quot;com.example.HeaderConfig&quot;&#125;;\n    &#125;\n&#125;\n启动类\n\njava@Import(MyImportSelector.class) //导入ImportSelector接口实现类\n@SpringBootApplication\npublic class SpringbootWebConfig2Application &#123;\n\n    public static void main(String[] args) &#123;\n        SpringApplication.run(SpringbootWebConfig2Application.class, args);\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n执行测试方法：\n\n我们使用@Import注解通过这三种方式都可以导入第三方依赖中所提供的bean或者是配置类。\n思考：如果基于以上方式完成自动配置，当要引入一个第三方依赖时，是不是还要知道第三方依赖中有哪些配置类和哪些Bean对象？\n\n答案：是的。 （对程序员来讲，很不友好，而且比较繁琐）\n\n思考：当我们要使用第三方依赖，依赖中到底有哪些bean和配置类，谁最清楚？\n\n答案：第三方依赖自身最清楚。\n\n\n\n\n\n\n\n\n\n\n结论：我们不用自己指定要导入哪些bean对象和配置类了，让第三方依赖它自己来指定。\n怎么让第三方依赖自己指定bean对象和配置类？\n\n比较常见的方案就是第三方依赖给我们提供一个注解，这个注解一般都以@EnableXxxx开头的注解，注解中封装的就是@Import注解\n\n4). 使用第三方依赖提供的 @EnableXxxxx注解\n\n第三方依赖中提供的注解\n\njava@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.TYPE)\n@Import(MyImportSelector.class)//指定要导入哪些bean对象或配置类\npublic @interface EnableHeaderConfig &#123; \n&#125;\n在使用时只需在启动类上加上@EnableXxxxx注解即可\n\njava@EnableHeaderConfig  //使用第三方依赖提供的Enable开头的注解\n@SpringBootApplication\npublic class SpringbootWebConfig2Application &#123;\n    public static void main(String[] args) &#123;\n        SpringApplication.run(SpringbootWebConfig2Application.class, args);\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n执行测试方法：\n\n以上四种方式都可以完成导入操作，但是第4种方式会更方便更优雅，而这种方式也是SpringBoot当中所采用的方式。\n16.2.3 原理分析前面我们讲解了在项目当中引入第三方依赖之后，如何加载第三方依赖中定义好的bean对象以及配置类，从而完成自动配置操作。那下面我们通过源码跟踪的形式来剖析下SpringBoot底层到底是如何完成自动配置的。\n\n\n\n\n\n\n\n\n\n源码跟踪技巧：\n在跟踪框架源码的时候，一定要抓住关键点，找到核心流程。一定不要从头到尾一行代码去看，一个方法的去研究，一定要找到关键流程，抓住关键点，先在宏观上对整个流程或者整个原理有一个认识，有精力再去研究其中的细节。\n要搞清楚SpringBoot的自动配置原理，要从SpringBoot启动类上使用的核心注解@SpringBootApplication开始分析：\n\n在@SpringBootApplication注解中包含了：\n\n元注解（不再解释）\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan\n\n我们先来看第一个注解：@SpringBootConfiguration\n\n\n\n\n\n\n\n\n\n\n@SpringBootConfiguration注解上使用了@Configuration，表明SpringBoot启动类就是一个配置类。\n@Indexed注解，是用来加速应用启动的（不用关心）。\n接下来再先看@ComponentScan注解：\n\n\n\n\n\n\n\n\n\n\n@ComponentScan注解是用来进行组件扫描的，扫描启动类所在的包及其子包下所有被@Component及其衍生注解声明的类。\nSpringBoot启动类，之所以具备扫描包功能，就是因为包含了@ComponentScan注解。\n最后我们来看看@EnableAutoConfiguration注解（自动配置核心注解）：\n\n\n\n\n\n\n\n\n\n\n使用@Import注解，导入了实现ImportSelector接口的实现类。\nAutoConfigurationImportSelector类是ImportSelector接口的实现类。\n\nAutoConfigurationImportSelector类中重写了ImportSelector接口的selectImports()方法：\n\n\n\n\n\n\n\n\n\n\nselectImports()方法底层调用getAutoConfigurationEntry()方法，获取可自动配置的配置类信息集合\n\n\n\n\n\n\n\n\n\n\ngetAutoConfigurationEntry()方法通过调用getCandidateConfigurations(annotationMetadata, attributes)方法获取在配置文件中配置的所有自动配置类的集合\n\n\n\n\n\n\n\n\n\n\ngetCandidateConfigurations方法的功能：\n获取所有基于META-INF&#x2F;spring&#x2F;org.springframework.boot.autoconfigure.AutoConfiguration.imports文件、META-INF&#x2F;spring.factories文件中配置类的集合\nMETA-INF&#x2F;spring&#x2F;org.springframework.boot.autoconfigure.AutoConfiguration.imports文件和META-INF&#x2F;spring.factories文件这两个文件在哪里呢？\n\n通常在引入的起步依赖中，都有包含以上两个文件\n\n \n\n在前面在给大家演示自动配置的时候，我们直接在测试类当中注入了一个叫gson的bean对象，进行JSON格式转换。虽然我们没有配置bean对象，但是我们是可以直接注入使用的。原因就是因为在自动配置类当中做了自动配置。到底是在哪个自动配置类当中做的自动配置呢？我们通过搜索来查询一下。\n在META-INF&#x2F;spring&#x2F;org.springframework.boot.autoconfigure.AutoConfiguration.imports配置文件中指定了第三方依赖Gson的配置类：GsonAutoConfiguration\n\n第三方依赖中提供的GsonAutoConfiguration类：\n\n\n\n\n\n\n\n\n\n\n在GsonAutoConfiguration类上，添加了注解@AutoConfiguration，通过查看源码，可以明确：GsonAutoConfiguration类是一个配置。\n\n看到这里，大家就应该明白为什么可以完成自动配置了，原理就是在配置类中定义一个@Bean标识的方法，而Spring会自动调用配置类中使用@Bean标识的方法，并把方法的返回值注册到IOC容器中。\n自动配置源码小结\n自动配置原理源码入口就是@SpringBootApplication注解，在这个注解中封装了3个注解，分别是：\n\n@SpringBootConfiguration\n声明当前类是一个配置类\n\n\n@ComponentScan\n进行组件扫描（SpringBoot中默认扫描的是启动类所在的当前包及其子包）\n\n\n@EnableAutoConfiguration\n封装了@Import注解（Import注解中指定了一个ImportSelector接口的实现类）\n在实现类重写的selectImports()方法，读取当前项目下所有依赖jar包中META-INF&#x2F;spring.factories、META-INF&#x2F;spring&#x2F;org.springframework.boot.autoconfigure.AutoConfiguration.imports两个文件里面定义的配置类（配置类中定义了@Bean注解标识的方法）。\n\n\n\n\n\n当SpringBoot程序启动时，就会加载配置文件当中所定义的配置类，并将这些配置类信息(类的全限定名)封装到String类型的数组中，最终通过@Import注解将这些配置类全部加载到Spring的IOC容器中，交给IOC容器管理。\n\n\n\n\n\n\n\n\n\n最后呢给大家抛出一个问题：在META-INF&#x2F;spring&#x2F;org.springframework.boot.autoconfigure.AutoConfiguration.imports文件中定义的配置类非常多，而且每个配置类中又可以定义很多的bean，那这些bean都会注册到Spring的IOC容器中吗？\n答案：并不是。 在声明bean对象时，上面有加一个以@Conditional开头的注解，这种注解的作用就是按照条件进行装配，只有满足条件之后，才会将bean注册到Spring的IOC容器中（下面会详细来讲解）\n我们在跟踪SpringBoot自动配置的源码的时候，在自动配置类声明bean的时候，除了在方法上加了一个@Bean注解以外，还会经常用到一个注解，就是以Conditional开头的这一类的注解。以Conditional开头的这些注解都是条件装配的注解。下面我们就来介绍下条件装配注解。\n@Conditional注解：\n\n作用：按照一定的条件进行判断，在满足给定条件后才会注册对应的bean对象到Spring的IOC容器中。\n位置：方法、类\n@Conditional本身是一个父注解，派生出大量的子注解：\n@ConditionalOnClass：判断环境中有对应字节码文件，才注册bean到IOC容器。\n@ConditionalOnMissingBean：判断环境中没有对应的bean(类型或名称)，才注册bean到IOC容器。\n@ConditionalOnProperty：判断配置文件中有对应属性和值，才注册bean到IOC容器。\n\n\n\n下面我们通过代码来演示下Conditional注解的使用：\n\n@ConditionalOnClass注解\n\njava@Configuration\npublic class HeaderConfig &#123;\n\n    @Bean\n    @ConditionalOnClass(name=&quot;io.jsonwebtoken.Jwts&quot;)//环境中存在指定的这个类，才会将该bean加入IOC容器\n    public HeaderParser headerParser()&#123;\n        return new HeaderParser();\n    &#125;\n    \n    //省略其他代码...\n&#125;\npom.xml\n\njava&lt;!--JWT令牌--&gt;\n&lt;dependency&gt;\n     &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;\n     &lt;artifactId&gt;jjwt&lt;/artifactId&gt;\n     &lt;version&gt;0.9.1&lt;/version&gt;\n&lt;/dependency&gt;\n测试类\n\njava@SpringBootTest\npublic class AutoConfigurationTests &#123;\n    @Autowired\n    private ApplicationContext applicationContext;\n\n    @Test\n    public void testHeaderParser()&#123;\n        System.out.println(applicationContext.getBean(HeaderParser.class));\n    &#125;\n    \n    //省略其他代码...\n&#125;\n\n\n\n\n\n\n\n\n执行testHeaderParser()测试方法：\n\n因为io.jsonwebtoken.Jwts字节码文件在启动SpringBoot程序时已存在，所以创建HeaderParser对象并注册到IOC容器中。\n\n@ConditionalOnMissingBean注解\n\njava@Configuration\npublic class HeaderConfig &#123;\n\n    @Bean\n    @ConditionalOnMissingBean //不存在该类型的bean，才会将该bean加入IOC容器\n    public HeaderParser headerParser()&#123;\n        return new HeaderParser();\n    &#125;\n    \n    //省略其他代码...\n&#125;\n\n\n\n\n\n\n\n\n执行testHeaderParser()测试方法：\n\nSpringBoot在调用@Bean标识的headerParser()前，IOC容器中是没有HeaderParser类型的bean，所以HeaderParser对象正常创建，并注册到IOC容器中。\n再次修改@ConditionalOnMissingBean注解：\njava@Configuration\npublic class HeaderConfig &#123;\n\n    @Bean\n    @ConditionalOnMissingBean(name=&quot;deptController2&quot;)//不存在指定名称的bean，才会将该bean加入IOC容器\n    public HeaderParser headerParser()&#123;\n        return new HeaderParser();\n    &#125;\n    \n    //省略其他代码...\n&#125;\n\n\n\n\n\n\n\n\n执行testHeaderParser()测试方法：\n\n因为在SpringBoot环境中不存在名字叫deptController2的bean对象，所以创建HeaderParser对象并注册到IOC容器中。\n再次修改@ConditionalOnMissingBean注解：\njava@Configuration\npublic class HeaderConfig &#123;\n\n    @Bean\n    @ConditionalOnMissingBean(HeaderConfig.class)//不存在指定类型的bean，才会将bean加入IOC容器\n    public HeaderParser headerParser()&#123;\n        return new HeaderParser();\n    &#125;\n    \n    //省略其他代码...\n&#125;java@SpringBootTest\npublic class AutoConfigurationTests &#123;\n    @Autowired\n    private ApplicationContext applicationContext;\n\n    @Test\n    public void testHeaderParser()&#123;\n        System.out.println(applicationContext.getBean(HeaderParser.class));\n    &#125;\n    \n    //省略其他代码...\n&#125;\n\n\n\n\n\n\n\n\n执行testHeaderParser()测试方法：\n\n因为HeaderConfig类中添加@Configuration注解，而@Configuration注解中包含了@Component，所以SpringBoot启动时会创建HeaderConfig类对象，并注册到IOC容器中。\n当IOC容器中有HeaderConfig类型的bean存在时，不会把创建HeaderParser对象注册到IOC容器中。而IOC容器中没有HeaderParser类型的对象时，通过getBean(HeaderParser.class)方法获取bean对象时，引发异常：NoSuchBeanDefinitionException\n\n@ConditionalOnProperty注解（这个注解和配置文件当中配置的属性有关系）\n\n先在application.yml配置文件中添加如下的键值对：\nyamlname: itheima在声明bean的时候就可以指定一个条件@ConditionalOnProperty\njava@Configuration\npublic class HeaderConfig &#123;\n\n    @Bean\n    @ConditionalOnProperty(name =&quot;name&quot;,havingValue = &quot;itheima&quot;)//配置文件中存在指定属性名与值，才会将bean加入IOC容器\n    public HeaderParser headerParser()&#123;\n        return new HeaderParser();\n    &#125;\n\n    @Bean\n    public HeaderGenerator headerGenerator()&#123;\n        return new HeaderGenerator();\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n执行testHeaderParser()测试方法：\n\n修改@ConditionalOnProperty注解：  havingValue的值修改为”itheima2”\njava@Bean\n@ConditionalOnProperty(name =&quot;name&quot;,havingValue = &quot;itheima2&quot;)//配置文件中存在指定属性名与值，才会将bean加入IOC容器\npublic HeaderParser headerParser()&#123;\n        return new HeaderParser();\n&#125;\n\n\n\n\n\n\n\n\n再次执行testHeaderParser()测试方法：\n\n因为application.yml配置文件中，不存在： name:  itheima2，所以HeaderParser对象在IOC容器中不存在\n我们再回头看看之前讲解SpringBoot源码时提到的一个配置类：GsonAutoConfiguration\n\n最后再给大家梳理一下自动配置原理：\n\n\n\n\n\n\n\n\n\n\n自动配置的核心就在@SpringBootApplication注解上，SpringBootApplication这个注解底层包含了3个注解，分别是：\n\n@SpringBootConfiguration\n\n@ComponentScan\n\n@EnableAutoConfiguration\n\n\n@EnableAutoConfiguration这个注解才是自动配置的核心。\n\n它封装了一个@Import注解，Import注解里面指定了一个ImportSelector接口的实现类。\n在这个实现类中，重写了ImportSelector接口中的selectImports()方法。\n而selectImports()方法中会去读取两份配置文件，并将配置文件中定义的配置类做为selectImports()方法的返回值返回，返回值代表的就是需要将哪些类交给Spring的IOC容器进行管理。\n那么所有自动配置类的中声明的bean都会加载到Spring的IOC容器中吗? 其实并不会，因为这些配置类中在声明bean时，通常都会添加@Conditional开头的注解，这个注解就是进行条件装配。而Spring会根据Conditional注解有选择性的进行bean的创建。\n@Enable 开头的注解底层，它就封装了一个注解 import 注解，它里面指定了一个类，是 ImportSelector 接口的实现类。在实现类当中，我们需要去实现 ImportSelector  接口当中的一个方法 selectImports 这个方法。这个方法的返回值代表的就是我需要将哪些类交给 spring 的 IOC容器进行管理。\n此时它会去读取两份配置文件，一份儿是 spring.factories，另外一份儿是 autoConfiguration.imports。而在  autoConfiguration.imports 这份儿文件当中，它就会去配置大量的自动配置的类。\n而前面我们也提到过这些所有的自动配置类当中，所有的 bean都会加载到 spring 的 IOC 容器当中吗？其实并不会，因为这些配置类当中，在声明 bean 的时候，通常会加上这么一类@Conditional 开头的注解。这个注解就是进行条件装配。所以SpringBoot非常的智能，它会根据 @Conditional 注解来进行条件装配。只有条件成立，它才会声明这个bean，才会将这个 bean 交给 IOC 容器管理。\n\n17.总结web后端开发现在基本上都是基于标准的三层架构进行开发的，在三层架构当中，Controller控制器层负责接收请求响应数据，Service业务层负责具体的业务逻辑处理，而Dao数据访问层也叫持久层，就是用来处理数据访问操作的，来完成数据库当中数据的增删改查操作。\n\n\n\n\n\n\n\n\n\n\n在三层架构当中，前端发起请求首先会到达Controller(不进行逻辑处理)，然后Controller会直接调用Service 进行逻辑处理， Service再调用Dao完成数据访问操作。\n如果我们在执行具体的业务处理之前，需要去做一些通用的业务处理，比如：我们要进行统一的登录校验，我们要进行统一的字符编码等这些操作时，我们就可以借助于Javaweb当中三大组件之一的过滤器Filter或者是Spring当中提供的拦截器Interceptor来实现。\n\n而为了实现三层架构层与层之间的解耦，我们学习了Spring框架当中的第一大核心：IOC控制反转与DI依赖注入。\n\n\n\n\n\n\n\n\n\n所谓控制反转，指的是将对象创建的控制权由应用程序自身交给外部容器，这个容器就是我们常说的IOC容器或Spring容器。\n而DI依赖注入指的是容器为程序提供运行时所需要的资源。\n除了IOC与DI我们还讲到了AOP面向切面编程，还有Spring中的事务管理、全局异常处理器，以及传递会话技术Cookie、Session以及新的会话跟踪解决方案JWT令牌，阿里云OSS对象存储服务，以及通过Mybatis持久层架构操作数据库等技术。\n\n我们在学习这些web后端开发技术的时候，我们都是基于主流的SpringBoot进行整合使用的。而SpringBoot又是用来简化开发，提高开发效率的。像过滤器、拦截器、IOC、DI、AOP、事务管理等这些技术到底是哪个框架提供的核心功能？\n\n\n\n\n\n\n\n\n\n\nFilter过滤器、Cookie、 Session这些都是传统的JavaWeb提供的技术。\nJWT令牌、阿里云OSS对象存储服务，是现在企业项目中常见的一些解决方案。\nIOC控制反转、DI依赖注入、AOP面向切面编程、事务管理、全局异常处理、拦截器等，这些技术都是 Spring Framework框架当中提供的核心功能。\nMybatis就是一个持久层的框架，是用来操作数据库的。\n在Spring框架的生态中，对web程序开发提供了很好的支持，如：全局异常处理器、拦截器这些都是Spring框架中web开发模块所提供的功能，而Spring框架的web开发模块，我们也称为：SpringMVC\n\n\n\n\n\n\n\n\n\n\nSpringMVC不是一个单独的框架，它是Spring框架的一部分，是Spring框架中的web开发模块，是用来简化原始的Servlet程序开发的。\n外界俗称的SSM，就是由：SpringMVC、Spring Framework、Mybatis三块组成。\n基于传统的SSM框架进行整合开发项目会比较繁琐，而且效率也比较低，所以在现在的企业项目开发当中，基本上都是直接基于SpringBoot整合SSM进行项目开发的。\n","slug":"Springboot学习3","date":"2024-02-11T09:42:12.000Z","categories_index":"Study","tags_index":"Java,SpringBoot","author_index":"Fioransh"},{"id":"6fe80b8a56f4931be3320509dc26530d","title":"SpringBoot知识点总结（二）","content":"9.登录校验9.1 问题分析我们已经完成了基础登录功能的开发与测试，在我们登录成功后就可以进入到后台管理系统中进行数据的操作。\n但是当我们在浏览器中新的页面上输入地址：http://localhost:9528/#/system/dept，发现没有登录仍然可以进入到后端管理系统页面。\n\n而真正的登录功能应该是：登陆后才能访问后端系统页面，不登陆则跳转登陆页面进行登陆。\n为什么会出现这个问题？其实原因很简单，就是因为针对于我们当前所开发的部门管理、员工管理以及文件上传等相关接口来说，我们在服务器端并没有做任何的判断，没有去判断用户是否登录了。所以无论用户是否登录，都可以访问部门管理以及员工管理的相关数据。所以我们目前所开发的登录功能，它只是徒有其表。而我们要想解决这个问题，我们就需要完成一步非常重要的操作：登录校验。\n\n什么是登录校验？\n\n所谓登录校验，指的是我们在服务器端接收到浏览器发送过来的请求之后，首先我们要对请求进行校验。先要校验一下用户登录了没有，如果用户已经登录了，就直接执行对应的业务操作就可以了；如果用户没有登录，此时就不允许他执行相关的业务操作，直接给前端响应一个错误的结果，最终跳转到登录页面，要求他登录成功之后，再来访问对应的数据。\n\n了解完什么是登录校验之后，接下来我们分析一下登录校验大概的实现思路。\n首先我们在宏观上先有一个认知：\n前面在讲解HTTP协议的时候，我们提到HTTP协议是无状态协议。什么又是无状态的协议？\n所谓无状态，指的是每一次请求都是独立的，下一次请求并不会携带上一次请求的数据。而浏览器与服务器之间进行交互，基于HTTP协议也就意味着现在我们通过浏览器来访问了登陆这个接口，实现了登陆的操作，接下来我们在执行其他业务操作时，服务器也并不知道这个员工到底登陆了没有。因为HTTP协议是无状态的，两次请求之间是独立的，所以是无法判断这个员工到底登陆了没有。\n\n那应该怎么来实现登录校验的操作呢？具体的实现思路可以分为两部分：\n\n在员工登录成功后，需要将用户登录成功的信息存起来，记录用户已经登录成功的标记。\n在浏览器发起请求时，需要在服务端进行统一拦截，拦截后进行登录校验。\n\n\n\n\n\n\n\n\n\n\n想要判断员工是否已经登录，我们需要在员工登录成功之后，存储一个登录成功的标记，接下来在每一个接口方法执行之前，先做一个条件判断，判断一下这个员工到底登录了没有。如果是登录了，就可以执行正常的业务操作，如果没有登录，会直接给前端返回一个错误的信息，前端拿到这个错误信息之后会自动的跳转到登录页面。\n我们程序中所开发的查询功能、删除功能、添加功能、修改功能，都需要使用以上套路进行登录校验。此时就会出现：相同代码逻辑，每个功能都需要编写，就会造成代码非常繁琐。\n为了简化这块操作，我们可以使用一种技术：统一拦截技术。\n通过统一拦截的技术，我们可以来拦截浏览器发送过来的所有的请求，拦截到这个请求之后，就可以通过请求来获取之前所存入的登录标记，在获取到登录标记且标记为登录成功，就说明员工已经登录了。如果已经登录，我们就直接放行(意思就是可以访问正常的业务接口了)。\n我们要完成以上操作，会涉及到web开发中的两个技术：\n\n会话技术\n统一拦截技术\n\n而统一拦截技术现实方案也有两种：\n\nServlet规范中的Filter过滤器\nSpring提供的interceptor拦截器\n\n下面我们先学习会话技术，然后再学习统一拦截技术。\n9.2 会话技术9.2.1 会话技术介绍什么是会话？\n\n在我们日常生活当中，会话指的就是谈话、交谈。\n\n在web开发当中，会话指的就是浏览器与服务器之间的一次连接，我们就称为一次会话。\n\n\n\n\n\n\n\n\n\n在用户打开浏览器第一次访问服务器的时候，这个会话就建立了，直到有任何一方断开连接，此时会话就结束了。在一次会话当中，是可以包含多次请求和响应的。\n比如：打开了浏览器来访问web服务器上的资源（浏览器不能关闭、服务器不能断开）\n\n第1次：访问的是登录的接口，完成登录操作\n第2次：访问的是部门管理接口，查询所有部门数据\n第3次：访问的是员工管理接口，查询员工数据\n\n只要浏览器和服务器都没有关闭，以上3次请求都属于一次会话当中完成的。\n\n\n\n需要注意的是：会话是和浏览器关联的，当有三个浏览器客户端和服务器建立了连接时，就会有三个会话。同一个浏览器在未关闭之前请求了多次服务器，这多次请求是属于同一个会话。比如：1、2、3这三个请求都是属于同一个会话。当我们关闭浏览器之后，这次会话就结束了。而如果我们是直接把web服务器关了，那么所有的会话就都结束了。\n知道了会话的概念了，接下来我们再来了解下会话跟踪。\n会话跟踪：一种维护浏览器状态的方法，服务器需要识别多次请求是否来自于同一浏览器，以便在同一次会话的多次请求间共享数据。\n\n\n\n\n\n\n\n\n\n服务器会接收很多的请求，但是服务器是需要识别出这些请求是不是同一个浏览器发出来的。比如：1和2这两个请求是不是同一个浏览器发出来的，3和5这两个请求不是同一个浏览器发出来的。如果是同一个浏览器发出来的，就说明是同一个会话。如果是不同的浏览器发出来的，就说明是不同的会话。而识别多次请求是否来自于同一浏览器的过程，我们就称为会话跟踪。\n我们使用会话跟踪技术就是要完成在同一个会话中，多个请求之间进行共享数据。\n\n\n\n\n\n\n\n\n\n为什么要共享数据呢？\n由于HTTP是无状态协议，在后面请求中怎么拿到前一次请求生成的数据呢？此时就需要在一次会话的多次请求之间进行数据共享\n会话跟踪技术有两种：\n\nCookie（客户端会话跟踪技术）\n数据存储在客户端浏览器当中\n\n\nSession（服务端会话跟踪技术）\n数据存储在储在服务端\n\n\n令牌技术\n\n9.2.2 会话跟踪方案-Cookiecookie 是客户端会话跟踪技术，它是存储在客户端浏览器的，我们使用 cookie 来跟踪会话，我们就可以在浏览器第一次发起请求来请求服务器的时候，我们在服务器端来设置一个cookie。\n比如第一次请求了登录接口，登录接口执行完成之后，我们就可以设置一个cookie，在 cookie 当中我们就可以来存储用户相关的一些数据信息。比如我可以在 cookie 当中来存储当前登录用户的用户名，用户的ID。\n服务器端在给客户端在响应数据的时候，会自动的将 cookie 响应给浏览器，浏览器接收到响应回来的 cookie 之后，会自动的将 cookie 的值存储在浏览器本地。接下来在后续的每一次请求当中，都会将浏览器本地所存储的 cookie 自动地携带到服务端。\n \n接下来在服务端我们就可以获取到 cookie 的值。我们可以去判断一下这个 cookie 的值是否存在，如果不存在这个cookie，就说明客户端之前是没有访问登录接口的；如果存在 cookie 的值，就说明客户端之前已经登录完成了。这样我们就可以基于 cookie 在同一次会话的不同请求之间来共享数据。\n我刚才在介绍流程的时候，用了 3 个自动：\n\n服务器会 自动 的将 cookie 响应给浏览器。\n\n浏览器接收到响应回来的数据之后，会 自动 的将 cookie 存储在浏览器本地。\n\n在后续的请求当中，浏览器会 自动 的将 cookie 携带到服务器端。\n\n\n为什么这一切都是自动化进行的？\n是因为 cookie 它是 HTP 协议当中所支持的技术，而各大浏览器厂商都支持了这一标准。在 HTTP 协议官方给我们提供了一个响应头和请求头：\n\n响应头 Set-Cookie ：设置Cookie数据的\n\n请求头 Cookie：携带Cookie数据的\n\n\n \n代码测试\njava@Slf4j\n@RestController\npublic class SessionController &#123;\n\n    //设置Cookie\n    @GetMapping(&quot;/c1&quot;)\n    public Result cookie1(HttpServletResponse response)&#123;\n        response.addCookie(new Cookie(&quot;login_username&quot;,&quot;itheima&quot;)); //设置Cookie/响应Cookie\n        return Result.success();\n    &#125;\n    \n    //获取Cookie\n    @GetMapping(&quot;/c2&quot;)\n    public Result cookie2(HttpServletRequest request)&#123;\n        Cookie[] cookies = request.getCookies();\n        for (Cookie cookie : cookies) &#123;\n            if(cookie.getName().equals(&quot;login_username&quot;))&#123;\n                System.out.println(&quot;login_username: &quot;+cookie.getValue()); //输出name为login_username的cookie\n            &#125;\n        &#125;\n        return Result.success();\n    &#125;\n&#125;    A. 访问c1接口，设置Cookie，http://localhost:8080/c1\n \n我们可以看到，设置的cookie，通过响应头Set-Cookie响应给浏览器，并且浏览器会将Cookie，存储在浏览器端。\n \nB. 访问c2接口 http://localhost:8080/c2，此时浏览器会自动的将Cookie携带到服务端，是通过**请求头Cookie**，携带的。\n \n优缺点\n\n优点：HTTP协议中支持的技术（像Set-Cookie 响应头的解析以及 Cookie 请求头数据的携带，都是浏览器自动进行的，是无需我们手动操作的）\n缺点：\n移动端APP(Android、IOS)中无法使用Cookie\n不安全，用户可以自己禁用Cookie\nCookie不能跨域\n\n\n\n\n\n\n\n\n\n\n\n\n跨域介绍：\n​\t  \n\n现在的项目，大部分都是前后端分离的，前后端最终也会分开部署，前端部署在服务器 192.168.150.200 上，端口 80，后端部署在 192.168.150.100上，端口 8080\n我们打开浏览器直接访问前端工程，访问url：http://192.168.150.200/login.html\n然后在该页面发起请求到服务端，而服务端所在地址不再是localhost，而是服务器的IP地址192.168.150.100，假设访问接口地址为：http://192.168.150.100:8080/login\n那此时就存在跨域操作了，因为我们是在 http://192.168.150.200/login.html 这个页面上访问了http://192.168.150.100:8080/login 接口\n此时如果服务器设置了一个Cookie，这个Cookie是不能使用的，因为Cookie无法跨域\n\n区分跨域的维度：\n\n协议\nIP&#x2F;协议\n端口\n\n只要上述的三个维度有任何一个维度不同，那就是跨域操作\n举例：\n​\thttp://192.168.150.200/login.html ———-&gt; https://192.168.150.200/login   \t\t[协议不同，跨域]\n​\thttp://192.168.150.200/login.html ———-&gt; http://192.168.150.100/login     \t\t[IP不同，跨域]\n​\thttp://192.168.150.200/login.html ———-&gt; http://192.168.150.200:8080/login   [端口不同，跨域]\n​    http://192.168.150.200/login.html ———-&gt; http://192.168.150.200/login    \t\t [不跨域]   \n9.2.3 会话跟踪方案-Session前面介绍的时候，我们提到Session，它是服务器端会话跟踪技术，所以它是存储在服务器端的。而 Session 的底层其实就是基于我们刚才所介绍的 Cookie 来实现的。\n\n获取Session\n \n如果我们现在要基于 Session 来进行会话跟踪，浏览器在第一次请求服务器的时候，我们就可以直接在服务器当中来获取到会话对象Session。如果是第一次请求Session ，会话对象是不存在的，这个时候服务器会自动的创建一个会话对象Session 。而每一个会话对象Session ，它都有一个ID（示意图中Session后面括号中的1，就表示ID），我们称之为 Session 的ID。\n\n响应Cookie (JSESSIONID)\n \n接下来，服务器端在给浏览器响应数据的时候，它会将 Session 的 ID 通过 Cookie 响应给浏览器。其实在响应头当中增加了一个 Set-Cookie 响应头。这个  Set-Cookie  响应头对应的值是不是cookie？ cookie 的名字是固定的 JSESSIONID 代表的服务器端会话对象 Session 的 ID。浏览器会自动识别这个响应头，然后自动将Cookie存储在浏览器本地。\n\n查找Session\n \n接下来，在后续的每一次请求当中，都会将 Cookie 的数据获取出来，并且携带到服务端。接下来服务器拿到JSESSIONID这个 Cookie 的值，也就是 Session 的ID。拿到 ID 之后，就会从众多的 Session 当中来找到当前请求对应的会话对象Session。\n这样我们是不是就可以通过 Session 会话对象在同一次会话的多次请求之间来共享数据了？好，这就是基于 Session 进行会话跟踪的流程。\n\n\n代码测试\njava@Slf4j\n@RestController\npublic class SessionController &#123;\n\n    @GetMapping(&quot;/s1&quot;)\n    public Result session1(HttpSession session)&#123;\n        log.info(&quot;HttpSession-s1: &#123;&#125;&quot;, session.hashCode());\n\n        session.setAttribute(&quot;loginUser&quot;, &quot;tom&quot;); //往session中存储数据\n        return Result.success();\n    &#125;\n\n    @GetMapping(&quot;/s2&quot;)\n    public Result session2(HttpServletRequest request)&#123;\n        HttpSession session = request.getSession();\n        log.info(&quot;HttpSession-s2: &#123;&#125;&quot;, session.hashCode());\n\n        Object loginUser = session.getAttribute(&quot;loginUser&quot;); //从session中获取数据\n        log.info(&quot;loginUser: &#123;&#125;&quot;, loginUser);\n        return Result.success(loginUser);\n    &#125;\n&#125;A. 访问 s1 接口，http://localhost:8080/s1\n \n请求完成之后，在响应头中，就会看到有一个Set-Cookie的响应头，里面响应回来了一个Cookie，就是JSESSIONID，这个就是服务端会话对象 Session 的ID。\nB. 访问 s2 接口，http://localhost:8080/s2\n \n接下来，在后续的每次请求时，都会将Cookie的值，携带到服务端，那服务端呢，接收到Cookie之后，会自动的根据JSESSIONID的值，找到对应的会话对象Session。\n那经过这两步测试，大家也会看到，在控制台中输出如下日志：\n \n两次请求，获取到的Session会话对象的hashcode是一样的，就说明是同一个会话对象。而且，第一次请求时，往Session会话对象中存储的值，第二次请求时，也获取到了。 那这样，我们就可以通过Session会话对象，在同一个会话的多次请求之间来进行数据共享了。\n优缺点\n\n优点：Session是存储在服务端的，安全\n缺点：\n服务器集群环境下无法直接使用Session\n移动端APP(Android、IOS)中无法使用Cookie\n用户可以自己禁用Cookie\nCookie不能跨域\n\n\n\n\n\n\n\n\n\n\n\n\nPS：Session 底层是基于Cookie实现的会话跟踪，如果Cookie不可用，则该方案，也就失效了。\n\n\n\n\n\n\n\n\n\n服务器集群环境为何无法使用Session？\n​\t \n\n首先第一点，我们现在所开发的项目，一般都不会只部署在一台服务器上，因为一台服务器会存在一个很大的问题，就是单点故障。所谓单点故障，指的就是一旦这台服务器挂了，整个应用都没法访问了。\n\n​     \n\n所以在现在的企业项目开发当中，最终部署的时候都是以集群的形式来进行部署，也就是同一个项目它会部署多份。比如这个项目我们现在就部署了 3 份。\n\n而用户在访问的时候，到底访问这三台其中的哪一台？其实用户在访问的时候，他会访问一台前置的服务器，我们叫负载均衡服务器，我们在后面项目当中会详细讲解。目前大家先有一个印象负载均衡服务器，它的作用就是将前端发起的请求均匀的分发给后面的这三台服务器。\n \n\n此时假如我们通过 session 来进行会话跟踪，可能就会存在这样一个问题。用户打开浏览器要进行登录操作，此时会发起登录请求。登录请求到达负载均衡服务器，将这个请求转给了第一台 Tomcat 服务器。\nTomcat 服务器接收到请求之后，要获取到会话对象session。获取到会话对象 session 之后，要给浏览器响应数据，最终在给浏览器响应数据的时候，就会携带这么一个 cookie 的名字，就是 JSESSIONID ，下一次再请求的时候，是不是又会将 Cookie 携带到服务端？\n好。此时假如又执行了一次查询操作，要查询部门的数据。这次请求到达负载均衡服务器之后，负载均衡服务器将这次请求转给了第二台 Tomcat 服务器，此时他就要到第二台 Tomcat 服务器当中。根据JSESSIONID 也就是对应的 session 的 ID 值，要找对应的 session 会话对象。\n我想请问在第二台服务器当中有没有这个ID的会话对象 Session， 是没有的。此时是不是就出现问题了？我同一个浏览器发起了 2 次请求，结果获取到的不是同一个会话对象，这就是Session这种会话跟踪方案它的缺点，在服务器集群环境下无法直接使用Session。\n\n\n大家会看到上面这两种传统的会话技术，在现在的企业开发当中是不是会存在很多的问题。 为了解决这些问题，在现在的企业开发当中，基本上都会采用第三种方案，通过令牌技术来进行会话跟踪。接下来我们就来介绍一下令牌技术，来看一下令牌技术又是如何跟踪会话的。\n9.2.4 会话跟踪方案-令牌技术这里我们所提到的令牌，其实它就是一个用户身份的标识，看似很高大上，很神秘，其实本质就是一个字符串。\n \n如果通过令牌技术来跟踪会话，我们就可以在浏览器发起请求。在请求登录接口的时候，如果登录成功，我就可以生成一个令牌，令牌就是用户的合法身份凭证。接下来我在响应数据的时候，我就可以直接将令牌响应给前端。\n接下来我们在前端程序当中接收到令牌之后，就需要将这个令牌存储起来。这个存储可以存储在 cookie 当中，也可以存储在其他的存储空间(比如：localStorage)当中。\n接下来，在后续的每一次请求当中，都需要将令牌携带到服务端。携带到服务端之后，接下来我们就需要来校验令牌的有效性。如果令牌是有效的，就说明用户已经执行了登录操作，如果令牌是无效的，就说明用户之前并未执行登录操作。\n此时，如果是在同一次会话的多次请求之间，我们想共享数据，我们就可以将共享的数据存储在令牌当中就可以了。\n优缺点\n\n优点：\n支持PC端、移动端\n解决集群环境下的认证问题\n减轻服务器的存储压力（无需在服务器端存储）\n\n\n缺点：需要自己实现（包括令牌的生成、令牌的传递、令牌的校验）\n\n针对于这三种方案，现在企业开发当中使用的最多的就是第三种令牌技术进行会话跟踪。而前面的这两种传统的方案，现在企业项目开发当中已经很少使用了。所以在我们的课程当中，我们也将会采用令牌技术来解决案例项目当中的会话跟踪问题。\n9.3 JWT令牌9.3.1 介绍JWT全称：JSON Web Token  （官网：https://jwt.io/）\n\n定义了一种简洁的、自包含的格式，用于在通信双方以json数据格式安全的传输信息。由于数字签名的存在，这些信息是可靠的。\n\n\n\n\n\n\n\n\n\n简洁：是指jwt就是一个简单的字符串。可以在请求参数或者是请求头当中直接传递。\n自包含：指的是jwt令牌，看似是一个随机的字符串，但是我们是可以根据自身的需求在jwt令牌中存储自定义的数据内容。如：可以直接在jwt令牌中存储用户的相关信息。\n简单来讲，jwt就是将原始的json数据格式进行了安全的封装，这样就可以直接基于jwt在通信双方安全的进行信息传输了。\n\n\nJWT的组成： （JWT令牌由三个部分组成，三个部分之间使用英文的点来分割）\n\n第一部分：Header(头）， 记录令牌类型、签名算法等。 例如：{“alg”:”HS256”,”type”:”JWT”}\n\n第二部分：Payload(有效载荷），携带一些自定义信息、默认信息等。 例如：{“id”:”1”,”username”:”Tom”}\n\n第三部分：Signature(签名），防止Token被篡改、确保安全性。将header、payload，并加入指定秘钥，通过指定签名算法计算而来。\n\n\n\n\n\n\n\n\n\n签名的目的就是为了防jwt令牌被篡改，而正是因为jwt令牌最后一个部分数字签名的存在，所以整个jwt 令牌是非常安全可靠的。一旦jwt令牌当中任何一个部分、任何一个字符被篡改了，整个令牌在校验的时候都会失败，所以它是非常安全可靠的。\n\n\n\n\n\n\n\n\n\n\n\n\nJWT是如何将原始的JSON格式数据，转变为字符串的呢？\n其实在生成JWT令牌时，会对JSON格式的数据进行一次编码：进行base64编码\nBase64：是一种基于64个可打印的字符来表示二进制数据的编码方式。既然能编码，那也就意味着也能解码。所使用的64个字符分别是A到Z、a到z、 0- 9，一个加号，一个斜杠，加起来就是64个字符。任何数据经过base64编码之后，最终就会通过这64个字符来表示。当然还有一个符号，那就是等号。等号它是一个补位的符号\n需要注意的是Base64是编码方式，而不是加密方式。\n \nJWT令牌最典型的应用场景就是登录认证：\n\n在浏览器发起请求来执行登录操作，此时会访问登录的接口，如果登录成功之后，我们需要生成一个jwt令牌，将生成的 jwt令牌返回给前端。\n前端拿到jwt令牌之后，会将jwt令牌存储起来。在后续的每一次请求中都会将jwt令牌携带到服务端。\n服务端统一拦截请求之后，先来判断一下这次请求有没有把令牌带过来，如果没有带过来，直接拒绝访问，如果带过来了，还要校验一下令牌是否是有效。如果有效，就直接放行进行请求的处理。\n\n在JWT登录认证的场景中我们发现，整个流程当中涉及到两步操作：\n\n在登录成功之后，要生成令牌。\n每一次请求当中，要接收令牌并对令牌进行校验。\n\n稍后我们再来学习如何来生成jwt令牌，以及如何来校验jwt令牌。\n9.3.2 生成和校验简单介绍了JWT令牌以及JWT令牌的组成之后，接下来我们就来学习基于Java代码如何生成和校验JWT令牌。\n首先我们先来实现JWT令牌的生成。要想使用JWT令牌，需要先引入JWT的依赖：\nxml&lt;!-- JWT依赖--&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;\n    &lt;artifactId&gt;jjwt&lt;/artifactId&gt;\n    &lt;version&gt;0.9.1&lt;/version&gt;\n&lt;/dependency&gt;\n\n\n\n\n\n\n\n\n在引入完JWT来赖后，就可以调用工具包中提供的API来完成JWT令牌的生成和校验\n工具类：Jwts\n生成JWT代码实现：\njava@Test\npublic void genJwt()&#123;\n    Map&lt;String,Object&gt; claims = new HashMap&lt;&gt;();\n    claims.put(&quot;id&quot;,1);\n    claims.put(&quot;username&quot;,&quot;Tom&quot;);\n    \n    String jwt = Jwts.builder()\n        .setClaims(claims) //自定义内容(载荷)          \n        .signWith(SignatureAlgorithm.HS256, &quot;itheima&quot;) //签名算法        \n        .setExpiration(new Date(System.currentTimeMillis() + 24*3600*1000)) //有效期   \n        .compact();\n    \n    System.out.println(jwt);\n&#125;运行测试方法：\ntxteyJhbGciOiJIUzI1NiJ9.eyJpZCI6MSwiZXhwIjoxNjcyNzI5NzMwfQ.fHi0Ub8npbyt71UqLXDdLyipptLgxBUg_mSuGJtXtBk输出的结果就是生成的JWT令牌,，通过英文的点分割对三个部分进行分割，我们可以将生成的令牌复制一下，然后打开JWT的官网，将生成的令牌直接放在Encoded位置，此时就会自动的将令牌解析出来。\n\n\n\n\n\n\n\n\n\n\n第一部分解析出来，看到JSON格式的原始数据，所使用的签名算法为HS256。\n第二个部分是我们自定义的数据，之前我们自定义的数据就是id，还有一个exp代表的是我们所设置的过期时间。\n由于前两个部分是base64编码，所以是可以直接解码出来。但最后一个部分并不是base64编码，是经过签名算法计算出来的，所以最后一个部分是不会解析的。\n实现了JWT令牌的生成，下面我们接着使用Java代码来校验JWT令牌(解析生成的令牌)：\njava@Test\npublic void parseJwt()&#123;\n    Claims claims = Jwts.parser()\n        .setSigningKey(&quot;itheima&quot;)//指定签名密钥（必须保证和生成令牌时使用相同的签名密钥）  \n        .parseClaimsJws(&quot;eyJhbGciOiJIUzI1NiJ9.eyJpZCI6MSwiZXhwIjoxNjcyNzI5NzMwfQ.fHi0Ub8npbyt71UqLXDdLyipptLgxBUg_mSuGJtXtBk&quot;)\n        .getBody();\n\n    System.out.println(claims);\n&#125;运行测试方法：\ntxt&#123;id=1, exp=1672729730&#125;\n\n\n\n\n\n\n\n\n令牌解析后，我们可以看到id和过期时间，如果在解析的过程当中没有报错，就说明解析成功了。\n下面我们做一个测试：把令牌header中的数字9变为8，运行测试方法后发现报错：\n\n\n\n\n\n\n\n\n\n原header： eyJhbGciOiJIUzI1NiJ9\n修改为： eyJhbGciOiJIUzI1NiJ8\n\n结论：篡改令牌中的任何一个字符，在对令牌进行解析时都会报错，所以JWT令牌是非常安全可靠的。\n我们继续测试：修改生成令牌的时指定的过期时间，修改为1分钟\njava@Test\npublic void genJwt()&#123;\n    Map&lt;String,Object&gt; claims = new HashMap&lt;&gt;();\n    claims.put(“id”,1);\n    claims.put(“username”,“Tom”);\n    String jwt = Jwts.builder()\n        .setClaims(claims) //自定义内容(载荷)          \n        .signWith(SignatureAlgorithm.HS256, “itheima”) //签名算法        \n        .setExpiration(new Date(System.currentTimeMillis() + 60*1000)) //有效期60秒   \n        .compact();\n    \n    System.out.println(jwt);\n    //输出结果：eyJhbGciOiJIUzI1NiJ9.eyJpZCI6MSwiZXhwIjoxNjczMDA5NzU0fQ.RcVIR65AkGiax-ID6FjW60eLFH3tPTKdoK7UtE4A1ro\n&#125;\n\n@Test\npublic void parseJwt()&#123;\n    Claims claims = Jwts.parser()\n        .setSigningKey(&quot;itheima&quot;)//指定签名密钥\n.parseClaimsJws(&quot;eyJhbGciOiJIUzI1NiJ9.eyJpZCI6MSwiZXhwIjoxNjczMDA5NzU0fQ.RcVIR65AkGiax-ID6FjW60eLFH3tPTKdoK7UtE4A1ro&quot;)\n        .getBody();\n\n    System.out.println(claims);\n&#125;等待1分钟之后运行测试方法发现也报错了，说明：JWT令牌过期后，令牌就失效了，解析的为非法令牌。\n通过以上测试，我们在使用JWT令牌时需要注意：\n\nJWT校验时使用的签名秘钥，必须和生成JWT令牌时使用的秘钥是配套的。\n\n如果JWT令牌解析校验时报错，则说明 JWT令牌被篡改 或 失效了，令牌非法。\n\n\n9.3.3 登录下发令牌JWT令牌的生成和校验的基本操作我们已经学习完了，接下来我们就需要在案例当中通过JWT令牌技术来跟踪会话。具体的思路我们前面已经分析过了，主要就是两步操作：\n\n生成令牌\n在登录成功之后来生成一个JWT令牌，并且把这个令牌直接返回给前端\n\n\n校验令牌\n拦截前端请求，从请求中获取到令牌，对令牌进行解析校验\n\n\n\n那我们首先来完成：登录成功之后生成JWT令牌，并且把令牌返回给前端。\nJWT令牌怎么返回给前端呢？此时我们就需要再来看一下接口文档当中关于登录接口的描述（主要看响应数据）：\n\n响应数据\n参数格式：application&#x2F;json\n参数说明：\n\n\n\n名称\n类型\n是否必须\n默认值\n备注\n其他信息\n\n\n\ncode\nnumber\n必须\n\n响应码, 1 成功 ; 0  失败\n\n\n\nmsg\nstring\n非必须\n\n提示信息\n\n\n\ndata\nstring\n必须\n\n返回的数据 , jwt令牌\n\n\n\n响应数据样例：\njson&#123;\n  &quot;code&quot;: 1,\n  &quot;msg&quot;: &quot;success&quot;,\n  &quot;data&quot;: &quot;eyJhbGciOiJIUzI1NiJ9.eyJuYW1lIjoi6YeR5bq4IiwiaWQiOjEsInVzZXJuYW1lIjoiamlueW9uZyIsImV4cCI6MTY2MjIwNzA0OH0.KkUc_CXJZJ8Dd063eImx4H9Ojfrr6XMJ-yVzaWCVZCo&quot;\n&#125;\n备注说明\n用户登录成功后，系统会自动下发JWT令牌，然后在后续的每次请求中，都需要在请求头header中携带到服务端，请求头的名称为 token ，值为 登录时下发的JWT令牌。\n如果检测到用户未登录，则会返回如下固定错误信息：\njson&#123;\n    &quot;code&quot;: 0,\n    &quot;msg&quot;: &quot;NOT_LOGIN&quot;,\n    &quot;data&quot;: null\n&#125;\n\n解读完接口文档中的描述了，目前我们先来完成令牌的生成和令牌的下发，我们只需要生成一个令牌返回给前端就可以了。\n实现步骤：\n\n引入JWT工具类\n在项目工程下创建com.itheima.utils包，并把提供JWT工具类复制到该包下\n\n\n登录完成后，调用工具类生成JWT令牌并返回\n\nJWT工具类\njavapublic class JwtUtils &#123;\n\n    private static String signKey = &quot;itheima&quot;;//签名密钥\n    private static Long expire = 43200000L; //有效时间\n\n    /**\n     * 生成JWT令牌\n     * @param claims JWT第二部分负载 payload 中存储的内容\n     * @return\n     */\n    public static String generateJwt(Map&lt;String, Object&gt; claims)&#123;\n        String jwt = Jwts.builder()\n                .addClaims(claims)//自定义信息（有效载荷）\n                .signWith(SignatureAlgorithm.HS256, signKey)//签名算法（头部）\n                .setExpiration(new Date(System.currentTimeMillis() + expire))//过期时间\n                .compact();\n        return jwt;\n    &#125;\n\n    /**\n     * 解析JWT令牌\n     * @param jwt JWT令牌\n     * @return JWT第二部分负载 payload 中存储的内容\n     */\n    public static Claims parseJWT(String jwt)&#123;\n        Claims claims = Jwts.parser()\n                .setSigningKey(signKey)//指定签名密钥\n                .parseClaimsJws(jwt)//指定令牌Token\n                .getBody();\n        return claims;\n    &#125;\n&#125;\n登录成功，生成JWT令牌并返回\njava@RestController\n@Slf4j\npublic class LoginController &#123;\n    //依赖业务层对象\n    @Autowired\n    private EmpService empService;\n\n    @PostMapping(&quot;/login&quot;)\n    public Result login(@RequestBody Emp emp) &#123;\n        //调用业务层：登录功能\n        Emp loginEmp = empService.login(emp);\n\n        //判断：登录用户是否存在\n        if(loginEmp !=null )&#123;\n            //自定义信息\n            Map&lt;String , Object&gt; claims = new HashMap&lt;&gt;();\n            claims.put(&quot;id&quot;, loginEmp.getId());\n            claims.put(&quot;username&quot;,loginEmp.getUsername());\n            claims.put(&quot;name&quot;,loginEmp.getName());\n\n            //使用JWT工具类，生成身份令牌\n            String token = JwtUtils.generateJwt(claims);\n            return Result.success(token);\n        &#125;\n        return Result.error(&quot;用户名或密码错误&quot;);\n    &#125;\n&#125;重启服务，打开postman测试登录接口：\n\n打开浏览器完成前后端联调操作：利用开发者工具，抓取一下网络请求\n\n\n\n\n\n\n\n\n\n\n登录请求完成后，可以看到JWT令牌已经响应给了前端，此时前端就会将JWT令牌存储在浏览器本地。\n服务器响应的JWT令牌存储在本地浏览器哪里了呢？\n\n在当前案例中，JWT令牌存储在浏览器的本地存储空间local storage中了。 local storage是浏览器的本地存储，在移动端也是支持的。\n\n\n我们在发起一个查询部门数据的请求，此时我们可以看到在请求头中包含一个token(JWT令牌)，后续的每一次请求当中，都会将这个令牌携带到服务端。\n\n9.4 过滤器Filter刚才通过浏览器的开发者工具，我们可以看到在后续的请求当中，都会在请求头中携带JWT令牌到服务端，而服务端需要统一拦截所有的请求，从而判断是否携带的有合法的JWT令牌。那怎么样来统一拦截到所有的请求校验令牌的有效性呢？这里我们会学习两种解决方案：\n\nFilter过滤器\nInterceptor拦截器\n\n我们首先来学习过滤器Filter。\n9.4.1 快速入门什么是Filter？\n\nFilter表示过滤器，是 JavaWeb三大组件(Servlet、Filter、Listener)之一。\n过滤器可以把对资源的请求拦截下来，从而实现一些特殊的功能\n使用了过滤器之后，要想访问web服务器上的资源，必须先经过滤器，过滤器处理完毕之后，才可以访问对应的资源。\n\n\n过滤器一般完成一些通用的操作，比如：登录校验、统一编码处理、敏感字符处理等。\n\n \n下面我们通过Filter快速入门程序掌握过滤器的基本使用操作：\n\n第1步，定义过滤器 ：1.定义一个类，实现 Filter 接口，并重写其所有方法。\n第2步，配置过滤器：Filter类上加 @WebFilter 注解，配置拦截资源的路径。引导类上加 @ServletComponentScan 开启Servlet组件支持。\n\n定义过滤器\njava//定义一个类，实现一个标准的Filter过滤器的接口\npublic class DemoFilter implements Filter &#123;\n    @Override //初始化方法, 只调用一次\n    public void init(FilterConfig filterConfig) throws ServletException &#123;\n        System.out.println(&quot;init 初始化方法执行了&quot;);\n    &#125;\n\n    @Override //拦截到请求之后调用, 调用多次\n    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123;\n        System.out.println(&quot;Demo 拦截到了请求...放行前逻辑&quot;);\n        //放行\n        chain.doFilter(request,response);\n    &#125;\n\n    @Override //销毁方法, 只调用一次\n    public void destroy() &#123;\n        System.out.println(&quot;destroy 销毁方法执行了&quot;);\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\ninit方法：过滤器的初始化方法。在web服务器启动的时候会自动的创建Filter过滤器对象，在创建过滤器对象的时候会自动调用init初始化方法，这个方法只会被调用一次。\n\ndoFilter方法：这个方法是在每一次拦截到请求之后都会被调用，所以这个方法是会被调用多次的，每拦截到一次请求就会调用一次doFilter()方法。\n\ndestroy方法： 是销毁的方法。当我们关闭服务器的时候，它会自动的调用销毁方法destroy，而这个销毁方法也只会被调用一次。\n\n\n在定义完Filter之后，Filter其实并不会生效，还需要完成Filter的配置，Filter的配置非常简单，只需要在Filter类上添加一个注解：@WebFilter，并指定属性urlPatterns，通过这个属性指定过滤器要拦截哪些请求\njava@WebFilter(urlPatterns = &quot;/*&quot;) //配置过滤器要拦截的请求路径（ /* 表示拦截浏览器的所有请求 ）\npublic class DemoFilter implements Filter &#123;\n    @Override //初始化方法, 只调用一次\n    public void init(FilterConfig filterConfig) throws ServletException &#123;\n        System.out.println(&quot;init 初始化方法执行了&quot;);\n    &#125;\n\n    @Override //拦截到请求之后调用, 调用多次\n    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123;\n        System.out.println(&quot;Demo 拦截到了请求...放行前逻辑&quot;);\n        //放行\n        chain.doFilter(request,response);\n    &#125;\n\n    @Override //销毁方法, 只调用一次\n    public void destroy() &#123;\n        System.out.println(&quot;destroy 销毁方法执行了&quot;);\n    &#125;\n&#125;当我们在Filter类上面加了@WebFilter注解之后，接下来我们还需要在启动类上面加上一个注解@ServletComponentScan，通过这个@ServletComponentScan注解来开启SpringBoot项目对于Servlet组件的支持。\njava@ServletComponentScan\n@SpringBootApplication\npublic class TliasWebManagementApplication &#123;\n\n    public static void main(String[] args) &#123;\n        SpringApplication.run(TliasWebManagementApplication.class, args);\n    &#125;\n\n&#125;重新启动服务，打开浏览器，执行部门管理的请求，可以看到控制台输出了过滤器中的内容：\n \n\n\n\n\n\n\n\n\n\n注意事项：\n​\t在过滤器Filter中，如果不执行放行操作，将无法访问后面的资源。 放行操作：chain.doFilter(request, response);\n现在我们已完成了Filter过滤器的基本使用，下面我们将学习Filter过滤器在使用过程中的一些细节。\n9.4.2 Filter详解Filter过滤器的快速入门程序我们已经完成了，接下来我们就要详细的介绍一下过滤器Filter在使用中的一些细节。主要介绍以下3个方面的细节：\n\n过滤器的执行流程\n过滤器的拦截路径配置\n过滤器链\n\n执行流程\n首先我们先来看下过滤器的执行流程：\n\n过滤器当中我们拦截到了请求之后，如果希望继续访问后面的web资源，就要执行放行操作，放行就是调用 FilterChain对象当中的doFilter()方法，在调用doFilter()这个方法之前所编写的代码属于放行之前的逻辑。\n在放行后访问完 web 资源之后还会回到过滤器当中，回到过滤器之后如有需求还可以执行放行之后的逻辑，放行之后的逻辑我们写在doFilter()这行代码之后。\njava@WebFilter(urlPatterns = &quot;/*&quot;) \npublic class DemoFilter implements Filter &#123;\n    \n    @Override //初始化方法, 只调用一次\n    public void init(FilterConfig filterConfig) throws ServletException &#123;\n        System.out.println(&quot;init 初始化方法执行了&quot;);\n    &#125;\n    \n    @Override\n    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123;\n        \n        System.out.println(&quot;DemoFilter   放行前逻辑.....&quot;);\n\n        //放行请求\n        filterChain.doFilter(servletRequest,servletResponse);\n\n        System.out.println(&quot;DemoFilter   放行后逻辑.....&quot;);\n        \n    &#125;\n\n    @Override //销毁方法, 只调用一次\n    public void destroy() &#123;\n        System.out.println(&quot;destroy 销毁方法执行了&quot;);\n    &#125;\n&#125;\n拦截路径\n执行流程我们搞清楚之后，接下来再来介绍一下过滤器的拦截路径，Filter可以根据需求，配置不同的拦截资源路径：\n\n\n\n拦截路径\nurlPatterns值\n含义\n\n\n\n拦截具体路径\n&#x2F;login\n只有访问 &#x2F;login 路径时，才会被拦截\n\n\n目录拦截\n&#x2F;emps&#x2F;*\n访问&#x2F;emps下的所有资源，都会被拦截\n\n\n拦截所有\n&#x2F;*\n访问所有资源，都会被拦截\n\n\n下面我们来测试”拦截具体路径”：\njava@WebFilter(urlPatterns = &quot;/login&quot;)  //拦截/login具体路径\npublic class DemoFilter implements Filter &#123;\n    @Override\n    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123;\n        System.out.println(&quot;DemoFilter   放行前逻辑.....&quot;);\n\n        //放行请求\n        filterChain.doFilter(servletRequest,servletResponse);\n\n        System.out.println(&quot;DemoFilter   放行后逻辑.....&quot;);\n    &#125;\n\n\n    @Override\n    public void init(FilterConfig filterConfig) throws ServletException &#123;\n        Filter.super.init(filterConfig);\n    &#125;\n\n    @Override\n    public void destroy() &#123;\n        Filter.super.destroy();\n    &#125;\n&#125;测试1：访问部门管理请求，发现过滤器没有拦截请求\n\n\n测试2：访问登录请求&#x2F;login，发现过滤器拦截请求\n\n下面我们来测试”目录拦截”：\njava@WebFilter(urlPatterns = &quot;/depts/*&quot;) //拦截所有以/depts开头，后面是什么无所谓\npublic class DemoFilter implements Filter &#123;\n    @Override\n    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123;\n        System.out.println(&quot;DemoFilter   放行前逻辑.....&quot;);\n\n        //放行请求\n        filterChain.doFilter(servletRequest,servletResponse);\n\n        System.out.println(&quot;DemoFilter   放行后逻辑.....&quot;);\n    &#125;\n\n\n    @Override\n    public void init(FilterConfig filterConfig) throws ServletException &#123;\n        Filter.super.init(filterConfig);\n    &#125;\n\n    @Override\n    public void destroy() &#123;\n        Filter.super.destroy();\n    &#125;\n&#125;测试1：访问部门管理请求，发现过滤器拦截了请求\n\n测试2：访问登录请求&#x2F;login，发现过滤器没有拦截请求\n\n过滤器链\n最后我们在来介绍下过滤器链，什么是过滤器链呢？所谓过滤器链指的是在一个web应用程序当中，可以配置多个过滤器，多个过滤器就形成了一个过滤器链。\n\n比如：在我们web服务器当中，定义了两个过滤器，这两个过滤器就形成了一个过滤器链。\n而这个链上的过滤器在执行的时候会一个一个的执行，会先执行第一个Filter，放行之后再来执行第二个Filter，如果执行到了最后一个过滤器放行之后，才会访问对应的web资源。\n访问完web资源之后，按照我们刚才所介绍的过滤器的执行流程，还会回到过滤器当中来执行过滤器放行后的逻辑，而在执行放行后的逻辑的时候，顺序是反着的。\n先要执行过滤器2放行之后的逻辑，再来执行过滤器1放行之后的逻辑，最后在给浏览器响应数据。\n以上就是当我们在web应用当中配置了多个过滤器，形成了这样一个过滤器链以及过滤器链的执行顺序。下面我们通过idea来验证下过滤器链。\n验证步骤：\n\n在filter包下再来新建一个Filter过滤器类：AbcFilter\n在AbcFilter过滤器中编写放行前和放行后逻辑\n配置AbcFilter过滤器拦截请求路径为：&#x2F;* \n重启SpringBoot服务，查看DemoFilter、AbcFilter的执行日志\n\n\nAbcFilter过滤器\njava@WebFilter(urlPatterns = &quot;/*&quot;)\npublic class AbcFilter implements Filter &#123;\n    @Override\n    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123;\n        System.out.println(&quot;Abc 拦截到了请求... 放行前逻辑&quot;);\n\n        //放行\n        chain.doFilter(request,response);\n\n        System.out.println(&quot;Abc 拦截到了请求... 放行后逻辑&quot;);\n    &#125;\n&#125;DemoFilter过滤器\njava@WebFilter(urlPatterns = &quot;/*&quot;) \npublic class DemoFilter implements Filter &#123;\n    @Override\n    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123;\n        System.out.println(&quot;DemoFilter   放行前逻辑.....&quot;);\n\n        //放行请求\n        filterChain.doFilter(servletRequest,servletResponse);\n\n        System.out.println(&quot;DemoFilter   放行后逻辑.....&quot;);\n    &#125;\n&#125;打开浏览器访问登录接口：\n\n通过控制台日志的输出，大家发现AbcFilter先执行DemoFilter后执行，这是为什么呢？\n其实是和过滤器的类名有关系。以注解方式配置的Filter过滤器，它的执行优先级是按时过滤器类名的自动排序确定的，类名排名越靠前，优先级越高。\n假如我们想让DemoFilter先执行，怎么办呢？答案就是修改类名。\n测试：修改AbcFilter类名为XbcFilter，运行程序查看控制台日志\njava@WebFilter(urlPatterns = &quot;/*&quot;)\npublic class XbcFilter implements Filter &#123;\n    @Override\n    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123;\n        System.out.println(&quot;Xbc 拦截到了请求...放行前逻辑&quot;);\n\n        //放行\n        chain.doFilter(request,response);\n\n        System.out.println(&quot;Xbc 拦截到了请求...放行后逻辑&quot;);\n    &#125;\n&#125;\n\n到此，关于过滤器的使用细节，我们已经全部介绍完毕了。\n9.4.3 登录校验-Filter过滤器Filter的快速入门以及使用细节我们已经介绍完了，接下来最后一步，我们需要使用过滤器Filter来完成案例当中的登录校验功能。\n\n我们先来回顾下前面分析过的登录校验的基本流程：\n\n要进入到后台管理系统，我们必须先完成登录操作，此时就需要访问登录接口login。\n\n登录成功之后，我们会在服务端生成一个JWT令牌，并且把JWT令牌返回给前端，前端会将JWT令牌存储下来。\n\n在后续的每一次请求当中，都会将JWT令牌携带到服务端，请求到达服务端之后，要想去访问对应的业务功能，此时我们必须先要校验令牌的有效性。\n\n对于校验令牌的这一块操作，我们使用登录校验的过滤器，在过滤器当中来校验令牌的有效性。如果令牌是无效的，就响应一个错误的信息，也不会再去放行访问对应的资源了。如果令牌存在，并且它是有效的，此时就会放行去访问对应的web资源，执行相应的业务操作。\n\n\n大概清楚了在Filter过滤器的实现步骤了，那在正式开发登录校验过滤器之前，我们思考两个问题：\n\n所有的请求，拦截到了之后，都需要校验令牌吗？\n\n答案：登录请求例外\n\n\n拦截到请求后，什么情况下才可以放行，执行业务操作？\n\n答案：有令牌，且令牌校验通过(合法)；否则都返回未登录错误结果\n\n\n\n具体流程\n我们要完成登录校验，主要是利用Filter过滤器实现，而Filter过滤器的流程步骤：\n \n基于上面的业务流程，我们分析出具体的操作步骤：\n\n获取请求url\n判断请求url中是否包含login，如果包含，说明是登录操作，放行\n获取请求头中的令牌（token）\n判断令牌是否存在，如果不存在，返回错误结果（未登录）\n解析token，如果解析失败，返回错误结果（未登录）\n放行\n\n分析清楚了以上的问题后，我们就参照接口文档来开发登录功能了，登录接口描述如下：\n\n基本信息\ntxt请求路径：/login\n\n请求方式：POST\n\n接口描述：该接口用于员工登录Tlias智能学习辅助系统，登录完毕后，系统下发JWT令牌。 \n请求参数\n参数格式：application&#x2F;json\n参数说明：\n\n\n\n名称\n类型\n是否必须\n备注\n\n\n\nusername\nstring\n必须\n用户名\n\n\npassword\nstring\n必须\n密码\n\n\n请求数据样例：\njson&#123;\n    &quot;username&quot;: &quot;jinyong&quot;,\n    &quot;password&quot;: &quot;123456&quot;\n&#125;\n响应数据\n参数格式：application&#x2F;json\n参数说明：\n\n\n\n名称\n类型\n是否必须\n默认值\n备注\n其他信息\n\n\n\ncode\nnumber\n必须\n\n响应码, 1 成功 ; 0  失败\n\n\n\nmsg\nstring\n非必须\n\n提示信息\n\n\n\ndata\nstring\n必须\n\n返回的数据 , jwt令牌\n\n\n\n响应数据样例：\njson&#123;\n  &quot;code&quot;: 1,\n  &quot;msg&quot;: &quot;success&quot;,\n  &quot;data&quot;: &quot;eyJhbGciOiJIUzI1NiJ9.eyJuYW1lIjoi6YeR5bq4IiwiaWQiOjEsInVzZXJuYW1lIjoiamlueW9uZyIsImV4cCI6MTY2MjIwNzA0OH0.KkUc_CXJZJ8Dd063eImx4H9Ojfrr6XMJ-yVzaWCVZCo&quot;\n&#125;\n备注说明\n用户登录成功后，系统会自动下发JWT令牌，然后在后续的每次请求中，都需要在请求头header中携带到服务端，请求头的名称为 token ，值为 登录时下发的JWT令牌。\n如果检测到用户未登录，则会返回如下固定错误信息：\njson&#123;\n    &quot;code&quot;: 0,\n    &quot;msg&quot;: &quot;NOT_LOGIN&quot;,\n    &quot;data&quot;: null\n&#125;\n\n登录校验过滤器：LoginCheckFilter\njava@Slf4j\n@WebFilter(urlPatterns = &quot;/*&quot;) //拦截所有请求\npublic class LoginCheckFilter implements Filter &#123;\n\n    @Override\n    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain chain) throws IOException, ServletException &#123;\n        //前置：强制转换为http协议的请求对象、响应对象 （转换原因：要使用子类中特有方法）\n        HttpServletRequest request = (HttpServletRequest) servletRequest;\n        HttpServletResponse response = (HttpServletResponse) servletResponse;\n\n        //1.获取请求url\n        String url = request.getRequestURL().toString();\n        log.info(&quot;请求路径：&#123;&#125;&quot;, url); //请求路径：http://localhost:8080/login\n\n\n        //2.判断请求url中是否包含login，如果包含，说明是登录操作，放行\n        if(url.contains(&quot;/login&quot;))&#123;\n            chain.doFilter(request, response);//放行请求\n            return;//结束当前方法的执行\n        &#125;\n\n\n        //3.获取请求头中的令牌（token）\n        String token = request.getHeader(&quot;token&quot;);\n        log.info(&quot;从请求头中获取的令牌：&#123;&#125;&quot;,token);\n\n\n        //4.判断令牌是否存在，如果不存在，返回错误结果（未登录）\n        if(!StringUtils.hasLength(token))&#123;\n            log.info(&quot;Token不存在&quot;);\n\n            Result responseResult = Result.error(&quot;NOT_LOGIN&quot;);\n            //把Result对象转换为JSON格式字符串 (fastjson是阿里巴巴提供的用于实现对象和json的转换工具类)\n            String json = JSONObject.toJSONString(responseResult);\n            response.setContentType(&quot;application/json;charset=utf-8&quot;);\n            //响应\n            response.getWriter().write(json);\n\n            return;\n        &#125;\n\n        //5.解析token，如果解析失败，返回错误结果（未登录）\n        try &#123;\n            JwtUtils.parseJWT(token);\n        &#125;catch (Exception e)&#123;\n            log.info(&quot;令牌解析失败!&quot;);\n\n            Result responseResult = Result.error(&quot;NOT_LOGIN&quot;);\n            //把Result对象转换为JSON格式字符串 (fastjson是阿里巴巴提供的用于实现对象和json的转换工具类)\n            String json = JSONObject.toJSONString(responseResult);\n            response.setContentType(&quot;application/json;charset=utf-8&quot;);\n            //响应\n            response.getWriter().write(json);\n\n            return;\n        &#125;\n\n\n        //6.放行\n        chain.doFilter(request, response);\n\n    &#125;\n&#125;在上述过滤器的功能实现中，我们使用到了一个第三方json处理的工具包fastjson。我们要想使用，需要引入如下依赖：\nxml&lt;dependency&gt;\n    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;\n    &lt;artifactId&gt;fastjson&lt;/artifactId&gt;\n    &lt;version&gt;1.2.76&lt;/version&gt;\n&lt;/dependency&gt;登录校验的过滤器我们编写完成了，接下来我们就可以重新启动服务来做一个测试：\n\n\n\n\n\n\n\n\n\n测试前先把之前所编写的测试使用的过滤器，暂时注释掉。直接将@WebFilter注解给注释掉即可。\n\n测试1：未登录是否可以访问部门管理页面\n首先关闭浏览器，重新打开浏览器，在地址栏中输入：http://localhost:9528/#/system/dept\n由于用户没有登录，登录校验过滤器返回错误信息，前端页面根据返回的错误信息结果，自动跳转到登录页面了\n\n\n测试2：先进行登录操作，再访问部门管理页面\n登录校验成功之后，可以正常访问相关业务操作页面\n\n\n\n9.5 拦截器Interceptor9.5.1 快速入门什么是拦截器？\n\n是一种动态拦截方法调用的机制，类似于过滤器。\n拦截器是Spring框架中提供的，用来动态拦截控制器方法的执行。\n\n拦截器的作用：\n\n拦截请求，在指定方法调用前后，根据业务需要执行预先设定的代码。\n\n在拦截器当中，我们通常也是做一些通用性的操作，比如：我们可以通过拦截器来拦截前端发起的请求，将登录校验的逻辑全部编写在拦截器当中。在校验的过程当中，如发现用户登录了(携带JWT令牌且是合法令牌)，就可以直接放行，去访问spring当中的资源。如果校验时发现并没有登录或是非法令牌，就可以直接给前端响应未登录的错误信息。\n下面我们通过快速入门程序，来学习下拦截器的基本使用。拦截器的使用步骤和过滤器类似，也分为两步：\n\n定义拦截器\n\n注册配置拦截器\n\n\n自定义拦截器：实现HandlerInterceptor接口，并重写其所有方法\njava//自定义拦截器\n@Component\npublic class LoginCheckInterceptor implements HandlerInterceptor &#123;\n    //目标资源方法执行前执行。 返回true：放行    返回false：不放行\n    @Override\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;\n        System.out.println(&quot;preHandle .... &quot;);\n        \n        return true; //true表示放行\n    &#125;\n\n    //目标资源方法执行后执行\n    @Override\n    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123;\n        System.out.println(&quot;postHandle ... &quot;);\n    &#125;\n\n    //视图渲染完毕后执行，最后执行\n    @Override\n    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123;\n        System.out.println(&quot;afterCompletion .... &quot;);\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n注意：\n​\tpreHandle方法：目标资源方法执行前执行。 返回true：放行    返回false：不放行\n​\tpostHandle方法：目标资源方法执行后执行\n​\tafterCompletion方法：视图渲染完毕后执行，最后执行\n注册配置拦截器：实现WebMvcConfigurer接口，并重写addInterceptors方法\njava@Configuration  \npublic class WebConfig implements WebMvcConfigurer &#123;\n\n    //自定义的拦截器对象\n    @Autowired\n    private LoginCheckInterceptor loginCheckInterceptor;\n\n    \n    @Override\n    public void addInterceptors(InterceptorRegistry registry) &#123;\n       //注册自定义拦截器对象\n        registry.addInterceptor(loginCheckInterceptor).addPathPatterns(&quot;/**&quot;);//设置拦截器拦截的请求路径（ /** 表示拦截所有请求）\n    &#125;\n&#125;重新启动SpringBoot服务，打开postman测试：\n\n\n接下来我们再来做一个测试：将拦截器中返回值改为false\n使用postman，再次点击send发送请求后，没有响应数据，说明请求被拦截了没有放行\n\n9.5.2 Interceptor详解首先我们先来看拦截器的拦截路径的配置，在注册配置拦截器的时候，我们要指定拦截器的拦截路径，通过addPathPatterns(&quot;要拦截路径&quot;)方法，就可以指定要拦截哪些资源。\n在入门程序中我们配置的是/**，表示拦截所有资源，而在配置拦截器时，不仅可以指定要拦截哪些资源，还可以指定不拦截哪些资源，只需要调用excludePathPatterns(&quot;不拦截路径&quot;)方法，指定哪些资源不需要拦截。\njava@Configuration  \npublic class WebConfig implements WebMvcConfigurer &#123;\n\n    //拦截器对象\n    @Autowired\n    private LoginCheckInterceptor loginCheckInterceptor;\n\n    @Override\n    public void addInterceptors(InterceptorRegistry registry) &#123;\n        //注册自定义拦截器对象\n        registry.addInterceptor(loginCheckInterceptor)\n                .addPathPatterns(&quot;/**&quot;)//设置拦截器拦截的请求路径（ /** 表示拦截所有请求）\n                .excludePathPatterns(&quot;/login&quot;);//设置不拦截的请求路径\n    &#125;\n&#125;在拦截器中除了可以设置/**拦截所有资源外，还有一些常见拦截路径设置：\n\n\n\n拦截路径\n含义\n举例\n\n\n\n&#x2F;*\n一级路径\n能匹配&#x2F;depts，&#x2F;emps，&#x2F;login，不能匹配 &#x2F;depts&#x2F;1\n\n\n&#x2F;**\n任意级路径\n能匹配&#x2F;depts，&#x2F;depts&#x2F;1，&#x2F;depts&#x2F;1&#x2F;2\n\n\n&#x2F;depts&#x2F;*\n&#x2F;depts下的一级路径\n能匹配&#x2F;depts&#x2F;1，不能匹配&#x2F;depts&#x2F;1&#x2F;2，&#x2F;depts\n\n\n&#x2F;depts&#x2F;**\n&#x2F;depts下的任意级路径\n能匹配&#x2F;depts，&#x2F;depts&#x2F;1，&#x2F;depts&#x2F;1&#x2F;2，不能匹配&#x2F;emps&#x2F;1\n\n\n下面主要来演示下/**与/*的区别： \n\n修改拦截器配置，把拦截路径设置为/*\n\njava@Configuration \npublic class WebConfig implements WebMvcConfigurer &#123;\n\n    //拦截器对象\n    @Autowired\n    private LoginCheckInterceptor loginCheckInterceptor;\n\n    @Override\n    public void addInterceptors(InterceptorRegistry registry) &#123;\n       //注册自定义拦截器对象\n        registry.addInterceptor(loginCheckInterceptor)\n                .addPathPatterns(&quot;/*&quot;)\n                .excludePathPatterns(&quot;/login&quot;);//设置不拦截的请求路径\n    &#125;\n&#125;使用postman测试：http://localhost:8080/emps/1 \n\n控制台没有输出拦截器中的日志信息，说明/*没有匹配到拦截路径/emp/1 。\n\n执行流程\n介绍完拦截路径的配置之后，接下来我们再来介绍拦截器的执行流程。通过执行流程，大家就能够清晰的知道过滤器与拦截器的执行时机。\n\n\n当我们打开浏览器来访问部署在web服务器当中的web应用时，此时我们所定义的过滤器会拦截到这次请求。拦截到这次请求之后，它会先执行放行前的逻辑，然后再执行放行操作。而由于我们当前是基于springboot开发的，所以放行之后是进入到了spring的环境当中，也就是要来访问我们所定义的controller当中的接口方法。\n\nTomcat并不识别所编写的Controller程序，但是它识别Servlet程序，所以在Spring的Web环境中提供了一个非常核心的Servlet：DispatcherServlet（前端控制器），所有请求都会先进行到DispatcherServlet，再将请求转给Controller。\n\n当我们定义了拦截器后，会在执行Controller的方法之前，请求被拦截器拦截住。执行preHandle()方法，这个方法执行完成后需要返回一个布尔类型的值，如果返回true，就表示放行本次操作，才会继续访问controller中的方法；如果返回false，则不会放行（controller中的方法也不会执行）。\n\n在controller当中的方法执行完毕之后，再回过来执行postHandle()这个方法以及afterCompletion() 方法，然后再返回给DispatcherServlet，最终再来执行过滤器当中放行后的这一部分逻辑的逻辑。执行完毕之后，最终给浏览器响应数据。\n\n\n接下来我们就来演示下过滤器和拦截器同时存在的执行流程：\n\n开启LoginCheckInterceptor拦截器\n\njava@Component\npublic class LoginCheckInterceptor implements HandlerInterceptor &#123;\n    @Override\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;\n        System.out.println(&quot;preHandle .... &quot;);\n        \n        return true; //true表示放行\n    &#125;\n\n    @Override\n    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123;\n        System.out.println(&quot;postHandle ... &quot;);\n    &#125;\n\n    @Override\n    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123;\n        System.out.println(&quot;afterCompletion .... &quot;);\n    &#125;\n&#125;java@Configuration  \npublic class WebConfig implements WebMvcConfigurer &#123;\n\n    //拦截器对象\n    @Autowired\n    private LoginCheckInterceptor loginCheckInterceptor;\n\n    @Override\n    public void addInterceptors(InterceptorRegistry registry) &#123;\n        //注册自定义拦截器对象\n        registry.addInterceptor(loginCheckInterceptor)\n                .addPathPatterns(&quot;/**&quot;)//拦截所有请求\n                .excludePathPatterns(&quot;/login&quot;);//不拦截登录请求\n    &#125;\n&#125;\n开启DemoFilter过滤器\n\njava@WebFilter(urlPatterns = &quot;/*&quot;) \npublic class DemoFilter implements Filter &#123;\n    @Override\n    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123;\n        System.out.println(&quot;DemoFilter   放行前逻辑.....&quot;);\n\n        //放行请求\n        filterChain.doFilter(servletRequest,servletResponse);\n\n        System.out.println(&quot;DemoFilter   放行后逻辑.....&quot;);\n    &#125;\n&#125;重启SpringBoot服务后，清空日志，打开Postman，测试查询部门：\n\n\n以上就是拦截器的执行流程。通过执行流程分析，大家应该已经清楚了过滤器和拦截器之间的区别，其实它们之间的区别主要是两点：\n\n接口规范不同：过滤器需要实现Filter接口，而拦截器需要实现HandlerInterceptor接口。\n拦截范围不同：过滤器Filter会拦截所有的资源，而Interceptor只会拦截Spring环境中的资源。\n\n9.5.3 登录校验- Interceptor讲解完了拦截器的基本操作之后，接下来我们需要完成最后一步操作：通过拦截器来完成案例当中的登录校验功能。\n登录校验的业务逻辑以及操作步骤我们前面已经分析过了，和登录校验Filter过滤器当中的逻辑是完全一致的。现在我们只需要把这个技术方案由原来的过滤器换成拦截器interceptor就可以了。\n登录校验拦截器\njava//自定义拦截器\n@Component //当前拦截器对象由Spring创建和管理\n@Slf4j\npublic class LoginCheckInterceptor implements HandlerInterceptor &#123;\n    //前置方式\n    @Override\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;\n        System.out.println(&quot;preHandle .... &quot;);\n        //1.获取请求url\n        //2.判断请求url中是否包含login，如果包含，说明是登录操作，放行\n\n        //3.获取请求头中的令牌（token）\n        String token = request.getHeader(&quot;token&quot;);\n        log.info(&quot;从请求头中获取的令牌：&#123;&#125;&quot;,token);\n\n        //4.判断令牌是否存在，如果不存在，返回错误结果（未登录）\n        if(!StringUtils.hasLength(token))&#123;\n            log.info(&quot;Token不存在&quot;);\n\n            //创建响应结果对象\n            Result responseResult = Result.error(&quot;NOT_LOGIN&quot;);\n            //把Result对象转换为JSON格式字符串 (fastjson是阿里巴巴提供的用于实现对象和json的转换工具类)\n            String json = JSONObject.toJSONString(responseResult);\n            //设置响应头（告知浏览器：响应的数据类型为json、响应的数据编码表为utf-8）\n            response.setContentType(&quot;application/json;charset=utf-8&quot;);\n            //响应\n            response.getWriter().write(json);\n\n            return false;//不放行\n        &#125;\n\n        //5.解析token，如果解析失败，返回错误结果（未登录）\n        try &#123;\n            JwtUtils.parseJWT(token);\n        &#125;catch (Exception e)&#123;\n            log.info(&quot;令牌解析失败!&quot;);\n\n            //创建响应结果对象\n            Result responseResult = Result.error(&quot;NOT_LOGIN&quot;);\n            //把Result对象转换为JSON格式字符串 (fastjson是阿里巴巴提供的用于实现对象和json的转换工具类)\n            String json = JSONObject.toJSONString(responseResult);\n            //设置响应头\n            response.setContentType(&quot;application/json;charset=utf-8&quot;);\n            //响应\n            response.getWriter().write(json);\n\n            return false;\n        &#125;\n\n        //6.放行\n        return true;\n    &#125;注册配置拦截器\njava@Configuration  \npublic class WebConfig implements WebMvcConfigurer &#123;\n    //拦截器对象\n    @Autowired\n    private LoginCheckInterceptor loginCheckInterceptor;\n\n    @Override\n    public void addInterceptors(InterceptorRegistry registry) &#123;\n       //注册自定义拦截器对象\n        registry.addInterceptor(loginCheckInterceptor)\n                .addPathPatterns(&quot;/**&quot;)\n                .excludePathPatterns(&quot;/login&quot;);\n    &#125;\n&#125;\n登录校验的拦截器编写完成后，接下来我们就可以重新启动服务来做一个测试： （关闭登录校验Filter过滤器）\n\n测试1：未登录是否可以访问部门管理页面\n首先关闭浏览器，重新打开浏览器，在地址栏中输入：http://localhost:9528/#/system/dept\n由于用户没有登录，校验机制返回错误信息，前端页面根据返回的错误信息结果，自动跳转到登录页面了\n\n\n测试2：先进行登录操作，再访问部门管理页面\n登录校验成功之后，可以正常访问相关业务操作页面\n\n\n\n到此我们也就验证了所开发的登录校验的拦截器也是没问题的。登录校验的过滤器和拦截器，我们只需要使用其中的一种就可以了。\n10.异常处理10.1 当前问题登录功能和登录校验功能我们都实现了，下面我们学习下今天最后一块技术点：异常处理。首先我们先来看一下系统出现异常之后会发生什么现象，再来介绍异常处理的方案。\n我们打开浏览器，访问系统中的新增部门操作，系统中已经有了 “就业部” 这个部门，我们再来增加一个就业部，看看会发生什么现象。\n   \n\n点击确定之后，窗口关闭了，页面没有任何反应，就业部也没有添加上。 而此时，大家会发现，网络请求报错了。\n \n\n状态码为500，表示服务器端异常，我们打开idea，来看一下，服务器端出了什么问题。\n \n上述错误信息的含义是，dept部门表的name字段的值 就业部 重复了，因为在数据库表dept中已经有了就业部，我们之前设计这张表时，为name字段建议了唯一约束，所以该字段的值是不能重复的。\n而当我们再添加就业部，这个部门时，就违反了唯一约束，此时就会报错。\n我们来看一下出现异常之后，最终服务端给前端响应回来的数据长什么样。\n \n响应回来的数据是一个JSON格式的数据。但这种JSON格式的数据还是我们开发规范当中所提到的统一响应结果Result吗？显然并不是。由于返回的数据不符合开发规范，所以前端并不能解析出响应的JSON数据。\n接下来我们需要思考的是出现异常之后，当前案例项目的异常是怎么处理的？\n\n答案：没有做任何的异常处理\n\n\n当我们没有做任何的异常处理时，我们三层架构处理异常的方案：\n\nMapper接口在操作数据库的时候出错了，此时异常会往上抛(谁调用Mapper就抛给谁)，会抛给service。 \nservice 中也存在异常了，会抛给controller。\n而在controller当中，我们也没有做任何的异常处理，所以最终异常会再往上抛。最终抛给框架之后，框架就会返回一个JSON格式的数据，里面封装的就是错误的信息，但是框架返回的JSON格式的数据并不符合我们的开发规范。\n\n3.2 解决方案那么在三层构架项目中，出现了异常，该如何处理?\n\n方案一：在所有Controller的所有方法中进行try…catch处理\n缺点：代码臃肿（不推荐）\n\n\n方案二：全局异常处理器\n好处：简单、优雅（推荐）\n\n\n\n\n3.3 全局异常处理器我们该怎么样定义全局异常处理器？\n\n定义全局异常处理器非常简单，就是定义一个类，在类上加上一个注解@RestControllerAdvice，加上这个注解就代表我们定义了一个全局异常处理器。\n在全局异常处理器当中，需要定义一个方法来捕获异常，在这个方法上需要加上注解@ExceptionHandler。通过@ExceptionHandler注解当中的value属性来指定我们要捕获的是哪一类型的异常。\n\njava@RestControllerAdvice\npublic class GlobalExceptionHandler &#123;\n\n    //处理异常\n    @ExceptionHandler(Exception.class) //指定能够处理的异常类型\n    public Result ex(Exception e)&#123;\n        e.printStackTrace();//打印堆栈中的异常信息\n\n        //捕获到异常之后，响应一个标准的Result\n        return Result.error(&quot;对不起,操作失败,请联系管理员&quot;);\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n@RestControllerAdvice &#x3D; @ControllerAdvice + @ResponseBody\n处理异常的方法返回值会转换为json后再响应给前端\n重新启动SpringBoot服务，打开浏览器，再来测试一下添加部门这个操作，我们依然添加已存在的 “就业部” 这个部门：\n \n \n此时，我们可以看到，出现异常之后，异常已经被全局异常处理器捕获了。然后返回的错误信息，被前端程序正常解析，然后提示出了对应的错误提示信息。\n以上就是全局异常处理器的使用，主要涉及到两个注解：\n\n@RestControllerAdvice  &#x2F;&#x2F;表示当前类为全局异常处理器\n@ExceptionHandler  &#x2F;&#x2F;指定可以捕获哪种类型的异常进行处理\n\n","slug":"Springboot学习2","date":"2024-02-11T08:42:10.000Z","categories_index":"Study","tags_index":"Java,SpringBoot","author_index":"Fioransh"},{"id":"f7169ad15bb8eef1b79f5633a9ccf533","title":"SpringBoot知识点总结（一）","content":"1.SpingBoot入门1.1 什么是SpringSpring的官网(https://spring.io)，去看一下Spring的简介：Spring makes Java simple。\nSpring的官方提供很多开源的项目，我们可以点击上面的projects，看到spring家族旗下的项目，按照流行程度排序为：\n\nSpring发展到今天已经形成了一种开发生态圈，Spring提供了若干个子项目，每个项目用于完成特定的功能。而我们在项目开发时，一般会偏向于选择这一套spring家族的技术，来解决对应领域的问题，那我们称这一套技术为spring全家桶。\n\n而Spring家族旗下这么多的技术，最基础、最核心的是 SpringFramework。其他的spring家族的技术，都是基于SpringFramework的，SpringFramework中提供很多实用功能，如：依赖注入、事务管理、web开发支持、数据访问、消息服务等等。\n\n而如果我们在项目中，直接基于SpringFramework进行开发，存在两个问题：配置繁琐、入门难度大。 \n\n所以基于此呢，spring官方推荐我们从另外一个项目开始学习，那就是目前最火爆的SpringBoot。 \nSpring Boot 可以帮助我们非常快速的构建应用程序、简化开发、提高效率 。\n1.2 SpringBootWeb快速入门1.2.1 开发步骤第1步：创建SpringBoot工程项目\n第2步：定义HelloController类，添加方法hello，并添加注解\n第3步：测试运行\n基于Spring官方骨架，创建SpringBoot工程。\n\n\n基本信息描述完毕之后，勾选web开发相关依赖。\n\n\n点击Finish之后，就会联网创建这个SpringBoot工程，创建好之后，结构如下：\n\n&#x3D;&#x3D;注意：在联网创建过程中，会下载相关资源(请耐心等待)&#x3D;&#x3D;\n\n \n定义请求处理类\n在com.itheima这个包下创建一个子包controller\n\n\n然后在controller包下新建一个类：HelloController\n\n\n运行SpringBoot自动生成的引导类\n\n打开浏览器，输入 http://localhost:8080/hello\n1.3 Web分析浏览器：\n\n输入网址：http://192.168.100.11:8080/hello\n\n通过IP地址192.168.100.11定位到网络上的一台计算机\n\n\n\n\n\n\n\n\n\n我们之前在浏览器中输入的localhost，就是127.0.0.1（本机）\n\n通过端口号8080找到计算机上运行的程序\n\n\n\n\n\n\n\n\n\nlocalhost:8080  , 意思是在本地计算机中找到正在运行的8080端口的程序\n\n&#x2F;hello是请求资源位置\n\n资源：对计算机而言资源就是数据\nweb资源：通过网络可以访问到的资源（通常是指存放在服务器上的数据）\n\n\n\n\n\n\n\n\n\n\n\n\nlocalhost:8080/hello ，意思是向本地计算机中的8080端口程序，获取资源位置是&#x2F;hello的数据\n\n8080端口程序，在服务器找&#x2F;hello位置的资源数据，发给浏览器\n\n\n\n\n\n服务器：（可以理解为ServerSocket）\n\n接收到浏览器发送的信息（如：&#x2F;hello）\n在服务器上找到&#x2F;hello的资源\n把资源发送给浏览器\n\n\n\n\n\n\n\n\n\n\n我们在JavaSE阶段学习网络编程时，有讲过网络三要素：\n\nIP  ：网络中计算机的唯一标识\n端口 ：计算机中运行程序的唯一标识\n协议 ：网络中计算机之间交互的规则\n\n2 HTTP协议2.1 HTTP概述HTTP：Hyper Text Transfer Protocol(超文本传输协议)，规定了浏览器与服务器之间数据传输的规则。\n\nhttp是互联网上应用最为广泛的一种网络协议 \nhttp协议要求：浏览器在向服务器发送请求数据时，或是服务器在向浏览器发送响应数据时，都必须按照固定的格式进行数据传输\n\n浏览器向服务器进行请求时：\n\n服务器按照固定的格式进行解析\n\n\n服务器向浏览器进行响应时：\n\n浏览器按照固定的格式进行解析\n\n\n我们刚才初步认识了HTTP协议，那么我们在看看HTTP协议有哪些特点：\n\n**基于TCP协议: **   面向连接，安全\n\n\n\n\n\n\n\n\n\nTCP是一种面向连接的(建立连接之前是需要经过三次握手)、可靠的、基于字节流的传输层通信协议，在数据传输方面更安全\n\n基于请求-响应模型:   一次请求对应一次响应（先请求后响应）\n\n\n\n\n\n\n\n\n\n请求和响应是一一对应关系，没有请求，就没有响应\n\nHTTP协议是无状态协议:  对于数据没有记忆能力。每次请求-响应都是独立的\n\n\n\n\n\n\n\n\n\n无状态指的是客户端发送HTTP请求给服务端之后，服务端根据请求响应数据，响应完后，不会记录任何信息。\n\n缺点:  多次请求间不能共享数据\n优点:  速度快\n\n请求之间无法共享数据会引发的问题：\n\n如：京东购物。加入购物车和去购物车结算是两次请求\n由于HTTP协议的无状态特性，加入购物车请求响应结束后，并未记录加入购物车是何商品\n发起去购物车结算的请求后，因为无法获取哪些商品加入了购物车，会导致此次请求无法正确展示数据\n\n具体使用的时候，我们发现京东是可以正常展示数据的，原因是Java早已考虑到这个问题，并提出了使用会话技术(Cookie、Session)来解决这个问题。\n\n\n2.2 HTTP-请求协议HTTP协议又分为：请求协议和响应协议\n\n请求协议：浏览器将数据以请求格式发送到服务器\n包括：请求行、请求头 、请求体\n\n\n响应协议：服务器将数据以响应格式返回给浏览器\n包括：响应行 、响应头 、响应体\n\n\n\n\n\n\n请求方式\n请求说明\n\n\n\nGET\n获取资源。向特定的资源发出请求。例：http://www.baidu.com/s?wd=itheima\n\n\nPOST\n传输实体主体。向指定资源提交数据进行处理请求（例：上传文件），数据被包含在请求体中。\n\n\nOPTIONS\n返回服务器针对特定资源所支持的HTTP请求方式。因为并不是所有的服务器都支持规定的方法，为了安全有些服务器可能会禁止掉一些方法，例如：DELETE、PUT等。那么OPTIONS就是用来询问服务器支持的方法。\n\n\nHEAD\n获得报文首部。HEAD方法类似GET方法，但是不同的是HEAD方法不要求返回数据。通常用于确认URI的有效性及资源更新时间等。\n\n\nPUT\n传输文件。PUT方法用来传输文件。类似FTP协议，文件内容包含在请求报文的实体中，然后请求保存到URL指定的服务器位置。\n\n\nDELETE\n删除文件。请求服务器删除Request-URI所标识的资源\n\n\nTRACE\n追踪路径。回显服务器收到的请求，主要用于测试或诊断\n\n\nCONNECT\n要求用隧道协议连接代理。HTTP&#x2F;1.1协议中预留给能够将连接改为管道方式的代理服务器\n\n\n在我们实际应用中常用的也就是 ：GET、POST\nGET方式的请求协议：\n \n\n请求行 ：HTTP请求中的第一行数据。由：请求方式、资源路径、协议/版本组成（之间使用空格分隔）\n\n请求方式：GET  \n资源路径：&#x2F;brand&#x2F;findAll?name&#x3D;OPPO&amp;status&#x3D;1\n请求路径：&#x2F;brand&#x2F;findAll\n请求参数：name&#x3D;OPPO&amp;status&#x3D;1\n请求参数是以key&#x3D;value形式出现\n多个请求参数之间使用&amp;连接\n\n\n请求路径和请求参数之间使用?连接\n\n \t\t\t \n\n协议&#x2F;版本：HTTP&#x2F;1.1\n\n\n请求头 ：第二行开始，上图黄色部分内容就是请求头。格式为key: value形式 \n\nhttp是个无状态的协议，所以在请求头设置浏览器的一些自身信息和想要响应的形式。这样服务器在收到信息后，就可以知道是谁，想干什么了\n\n常见的HTTP请求头有:\ntxtHost: 表示请求的主机名\n\nUser-Agent: 浏览器版本。 例如：Chrome浏览器的标识类似Mozilla/5.0 ...Chrome/79 ，IE浏览器的标识类似Mozilla/5.0 (Windows NT ...)like Gecko\n\nAccept：表示浏览器能接收的资源类型，如text/*，image/*或者*/*表示所有；\n\nAccept-Language：表示浏览器偏好的语言，服务器可以据此返回不同语言的网页；\n\nAccept-Encoding：表示浏览器可以支持的压缩类型，例如gzip, deflate等。\n\nContent-Type：请求主体的数据类型\n\nContent-Length：数据主体的大小（单位：字节）\n\n\n请求体 ：存储请求参数\nGET请求的请求参数在请求行中，故不需要设置请求体\n\n\n\nPOST方式的请求协议：\t\n\n\n请求行(以上图中红色部分)：包含请求方式、资源路径、协议&#x2F;版本\n请求方式：POST\n资源路径：&#x2F;brand\n协议&#x2F;版本：HTTP&#x2F;1.1\n\n\n请求头(以上图中黄色部分)   \n请求体(以上图中绿色部分) ：存储请求参数 \n请求体和请求头之间是有一个空行隔开（作用：用于标记请求头结束）\n\n\n\nGET请求和POST请求的区别：\n\n\n\n区别方式\nGET请求\nPOST请求\n\n\n\n请求参数\n请求参数在请求行中。例：&#x2F;brand&#x2F;findAll?name&#x3D;OPPO&amp;status&#x3D;1\n请求参数在请求体中\n\n\n请求参数长度\n请求参数长度有限制(浏览器不同限制也不同)\n请求参数长度没有限制\n\n\n安全性\n安全性低。原因：请求参数暴露在浏览器地址栏中。\n安全性相对高\n\n\n2.3 HTTP-响应协议与HTTP的请求一样，HTTP响应的数据也分为3部分：响应行、响应头 、响应体 \n \n\n响应行(以上图中红色部分)：响应数据的第一行。响应行由协议及版本、响应状态码、状态码描述组成\n\n协议&#x2F;版本：HTTP&#x2F;1.1\n响应状态码：200\n状态码描述：OK\n\n\n响应头(以上图中黄色部分)：响应数据的第二行开始。格式为key：value形式\n\nhttp是个无状态的协议，所以可以在请求头和响应头中设置一些信息和想要执行的动作，这样，对方在收到信息后，就可以知道你是谁，你想干什么\n\n常见的HTTP响应头有:\ntxtContent-Type：表示该响应内容的类型，例如text/html，image/jpeg ；\n\nContent-Length：表示该响应内容的长度（字节数）；\n\nContent-Encoding：表示该响应压缩算法，例如gzip ；\n\nCache-Control：指示客户端应如何缓存，例如max-age=300表示可以最多缓存300秒 ;\n\nSet-Cookie: 告诉浏览器为当前页面所在的域设置cookie ;\n\n\n响应体(以上图中绿色部分)： 响应数据的最后一部分。存储响应的数据\n\n响应体和响应头之间有一个空行隔开（作用：用于标记响应头结束）\n\n\nServerSocket程序，会读取服务器上html/a.html文件，并把文件数据发送给浏览器\n\n浏览器接收到a.html文件中的数据后进行解析，显示以下内容\n\n\n现在大家知道了服务器是可以使用java完成编写，是可以接受页面发送的请求和响应数据给前端浏览器的，而在开发中真正用到的Web服务器，我们不会自己写的，都是使用目前比较流行的web服务器。如：Tomcat\n3.WEB服务器-Tomcat3.1 介绍服务器硬件\n\n指的也是计算机，只不过服务器要比我们日常使用的计算机大很多。\n\n服务器，也称伺服器。是提供计算服务的设备。由于服务器需要响应服务请求，并进行处理，因此一般来说服务器应具备承担服务并且保障服务的能力。\n服务器的构成包括处理器、硬盘、内存、系统总线等，和通用的计算机架构类似，但是由于需要提供高可靠的服务，因此在处理能力、稳定性、可靠性、安全性、可扩展性、可管理性等方面要求较高。\n在网络环境下，根据服务器提供的服务类型不同，可分为：文件服务器，数据库服务器，应用程序服务器，WEB服务器等。\n服务器只是一台设备，必须安装服务器软件才能提供相应的服务。\n服务器软件\n服务器软件：基于ServerSocket编写的程序\n\n服务器软件本质是一个运行在服务器设备上的应用程序\n能够接收客户端请求，并根据请求给客户端响应数据\n\n3.2 Web服务器Web服务器是一个应用程序(软件)，对HTTP协议的操作进行封装，使得程序员不必直接对协议进行操作(不用程序员自己写代码去解析http协议规则)，让Web开发更加便捷。主要功能是”提供网上信息浏览服务”。\n\nWeb服务器是安装在服务器端的一款软件，将来我们把自己写的Web项目部署到Tomcat服务器软件中，当Web服务器软件启动后，部署在Web服务器软件中的页面就可以直接通过浏览器来访问了。\nWeb服务器软件使用步骤\n\n准备静态资源\n下载安装Web服务器软件\n将静态资源部署到Web服务器上\n启动Web服务器使用浏览器访问对应的资源\n\n第1步：准备静态资源\n\n在提供的资料中找到静态资源文件\n\n \n第2步：下载安装Web服务器软件\n\n第3步：将静态资源部署到Web服务器上\n\n第4步：启动Web服务器使用浏览器访问对应的资源\n\n浏览器输入：http://localhost:8080/demo/index.html\n\n上述内容在演示的时候，使用的是Apache下的Tomcat软件，至于Tomcat软件如何使用，后面会详细的讲到。而对于Web服务器来说，实现的方案有很多，Tomcat只是其中的一种，而除了Tomcat以外，还有很多优秀的Web服务器，比如:\n\n3.3 Tomcat3.3.1 介绍Tomcat服务器软件是一个免费的开源的web应用服务器。是Apache软件基金会的一个核心项目。由Apache，Sun和其他一些公司及个人共同开发而成。\n由于Tomcat只支持Servlet&#x2F;JSP少量JavaEE规范，所以是一个开源免费的轻量级Web服务器。\n因为Tomcat支持Servlet&#x2F;JSP规范，所以Tomcat也被称为Web容器、Servlet容器。JavaWeb程序需要依赖Tomcat才能运行。\nTomcat的官网: https://tomcat.apache.org/ \n3.3.2 基本使用直接从官方网站下载：https://tomcat.apache.org/download-90.cgi\n安装: Tomcat是绿色版，直接解压即安装\n&#x3D;&#x3D;注意，Tomcat在解压缩的时候，解压所在的目录可以任意，但最好解压到一个不包含中文和空格的目录，因为后期在部署项目的时候，如果路径有中文或者空格可能会导致程序部署失败。&#x3D;&#x3D;\n打开apache-tomcat-9.0.27目录就能看到如下目录结构，每个目录中包含的内容需要认识下\n  \nbin：目录下有两类文件，一种是以.bat结尾的，是Windows系统的可执行文件，一种是以.sh结尾的，是Linux系统的可执行文件。\nwebapps：就是以后项目部署的目录\n卸载：卸载比较简单，可以直接删除目录即可\n启动Tomcat \n\n双击tomcat解压目录&#x2F;bin&#x2F;startup.bat文件即可启动tomcat\n\n\n&#x3D;&#x3D;注意: tomcat服务器启动后,黑窗口不会关闭,只要黑窗口不关闭,就证明tomcat服务器正在运行&#x3D;&#x3D;\nTomcat的默认端口为8080，所以在浏览器的地址栏输入：http://127.0.0.1:8080 即可访问tomcat服务器\n&#x3D;&#x3D;注意事项&#x3D;&#x3D; ：Tomcat启动的过程中，遇到控制台有中文乱码时，可以通常修改conf&#x2F;logging.prooperties文件解决\n\n关闭:  关闭有三种方式 \n1、强制关闭：直接x掉Tomcat窗口（不建议）\n2、正常关闭：bin\\shutdown.bat\n3、正常关闭：在Tomcat启动窗口中按下 Ctrl+C\n3.3.3 常见问题问题1：Tomcat启动时，窗口一闪而过\n\n检查JAVA_HOME环境变量是否正确配置\n\n问题2：端口号冲突\n\n发生问题的原因：Tomcat使用的端口被占用了。\n\n解决方案：换Tomcat端口号\n\n要想修改Tomcat启动的端口号，需要修改 conf&#x2F;server.xml文件\n\n\n\n3.4 入门程序3.4.1 Spring官方骨架之前我们创建的SpringBoot入门案例，是基于Spring官方提供的骨架实现的。\nSpring官方骨架，可以理解为Spring官方为程序员提供一个搭建项目的模板。\n我们可以通过访问：https://start.spring.io/ ，进入到官方骨架页面\n\n\n\nSpring官方生成的SpringBoot项目，怎么使用呢？\n\n解压缩后，就会得到一个SpringBoot项目工程\n\n\n\n打开pom.xml文件，我们可以看到springboot项目中引入了web依赖和test依赖\n\n\n\n\n\n\n\n\n\n\n结论：不论使用IDEA创建SpringBoot项目，还是直接在官方网站利用骨架生成SpringBoot项目，项目的结构和pom.xml文件中内容是相似的。\n3.4.2 起步依赖在我们之前讲解的SpringBoot快速入门案例中，同样也引用了：web依赖和test依赖\n\nspring-boot-starter-web和spring-boot-starter-test，在SpringBoot中又称为：起步依赖\n而在SpringBoot的项目中，有很多的起步依赖，他们有一个共同的特征：就是以spring-boot-starter-作为开头。在以后大家遇到spring-boot-starter-xxx这类的依赖，都为起步依赖。\n起步依赖有什么特殊之处呢，这里我们以入门案例中引入的起步依赖做为讲解：\n\nspring-boot-starter-web：包含了web应用开发所需要的常见依赖\nspring-boot-starter-test：包含了单元测试所需要的常见依赖\n\n\n\n\n\n\n\n\n\n\nspring-boot-starter-web内部把关于Web开发所有的依赖都已经导入并且指定了版本，只需引入 spring-boot-starter-web 依赖就可以实现Web开发的需要的功能\n\nSpring的官方提供了很多现成的starter(起步依赖)，我们在开发相关应用时，只需要引入对应的starter即可。\n官方地址：https://docs.spring.io/spring-boot/docs/2.7.2/reference/htmlsingle/#using.build-systems.starters\n每一个起步依赖，都用于开发一个特定的功能。\n\n\n\n\n\n\n\n\n\n举例：当我们开发中需要使用redis数据库时，只需要在SpringBoot项目中，引入：spring-boot-starter-redis ，即可导入redis开发所需要的依赖。\n3.4.3 SpringBoot父工程在我们之前开发的SpringBoot入门案例中，我们通过maven引入的依赖，是没有指定具体的依赖版本号的。\n\n为什么没有指定版本号，可以正常使用呢？\n\n因为每一个SpringBoot工程，都有一个父工程。依赖的版本号，在父工程中统一管理。\n\n\n3.4.4 内嵌Tomcat问题：为什么我们之前书写的SpringBoot入门程序中，并没有把程序部署到Tomcat的webapps目录下，也可以运行呢？\n原因呢，是因为在我们的SpringBoot中，引入了web运行环境(也就是引入spring-boot-starter-web起步依赖)，其内部已经集成了内置的Tomcat服务器。\n我们可以通过IDEA开发工具右侧的maven面板中，就可以看到当前工程引入的依赖。其中已经将Tomcat的相关依赖传递下来了，也就是说在SpringBoot中可以直接使用Tomcat服务器。\n \n当我们运行SpringBoot的引导类时(运行main方法)，就会看到命令行输出的日志，其中占用8080端口的就是Tomcat。\n\n4.SpringBoot请求4.1 BS架构我们在浏览器发起请求，请求了我们的后端web服务器(也就是内置的Tomcat)。而我们在开发web程序时呢，定义了一个控制器类Controller，请求会被部署在Tomcat中的Controller接收，然后Controller再给浏览器一个响应，响应一个字符串 “Hello World”。 而在请求响应的过程中是遵循HTTP协议的。\n但是呢，这里要告诉大家的时，其实在Tomcat这类Web服务器中，是不识别我们自己定义的Controller的。但是我们前面讲到过Tomcat是一个Servlet容器，是支持Serlvet规范的，所以呢，在tomcat中是可以识别 Servlet程序的。 那我们所编写的XxxController 是如何处理请求的，又与Servlet之间有什么联系呢？\n其实呢，在SpringBoot进行web程序开发时，它内置了一个核心的Servlet程序 DispatcherServlet，称之为 核心控制器。 DispatcherServlet 负责接收页面发送的请求，然后根据执行的规则，将请求再转发给后面的请求处理器Controller，请求处理器处理完请求之后，最终再由DispatcherServlet给浏览器响应数据。\n那将来浏览器发送请求，会携带请求数据，包括：请求行、请求头；请求到达tomcat之后，tomcat会负责解析这些请求数据，然后呢将解析后的请求数据会传递给Servlet程序的HttpServletRequest对象，那也就意味着 HttpServletRequest 对象就可以获取到请求数据。 而Tomcat，还给Servlet程序传递了一个参数 HttpServletResponse，通过这个对象，我们就可以给浏览器设置响应数据 。\n \n那上述所描述的这种浏览器&#x2F;服务器的架构模式呢，我们称之为：BS架构。\n \n• BS架构：Browser&#x2F;Server，浏览器&#x2F;服务器架构模式。客户端只需要浏览器，应用程序的逻辑和数据都存储在服务端。\n4.2 Postman4.2.1 入门前后端分离这种模式下，前端技术人员基于”接口文档”，开发前端程序；后端技术人员也基于”接口文档”，开发后端程序。\n方式1：像之前SpringBoot入门案例中一样，直接使用浏览器。在浏览器中输入地址，测试后端程序。\n\n弊端：在浏览器地址栏中输入地址这种方式都是GET请求，如何我们要用到POST请求怎么办呢？\n要解决POST请求，需要程序员自己编写前端代码（比较麻烦）\n\n\n\n方式2：使用专业的接口测试工具（课程中我们使用Postman工具）\n\nPostman是一款功能强大的网页调试与发送网页HTTP请求的Chrome插件。\n\n\n\n\n\n\n\n\n\nPostman原是Chrome浏览器的插件，可以模拟浏览器向后端服务器发起任何形式(如:get、post)的HTTP请求\n使用Postman还可以在发起请求时，携带一些请求参数、请求头等信息\n\n作用：常用于进行接口测试\n\n\n界面介绍:\n\n4.2.2 简单参数传递简单参数：在向服务器发起请求时，向服务器传递的是一些普通的请求数据。\n\n那么在后端程序中，如何接收传递过来的普通参数数据呢？我们在这里讲解两种方式：\n\n原始方式\n\n在原始的Web程序当中，需要通过Servlet中提供的API：HttpServletRequest（请求对象），获取请求的相关信息。比如获取请求参数：\n\n\n\n\n\n\n\n\n\nTomcat接收到http请求时：把请求的相关信息封装到HttpServletRequest对象中\n在Controller中，我们要想获取Request对象，可以直接在方法的形参中声明 HttpServletRequest 对象。然后就可以通过该对象来获取请求信息。\n\nSpringBoot方式\n\n在Springboot的环境中，对原始的API进行了封装，接收参数的形式更加简单。 如果是简单参数，参数名与形参变量名相同，定义同名的形参即可接收参数。\njava@RestController\npublic class RequestController &#123;\n    // http://localhost:8080/simpleParam?name=Tom&amp;age=10\n    // 第1个请求参数： name=Tom   参数名:name，参数值:Tom\n    // 第2个请求参数： age=10     参数名:age , 参数值:10\n    \n    //springboot方式\n    @RequestMapping(&quot;/simpleParam&quot;)\n    public String simpleParam(String name , Integer age )&#123;//形参名和请求参数名保持一致\n        System.out.println(name+&quot;  :  &quot;+age);\n        return &quot;OK&quot;;\n    &#125;\n&#125;postman测试( GET 请求)：\n \npostman测试( POST请求 )：\n\n\n\n\n\n\n\n\n\n\n结论：不论是GET请求还是POST请求，对于简单参数来讲，只要保证&#x3D;&#x3D;请求参数名和Controller方法中的形参名保持一致&#x3D;&#x3D;，就可以获取到请求参数中的数据值。\n对于简单参数来讲，请求参数名和controller方法中的形参名不一致时，无法接收到请求数据\n那么如果我们开发中，遇到了这种请求参数名和controller方法中的形参名不相同，怎么办？\n解决方案：可以使用Spring提供的@RequestParam注解完成映射\n在方法形参前面加上 @RequestParam 然后通过value属性执行请求参数名，从而完成映射。代码如下：\njava@RestController\npublic class RequestController &#123;\n    // http://localhost:8080/simpleParam?name=Tom&amp;age=20\n    // 请求参数名：name\n\n    //springboot方式\n    @RequestMapping(&quot;/simpleParam&quot;)\n    public String simpleParam(@RequestParam(&quot;name&quot;) String username , Integer age )&#123;\n        System.out.println(username+&quot;  :  &quot;+age);\n        return &quot;OK&quot;;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n注意事项：\n@RequestParam中的required属性默认为true（默认值也是true），代表该请求参数必须传递，如果不传递将报错\n\n如果该参数是可选的，可以将required属性设置为false\njava@RequestMapping(&quot;/simpleParam&quot;)\npublic String simpleParam(@RequestParam(name = &quot;name&quot;, required = false) String username, Integer age)&#123;\nSystem.out.println(username+ &quot;:&quot; + age);\nreturn &quot;OK&quot;;\n&#125;\n4.2.3 实体参数在使用简单参数做为数据传递方式时，前端传递了多少个请求参数，后端controller方法中的形参就要书写多少个。如果请求参数比较多，通过上述的方式一个参数一个参数的接收，会比较繁琐。 \n此时，我们可以考虑将请求参数封装到一个实体类对象中。 要想完成数据封装，需要遵守如下规则：请求参数名与实体类的属性名相同\n\n简单实体对象\n定义POJO实体类：\njavapublic class User &#123;\n    private String name;\n    private Integer age;\n\n    public String getName() &#123;\n        return name;\n    &#125;\n\n    public void setName(String name) &#123;\n        this.name = name;\n    &#125;\n\n    public Integer getAge() &#123;\n        return age;\n    &#125;\n\n    public void setAge(Integer age) &#123;\n        this.age = age;\n    &#125;\n\n    @Override\n    public String toString() &#123;\n        return &quot;User&#123;&quot; +\n                &quot;name=&#39;&quot; + name + &#39;\\&#39;&#39; +\n                &quot;, age=&quot; + age +\n                &#39;&#125;&#39;;\n    &#125;\n&#125;\nController方法：\njava@RestController\npublic class RequestController &#123;\n    //实体参数：简单实体对象\n    @RequestMapping(&quot;/simplePojo&quot;)\n    public String simplePojo(User user)&#123;\n        System.out.println(user);\n        return &quot;OK&quot;;\n    &#125;\n&#125;Postman测试：\n\n参数名和实体类属性名一致时\n\n \n\n参数名和实体类属性名不一致时\n\n\n复杂实体对象\n复杂实体对象指的是，在实体类中有一个或多个属性，也是实体对象类型的。如下：\n\nUser类中有一个Address类型的属性（Address是一个实体类）\n\n\n复杂实体对象的封装，需要遵守如下规则：\n\n请求参数名与形参对象属性名相同，按照对象层次结构关系即可接收嵌套实体类属性参数。\n\n定义POJO实体类：\n\nAddress实体类\n\njavapublic class Address &#123;\n    private String province;\n    private String city;\n\n    public String getProvince() &#123;\n        return province;\n    &#125;\n\n    public void setProvince(String province) &#123;\n        this.province = province;\n    &#125;\n\n    public String getCity() &#123;\n        return city;\n    &#125;\n\n    public void setCity(String city) &#123;\n        this.city = city;\n    &#125;\n\n    @Override\n    public String toString() &#123;\n        return &quot;Address&#123;&quot; +\n                &quot;province=&#39;&quot; + province + &#39;\\&#39;&#39; +\n                &quot;, city=&#39;&quot; + city + &#39;\\&#39;&#39; +\n                &#39;&#125;&#39;;\n    &#125;\n&#125;\nUser实体类\n\njavapublic class User &#123;\n    private String name;\n    private Integer age;\n    private Address address; //地址对象\n\n    public String getName() &#123;\n        return name;\n    &#125;\n\n    public void setName(String name) &#123;\n        this.name = name;\n    &#125;\n\n    public Integer getAge() &#123;\n        return age;\n    &#125;\n\n    public void setAge(Integer age) &#123;\n        this.age = age;\n    &#125;\n\n    public Address getAddress() &#123;\n        return address;\n    &#125;\n\n    public void setAddress(Address address) &#123;\n        this.address = address;\n    &#125;\n\n    @Override\n    public String toString() &#123;\n        return &quot;User&#123;&quot; +\n                &quot;name=&#39;&quot; + name + &#39;\\&#39;&#39; +\n                &quot;, age=&quot; + age +\n                &quot;, address=&quot; + address +\n                &#39;&#125;&#39;;\n    &#125;\n&#125;Controller方法：\njava@RestController\npublic class RequestController &#123;\n    //实体参数：复杂实体对象\n    @RequestMapping(&quot;/complexPojo&quot;)\n    public String complexPojo(User user)&#123;\n        System.out.println(user);\n        return &quot;OK&quot;;\n    &#125;\n&#125;Postman测试：\n \n4.2.4 数组集合参数数组集合参数的使用场景：在HTML的表单中，有一个表单项是支持多选的(复选框)，可以提交选择的多个值。\n多个值是怎么提交的呢？其实多个值也是一个一个的提交。\n \n后端程序接收上述多个值的方式有两种：\n\n数组\n集合\n\n数组\n数组参数：请求参数名与形参数组名称相同且请求参数为多个，定义数组类型形参即可接收参数\n\nController方法：\njava@RestController\npublic class RequestController &#123;\n    //数组集合参数\n    @RequestMapping(&quot;/arrayParam&quot;)\n    public String arrayParam(String[] hobby)&#123;\n        System.out.println(Arrays.toString(hobby));\n        return &quot;OK&quot;;\n    &#125;\n&#125;在前端请求时，有两种传递形式：\n方式一： xxxxxxxxxx?hobby&#x3D;game&amp;hobby&#x3D;java\n方式二：xxxxxxxxxxxxx?hobby&#x3D;game,java\n集合\n集合参数：请求参数名与形参集合对象名相同且请求参数为多个，@RequestParam 绑定参数关系\n\n默认情况下，请求中参数名相同的多个值，是封装到数组。如果要封装到集合，要使用@RequestParam绑定参数关系\n\nController方法：\njava@RestController\npublic class RequestController &#123;\n    //数组集合参数\n    @RequestMapping(&quot;/listParam&quot;)\n    public String listParam(@RequestParam List&lt;String&gt; hobby)&#123;\n        System.out.println(hobby);\n        return &quot;OK&quot;;\n    &#125;\n&#125;方式一： xxxxxxxxxx?hobby&#x3D;game&amp;hobby&#x3D;java\n方式二：xxxxxxxxxxxxx?hobby&#x3D;game,java\n4.2.5 日期参数上述演示的都是一些普通的参数，在一些特殊的需求中，可能会涉及到日期类型数据的封装。比如，如下需求：\n \n因为日期的格式多种多样（如：2022-12-12 10:05:45 、2022&#x2F;12&#x2F;12 10:05:45），那么对于日期类型的参数在进行封装的时候，需要通过@DateTimeFormat注解，以及其pattern属性来设置日期的格式。\n\n\n@DateTimeFormat注解的pattern属性中指定了哪种日期格式，前端的日期参数就必须按照指定的格式传递。\n后端controller方法中，需要使用Date类型或LocalDateTime类型，来封装传递的参数。\n\nController方法：\njava@RestController\npublic class RequestController &#123;\n    //日期时间参数\n   @RequestMapping(&quot;/dateParam&quot;)\n    public String dateParam(@DateTimeFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;) LocalDateTime updateTime)&#123;\n        System.out.println(updateTime);\n        return &quot;OK&quot;;\n    &#125;\n&#125;Postman测试：\n\n4.2.6 JSON参数在学习前端技术时，我们有讲到过JSON，而在前后端进行交互时，如果是比较复杂的参数，前后端通过会使用JSON格式的数据进行传输。 （JSON是开发中最常用的前后端数据交互方式）\n我们学习JSON格式参数，主要从以下两个方面着手：\n\nPostman在发送请求时，如何传递json格式的请求参数\n在服务端的controller方法中，如何接收json格式的请求参数\n\nPostman发送JSON格式数据：\n\n服务端Controller方法接收JSON格式数据：\n\n传递json格式的参数，在Controller中会使用实体类进行封装。 \n封装规则：JSON数据键名与形参对象属性名相同，定义POJO类型形参即可接收参数。需要使用 @RequestBody标识。\n\n\n\n@RequestBody注解：将JSON数据映射到形参的实体类对象中（JSON中的key和实体类中的属性名保持一致）\n\n实体类：Address\njavapublic class Address &#123;\n    private String province;\n    private String city;\n    \n    //省略GET , SET 方法\n&#125;实体类：User\njavapublic class User &#123;\n    private String name;\n    private Integer age;\n    private Address address;\n    \n    //省略GET , SET 方法\n&#125;    Controller方法：\njava@RestController\npublic class RequestController &#123;\n    //JSON参数\n    @RequestMapping(&quot;/jsonParam&quot;)\n    public String jsonParam(@RequestBody User user)&#123;\n        System.out.println(user);\n        return &quot;OK&quot;;\n    &#125;\n&#125;Postman测试：\n \n4.2.7 路径参数传统的开发中请求参数是放在请求体(POST请求)传递或跟在URL后面通过?key&#x3D;value的形式传递(GET请求)。\n\n在现在的开发中，经常还会直接在请求的URL中传递参数。例如：\ntxthttp://localhost:8080/user/1\t\t\nhttp://localhost:880/user/1/0上述的这种传递请求参数的形式呢，我们称之为：路径参数。\n学习路径参数呢，主要掌握在后端的controller方法中，如何接收路径参数。\n路径参数：\n\n前端：通过请求URL直接传递参数\n后端：使用{…}来标识该路径参数，需要使用@PathVariable获取路径参数\n\n\nController方法：\njava@RestController\npublic class RequestController &#123;\n    //路径参数\n    @RequestMapping(&quot;/path/&#123;id&#125;&quot;)\n    public String pathParam(@PathVariable Integer id)&#123;\n        System.out.println(id);\n        return &quot;OK&quot;;\n    &#125;\n&#125;Postman测试：\n\n传递多个路径参数：\nPostman：\n\nController方法：\njava@RestController\npublic class RequestController &#123;\n    //路径参数\n    @RequestMapping(&quot;/path/&#123;id&#125;/&#123;name&#125;&quot;)\n    public String pathParam2(@PathVariable Integer id, @PathVariable String name)&#123;\n        System.out.println(id+ &quot; : &quot; +name);\n        return &quot;OK&quot;;\n    &#125;\n&#125;5.SpringBoot响应5.1 ResponseBody注解前面我们学习过HTTL协议的交互方式：请求响应模式（有请求就有响应）\n那么Controller程序呢，除了接收请求外，还可以进行响应。\n在我们前面所编写的controller方法中，都已经设置了响应数据。\n\ncontroller方法中的return的结果，怎么就可以响应给浏览器呢？\n答案：使用@ResponseBody注解\n@ResponseBody注解：\n\n类型：方法注解、类注解\n位置：书写在Controller方法上或类上\n作用：将方法返回值直接响应给浏览器\n如果返回值类型是实体对象&#x2F;集合，将会转换为JSON格式后在响应给浏览器\n\n\n\n但是在我们所书写的Controller中，只在类上添加了@RestController注解、方法添加了@RequestMapping注解，并没有使用@ResponseBody注解，怎么给浏览器响应呢？\njava@RestController\npublic class HelloController &#123;\n    @RequestMapping(&quot;/hello&quot;)\n    public String hello()&#123;\n        System.out.println(&quot;Hello World ~&quot;);\n        return &quot;Hello World ~&quot;;\n    &#125;\n&#125;原因：在类上添加的@RestController注解，是一个组合注解。\n\n@RestController &#x3D; @Controller + @ResponseBody \n\n类上有@RestController注解或@ResponseBody注解时：表示当前类下所有的方法返回值做为响应数据\n\n方法的返回值，如果是一个POJO对象或集合时，会先转换为JSON格式，在响应给浏览器\n\n\n\n5.2 统一响应结果在真实的项目开发中，无论是哪种方法，我们都会定义一个统一的返回结果。方案如下：\n\n\n\n\n\n\n\n\n\n\n前端：只需要按照统一格式的返回结果进行解析(仅一种解析方案)，就可以拿到数据。\n统一的返回结果使用类来描述，在这个结果中包含：\n\n响应状态码：当前请求是成功，还是失败\n\n状态码信息：给页面的提示信息\n\n返回的数据：给前端响应的数据（字符串、对象、集合）\n\n\n定义在一个实体类Result来包含以上信息。代码如下：\njavapublic class Result &#123;\n    private Integer code;//响应码，1 代表成功; 0 代表失败\n    private String msg;  //响应码 描述字符串\n    private Object data; //返回的数据\n\n    public Result() &#123; &#125;\n    public Result(Integer code, String msg, Object data) &#123;\n        this.code = code;\n        this.msg = msg;\n        this.data = data;\n    &#125;\n\n    public Integer getCode() &#123;\n        return code;\n    &#125;\n\n    public void setCode(Integer code) &#123;\n        this.code = code;\n    &#125;\n\n    public String getMsg() &#123;\n        return msg;\n    &#125;\n\n    public void setMsg(String msg) &#123;\n        this.msg = msg;\n    &#125;\n\n    public Object getData() &#123;\n        return data;\n    &#125;\n\n    public void setData(Object data) &#123;\n        this.data = data;\n    &#125;\n\n    //增删改 成功响应(不需要给前端返回数据)\n    public static Result success()&#123;\n        return new Result(1,&quot;success&quot;,null);\n    &#125;\n    //查询 成功响应(把查询结果做为返回数据响应给前端)\n    public static Result success(Object data)&#123;\n        return new Result(1,&quot;success&quot;,data);\n    &#125;\n    //失败响应\n    public static Result error(String msg)&#123;\n        return new Result(0,msg,null);\n    &#125;\n&#125;改造Controller：\njava@RestController\npublic class ResponseController &#123; \n    //响应统一格式的结果\n    @RequestMapping(&quot;/hello&quot;)\n    public Result hello()&#123;\n        System.out.println(&quot;Hello World ~&quot;);\n        //return new Result(1,&quot;success&quot;,&quot;Hello World ~&quot;);\n        return Result.success(&quot;Hello World ~&quot;);\n    &#125;\n\n    //响应统一格式的结果\n    @RequestMapping(&quot;/getAddr&quot;)\n    public Result getAddr()&#123;\n        Address addr = new Address();\n        addr.setProvince(&quot;广东&quot;);\n        addr.setCity(&quot;深圳&quot;);\n        return Result.success(addr);\n    &#125;\n\n    //响应统一格式的结果\n    @RequestMapping(&quot;/listAddr&quot;)\n    public Result listAddr()&#123;\n        List&lt;Address&gt; list = new ArrayList&lt;&gt;();\n\n        Address addr = new Address();\n        addr.setProvince(&quot;广东&quot;);\n        addr.setCity(&quot;深圳&quot;);\n\n        Address addr2 = new Address();\n        addr2.setProvince(&quot;陕西&quot;);\n        addr2.setCity(&quot;西安&quot;);\n\n        list.add(addr);\n        list.add(addr2);\n        return Result.success(list);\n    &#125;\n&#125;6.分层解耦6.1 三层架构在我们进行程序设计以及程序开发时，尽可能让每一个接口、类、方法的职责更单一些（单一职责原则）。\n\n\n\n\n\n\n\n\n\n单一职责原则：一个类或一个方法，就只做一件事情，只管一块功能。\n这样就可以让类、接口、方法的复杂度更低，可读性更强，扩展性更好，也更利用后期的维护。\n从组成上看可以分为三个部分：\n\n数据访问：负责业务数据的维护操作，包括增、删、改、查等操作。\n逻辑处理：负责业务逻辑处理的代码。\n请求处理、响应数据：负责，接收页面的请求，给页面响应数据。\n\n按照上述的三个组成部分，在我们项目开发中呢，可以将代码分为三层：\n\nController：控制层。接收前端发送的请求，对请求进行处理，并响应数据。\nService：业务逻辑层。处理具体的业务逻辑。\nDao：数据访问层(Data Access Object)，也称为持久层。负责数据访问操作，包括数据的增、删、改、查。\n\n基于三层架构的程序执行流程：\n\n\n前端发起的请求，由Controller层接收（Controller响应数据给前端）\nController层调用Service层来进行逻辑处理（Service层处理完后，把处理结果返回给Controller层）\nSerivce层调用Dao层（逻辑处理过程中需要用到的一些数据要从Dao层获取）\nDao层操作文件中的数据（Dao拿到的数据会返回给Service层）\n\n\n\n\n\n\n\n\n\n\n思考：按照三层架构的思想，如何要对业务逻辑(Service层)进行变更，会影响到Controller层和Dao层吗？ \n答案：不会影响。 （程序的扩展性、维护性变得更好了）\n6.2 解耦首先需要了解软件开发涉及到的两个概念：内聚和耦合。\n\n内聚：软件中各个功能模块内部的功能联系。\n\n耦合：衡量软件中各个层&#x2F;模块之间的依赖、关联的程度。\n\n\n软件设计原则：高内聚低耦合。\n\n\n\n\n\n\n\n\n\n高内聚指的是：一个模块中各个元素之间的联系的紧密程度，如果各个元素(语句、程序段)之间的联系程度越高，则内聚性越高，即 “高内聚”。\n低耦合指的是：软件中各个层、模块之间的依赖关联程序越低越好。\n程序中高内聚的体现：\n\nEmpServiceA类中只编写了和员工相关的逻辑处理代码\n\n程序中耦合代码的体现：\n\n把业务类变为EmpServiceB时，需要修改controller层中的代码\n\n高内聚、低耦合的目的是使程序模块的可重用性、移植性大大增强。\n\n 那应该怎么解耦呢？\n\n首先不能在EmpController中使用new对象。代码如下：\n\n\n\n此时，就存在另一个问题了，不能new，就意味着没有业务层对象（程序运行就报错），怎么办呢？\n我们的解决思路是：\n提供一个容器，容器中存储一些对象(例：EmpService对象)\ncontroller程序从容器中获取EmpService类型的对象\n\n\n\n\n\n我们想要实现上述解耦操作，就涉及到Spring中的两个核心概念：\n\n控制反转： Inversion Of Control，简称IOC。对象的创建控制权由程序自身转移到外部（容器），这种思想称为控制反转。\n\n\n\n\n\n\n\n\n\n对象的创建权由程序员主动创建转移到容器(由容器创建、管理对象)。这个容器称为：IOC容器或Spring容器\n\n依赖注入： Dependency Injection，简称DI。容器为应用程序提供运行时，所依赖的资源，称之为依赖注入。\n\n\n\n\n\n\n\n\n\n程序运行时需要某个资源，此时容器就为其提供这个资源。\n例：EmpController程序运行时需要EmpService对象，Spring容器就为其提供并注入EmpService对象\n\n\nIOC容器中创建、管理的对象，称之为：bean对象\n6.3 IOC&amp;DI6.3.1 解耦步骤任务：完成Controller层、Service层、Dao层的代码解耦\n\n思路：\n\n删除Controller层、Service层中new对象的代码\n\nService层及Dao层的实现类，交给IOC容器管理\n\n使用Spring提供的注解：@Component ，就可以实现类交给IOC容器管理\n\n\n为Controller及Service注入运行时依赖的对象\n\n使用Spring提供的注解：@Autowired ，就可以实现程序运行时IOC容器自动注入需要的依赖对象\n\nController程序中注入依赖的Service层对象\n\nService程序中注入依赖的Dao层对象\n\n\n\n\n\n\n6.3.2 Bean的声明通过IOC和DI的入门程序呢，我们已经基本了解了IOC和DI的基础操作。接下来呢，我们学习下IOC控制反转和DI依赖注入的细节。\n前面我们提到IOC控制反转，就是将对象的控制权交给Spring的IOC容器，由IOC容器创建及管理对象。IOC容器创建的对象称为bean对象。\n在之前的入门案例中，要把某个对象交给IOC容器管理，需要在类上添加一个注解：@Component \n而Spring框架为了更好的标识web应用程序开发当中，bean对象到底归属于哪一层，又提供了@Component的衍生注解：\n\n@Controller    （标注在控制层类上）\n@Service          （标注在业务层类上）\n@Repository    （标注在数据访问层类上）\n\n要把某个对象交给IOC容器管理，需要在对应的类上加上如下注解之一：\n\n\n\n注解\n说明\n位置\n\n\n\n@Controller\n@Component的衍生注解\n标注在控制器类上\n\n\n@Service\n@Component的衍生注解\n标注在业务类上\n\n\n@Repository\n@Component的衍生注解\n标注在数据访问类上（由于与mybatis整合，用的少）\n\n\n@Component\n声明bean的基础注解\n不属于以上三类时，用此注解\n\n\n在IOC容器中，每一个Bean都有一个属于自己的名字，可以通过注解的value属性指定bean的名字。如果没有指定，默认为类名首字母小写。\n\n\n\n\n\n\n\n\n\n\n注意事项: \n\n声明bean的时候，可以通过value属性指定bean的名字，如果没有指定，默认为类名首字母小写。\n使用以上四个注解都可以声明bean，但是在springboot集成web开发中，声明控制器bean只能用@Controller。\n\n6.3.3 组件扫描问题：使用前面学习的四个注解声明的bean，一定会生效吗？\n答案：不一定。（原因：bean想要生效，还需要被组件扫描）\n\n使用四大注解声明的bean，要想生效，还需要被组件扫描注解@ComponentScan扫描\n\n\n\n\n\n\n\n\n\n\n@ComponentScan注解虽然没有显式配置，但是实际上已经包含在了引导类声明注解 @SpringBootApplication 中，&#x3D;&#x3D;默认扫描的范围是SpringBoot启动类所在包及其子包&#x3D;&#x3D;。\n \n\n解决方案：手动添加@ComponentScan注解，指定要扫描的包   （&#x3D;&#x3D;仅做了解，不推荐&#x3D;&#x3D;）\n\n\n推荐做法（如下图）：\n\n将我们定义的controller，service，dao这些包呢，都放在引导类所在包com.itheima的子包下，这样我们定义的bean就会被自动的扫描到\n\n\n6.3.4 DI详解依赖注入，是指IOC容器要为应用程序去提供运行时所依赖的资源，而资源指的就是对象。\n在入门程序案例中，我们使用了@Autowired这个注解，完成了依赖注入的操作，而这个Autowired翻译过来叫：自动装配。\n@Autowired注解，默认是按照类型进行自动装配的（去IOC容器中找某个类型的对象，然后完成注入操作）\n\n\n\n\n\n\n\n\n\n入门程序举例：在EmpController运行的时候，就要到IOC容器当中去查找EmpService这个类型的对象，而我们的IOC容器中刚好有一个EmpService这个类型的对象，所以就找到了这个类型的对象完成注入操作。\n那如果在IOC容器中，存在多个相同类型的bean对象，会出现什么情况呢？程序运行会报错\n如何解决上述问题呢？Spring提供了以下几种解决方案：\n\n@Primary\n\n@Qualifier\n\n@Resource\n\n\n使用@Primary注解：当存在多个相同类型的Bean注入时，加上@Primary注解，来确定默认的实现。\n \n使用@Qualifier注解：指定当前要注入的bean对象。 在@Qualifier的value属性中，指定注入的bean的名称。\n\n@Qualifier注解不能单独使用，必须配合@Autowired使用\n\n\n使用@Resource注解：是按照bean的名称进行注入。通过name属性指定要注入的bean的名称。\n\n\n\n\n\n\n\n\n\n\n面试题 ： @Autowird 与 @Resource的区别\n\n@Autowired 是spring框架提供的注解，而@Resource是JDK提供的注解\n@Autowired 默认是按照类型注入，而@Resource是按照名称注入\n\n7.文件上传7.1 简介文件上传，是指将本地图片、视频、音频等文件上传到服务器，供其他用户浏览或下载的过程。\n文件上传在项目中应用非常广泛，我们经常发微博、发微信朋友圈都用到了文件上传功能。\n\n\n\n\n\n\n\n\n\n\n在我们的案例中，在新增员工的时候，要上传员工的头像，此时就会涉及到文件上传的功能。在进行文件上传时，我们点击加号或者是点击图片，就可以选择手机或者是电脑本地的图片文件了。当我们选择了某一个图片文件之后，这个文件就会上传到服务器，从而完成文件上传的操作。\n想要完成文件上传这个功能需要涉及到两个部分：\n\n前端程序\n服务端程序\n\n我们先来看看在前端程序中要完成哪些代码：\nhtml&lt;form action=&quot;/upload&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt;\n    姓名: &lt;input type=&quot;text&quot; name=&quot;username&quot;&gt;&lt;br&gt;\n    年龄: &lt;input type=&quot;text&quot; name=&quot;age&quot;&gt;&lt;br&gt;\n    头像: &lt;input type=&quot;file&quot; name=&quot;image&quot;&gt;&lt;br&gt;\n    &lt;input type=&quot;submit&quot; value=&quot;提交&quot;&gt;\n&lt;/form&gt;上传文件的原始form表单，要求表单必须具备以下三点（上传文件页面三要素）：\n\n表单必须有file域，用于选择要上传的文件\n\n\n\n\n\n\n\n\n\nhtml&lt;input type=&quot;file&quot; name=&quot;image&quot;/&gt;\n\n表单提交方式必须为POST\n\n通常上传的文件会比较大，所以需要使用 POST 提交方式\n\n表单的编码类型enctype必须要设置为：multipart&#x2F;form-data\n\n\n\n\n\n\n\n\n\n普通默认的编码格式是不适合传输大型的二进制数据的，所以在文件上传时，表单的编码格式必须设置为multipart&#x2F;form-data\n\n\n前端页面的3要素我们了解后，接下来我们就来验证下所讲解的文件上传3要素。\n在提供的”课程资料”中有一个名叫”文件上传”的文件夹，直接将里的”upload.html”文件，复制到springboot项目工程下的static目录里面。\n\n下面我们来验证：删除form表单中enctype属性值，会是什么情况？\n\n在IDEA中直接使用浏览器打开upload.html页面\n\n\n\n选择要上传的本地文件\n\n\n\n点击”提交”按钮，进入到开发者模式观察\n\n\n\n我们再来验证：设置form表单中enctype属性值为multipart&#x2F;form-data，会是什么情况？\nhtml &lt;form action=&quot;/upload&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt;\n        姓名: &lt;input type=&quot;text&quot; name=&quot;username&quot;&gt;&lt;br&gt;\n        年龄: &lt;input type=&quot;text&quot; name=&quot;age&quot;&gt;&lt;br&gt;\n        头像: &lt;input type=&quot;file&quot; name=&quot;image&quot;&gt;&lt;br&gt;\n        &lt;input type=&quot;submit&quot; value=&quot;提交&quot;&gt;\n    &lt;/form&gt;知道了前端程序中需要设置上传文件页面三要素，那我们的后端程序又是如何实现的呢？\n\n首先在服务端定义这么一个controller，用来进行文件上传，然后在controller当中定义一个方法来处理/upload 请求\n\n在定义的方法中接收提交过来的数据 （方法中的形参名和请求参数的名字保持一致）\n\n用户名：String  name\n年龄： Integer  age\n文件： MultipartFile  image\n\n\n\n\n\n\n\n\n\n\nSpring中提供了一个API：MultipartFile，使用这个API就可以来接收到上传的文件\n\n\n\n\n\n\n\n\n\n\n\n\n问题：如果表单项的名字和方法中形参名不一致，该怎么办？\n\njavascriptpublic Result upload(String username,\n                     Integer age, \n                     MultipartFile file) //file形参名和请求参数名image不一致\n\n解决：使用@RequestParam注解进行参数绑定\n\njavapublic Result upload(String username,\n                     Integer age, \n                     @RequestParam(&quot;image&quot;) MultipartFile file)\n\nUploadController代码：\njava@Slf4j\n@RestController\npublic class UploadController &#123;\n\n    @PostMapping(&quot;/upload&quot;)\n    public Result upload(String username, Integer age, MultipartFile image)  &#123;\n        log.info(&quot;文件上传：&#123;&#125;,&#123;&#125;,&#123;&#125;&quot;,username,age,image);\n        return Result.success();\n    &#125;\n\n&#125;\n\n\n\n\n\n\n\n\n后端程序编写完成之后，打个断点，以debug方式启动SpringBoot项目\n\n\n\n\n\n\n\n\n\n\n打开浏览器输入：http://localhost:8080/upload.html ， 录入数据并提交\n\n通过后端程序控制台可以看到，上传的文件是存放在一个临时目录\n\n\n\n\n\n\n\n\n\n\n打开临时目录可以看到以下内容：\n\n\n\n\n\n\n\n\n\n\n表单提交的三项数据(姓名、年龄、文件)，分别存储在不同的临时文件中：\n\n\n\n\n\n\n\n\n\n当我们程序运行完毕之后，这个临时文件会自动删除。 \n所以，我们如果想要实现文件上传，需要将这个临时文件，要转存到我们的磁盘目录中。\n7.2 本地存储前面我们已分析了文件上传功能前端和后端的基础代码实现，文件上传时在服务端会产生一个临时文件，请求响应完成之后，这个临时文件被自动删除，并没有进行保存。下面呢，我们就需要完成将上传的文件保存在服务器的本地磁盘上。\n代码实现：\n\n在服务器本地磁盘上创建images目录，用来存储上传的文件（例：E盘创建images目录）\n使用MultipartFile类提供的API方法，把临时文件转存到本地磁盘目录下\n\n\n\n\n\n\n\n\n\n\nMultipartFile 常见方法： \n\nString  getOriginalFilename();  &#x2F;&#x2F;获取原始文件名\nvoid  transferTo(File dest);     &#x2F;&#x2F;将接收的文件转存到磁盘文件中\nlong  getSize();     &#x2F;&#x2F;获取文件的大小，单位：字节\nbyte[]  getBytes();    &#x2F;&#x2F;获取文件内容的字节数组\nInputStream  getInputStream();    &#x2F;&#x2F;获取接收到的文件内容的输入流\n\njava@Slf4j\n@RestController\npublic class UploadController &#123;\n\n    @PostMapping(&quot;/upload&quot;)\n    public Result upload(String username, Integer age, MultipartFile image) throws IOException &#123;\n        log.info(&quot;文件上传：&#123;&#125;,&#123;&#125;,&#123;&#125;&quot;,username,age,image);\n\n        //获取原始文件名\n        String originalFilename = image.getOriginalFilename();\n\n        //将文件存储在服务器的磁盘目录\n        image.transferTo(new File(&quot;E:/images/&quot;+originalFilename));\n\n        return Result.success();\n    &#125;\n\n&#125;利用postman测试：\n\n\n\n\n\n\n\n\n\n注意：请求参数名和controller方法形参名保持一致\n\n\n\n通过postman测试，我们发现文件上传是没有问题的。但是由于我们是使用原始文件名作为所上传文件的存储名字，当我们再次上传一个名为1.jpg文件时，发现会把之前已经上传成功的文件覆盖掉。\n解决方案：保证每次上传文件时文件名都唯一的（使用UUID获取随机文件名）\njava@Slf4j\n@RestController\npublic class UploadController &#123;\n\n    @PostMapping(&quot;/upload&quot;)\n    public Result upload(String username, Integer age, MultipartFile image) throws IOException &#123;\n        log.info(&quot;文件上传：&#123;&#125;,&#123;&#125;,&#123;&#125;&quot;,username,age,image);\n\n        //获取原始文件名\n        String originalFilename = image.getOriginalFilename();\n\n        //构建新的文件名\n        String extname = originalFilename.substring(originalFilename.lastIndexOf(&quot;.&quot;));//文件扩展名\n        String newFileName = UUID.randomUUID().toString()+extname;//随机名+文件扩展名\n\n        //将文件存储在服务器的磁盘目录\n        image.transferTo(new File(&quot;E:/images/&quot;+newFileName));\n\n        return Result.success();\n    &#125;\n\n&#125;在解决了文件名唯一性的问题后，我们再次上传一个较大的文件(超出1M)时发现，后端程序报错：\n\n报错原因呢是因为：在SpringBoot中，文件上传时默认单个文件最大大小为1M\n那么如果需要上传大文件，可以在application.properties进行如下配置：\nproperties#配置单个文件最大上传大小\nspring.servlet.multipart.max-file-size=10MB\n\n#配置单个请求最大上传大小(一次请求可以上传多个文件)\nspring.servlet.multipart.max-request-size=100MB到时此，我们文件上传的本地存储方式已完成了。但是这种本地存储方式还存在一问题： \n \n如果直接存储在服务器的磁盘目录中，存在以下缺点：\n\n不安全：磁盘如果损坏，所有的文件就会丢失\n容量有限：如果存储大量的图片，磁盘空间有限(磁盘不可能无限制扩容)\n无法直接访问\n\n为了解决上述问题呢，通常有两种解决方案：\n\n自己搭建存储服务器，如：fastDFS 、MinIO\n使用现成的云服务，如：阿里云，腾讯云，华为云\n\n7.3 阿里云OSS阿里云是阿里巴巴集团旗下全球领先的云计算公司，也是国内最大的云服务提供商 。\n\n\n\n\n\n\n\n\n\n\n云服务指的就是通过互联网对外提供的各种各样的服务，比如像：语音服务、短信服务、邮件服务、视频直播服务、文字识别服务、对象存储服务等等。\n当我们在项目开发时需要用到某个或某些服务，就不需要自己来开发了，可以直接使用阿里云提供好的这些现成服务就可以了。比如：在项目开发当中，我们要实现一个短信发送的功能，如果我们项目组自己实现，将会非常繁琐，因为你需要和各个运营商进行对接。而此时阿里云完成了和三大运营商对接，并对外提供了一个短信服务。我们项目组只需要调用阿里云提供的短信服务，就可以很方便的来发送短信了。这样就降低了我们项目的开发难度，同时也提高了项目的开发效率。（大白话：别人帮我们实现好了功能，我们只要调用即可）\n云服务提供商给我们提供的软件服务通常是需要收取一部分费用的。\n阿里云对象存储OSS（Object Storage Service），是一款海量、安全、低成本、高可靠的云存储服务。使用OSS，您可以通过网络随时存储和调用包括文本、图片、音频和视频等在内的各种文件。\n \n在我们使用了阿里云OSS对象存储服务之后，我们的项目当中如果涉及到文件上传这样的业务，在前端进行文件上传并请求到服务端时，在服务器本地磁盘当中就不需要再来存储文件了。我们直接将接收到的文件上传到oss，由 oss帮我们存储和管理，同时阿里云的oss存储服务还保障了我们所存储内容的安全可靠。\n\n那我们学习使用这类云服务，我们主要学习什么呢？其实我们主要学习的是如何在项目当中来使用云服务完成具体的业务功能。而无论使用什么样的云服务，阿里云也好，腾讯云、华为云也罢，在使用第三方的服务时，操作的思路都是一样的。\n\n\n\n\n\n\n\n\n\n\nSDK：Software Development Kit 的缩写，软件开发工具包，包括辅助软件开发的依赖（jar包）、代码示例等，都可以叫做SDK。\n简单说，sdk中包含了我们使用第三方云服务时所需要的依赖，以及一些示例代码。我们可以参照sdk所提供的示例代码就可以完成入门程序。\n第三方服务使用的通用思路，我们做一个简单介绍之后，接下来我们就来介绍一下我们当前要使用的阿里云oss对象存储服务具体的使用步骤。\n\n\n\n\n\n\n\n\n\n\nBucket：存储空间是用户用于存储对象（Object，就是文件）的容器，所有的对象都必须隶属于某个存储空间。\n下面我们根据之前介绍的使用步骤，完成准备工作：\n\n注册阿里云账户（注册完成后需要实名认证）\n注册完账号之后，就可以登录阿里云\n\n \n\n通过控制台找到对象存储OSS服务\n\n \n\n\n\n\n\n\n\n\n\n如果是第一次访问，还需要开通对象存储服务OSS\n \n \n\n开通OSS服务之后，就可以进入到阿里云对象存储的控制台\n\n \n\n点击左侧的 “Bucket列表”，创建一个Bucket\n\n \n\n\n\n\n\n\n\n\n\n\n大家可以参照”资料\\04. 阿里云oss&quot;中提供的文档，开通阿里云OSS服务。\n阿里云oss 对象存储服务的准备工作我们已经完成了，接下来我们就来完成第二步操作：参照官方所提供的sdk示例来编写入门程序。\n首先我们需要来打开阿里云OSS的官方文档，在官方文档中找到 SDK 的示例代码：\n\n\n\n\n\n\n\n\n\n\n\n如果是在实际开发当中，我们是需要从前往后仔细的去阅读这一份文档的，但是由于现在是教学，我们就只挑重点的去看。有兴趣的同学大家下来也可以自己去看一下这份官方文档。\n\n\n参照官方提供的SDK，改造一下，即可实现文件上传功能：\njavaimport com.aliyun.oss.ClientException;\nimport com.aliyun.oss.OSS;\nimport com.aliyun.oss.OSSClientBuilder;\nimport com.aliyun.oss.OSSException;\nimport com.aliyun.oss.model.PutObjectRequest;\nimport com.aliyun.oss.model.PutObjectResult;\n\nimport java.io.FileInputStream;\nimport java.io.InputStream;\n\npublic class AliOssTest &#123;\n    public static void main(String[] args) throws Exception &#123;\n        // Endpoint以华东1（杭州）为例，其它Region请按实际情况填写。\n        String endpoint = &quot;&quot;;\n        \n        // 阿里云账号AccessKey拥有所有API的访问权限，风险很高。强烈建议您创建并使用RAM用户进行API访问或日常运维，请登录RAM控制台创建RAM用户。\n        String accessKeyId = &quot;&quot;;\n        String accessKeySecret = &quot;&quot;;\n        \n        // 填写Bucket名称，例如examplebucket。\n        String bucketName = &quot;web-framework01&quot;;\n        // 填写Object完整路径，完整路径中不能包含Bucket名称，例如exampledir/exampleobject.txt。\n        String objectName = &quot;1.jpg&quot;;\n        // 填写本地文件的完整路径，例如D:\\\\localpath\\\\examplefile.txt。\n        // 如果未指定本地路径，则默认从示例程序所属项目对应本地路径中上传文件流。\n        String filePath= &quot;C:\\\\Users\\\\Administrator\\\\Pictures\\\\1.jpg&quot;;\n\n        // 创建OSSClient实例。\n        OSS ossClient = new OSSClientBuilder().build(endpoint, accessKeyId, accessKeySecret);\n\n        try &#123;\n            InputStream inputStream = new FileInputStream(filePath);\n            // 创建PutObjectRequest对象。\n            PutObjectRequest putObjectRequest = new PutObjectRequest(bucketName, objectName, inputStream);\n            // 设置该属性可以返回response。如果不设置，则返回的response为空。\n            putObjectRequest.setProcess(&quot;true&quot;);\n            // 创建PutObject请求。\n            PutObjectResult result = ossClient.putObject(putObjectRequest);\n            // 如果上传成功，则返回200。\n            System.out.println(result.getResponse().getStatusCode());\n        &#125; catch (OSSException oe) &#123;\n            System.out.println(&quot;Caught an OSSException, which means your request made it to OSS, &quot;\n                    + &quot;but was rejected with an error response for some reason.&quot;);\n            System.out.println(&quot;Error Message:&quot; + oe.getErrorMessage());\n            System.out.println(&quot;Error Code:&quot; + oe.getErrorCode());\n            System.out.println(&quot;Request ID:&quot; + oe.getRequestId());\n            System.out.println(&quot;Host ID:&quot; + oe.getHostId());\n        &#125; catch (ClientException ce) &#123;\n            System.out.println(&quot;Caught an ClientException, which means the client encountered &quot;\n                    + &quot;a serious internal problem while trying to communicate with OSS, &quot;\n                    + &quot;such as not being able to access the network.&quot;);\n            System.out.println(&quot;Error Message:&quot; + ce.getMessage());\n        &#125; finally &#123;\n            if (ossClient != null) &#123;\n                ossClient.shutdown();\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n在以上代码中，需要替换的内容为：\n\naccessKeyId：阿里云账号AccessKey\naccessKeySecret：阿里云账号AccessKey对应的秘钥\nbucketName：Bucket名称\nobjectName：对象名称，在Bucket中存储的对象的名称\nfilePath：文件路径\n\nAccessKey ：\n \n运行以上程序后，会把本地的文件上传到阿里云OSS服务器上：\n\n阿里云oss对象存储服务的准备工作以及入门程序我们都已经完成了，接下来我们就需要在案例当中集成oss对象存储服务，来存储和管理案例中上传的图片。\n\n\n\n\n\n\n\n\n\n\n在新增员工的时候，上传员工的图像，而之所以需要上传员工的图像，是因为将来我们需要在系统页面当中访问并展示员工的图像。而要想完成这个操作，需要做两件事：\n\n需要上传员工的图像，并把图像保存起来（存储到阿里云OSS）\n访问员工图像（通过图像在阿里云OSS的存储地址访问图像）\nOSS中的每一个文件都会分配一个访问的url，通过这个url就可以访问到存储在阿里云上的图片。所以需要把url返回给前端，这样前端就可以通过url获取到图像。\n\n\n\n我们参照接口文档来开发文件上传功能：\n\n基本信息\ntxt请求路径：/upload\n\n请求方式：POST\n\n接口描述：上传图片接口\n请求参数\n参数格式：multipart&#x2F;form-data\n参数说明：\n\n\n\n参数名称\n参数类型\n是否必须\n示例\n备注\n\n\n\nimage\nfile\n是\n\n\n\n\n\n响应数据\n参数格式：application&#x2F;json\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\ncode\nnumber\n必须\n响应码，1 代表成功，0 代表失败\n\n\nmsg\nstring\n非必须\n提示信息\n\n\ndata\nobject\n非必须\n返回的数据，上传图片的访问路径\n\n\n响应数据样例：\njson&#123;\n    &quot;code&quot;: 1,\n    &quot;msg&quot;: &quot;success&quot;,\n    &quot;data&quot;: &quot;https://web-framework.oss-cn-hangzhou.aliyuncs.com/2022-09-02-00-27-0400.jpg&quot;\n&#125;\n\n引入阿里云OSS上传文件工具类（由官方的示例代码改造而来）\njavaimport com.aliyun.oss.OSS;\nimport com.aliyun.oss.OSSClientBuilder;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.multipart.MultipartFile;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.UUID;\n\n@Component\npublic class AliOSSUtils &#123;\n    private String endpoint = &quot;&quot;;\n    private String accessKeyId = &quot;&quot;;\n    private String accessKeySecret = &quot;&quot;;\n    private String bucketName = &quot;&quot;;\n\n    /**\n     * 实现上传图片到OSS\n     */\n    public String upload(MultipartFile multipartFile) throws IOException &#123;\n        // 获取上传的文件的输入流\n        InputStream inputStream = multipartFile.getInputStream();\n\n        // 避免文件覆盖\n        String originalFilename = multipartFile.getOriginalFilename();\n        String fileName = UUID.randomUUID().toString() + originalFilename.substring(originalFilename.lastIndexOf(&quot;.&quot;));\n\n        //上传文件到 OSS\n        OSS ossClient = new OSSClientBuilder().build(endpoint, accessKeyId, accessKeySecret);\n        ossClient.putObject(bucketName, fileName, inputStream);\n\n        //文件访问路径\n        String url = endpoint.split(&quot;//&quot;)[0] + &quot;//&quot; + bucketName + &quot;.&quot; + endpoint.split(&quot;//&quot;)[1] + &quot;/&quot; + fileName;\n\n        // 关闭ossClient\n        ossClient.shutdown();\n        return url;// 把上传到oss的路径返回\n    &#125;\n&#125;修改UploadController代码：\njavaimport com.itheima.pojo.Result;\nimport com.itheima.utils.AliOSSUtils;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RestController;\nimport org.springframework.web.multipart.MultipartFile;\nimport java.io.IOException;\n\n@Slf4j\n@RestController\npublic class UploadController &#123;\n\n    @Autowired\n    private AliOSSUtils aliOSSUtils;\n\n    @PostMapping(&quot;/upload&quot;)\n    public Result upload(MultipartFile image) throws IOException &#123;\n        //调用阿里云OSS工具类，将上传上来的文件存入阿里云\n        String url = aliOSSUtils.upload(image);\n        //将图片上传完成后的url返回，用于浏览器回显展示\n        return Result.success(url);\n    &#125;\n    \n&#125;使用postman测试：\n\n8.配置文件8.1 参数配置化\n在我们之前编写的程序中进行文件上传时，需要调用AliOSSUtils工具类，将文件上传到阿里云OSS对象存储服务当中。而在调用工具类进行文件上传时，需要一些参数：\n\nendpoint       &#x2F;&#x2F;阿里云OSS域名\naccessKeyID    &#x2F;&#x2F;用户身份ID\naccessKeySecret   &#x2F;&#x2F;用户密钥\nbucketName      &#x2F;&#x2F;存储空间的名字\n\n关于以上的这些阿里云相关配置信息，我们是直接写死在java代码中了(硬编码)，如果我们在做项目时每涉及到一个第三方技术服务，就将其参数硬编码，那么在Java程序中会存在两个问题：\n\n如果这些参数发生变化了，就必须在源程序代码中改动这些参数，然后需要重新进行代码的编译，将Java代码编译成class字节码文件再重新运行程序。（比较繁琐）\n如果我们开发的是一个真实的企业级项目， Java类可能会有很多，如果将这些参数分散的定义在各个Java类当中，我们要修改一个参数值，我们就需要在众多的Java代码当中来定位到对应的位置，再来修改参数，修改完毕之后再重新编译再运行。（参数配置过于分散，是不方便集中的管理和维护）\n\n为了解决以上分析的问题，我们可以将参数配置在配置文件中。如下：\nproperties#自定义的阿里云OSS配置信息\naliyun.oss.endpoint=\naliyun.oss.accessKeyId=\naliyun.oss.accessKeySecret=\naliyun.oss.bucketName=在将阿里云OSS配置参数交给properties配置文件来管理之后，我们的AliOSSUtils工具类就变为以下形式：\njava@Component\npublic class AliOSSUtils &#123;\n    /*以下4个参数没有指定值（默认值：null）*/\n    private String endpoint;\n    private String accessKeyId;\n    private String accessKeySecret;\n    private String bucketName;\n\n    //省略其他代码...\n&#125;\n\n\n\n\n\n\n\n\n而此时如果直接调用AliOSSUtils类当中的upload方法进行文件上传时，这4项参数全部为null，原因是因为并没有给它赋值。\n此时我们是不是需要将配置文件当中所配置的属性值读取出来，并分别赋值给AliOSSUtils工具类当中的各个属性呢？那应该怎么做呢？\n因为application.properties是springboot项目默认的配置文件，所以springboot程序在启动时会默认读取application.properties配置文件，而我们可以使用一个现成的注解：@Value，获取配置文件中的数据。\n@Value 注解通常用于外部配置的属性注入，具体用法为： @Value(“${配置文件中的key}”)\njava@Component\npublic class AliOSSUtils &#123;\n\n    @Value(&quot;$&#123;aliyun.oss.endpoint&#125;&quot;)\n    private String endpoint;\n    \n    @Value(&quot;$&#123;aliyun.oss.accessKeyId&#125;&quot;)\n    private String accessKeyId;\n    \n    @Value(&quot;$&#123;aliyun.oss.accessKeySecret&#125;&quot;)\n    private String accessKeySecret;\n    \n    @Value(&quot;$&#123;aliyun.oss.bucketName&#125;&quot;)\n    private String bucketName;\n     \n     //省略其他代码...\n &#125;   \n使用postman测试：\n\n8.2 yml配置文件前面我们一直使用springboot项目创建完毕后自带的application.properties进行属性的配置，那其实呢，在springboot项目当中是支持多种配置方式的，除了支持properties配置文件以外，还支持另外一种类型的配置文件，就是我们接下来要讲解的yml格式的配置文件。\n\napplication.properties\npropertiesserver.port=8080\nserver.address=127.0.0.1\napplication.yml \nymlserver:\n  port: 8080\n  address: 127.0.0.1\napplication.yaml \nymlserver:\n  port: 8080\n  address: 127.0.0.1\n\n\n\n\n\n\n\n\n\n\nyml 格式的配置文件，后缀名有两种：\n\nyml （推荐）\nyaml\n\n常见配置文件格式对比：\n\n我们可以看到配置同样的数据信息，yml格式的数据有以下特点：\n\n容易阅读\n容易与脚本语言交互\n以数据为核心，重数据轻格式\n\n简单的了解过springboot所支持的配置文件，以及不同类型配置文件之间的优缺点之后，接下来我们就来了解下yml配置文件的基本语法：\n\n大小写敏感\n数值前边必须有空格，作为分隔符\n使用缩进表示层级关系，缩进时，不允许使用Tab键，只能用空格（idea中会自动将Tab转换为空格）\n缩进的空格数目不重要，只要相同层级的元素左侧对齐即可\n#表示注释，从这个字符一直到行尾，都会被解析器忽略\n\n\n了解完yml格式配置文件的基本语法之后，接下来我们再来看下yml文件中常见的数据格式。在这里我们主要介绍最为常见的两类：\n\n定义对象或Map集合\n定义数组、list或set集合\n\n对象&#x2F;Map集合\nymluser:\n  name: zhangsan\n  age: 18\n  password: 123456数组&#x2F;List&#x2F;Set集合\nymlhobby: \n  - java\n  - game\n  - sport熟悉完了yml文件的基本语法后，我们修改下之前案例中使用的配置文件，变更为application.yml配置方式：\n\n修改application.properties名字为：_application.properties（名字随便更换，只要加载不到即可）\n创建新的配置文件： application.yml\n\n原有application.properties文件：\n\n新建的application.yml文件：\nyamlspring:\n  datasource:\n    driver-class-name: com.mysql.cj.jdbc.Driver\n    url: jdbc:mysql://localhost:3306/tlias\n    username: root\n    password: 1234\n  servlet:\n    multipart:\n      max-file-size: 10MB\n      max-request-size: 100MB\n      \nmybatis:\n  configuration:\n    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl\n    map-underscore-to-camel-case: true\n    \naliyun:\n  oss:\n    endpoint: https://oss-cn-hangzhou.aliyuncs.com\n    accessKeyId: \n    accessKeySecret: \n    bucketName: web-3978.3 @ConfigurationProperties讲解完了yml配置文件之后，最后再来介绍一个注解@ConfigurationProperties。在介绍注解之前，我们先来看一个场景，分析下代码当中可能存在的问题：\n\n我们在application.properties或者application.yml中配置了阿里云OSS的四项参数之后，如果java程序中需要这四项参数数据，我们直接通过@Value注解来进行注入。这种方式本身没有什么问题问题，但是如果说需要注入的属性较多(例：需要20多个参数数据)，我们写起来就会比较繁琐。\n那么有没有一种方式可以简化这些配置参数的注入呢？答案是肯定有，在Spring中给我们提供了一种简化方式，可以直接将配置文件中配置项的值自动的注入到对象的属性中。\nSpring提供的简化方式套路：\n\n需要创建一个实现类，且实体类中的属性名和配置文件当中key的名字必须要一致\n\n\n\n\n\n\n\n\n\n比如：配置文件当中叫endpoints，实体类当中的属性也得叫endpoints，另外实体类当中的属性还需要提供 getter &#x2F; setter方法\n\n需要将实体类交给Spring的IOC容器管理，成为IOC容器当中的bean对象\n\n在实体类上添加@ConfigurationProperties注解，并通过perfect属性来指定配置参数项的前缀\n\n\n\n实体类：AliOSSProperties\njavaimport lombok.Data;\nimport org.springframework.boot.context.properties.ConfigurationProperties;\nimport org.springframework.stereotype.Component;\n\n/*阿里云OSS相关配置*/\n@Data\n@Component\n@ConfigurationProperties(prefix = &quot;aliyun.oss&quot;)\npublic class AliOSSProperties &#123;\n    //区域\n    private String endpoint;\n    //身份ID\n    private String accessKeyId ;\n    //身份密钥\n    private String accessKeySecret ;\n    //存储空间\n    private String bucketName;\n&#125;AliOSSUtils工具类：\njavaimport com.aliyun.oss.OSS;\nimport com.aliyun.oss.OSSClientBuilder;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.multipart.MultipartFile;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.UUID;\n\n@Component //当前类对象由Spring创建和管理\npublic class AliOSSUtils &#123;\n\n    //注入配置参数实体类对象\n    @Autowired\n    private AliOSSProperties aliOSSProperties;\n   \n    \n    /**\n     * 实现上传图片到OSS\n     */\n    public String upload(MultipartFile multipartFile) throws IOException &#123;\n        // 获取上传的文件的输入流\n        InputStream inputStream = multipartFile.getInputStream();\n\n        // 避免文件覆盖\n        String originalFilename = multipartFile.getOriginalFilename();\n        String fileName = UUID.randomUUID().toString() + originalFilename.substring(originalFilename.lastIndexOf(&quot;.&quot;));\n\n        //上传文件到 OSS\n        OSS ossClient = new OSSClientBuilder().build(aliOSSProperties.getEndpoint(),\n                aliOSSProperties.getAccessKeyId(), aliOSSProperties.getAccessKeySecret());\n        ossClient.putObject(aliOSSProperties.getBucketName(), fileName, inputStream);\n\n        //文件访问路径\n        String url =aliOSSProperties.getEndpoint().split(&quot;//&quot;)[0] + &quot;//&quot; + aliOSSProperties.getBucketName() + &quot;.&quot; + aliOSSProperties.getEndpoint().split(&quot;//&quot;)[1] + &quot;/&quot; + fileName;\n\n        // 关闭ossClient\n        ossClient.shutdown();\n        return url;// 把上传到oss的路径返回\n    &#125;\n&#125;\n在我们添加上注解后，会发现idea窗口上面出现一个红色警告：\n \n这个警告提示是告知我们还需要引入一个依赖：\nxml&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;\n&lt;/dependency&gt;当我们在pom.xml文件当中配置了这项依赖之后，我们重新启动服务，大家就会看到在properties或者是yml配置文件当中，就会提示阿里云 OSS 相关的配置项。所以这项依赖它的作用就是会自动的识别被@Configuration Properties注解标识的bean对象。\n\n\n\n\n\n\n\n\n\n刚才的红色警告，已经变成了一个灰色的提示，提示我们需要重新运行springboot服务\n@ConfigurationProperties注解我们已经介绍完了，接下来我们就来区分一下@ConfigurationProperties注解以及我们前面所介绍的另外一个@Value注解：\n相同点：都是用来注入外部配置的属性的。\n不同点：\n\n@Value注解只能一个一个的进行外部属性的注入。\n\n@ConfigurationProperties可以批量的将外部的属性配置注入到bean对象的属性中。\n\n\n如果要注入的属性非常的多，并且还想做到复用，就可以定义这么一个bean对象。通过 configuration properties 批量的将外部的属性配置直接注入到 bin 对象的属性当中。在其他的类当中，我要想获取到注入进来的属性，我直接注入 bin 对象，然后调用 get 方法，就可以获取到对应的属性值了\n","slug":"Springboot学习","date":"2024-02-11T08:10:12.000Z","categories_index":"Study","tags_index":"Java,SpringBoot","author_index":"Fioransh"},{"id":"98d7dfbbb096f447064b1064021af412","title":"Mybatis知识点总结","content":"1.Mybatis入门在前面我们学习MySQL数据库时，都是利用图形化客户端工具(如：idea、datagrip)，来操作数据库的。\n\n\n\n\n\n\n\n\n\n在客户端工具中，编写增删改查的SQL语句，发给MySQL数据库管理系统，由数据库管理系统执行SQL语句并返回执行结果。\n增删改操作：返回受影响行数\n查询操作：返回结果集(查询的结果)\n我们做为后端程序开发人员，通常会使用Java程序来完成对数据库的操作。Java程序操作数据库，现在主流的方式是：Mybatis。\n什么是MyBatis?\n\nMyBatis是一款优秀的 持久层 框架，用于简化JDBC的开发。\n\nMyBatis本是 Apache的一个开源项目iBatis，2010年这个项目由apache迁移到了google code，并且改名为MyBatis 。2013年11月迁移到Github。\n\n官网：https://mybatis.org/mybatis-3/zh/index.html\n\n\n在上面我们提到了两个词：一个是持久层，另一个是框架。\n\n持久层：指的是就是数据访问层(dao)，是用来操作数据库的。\n\n \n\n框架：是一个半成品软件，是一套可重用的、通用的、软件基础代码模型。在框架的基础上进行软件开发更加高效、规范、通用、可拓展。\n\n1.1 入门程序以前我们是在图形化客户端工具中编写SQL查询代码，发送给数据库执行，数据库执行后返回操作结果。\n图形化工具会把数据库执行的查询结果，使用表格的形式展现出来\n现在使用Mybatis操作数据库，就是在Mybatis中编写SQL查询代码，发送给数据库执行，数据库执行后返回结果。\nMybatis会把数据库执行的查询结果，使用实体类封装起来（一行记录对应一个实体类对象）\n\nMybatis操作数据库的步骤：\n\n准备工作(创建springboot工程、数据库表user、实体类User)\n\n引入Mybatis的相关依赖，配置Mybatis(数据库连接信息)\n\n编写SQL语句(注解&#x2F;XML)\n\n\n创建springboot工程，并导入 mybatis的起步依赖、mysql的驱动包。\n\n\n\n\n\n\n\n\n\n\n\n项目工程创建完成后，自动在pom.xml文件中，导入Mybatis依赖和MySQL驱动依赖\nxml&lt;!-- 仅供参考：只粘贴了pom.xml中部分内容 --&gt;\n&lt;dependencies&gt;\n        &lt;!-- mybatis起步依赖 --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;\n            &lt;version&gt;2.3.0&lt;/version&gt;\n        &lt;/dependency&gt;\n\n        &lt;!-- mysql驱动包依赖 --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.mysql&lt;/groupId&gt;\n            &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt;\n            &lt;scope&gt;runtime&lt;/scope&gt;\n        &lt;/dependency&gt;\n        \n        &lt;!-- spring单元测试 (集成了junit) --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n&lt;/dependencies&gt;\n\n\n\n\n\n\n\n\n在之前使用图形化客户端工具，连接MySQL数据库时，需要配置：\n\n连接数据库的四大参数：\n\nMySQL驱动类 \n登录名\n密码\n数据库连接字符串\n\n基于上述分析，在Mybatis中要连接数据库，同样也需要以上4个参数配置。\n在springboot项目中，可以编写application.properties文件，配置数据库连接信息。我们要连接数据库，就需要配置数据库连接的基本信息，包括：driver-class-name、url 、username，password。\n\n\n\n\n\n\n\n\n\n在入门程序中，大家可以直接这么配置，后面会介绍什么是驱动。\napplication.properties:\nproperties#驱动类名称\nspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver\n#数据库连接的url\nspring.datasource.url=jdbc:mysql://localhost:3306/mybatis\n#连接数据库的用户名\nspring.datasource.username=root\n#连接数据库的密码\nspring.datasource.password=1234\n\n\n\n\n\n\n\n\n上述的配置，可以直接复制过去，不要敲错了。 全部都是 spring.datasource.xxxx 开头。\n在创建出来的springboot工程中，在引导类所在包下，在创建一个包 mapper。在mapper包下创建一个接口 UserMapper ，这是一个持久层接口（Mybatis的持久层接口规范一般都叫 XxxMapper）。\n\nUserMapper：\njavaimport com.itheima.pojo.User;\nimport org.apache.ibatis.annotations.Mapper;\nimport org.apache.ibatis.annotations.Select;\nimport java.util.List;\n\n@Mapper\npublic interface UserMapper &#123;\n    \n    //查询所有用户数据\n    @Select(&quot;select id, name, age, gender, phone from user&quot;)\n    public List&lt;User&gt; list();\n    \n&#125;\n\n\n\n\n\n\n\n\n@Mapper注解：表示是mybatis中的Mapper接口\n\n程序运行时：框架会自动生成接口的实现类对象(代理对象)，并给交Spring的IOC容器管理\n\n @Select注解：代表的就是select查询，用于书写select查询语句\n在创建出来的SpringBoot工程中，在src下的test目录下，已经自动帮我们创建好了测试类 ，并且在测试类上已经添加了注解 @SpringBootTest，代表该测试类已经与SpringBoot整合。 \n该测试类在运行时，会自动通过引导类加载Spring的环境（IOC容器）。我们要测试那个bean对象，就可以直接通过@Autowired注解直接将其注入进行，然后就可以测试了。 \n1.2 解决SQL警告与提示默认我们在UserMapper接口上加的@Select注解中编写SQL语句是没有提示的。 如果想让idea给我们提示对应的SQL语句，我们需要在IDEA中配置与MySQL数据库的链接。 \n默认我们在UserMapper接口上的@Select注解中编写SQL语句是没有提示的。如果想让idea给出提示，可以做如下配置：\n\n配置完成之后，发现SQL语句中的关键字有提示了，但还存在不识别表名(列名)的情况：\n\n\n\n\n\n\n\n\n\n\n产生原因：Idea和数据库没有建立连接，不识别表信息\n解决方案：在Idea中配置MySQL数据库连接\n \n\n\n\n\n\n\n\n\n\n在配置的时候指定连接那个数据库，如上图所示连接的就是mybatis数据库。\n2.JDBC介绍2.1 介绍通过Mybatis的快速入门，我们明白了，通过Mybatis可以很方便的进行数据库的访问操作。但是大家要明白，其实java语言操作数据库呢，只能通过一种方式：使用sun公司提供的 JDBC 规范。\n\n\n\n\n\n\n\n\n\nMybatis框架，就是对原始的JDBC程序的封装。 \n那到底什么是JDBC呢，接下来，我们就来介绍一下。\nJDBC： ( Java DataBase Connectivity )，就是使用Java语言操作关系型数据库的一套API。\n \n\n\n\n\n\n\n\n\n\n本质：\n\nsun公司官方定义的一套操作所有关系型数据库的规范，即接口。\n\n各个数据库厂商去实现这套接口，提供数据库驱动jar包。\n\n我们可以使用这套接口(JDBC)编程，真正执行的代码是驱动jar包中的实现类。\n\n\n2.2 代码下面我们看看原始的JDBC程序是如何操作数据库的。操作步骤如下：\n\n注册驱动\n获取连接对象\n执行SQL语句，返回执行结果\n处理执行结果\n释放资源\n\n\n\n\n\n\n\n\n\n\n在pom.xml文件中已引入MySQL驱动依赖，我们直接编写JDBC代码即可\nJDBC具体代码实现：\njavaimport com.itheima.pojo.User;\nimport org.junit.jupiter.api.Test;\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.Statement;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class JdbcTest &#123;\n    @Test\n    public void testJdbc() throws Exception &#123;\n        //1. 注册驱动\n        Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;);\n\n        //2. 获取数据库连接\n        String url=&quot;jdbc:mysql://127.0.0.1:3306/mybatis&quot;;\n        String username = &quot;root&quot;;\n        String password = &quot;1234&quot;;\n        Connection connection = DriverManager.getConnection(url, username, password);\n\n        //3. 执行SQL\n        Statement statement = connection.createStatement(); //操作SQL的对象\n        String sql=&quot;select id,name,age,gender,phone from user&quot;;\n        ResultSet rs = statement.executeQuery(sql);//SQL查询结果会封装在ResultSet对象中\n\n        List&lt;User&gt; userList = new ArrayList&lt;&gt;();//集合对象（用于存储User对象）\n        //4. 处理SQL执行结果\n        while (rs.next())&#123;\n            //取出一行记录中id、name、age、gender、phone下的数据\n            int id = rs.getInt(&quot;id&quot;);\n            String name = rs.getString(&quot;name&quot;);\n            short age = rs.getShort(&quot;age&quot;);\n            short gender = rs.getShort(&quot;gender&quot;);\n            String phone = rs.getString(&quot;phone&quot;);\n            //把一行记录中的数据，封装到User对象中\n            User user = new User(id,name,age,gender,phone);\n            userList.add(user);//User对象添加到集合\n        &#125;\n        //5. 释放资源\n        statement.close();\n        connection.close();\n        rs.close();\n\n        //遍历集合\n        for (User user : userList) &#123;\n            System.out.println(user);\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\nDriverManager(类)：数据库驱动管理类。\n\n作用：\n\n注册驱动\n\n创建java代码和数据库之间的连接，即获取Connection对象\n\n\n\n\nConnection(接口)：建立数据库连接的对象\n\n作用：用于建立java程序和数据库之间的连接\n\nStatement(接口)： 数据库操作对象(执行SQL语句的对象)。\n\n作用：用于向数据库发送sql语句\n\nResultSet(接口)：结果集对象（一张虚拟表）\n\n作用：sql查询语句的执行结果会封装在ResultSet中\n\n通过上述代码，我们看到直接基于JDBC程序来操作数据库，代码实现非常繁琐，所以在项目开发中，我们很少使用。  在项目开发中，通常会使用Mybatis这类的高级技术来操作数据库，从而简化数据库操作、提高开发效率。\n2.3 问题分析始的JDBC程序，存在以下几点问题：\n\n数据库链接的四要素(驱动、链接、用户名、密码)全部硬编码在java代码中\n查询结果的解析及封装非常繁琐\n每一次查询数据库都需要获取连接,操作完毕后释放连接, 资源浪费, 性能降低\n\n\n2.4 技术对比分析了JDBC的缺点之后，我们再来看一下在mybatis中，是如何解决这些问题的：\n\n数据库连接四要素(驱动、链接、用户名、密码)，都配置在springboot默认的配置文件 application.properties中\n\n查询结果的解析及封装，由mybatis自动完成映射封装，我们无需关注\n\n在mybatis中使用了数据库连接池技术，从而避免了频繁的创建连接、销毁连接而带来的资源浪费。\n\n\n\n\n\n\n\n\n\n\n\n使用SpringBoot+Mybatis的方式操作数据库，能够提升开发效率、降低资源浪费\n而对于Mybatis来说，我们在开发持久层程序操作数据库时，需要重点关注以下两个方面：\n\napplication.properties\nproperties#驱动类名称\nspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver\n#数据库连接的url\nspring.datasource.url=jdbc:mysql://localhost:3306/mybatis\n#连接数据库的用户名\nspring.datasource.username=root\n#连接数据库的密码\nspring.datasource.password=1234\nMapper接口（编写SQL语句）\njava@Mapper\npublic interface UserMapper &#123;\n    @Select(&quot;select id, name, age, gender, phone from user&quot;)\n    public List&lt;User&gt; list();\n&#125;\n\n3.数据库连接池3.1 介绍\n\n\n\n\n\n\n\n\n\n没有使用数据库连接池：\n\n客户端执行SQL语句：要先创建一个新的连接对象，然后执行SQL语句，SQL语句执行后又需要关闭连接对象从而释放资源，每次执行SQL时都需要创建连接、销毁链接，这种频繁的重复创建销毁的过程是比较耗费计算机的性能。\n\n\n数据库连接池是个容器，负责分配、管理数据库连接(Connection)\n\n程序在启动时，会在数据库连接池(容器)中，创建一定数量的Connection对象\n\n允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个\n\n客户端在执行SQL时，先从连接池中获取一个Connection对象，然后在执行SQL语句，SQL语句执行完之后，释放Connection时就会把Connection对象归还给连接池（Connection对象可以复用）\n\n释放空闲时间超过最大空闲时间的连接，来避免因为没有释放连接而引起的数据库连接遗漏\n\n客户端获取到Connection对象了，但是Connection对象并没有去访问数据库(处于空闲)，数据库连接池发现Connection对象的空闲时间 &gt; 连接池中预设的最大空闲时间，此时数据库连接池就会自动释放掉这个连接对象\n\n数据库连接池的好处：\n\n资源重用\n提升系统响应速度\n避免数据库连接遗漏\n\n3.2 产品要怎么样实现数据库连接池呢？\n\n官方(sun)提供了数据库连接池标准（javax.sql.DataSource接口）\n\n功能：获取连接 \njavapublic Connection getConnection() throws SQLException;\n第三方组织必须按照DataSource接口实现\n\n\n\n\n常见的数据库连接池：\n\nC3P0\nDBCP\nDruid\nHikari (springboot默认)\n\n现在使用更多的是：Hikari、Druid  （性能更优越）\n\nHikari（追光者） [默认的连接池]\n\n \n\nDruid（德鲁伊）\n\nDruid连接池是阿里巴巴开源的数据库连接池项目 \n\n功能强大，性能优秀，是Java语言最好的数据库连接池之一\n\n\n\n\n​\t\t\n如果我们想把默认的数据库连接池切换为Druid数据库连接池，只需要完成以下两步操作即可：\n\n\n\n\n\n\n\n\n\n参考官方地址：https://github.com/alibaba/druid/tree/master/druid-spring-boot-starter\n\n在pom.xml文件中引入依赖\n\nxml&lt;dependency&gt;\n    &lt;!-- Druid连接池依赖 --&gt;\n    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;\n    &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt;\n    &lt;version&gt;1.2.8&lt;/version&gt;\n&lt;/dependency&gt;\n在application.properties中引入数据库连接配置\n\n方式1：\npropertiesspring.datasource.druid.driver-class-name=com.mysql.cj.jdbc.Driver\nspring.datasource.druid.url=jdbc:mysql://localhost:3306/mybatis\nspring.datasource.druid.username=root\nspring.datasource.druid.password=1234方式2：\npropertiesspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver\nspring.datasource.url=jdbc:mysql://localhost:3306/mybatis\nspring.datasource.username=root\nspring.datasource.password=12344.Lombok4.1 介绍Lombok是一个实用的Java类库，可以通过简单的注解来简化和消除一些必须有但显得很臃肿的Java代码。\n\n\n\n\n\n\n\n\n\n\n通过注解的形式自动生成构造器、getter&#x2F;setter、equals、hashcode、toString等方法，并可以自动化生成日志变量，简化java开发、提高效率。\n\n\n\n注解\n作用\n\n\n\n@Getter&#x2F;@Setter\n为所有的属性提供get&#x2F;set方法\n\n\n@ToString\n会给类自动生成易阅读的  toString 方法\n\n\n@EqualsAndHashCode\n根据类所拥有的非静态字段自动重写 equals 方法和  hashCode 方法\n\n\n@Data\n提供了更综合的生成代码功能（@Getter  + @Setter + @ToString + @EqualsAndHashCode）\n\n\n@NoArgsConstructor\n为实体类生成无参的构造器方法\n\n\n@AllArgsConstructor\n为实体类生成除了static修饰的字段之外带有各参数的构造器方法。\n\n\n4.2 使用第1步：在pom.xml文件中引入依赖\nxml&lt;!-- 在springboot的父工程中，已经集成了lombok并指定了版本号，故当前引入依赖时不需要指定version --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n    &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n&lt;/dependency&gt;第2步：在实体类上添加注解\njavaimport lombok.Data;\n\n@Data\npublic class User &#123;\n    private Integer id;\n    private String name;\n    private Short age;\n    private Short gender;\n    private String phone;\n&#125;\n\n\n\n\n\n\n\n\n在实体类上添加了@Data注解，那么这个类在编译时期，就会生成getter&#x2F;setter、equals、hashcode、toString等方法。\n\n说明：@Data注解中不包含全参构造方法，通常在实体类上，还会添加上：全参构造、无参构造\njavaimport lombok.Data;\n\n@Data //getter方法、setter方法、toString方法、hashCode方法、equals方法\n@NoArgsConstructor //无参构造\n@AllArgsConstructor//全参构造\npublic class User &#123;\n    private Integer id;\n    private String name;\n    private Short age;\n    private Short gender;\n    private String phone;\n&#125;Lombok的注意事项：\n\nLombok会在编译时，会自动生成对应的java代码\n在使用lombok时，还需要安装一个lombok的插件（新版本的IDEA中自带）\n\n\n5.Mybatis基本操作5.1 删除页面原型：\n\n\n\n\n\n\n\n\n\n\n当我们点击后面的”删除”按钮时，前端页面会给服务端传递一个参数，也就是该行数据的ID。 我们接收到ID后，根据ID删除数据即可。\n功能：根据主键删除数据\n\nSQL语句\n\ntxt-- 删除id=17的数据\ndelete from emp where id = 17;\n\n\n\n\n\n\n\n\nMybatis框架让程序员更关注于SQL语句\n\n接口方法\n\njava@Mapper\npublic interface EmpMapper &#123;\n    \n    //@Delete(&quot;delete from emp where id = 17&quot;)\n    //public void delete();\n    //以上delete操作的SQL语句中的id值写成固定的17，就表示只能删除id=17的用户数据\n    //SQL语句中的id值不能写成固定数值，需要变为动态的数值\n    //解决方案：在delete方法中添加一个参数(用户id)，将方法中的参数，传给SQL语句\n    \n    /**\n     * 根据id删除数据\n     * @param id    用户id\n     */\n    @Delete(&quot;delete from emp where id = #&#123;id&#125;&quot;)//使用#&#123;key&#125;方式获取方法中的参数值\n    public void delete(Integer id);\n    \n&#125;\n\n\n\n\n\n\n\n\n@Delete注解：用于编写delete操作的SQL语句\n\n\n\n\n\n\n\n\n\n如果mapper接口方法形参只有一个普通类型的参数，#{…} 里面的属性名可以随便写，如：#{id}、#{value}。但是建议保持名字一致。\n\n测试\n在单元测试类中通过@Autowired注解注入EmpMapper类型对象\n\n\n\njava@SpringBootTest\nclass SpringbootMybatisCrudApplicationTests &#123;\n    @Autowired //从Spring的IOC容器中，获取类型是EmpMapper的对象并注入\n    private EmpMapper empMapper;\n\n    @Test\n    public void testDel()&#123;\n        //调用删除方法\n        empMapper.delete(16);\n    &#125;\n\n&#125;5.1.1 日志输入在Mybatis当中我们可以借助日志，查看到sql语句的执行、执行传递的参数以及执行结果。具体操作如下：\n\n打开application.properties文件\n\n开启mybatis的日志，并指定输出到控制台\n\n\nproperties#指定mybatis输出日志的位置, 输出控制台\nmybatis.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl开启日志之后，我们再次运行单元测试，可以看到在控制台中，输出了以下的SQL语句信息：\n \n\n\n\n\n\n\n\n\n\n但是我们发现输出的SQL语句：delete from emp where id &#x3D; ?，我们输入的参数16并没有在后面拼接，id的值是使用?进行占位。那这种SQL语句我们称为预编译SQL。\n5.1.2 预编译SQL预编译SQL有两个优势：\n\n性能更高\n更安全(防止SQL注入)\n\n\n\n\n\n\n\n\n\n\n\n性能更高：预编译SQL，编译一次之后会将编译后的SQL语句缓存起来，后面再次执行这条语句时，不会再次编译。（只是输入的参数不同）\n更安全(防止SQL注入)：将敏感字进行转义，保障SQL的安全性。\nSQL注入：是通过操作输入的数据来修改事先定义好的SQL语句，以达到执行代码对服务器进行攻击的方法。\n\n\n\n\n\n\n\n\n\n由于没有对用户输入进行充分检查，而SQL又是拼接而成，在用户输入参数时，在参数中添加一些SQL关键字，达到改变SQL运行结果的目的，也可以完成恶意攻击。\n测试1：使用资料中提供的程序，来验证SQL注入问题\n\n第1步：进入到DOS\n\n\n第2步：执行以下命令，启动程序\npowershell#启动存在SQL注入的程序\njava -jar sql_Injection_demo-0.0.1-SNAPSHOT.jar \n第3步：打开浏览器输入http://localhost:9090/login.html\n\n发现竟然能够登录成功：\n\n以上操作为什么能够登录成功呢？\n\n由于没有对用户输入内容进行充分检查，而SQL又是字符串拼接方式而成，在用户输入参数时，在参数中添加一些SQL关键字，达到改变SQL运行结果的目的，从而完成恶意攻击。\n\n\n\n\n\n\n\n\n\n\n\n\n用户在页面提交数据的时候人为的添加一些特殊字符，使得sql语句的结构发生了变化，最终可以在没有用户名或者密码的情况下进行登录。\n测试2：使用资料中提供的程序，来验证SQL注入问题\n第1步：进入到DOS\n第2步：执行以下命令，启动程序：\npowershell#启动解决了SQL注入的程序\njava -jar sql_prepared_demo-0.0.1-SNAPSHOT.jar第3步：打开浏览器输入http://localhost:9090/login.html\n\n发现无法登录：\n\n以上操作SQL语句的执行：\n\n\n\n\n\n\n\n\n\n\n把整个&#39; or &#39;1&#39;=&#39;1作为一个完整的参数，赋值给第2个问号（&#39; or &#39;1&#39;=&#39;1进行了转义，只当做字符串使用）\n在Mybatis中提供的参数占位符有两种：${…} 、#{…}\n\n#{…}\n\n执行SQL时，会将#{…}替换为?，生成预编译SQL，会自动设置参数值\n使用时机：参数传递，都使用#{…}\n\n\n${…}\n\n拼接SQL。直接将参数拼接在SQL语句中，存在SQL注入问题\n使用时机：如果对表名、列表进行动态设置时使用\n\n\n\n\n\n\n\n\n\n\n\n\n注意事项：在项目开发中，建议使用#{…}，生成预编译SQL，防止SQL注入安全。\n5.2  新增SQL语句：\nsqlinsert into emp(username, name, gender, image, job, entrydate, dept_id, create_time, update_time) values (&#39;songyuanqiao&#39;,&#39;宋远桥&#39;,1,&#39;1.jpg&#39;,2,&#39;2012-10-09&#39;,2,&#39;2022-10-01 10:00:00&#39;,&#39;2022-10-01 10:00:00&#39;);接口方法：\njava@Mapper\npublic interface EmpMapper &#123;\n\n    @Insert(&quot;insert into emp(username, name, gender, image, job, entrydate, dept_id, create_time, update_time) values (#&#123;username&#125;, #&#123;name&#125;, #&#123;gender&#125;, #&#123;image&#125;, #&#123;job&#125;, #&#123;entrydate&#125;, #&#123;deptId&#125;, #&#123;createTime&#125;, #&#123;updateTime&#125;)&quot;)\n    public void insert(Emp emp);\n\n&#125;\n\n\n\n\n\n\n\n\n说明：#{…} 里面写的名称是对象的属性名\n测试类：\njavaimport com.itheima.mapper.EmpMapper;\nimport com.itheima.pojo.Emp;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.context.SpringBootTest;\nimport java.time.LocalDate;\nimport java.time.LocalDateTime;\n\n@SpringBootTest\nclass SpringbootMybatisCrudApplicationTests &#123;\n    @Autowired\n    private EmpMapper empMapper;\n\n    @Test\n    public void testInsert()&#123;\n        //创建员工对象\n        Emp emp = new Emp();\n        emp.setUsername(&quot;tom&quot;);\n        emp.setName(&quot;汤姆&quot;);\n        emp.setImage(&quot;1.jpg&quot;);\n        emp.setGender((short)1);\n        emp.setJob((short)1);\n        emp.setEntrydate(LocalDate.of(2000,1,1));\n        emp.setCreateTime(LocalDateTime.now());\n        emp.setUpdateTime(LocalDateTime.now());\n        emp.setDeptId(1);\n        //调用添加方法\n        empMapper.insert(emp);\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n日志输出：\n\n主键返回\n概念：在数据添加成功后，需要获取插入数据库数据的主键。\n\n\n\n\n\n\n\n\n\n如：添加套餐数据时，还需要维护套餐菜品关系表数据。\n\n业务场景：在前面讲解到的苍穹外卖菜品与套餐模块的表结构，菜品与套餐是多对多的关系，一个套餐对应多个菜品。既然是多对多的关系，是不是有一张套餐菜品中间表来维护它们之间的关系。\n\n在添加套餐的时候，我们需要在界面当中来录入套餐的基本信息，还需要来录入套餐与菜品的关联信息。这些信息录入完毕之后，我们一点保存，就需要将套餐的信息以及套餐与菜品的关联信息都需要保存到数据库当中。其实具体的过程包括两步，首先第一步先需要将套餐的基本信息保存了，接下来第二步再来保存套餐与菜品的关联信息。套餐与菜品的关联信息就是往中间表当中来插入数据，来维护它们之间的关系。而中间表当中有两个外键字段，一个是菜品的ID，就是当前菜品的ID，还有一个就是套餐的ID，而这个套餐的 ID 指的就是此次我所添加的套餐的ID，所以我们在第一步保存完套餐的基本信息之后，就需要将套餐的主键值返回来供第二步进行使用。这个时候就需要用到主键返回功能。\n那要如何实现在插入数据之后返回所插入行的主键值呢？\n\n默认情况下，执行插入操作时，是不会主键值返回的。如果我们想要拿到主键值，需要在Mapper接口中的方法上添加一个Options注解，并在注解中指定属性useGeneratedKeys&#x3D;true和keyProperty&#x3D;”实体类属性名”\n\n主键返回代码实现：\njava@Mapper\npublic interface EmpMapper &#123;\n    \n    //会自动将生成的主键值，赋值给emp对象的id属性\n    @Options(useGeneratedKeys = true,keyProperty = &quot;id&quot;)\n    @Insert(&quot;insert into emp(username, name, gender, image, job, entrydate, dept_id, create_time, update_time) values (#&#123;username&#125;, #&#123;name&#125;, #&#123;gender&#125;, #&#123;image&#125;, #&#123;job&#125;, #&#123;entrydate&#125;, #&#123;deptId&#125;, #&#123;createTime&#125;, #&#123;updateTime&#125;)&quot;)\n    public void insert(Emp emp);\n\n&#125;测试：\njava@SpringBootTest\nclass SpringbootMybatisCrudApplicationTests &#123;\n    @Autowired\n    private EmpMapper empMapper;\n\n    @Test\n    public void testInsert()&#123;\n        //创建员工对象\n        Emp emp = new Emp();\n        emp.setUsername(&quot;jack&quot;);\n        emp.setName(&quot;杰克&quot;);\n        emp.setImage(&quot;1.jpg&quot;);\n        emp.setGender((short)1);\n        emp.setJob((short)1);\n        emp.setEntrydate(LocalDate.of(2000,1,1));\n        emp.setCreateTime(LocalDateTime.now());\n        emp.setUpdateTime(LocalDateTime.now());\n        emp.setDeptId(1);\n        //调用添加方法\n        empMapper.insert(emp);\n\n        System.out.println(emp.getDeptId());\n    &#125;\n&#125;5.3 更新功能：修改员工信息\n\n\n\n\n\n\n\n\n\n\n点击”编辑”按钮后，会查询所在行记录的员工信息，并把员工信息回显在修改员工的窗体上(下个知识点学习)\n在修改员工的窗体上，可以修改的员工数据：用户名、员工姓名、性别、图像、职位、入职日期、归属部门\n思考：在修改员工数据时，要以什么做为条件呢？\n答案：员工id\nSQL语句：\nsqlupdate emp set username = &#39;linghushaoxia&#39;, name = &#39;令狐少侠&#39;, gender = 1 , image = &#39;1.jpg&#39; , job = 2, entrydate = &#39;2012-01-01&#39;, dept_id = 2, update_time = &#39;2022-10-01 12:12:12&#39; where id = 18;接口方法：\njava@Mapper\npublic interface EmpMapper &#123;\n    /**\n     * 根据id修改员工信息\n     * @param emp\n     */\n    @Update(&quot;update emp set username=#&#123;username&#125;, name=#&#123;name&#125;, gender=#&#123;gender&#125;, image=#&#123;image&#125;, job=#&#123;job&#125;, entrydate=#&#123;entrydate&#125;, dept_id=#&#123;deptId&#125;, update_time=#&#123;updateTime&#125; where id=#&#123;id&#125;&quot;)\n    public void update(Emp emp);\n    \n&#125;测试类：\njava@SpringBootTest\nclass SpringbootMybatisCrudApplicationTests &#123;\n    @Autowired\n    private EmpMapper empMapper;\n\n    @Test\n    public void testUpdate()&#123;\n        //要修改的员工信息\n        Emp emp = new Emp();\n        emp.setId(23);\n        emp.setUsername(&quot;songdaxia&quot;);\n        emp.setPassword(null);\n        emp.setName(&quot;老宋&quot;);\n        emp.setImage(&quot;2.jpg&quot;);\n        emp.setGender((short)1);\n        emp.setJob((short)2);\n        emp.setEntrydate(LocalDate.of(2012,1,1));\n        emp.setCreateTime(null);\n        emp.setUpdateTime(LocalDateTime.now());\n        emp.setDeptId(2);\n        //调用方法，修改员工数据\n        empMapper.update(emp);\n    &#125;\n&#125;5.4 查询SQL语句：\ntxtselect id, username, password, name, gender, image, job, entrydate, dept_id, create_time, update_time from emp;接口方法：\njava@Mapper\npublic interface EmpMapper &#123;\n    @Select(&quot;select id, username, password, name, gender, image, job, entrydate, dept_id, create_time, update_time from emp where id=#&#123;id&#125;&quot;)\n    public Emp getById(Integer id);\n&#125;测试类：\njava@SpringBootTest\nclass SpringbootMybatisCrudApplicationTests &#123;\n    @Autowired\n    private EmpMapper empMapper;\n\n    @Test\n    public void testGetById()&#123;\n        Emp emp = empMapper.getById(1);\n        System.out.println(emp);\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n执行结果：\n\n而在测试的过程中，我们会发现有几个字段(deptId、createTime、updateTime)是没有数据值的\n我们看到查询返回的结果中大部分字段是有值的，但是deptId，createTime，updateTime这几个字段是没有值的，而数据库中是有对应的字段值的，这是为什么呢？\n\n原因如下： \n\n实体类属性名和数据库表查询返回的字段名一致，mybatis会自动封装。\n如果实体类属性名和数据库表查询返回的字段名不一致，不能自动封装。\n\n 解决方案：\n\n起别名\n结果映射\n开启驼峰命名\n\n起别名：在SQL语句中，对不一样的列名起别名，别名和实体类属性名一样\njava@Select(&quot;select id, username, password, name, gender, image, job, entrydate, &quot; +\n        &quot;dept_id AS deptId, create_time AS createTime, update_time AS updateTime &quot; +\n        &quot;from emp &quot; +\n        &quot;where id=#&#123;id&#125;&quot;)\npublic Emp getById(Integer id);\n\n\n\n\n\n\n\n\n再次执行测试类：\n\n手动结果映射：通过 @Results及@Result 进行手动结果映射\njava@Results(&#123;@Result(column = &quot;dept_id&quot;, property = &quot;deptId&quot;),\n          @Result(column = &quot;create_time&quot;, property = &quot;createTime&quot;),\n          @Result(column = &quot;update_time&quot;, property = &quot;updateTime&quot;)&#125;)\n@Select(&quot;select id, username, password, name, gender, image, job, entrydate, dept_id, create_time, update_time from emp where id=#&#123;id&#125;&quot;)\npublic Emp getById(Integer id);\n\n\n\n\n\n\n\n\n@Results源代码：\njava@Documented\n@Retention(RetentionPolicy.RUNTIME)\n@Target(&#123;ElementType.METHOD&#125;)\npublic @interface Results &#123;\nString id() default &quot;&quot;;\n\nResult[] value() default &#123;&#125;;  //Result类型的数组\n&#125;@Result源代码：\njava@Documented\n@Retention(RetentionPolicy.RUNTIME)\n@Target(&#123;ElementType.METHOD&#125;)\n@Repeatable(Results.class)\npublic @interface Result &#123;\nboolean id() default false;//表示当前列是否为主键（true:是主键）\n\nString column() default &quot;&quot;;//指定表中字段名\n\nString property() default &quot;&quot;;//指定类中属性名\n\nClass&lt;?&gt; javaType() default void.class;\n\nJdbcType jdbcType() default JdbcType.UNDEFINED;\n\nClass&lt;? extends TypeHandler&gt; typeHandler() default UnknownTypeHandler.class;\n\nOne one() default @One;\n\nMany many() default @Many;\n&#125;\n**开启驼峰命名(推荐)**：如果字段名与属性名符合驼峰命名规则，mybatis会自动通过驼峰命名规则映射\n\n驼峰命名规则：   abc_xyz    &#x3D;&gt;   abcXyz\n\n表中字段名：abc_xyz\n类中属性名：abcXyz\n\nproperties# 在application.properties中添加：\nmybatis.configuration.map-underscore-to-camel-case=true\n\n\n\n\n\n\n\n\n要使用驼峰命名前提是 实体类的属性 与 数据库表中的字段名严格遵守驼峰命名。\n条件查询\nSQL语句：\nsqlselect id, username, password, name, gender, image, job, entrydate, dept_id, create_time, update_time \nfrom emp \nwhere name like &#39;%张%&#39; \n      and gender = 1 \n      and entrydate between &#39;2010-01-01&#39; and &#39;2020-01-01 &#39; \norder by update_time desc;接口方法：\n\n方式一\n\njava@Mapper\npublic interface EmpMapper &#123;\n    @Select(&quot;select * from emp &quot; +\n            &quot;where name like &#39;%$&#123;name&#125;%&#39; &quot; +\n            &quot;and gender = #&#123;gender&#125; &quot; +\n            &quot;and entrydate between #&#123;begin&#125; and #&#123;end&#125; &quot; +\n            &quot;order by update_time desc&quot;)\n    public List&lt;Emp&gt; list(String name, Short gender, LocalDate begin, LocalDate end);\n&#125;\n\n\n\n\n\n\n\n\n\n以上方式注意事项：\n\n方法中的形参名和SQL语句中的参数占位符名保持一致\n\n模糊查询使用${…}进行字符串拼接，这种方式呢，由于是字符串拼接，并不是预编译的形式，所以效率不高、且存在sql注入风险。\n\n\n\n方式二（解决SQL注入风险）\n使用MySQL提供的字符串拼接函数：concat(‘%’ , ‘关键字’ , ‘%’)\n\n\n\njava@Mapper\npublic interface EmpMapper &#123;\n\n    @Select(&quot;select * from emp &quot; +\n            &quot;where name like concat(&#39;%&#39;,#&#123;name&#125;,&#39;%&#39;) &quot; +\n            &quot;and gender = #&#123;gender&#125; &quot; +\n            &quot;and entrydate between #&#123;begin&#125; and #&#123;end&#125; &quot; +\n            &quot;order by update_time desc&quot;)\n    public List&lt;Emp&gt; list(String name, Short gender, LocalDate begin, LocalDate end);\n\n&#125;\n\n\n\n\n\n\n\n\n\n执行结果：生成的SQL都是预编译的SQL语句（性能高、安全）\n\n参数名说明\n在上面我们所编写的条件查询功能中，我们需要保证接口中方法的形参名和SQL语句中的参数占位符名相同。\n\n\n\n\n\n\n\n\n\n当方法中的形参名和SQL语句中的占位符参数名不相同时，就会出现以下问题：\n\n参数名在不同的SpringBoot版本中，处理方案还不同：\n\n在springBoot的2.x版本（保证参数名一致）\n\n\n\n\n\n\n\n\n\n\n\nspringBoot的父工程对compiler编译插件进行了默认的参数parameters配置，使得在编译时，会在生成的字节码文件中保留原方法形参的名称，所以#{…}里面可以直接通过形参名获取对应的值\n\n\n在springBoot的1.x版本&#x2F;单独使用mybatis（使用@Param注解来指定SQL语句中的参数名）\n\n\n\n\n\n\n\n\n\n\n\n在编译时，生成的字节码文件当中，不会保留Mapper接口中方法的形参名称，而是使用var1、var2、…这样的形参名字，此时要获取参数值时，就要通过@Param注解来指定SQL语句中的参数名\n\n6.Mybatis的XML配置文件Mybatis的开发有两种方式：\n\n注解\nXML\n\n6.1 XML配置文件规范使用Mybatis的注解方式，主要是来完成一些简单的增删改查功能。如果需要实现复杂的SQL功能，建议使用XML来配置映射语句，也就是将SQL语句写在XML配置文件中。\n在Mybatis中使用XML映射文件方式开发，需要符合一定的规范：\n\nXML映射文件的名称与Mapper接口名称一致，并且将XML映射文件和Mapper接口放置在相同包下（同包同名）\n\nXML映射文件的namespace属性为Mapper接口全限定名一致\n\nXML映射文件中sql语句的id与Mapper接口中的方法名一致，并保持返回类型一致。\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;select&gt;标签：就是用于编写select查询语句的。\n\nresultType属性，指的是查询返回的单条记录所封装的类型。\n\n6.2 XML配置文件实现第1步：创建XML映射文件\n\n\n\n第2步：编写XML映射文件\n\n\n\n\n\n\n\n\n\nxml映射文件中的dtd约束，直接从mybatis官网复制即可\nxml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;\n&lt;!DOCTYPE mapper\n  PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;\n  &quot;https://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;\n&lt;mapper namespace=&quot;&quot;&gt;\n \n&lt;/mapper&gt;配置：XML映射文件的namespace属性为Mapper接口全限定名\n\nxml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;\n&lt;!DOCTYPE mapper\n        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;\n        &quot;https://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;\n&lt;mapper namespace=&quot;com.itheima.mapper.EmpMapper&quot;&gt;\n\n&lt;/mapper&gt;配置：XML映射文件中sql语句的id与Mapper接口中的方法名一致，并保持返回类型一致\n\nxml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;\n&lt;!DOCTYPE mapper\n        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;\n        &quot;https://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;\n&lt;mapper namespace=&quot;com.itheima.mapper.EmpMapper&quot;&gt;\n\n    &lt;!--查询操作--&gt;\n    &lt;select id=&quot;list&quot; resultType=&quot;com.itheima.pojo.Emp&quot;&gt;\n        select * from emp\n        where name like concat(&#39;%&#39;,#&#123;name&#125;,&#39;%&#39;)\n              and gender = #&#123;gender&#125;\n              and entrydate between #&#123;begin&#125; and #&#123;end&#125;\n        order by update_time desc\n    &lt;/select&gt;\n&lt;/mapper&gt;\n\n\n\n\n\n\n\n\n运行测试类，执行结果：\n\n6.3 MybatisX的使用MybatisX是一款基于IDEA的快速开发Mybatis的插件，为效率而生。\nMybatisX的安装：\n\n可以通过MybatisX快速定位：\n\n\n\n\n\n\n\n\n\n\nMybatisX的使用在后续学习中会继续分享\n学习了Mybatis中XML配置文件的开发方式了，大家可能会存在一个疑问：到底是使用注解方式开发还是使用XML方式开发？\n\n\n\n\n\n\n\n\n\n官方说明：https://mybatis.net.cn/getting-started.html\n \n结论：使用Mybatis的注解，主要是来完成一些简单的增删改查功能。如果需要实现复杂的SQL功能，建议使用XML来配置映射语句。\n7.Mybatis动态SQL7.1 什么的动态SQL在页面原型中，列表上方的条件是动态的，是可以不传递的，也可以只传递其中的1个或者2个或者全部。\n\n\n而在我们刚才编写的SQL语句中，我们会看到，我们将三个条件直接写死了。 如果页面只传递了参数姓名name 字段，其他两个字段 性别 和 入职时间没有传递，那么这两个参数的值就是null。\n此时，执行的SQL语句为：\n \n这个查询结果是不正确的。正确的做法应该是：传递了参数，再组装这个查询条件；如果没有传递参数，就不应该组装这个查询条件。\n比如：如果姓名输入了”张”, 对应的SQL为:\nsqlselect *  from emp where name like &#39;%张%&#39; order by update_time desc;如果姓名输入了”张”,，性别选择了”男”，则对应的SQL为:\nsqlselect *  from emp where name like &#39;%张%&#39; and gender = 1 order by update_time desc;SQL语句会随着用户的输入或外部条件的变化而变化，我们称为：动态SQL。\n\n在Mybatis中提供了很多实现动态SQL的标签，我们学习Mybatis中的动态SQL就是掌握这些动态SQL标签。\n7.2 动态SQL-if&lt;if&gt;：用于判断条件是否成立。使用test属性进行条件判断，如果条件为true，则拼接SQL。\nxml&lt;if test=&quot;条件表达式&quot;&gt;\n   要拼接的sql语句\n&lt;/if&gt;接下来，我们就通过&lt;if&gt;标签来改造之前条件查询的案例。\n示例：把SQL语句改造为动态SQL方式\n\n原有的SQL语句\n\nxml&lt;select id=&quot;list&quot; resultType=&quot;com.itheima.pojo.Emp&quot;&gt;\n        select * from emp\n        where name like concat(&#39;%&#39;,#&#123;name&#125;,&#39;%&#39;)\n              and gender = #&#123;gender&#125;\n              and entrydate between #&#123;begin&#125; and #&#123;end&#125;\n        order by update_time desc\n&lt;/select&gt;\n动态SQL语句\n\nxml&lt;select id=&quot;list&quot; resultType=&quot;com.itheima.pojo.Emp&quot;&gt;\n        select * from emp\n        where\n    \n             &lt;if test=&quot;name != null&quot;&gt;\n                 name like concat(&#39;%&#39;,#&#123;name&#125;,&#39;%&#39;)\n             &lt;/if&gt;\n             &lt;if test=&quot;gender != null&quot;&gt;\n                 and gender = #&#123;gender&#125;\n             &lt;/if&gt;\n             &lt;if test=&quot;begin != null and end != null&quot;&gt;\n                 and entrydate between #&#123;begin&#125; and #&#123;end&#125;\n             &lt;/if&gt;\n    \n        order by update_time desc\n&lt;/select&gt;测试方法：\njava@Test\npublic void testList()&#123;\n    //性别数据为null、开始时间和结束时间也为null\n    List&lt;Emp&gt; list = empMapper.list(&quot;张&quot;, null, null, null);\n    for(Emp emp : list)&#123;\n        System.out.println(emp);\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n执行的SQL语句： \n\n下面呢，我们修改测试方法中的代码，再次进行测试，观察执行情况：\njava@Test\npublic void testList()&#123;\n    //姓名为null\n    List&lt;Emp&gt; list = empMapper.list(null, (short)1, null, null);\n    for(Emp emp : list)&#123;\n        System.out.println(emp);\n    &#125;\n&#125;执行结果：\n \n \n再次修改测试方法中的代码，再次进行测试：\njava@Test\npublic void testList()&#123;\n    //传递的数据全部为null\n    List&lt;Emp&gt; list = empMapper.list(null, null, null, null);\n    for(Emp emp : list)&#123;\n        System.out.println(emp);\n    &#125;\n&#125;执行的SQL语句：\n\n以上问题的解决方案：使用&lt;where&gt;标签代替SQL语句中的where关键字\n\n&lt;where&gt;只会在子元素有内容的情况下才插入where子句，而且会自动去除子句的开头的AND或OR\n\nxml&lt;select id=&quot;list&quot; resultType=&quot;com.itheima.pojo.Emp&quot;&gt;\n        select * from emp\n        &lt;where&gt;\n             &lt;!-- if做为where标签的子元素 --&gt;\n             &lt;if test=&quot;name != null&quot;&gt;\n                 and name like concat(&#39;%&#39;,#&#123;name&#125;,&#39;%&#39;)\n             &lt;/if&gt;\n             &lt;if test=&quot;gender != null&quot;&gt;\n                 and gender = #&#123;gender&#125;\n             &lt;/if&gt;\n             &lt;if test=&quot;begin != null and end != null&quot;&gt;\n                 and entrydate between #&#123;begin&#125; and #&#123;end&#125;\n             &lt;/if&gt;\n        &lt;/where&gt;\n        order by update_time desc\n&lt;/select&gt;测试方法：\njava@Test\npublic void testList()&#123;\n    //只有性别\n    List&lt;Emp&gt; list = empMapper.list(null, (short)1, null, null);\n    for(Emp emp : list)&#123;\n        System.out.println(emp);\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n执行的SQL语句：\n\n\n&lt;if&gt;\n\n用于判断条件是否成立，如果条件为true，则拼接SQL\n\n形式：\nxml&lt;if test=&quot;name != null&quot;&gt; … &lt;/if&gt;\n\n\n&lt;where&gt;\n\nwhere元素只会在子元素有内容的情况下才插入where子句，而且会自动去除子句的开头的AND或OR\n\n\n&lt;set&gt;\n\n动态地在行首插入 SET 关键字，并会删掉额外的逗号。（用在update语句中）\n\n\n\n7.3 动态SQL-foreach案例：员工删除功能（既支持删除单条记录，又支持批量删除）\n \nSQL语句：\ntxtdelete from emp where id in (1,2,3);Mapper接口：\njava@Mapper\npublic interface EmpMapper &#123;\n    //批量删除\n    public void deleteByIds(List&lt;Integer&gt; ids);\n&#125;XML映射文件：\n\n使用&lt;foreach&gt;遍历deleteByIds方法中传递的参数ids集合\n\nxml&lt;foreach collection=&quot;集合名称&quot; item=&quot;集合遍历出来的元素/项&quot; separator=&quot;每一次遍历使用的分隔符&quot; \n         open=&quot;遍历开始前拼接的片段&quot; close=&quot;遍历结束后拼接的片段&quot;&gt;\n&lt;/foreach&gt;xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;\n&lt;!DOCTYPE mapper\n        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;\n        &quot;https://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;\n&lt;mapper namespace=&quot;com.itheima.mapper.EmpMapper&quot;&gt;\n    &lt;!--删除操作--&gt;\n    &lt;delete id=&quot;deleteByIds&quot;&gt;\n        delete from emp where id in\n        &lt;foreach collection=&quot;ids&quot; item=&quot;id&quot; separator=&quot;,&quot; open=&quot;(&quot; close=&quot;)&quot;&gt;\n            #&#123;id&#125;\n        &lt;/foreach&gt;\n    &lt;/delete&gt;\n&lt;/mapper&gt; \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n执行的SQL语句：\n\n7.4 动态SQL-sql&amp;include问题分析：\n\n在xml映射文件中配置的SQL，有时可能会存在很多重复的片段，此时就会存在很多冗余的代码\n\n\n\n我们可以对重复的代码片段进行抽取，将其通过&lt;sql&gt;标签封装到一个SQL片段，然后再通过&lt;include&gt;标签进行引用。\n\n&lt;sql&gt;：定义可重用的SQL片段\n\n&lt;include&gt;：通过属性refid，指定包含的SQL片段\n\n\n\nSQL片段： 抽取重复的代码\nxml&lt;sql id=&quot;commonSelect&quot;&gt;\n     select id, username, password, name, gender, image, job, entrydate, dept_id, create_time, update_time from emp\n&lt;/sql&gt;然后通过&lt;include&gt; 标签在原来抽取的地方进行引用。操作如下：\nxml&lt;select id=&quot;list&quot; resultType=&quot;com.itheima.pojo.Emp&quot;&gt;\n    &lt;include refid=&quot;commonSelect&quot;/&gt;\n    &lt;where&gt;\n        &lt;if test=&quot;name != null&quot;&gt;\n            name like concat(&#39;%&#39;,#&#123;name&#125;,&#39;%&#39;)\n        &lt;/if&gt;\n        &lt;if test=&quot;gender != null&quot;&gt;\n            and gender = #&#123;gender&#125;\n        &lt;/if&gt;\n        &lt;if test=&quot;begin != null and end != null&quot;&gt;\n            and entrydate between #&#123;begin&#125; and #&#123;end&#125;\n        &lt;/if&gt;\n    &lt;/where&gt;\n    order by update_time desc\n&lt;/select&gt;","slug":"Mybatis学习","date":"2024-02-11T08:04:12.000Z","categories_index":"Study","tags_index":"Java,Mybatis","author_index":"Fioransh"},{"id":"3a4ba5bc78945135efd42b16374ed036","title":"MySQL知识点总结","content":"1.前言在我们讲解SpringBootWeb基础知识(请求响应案例)的时候，我们讲到在web开发中，为了应用程序职责单一，方便维护，我们一般将web应用程序分为三层，即：Controller、Service、Dao 。\n之前我们的案例中，是这样子的请求流程：浏览器发起请求，先请求Controller；Controller接收到请求之后，调用Service进行业务逻辑处理；Service再调用Dao，Dao再解析user.xml中所存储的数据。\nxml文件中可以存储数据，但是在企业项目开发中不会使用xml文件存储数据，因为不便管理维护，操作难度大。 在真实的企业开发中呢，都会采用数据库来存储和管理数据，那此时，web开发调用流程图如下所示：\n\n2.初识MySQL2.1 介绍首先来了解一下什么是数据库。\n\n数据库：英文为 DataBase，简称DB，它是存储和管理数据的仓库。\n\n数据是存储在数据库中的，那我们要如何来操作数据库以及数据库中所存放的数据呢？\n那这里呢，会涉及到一个软件：数据库管理系统（DataBase Management System，简称DBMS）\n\nDBMS是操作和管理数据库的大型软件。将来我们只需要操作这个软件，就可以通过这个软件来操纵和管理数据库了。\n\n此时又出现一个问题：DBMS这个软件怎么知道要操作的是哪个数据库、哪个数据呢？是对数据做修改还是查询呢？\n\n需要给DBMS软件发送一条指令，告诉这个软件我们要执行的是什么样的操作，要对哪个数据进行操作。而这个指令就是SQL语句\n\nSQL（Structured Query Language，简称SQL）：结构化查询语言，它是操作关系型数据库的编程语言，定义了一套操作关系型数据库的统一标准。我们学习数据库开发，最为重要的就是学习SQL语句 。\n\n\n\n\n\n\n\n\n\n关系型数据库：我们后面会详细讲解，现在大家只需要知道我们学习的数据库属于关系型数据库即可。\n结论：程序员给数据库管理系统(DBMS)发送SQL语句，再由数据库管理系统操作数据库当中的数据。\n了解了数据库的一些简单概念之后，接下来我们再来介绍下目前主流的数据库，这里截取了排名前十的数据库：\n \n\nOracle：大型的收费数据库，Oracle公司产品，价格昂贵。（通常是不差钱的公司会选择使用这个数据库）\nMySQL：开源免费的中小型数据库，后来Sun公司收购了MySQL，而Oracle又收购了Sun公司。目前Oracle推出两个版本的Mysql：社区版(开源免费)、商业版(收费)。\nSQL Server：Microsoft 公司推出的收费的中型数据库，C#、.net等语言常用。\nPostgreSQL：开源免费的中小型数据库。\nDB2：IBM公司的大型收费数据库产品。\nSQLLite：嵌入式的微型数据库。Android内置的数据库采用的就是该数据库。\nMariaDB：开源免费的中小型数据库。是MySQL数据库的另外一个分支、另外一个衍生产品，与MySQL数据库有很好的兼容性。\n\n2.2 MySQL入门MySQL官方提供了两个版本：\n\n商业版本（MySQL Enterprise Edition）\n\n该版本是收费的，我们可以使用30天。 官方会提供对应的技术支持。\n\n\n社区版本（MySQL Community Server）\n\n该版本是免费的，但是MySQL不会提供任何的技术支持。\n\n\n\n官网下载地址：https://downloads.mysql.com/archives/community/\n\n\n\n\n\n\n\n\n\n\n安装MySQL具体的步骤，参考资料中提供的 《MySQL安装文档》 ，进行软件的安装即可。\nMySQL服务器启动完毕后，然后再使用如下指令，来连接MySQL服务器：\ntxtmysql -u用户名 -p密码 [-h数据库服务器的IP地址 -P端口号]\n\n\n\n\n\n\n\n\n-h  参数不加，默认连接的是本地 127.0.0.1 的MySQL服务器\n-P  参数不加，默认连接的端口号是 3306\n上述指令，可以有两种形式：\n\n密码直接在-p参数之后直接指定 （这种方式不安全，密码直接以明文形式出现在命令行）\n\n\n\n密码在-p回车之后，在命令行中输入密码，然后回车\n\n \n在真实的企业开发中，MySQL数据库服务器是不会在我们本地安装的，是在公司的服务器上安装的，而服务器还需要放置在专门的IDC机房中的，IDC机房呢，就需要保证恒温、恒湿、恒压，而且还要保证网络、电源的可靠性(备用电源及网络)。\n我们在学习阶段，如果想提前体验一下企业中数据库的使用方式，可以借助于VMware虚拟机来实现。我们可以在我们的电脑上安装一个VMware，然后在Vmware虚拟机上在安装一个服务器操作系统Linux，然后再在Linux服务器上安装各种企业级软件。\n2.3 数据模型关系型数据库（RDBMS）\n概念：建立在关系模型基础上，由多张相互连接的二维表组成的数据库。\n二维表的优点：\n\n使用表存储数据，格式统一，便于维护\n\n使用SQL语言操作，标准统一，使用方便，可用于复杂查询\n\n\n\n\n\n\n\n\n\n\n\n我们之前提到的MySQL、Oracle、DB2、SQLServer这些都是属于关系型数据库，里面都是基于二维表存储数据的。\n结论：基于二维表存储数据的数据库就成为关系型数据库，不是基于二维表存储数据的数据库，就是非关系型数据库（比如大家后面要学习的Redis，就属于非关系型数据库）。\n数据模型\nMySQL是关系型数据库，是基于二维表进行数据存储的，具体的结构图下:\n\n\n通过MySQL客户端连接数据库管理系统DBMS，然后通过DBMS操作数据库\n使用MySQL客户端，向数据库管理系统发送一条SQL语句，由数据库管理系统根据SQL语句指令去操作数据库中的表结构及数据\n一个数据库服务器中可以创建多个数据库，一个数据库中也可以包含多张表，而一张表中又可以包含多行记录。\n\n\n\n\n\n\n\n\n\n\n在Mysql数据库服务器当中存储数据，你需要：\n\n先去创建数据库（可以创建多个数据库，之间是相互独立的）\n在数据库下再去创建数据表（一个数据库下可以创建多张表）\n再将数据存放在数据表中（一张表可以存储多行数据）\n\n2.4 SQL简介SQL：结构化查询语言。一门操作关系型数据库的编程语言，定义操作所有关系型数据库的统一标准。\n2.4.1 SQL通用语法1、SQL语句可以单行或多行书写，以分号结尾。\n2、SQL语句可以使用空格&#x2F;缩进来增强语句的可读性。\n3、MySQL数据库的SQL语句不区分大小写。\n4、注释：\n\n单行注释：– 注释内容   或   # 注释内容(MySQL特有)\n多行注释： &#x2F;* 注释内容 *&#x2F;\n\n2.4.2 分类SQL语句根据其功能被分为四大类：DDL、DML、DQL、DCL \n\n\n\n分类\n全称\n说明\n\n\n\nDDL\nData Definition  Language\n数据定义语言，用来定义数据库对象(数据库，表，字段)\n\n\nDML\nData Manipulation  Language\n数据操作语言，用来对数据库表中的数据进行增删改\n\n\nDQL\nData Query Language\n数据查询语言，用来查询数据库中表的记录\n\n\nDCL\nData Control  Language\n数据控制语言，用来创建数据库用户、控制数据库的访问权限\n\n\n\n3.数据库设计-DDL3.1  项目开发流程\n需求文档：\n\n在我们开发一个项目或者项目当中的某个模块之前，会先会拿到产品经理给我们提供的页面原型及需求文档。\n\n设计：\n\n拿到产品原型和需求文档之后，我们首先要做的不是编码，而是要先进行项目的设计，其中就包括概要设计、详细设计、接口设计、数据库设计等等。\n数据库设计根据产品原型以及需求文档，要分析各个模块涉及到的表结构以及表结构之间的关系，以及表结构的详细信息。最终我们需要将数据库以及数据库当中的表结构设计创建出来。\n\n开发&#x2F;测试：\n\n参照页面原型和需求进行编码，实现业务功能。在这个过程当中，我们就需要来操作设计出来的数据库表结构，来完成业务的增删改查操作等。\n\n部署上线：\n\n在项目的功能开发测试完成之后，项目就可以上线运行了，后期如果项目遇到性能瓶颈，还需要对项目进行优化。优化很重要的一个部分就是数据库的优化，包括数据库当中索引的建立、SQL 的优化、分库分表等操作。\n\n在上述的流程当中，针对于数据库来说，主要包括三个阶段：\n\n数据库设计阶段\n参照页面原型以及需求文档设计数据库表结构\n\n\n数据库操作阶段\n根据业务功能的实现，编写SQL语句对数据表中的数据进行增删改查操作\n\n\n数据库优化阶段\n通过数据库的优化来提高数据库的访问性能。优化手段：索引、SQL优化、分库分表等\n\n\n\n3.2 数据库操作我们在进行数据库设计，需要使用到刚才所介绍SQL分类中的DDL语句。\nDDL英文全称是Data Definition Language(数据定义语言)，用来定义数据库对象(数据库、表)。\nDDL中数据库的常见操作：查询、创建、使用、删除。\n3.2.1 查询数据库查询所有数据库：\ntxtshow databases;查询当前数据库：\ntxtselect database();命令行中执行效果如果：\n\n\n\n\n\n\n\n\n\n\n我们要操作某一个数据库，必须要切换到对应的数据库中。 \n通过指令：select  database() ，就可以查询到当前所处的数据库 \n3.2.2 创建数据库语法：\ntxtcreate database [ if not exists ] 数据库名;&#x3D;&#x3D;注意：在同一个数据库服务器中，不能创建两个名称相同的数据库，否则将会报错。&#x3D;&#x3D;\n\n可以使用if not exists来避免这个问题\n\nsql-- 数据库不存在,则创建该数据库；如果存在则不创建\ncreate database if not extists itcast; 3.2.3 使用数据库语法：\ntxtuse 数据库名 ;\n\n\n\n\n\n\n\n\n我们要操作某一个数据库下的表时，就需要通过该指令，切换到对应的数据库下，否则不能操作。\n3.2.4 删除数据库语法：\ntxtdrop database [ if exists ] 数据库名 ;\n\n\n\n\n\n\n\n\n如果删除一个不存在的数据库，将会报错。\n可以加上参数 if exists ，如果数据库存在，再执行删除，否则不执行删除。\n说明：上述语法中的database，也可以替换成 schema\n\n如：create schema db01;\n如：show schemas;\n\n3.3 图形化工具3.3.1 介绍在项目开发当中，通常为了提高开发效率，都会借助于现成的图形化管理工具来操作数据库。\n目前MySQL主流的图形化界面工具有以下几种：\n\nDataGrip是JetBrains旗下的一款数据库管理工具，是管理和开发MySQL、Oracle、PostgreSQL的理想解决方案。\n官网： https://www.jetbrains.com/zh-cn/datagrip/\n3.3.2 安装安装： 参考资料中提供的《DataGrip安装手册》\n\n\n\n\n\n\n\n\n\n说明：DataGrip这款工具可以不用安装，因为Jetbrains公司已经将DataGrip这款工具的功能已经集成到了 IDEA当中，所以我们就可以使用IDEA来作为一款图形化界面工具来操作Mysql数据库。\n3.3.3 使用连接数据库\n1、打开IDEA自带的Database\n\n2、配置MySQL\n\n3、输入相关信息\n \n4、下载MySQL连接驱动\n\n5、测试数据库连接\n\n6、保存配置\n\n创建数据库：\n\n\n查看所有数据库：\n\n\n3.4 表操作关于表结构的操作也是包含四个部分：创建表、查询表、修改表、删除表。\n3.4.1 创建3.4.1.1 语法txtcreate table  表名(\n    字段1  字段1类型 [约束]  [comment  字段1注释 ],\n    字段2  字段2类型 [约束]  [comment  字段2注释 ],\n    ......\n    字段n  字段n类型 [约束]  [comment  字段n注释 ] \n) [ comment  表注释 ] ;\n\n\n\n\n\n\n\n\n注意： [ ] 中的内容为可选参数； 最后一个字段后面没有逗号\n\n建表语句：\n\ntxtcreate table tb_user (\n    id int comment &#39;ID,唯一标识&#39;,   # id是一行数据的唯一标识（不能重复）\n    username varchar(20) comment &#39;用户名&#39;,\n    name varchar(10) comment &#39;姓名&#39;,\n    age int comment &#39;年龄&#39;,\n    gender char(1) comment &#39;性别&#39;\n) comment &#39;用户表&#39;;\n其实我们现在创建表结构的时候， id这个字段我们只加了一个备注信息说明它是一个唯一标识，但是在数据库层面呢，并没有去限制字段存储的数据。所以id这个字段没有起到唯一标识的作用。\n\n\n\n\n\n\n\n\n\n\n想要限制字段所存储的数据，就需要用到数据库中的约束。\n3.4.1.2 约束概念：所谓约束就是作用在表中字段上的规则，用于限制存储在表中的数据。\n作用：就是来保证数据库当中数据的正确性、有效性和完整性。（后面的学习会验证这些）\n在MySQL数据库当中，提供了以下5种约束：\n\n\n\n约束\n描述\n关键字\n\n\n\n非空约束\n限制该字段值不能为null\nnot null\n\n\n唯一约束\n保证字段的所有数据都是唯一、不重复的\nunique\n\n\n主键约束\n主键是一行数据的唯一标识，要求非空且唯一\nprimary key\n\n\n默认约束\n保存数据时，如果未指定该字段值，则采用默认值\ndefault\n\n\n外键约束\n让两张表的数据建立连接，保证数据的一致性和完整性\nforeign key\n\n\n\n\n\n\n\n\n\n\n\n注意：约束是作用于表中字段上的，可以在创建表&#x2F;修改表的时候添加约束。\nid字段下存储的值，如果由我们自己来维护会比较麻烦(必须保证值的唯一性)。MySQL数据库为了解决这个问题，给我们提供了一个关键字：auto_increment（自动增长）\n\n\n\n\n\n\n\n\n\n主键自增：auto_increment\n\n每次插入新的行记录时，数据库自动生成id字段(主键)下的值\n具有auto_increment的数据列是一个正数序列开始增长(从1开始自增)\n\n3.4.1.3 数据类型MySQL中的数据类型有很多，主要分为三类：数值类型、字符串类型、日期时间类型。\n数值类型\n\n\n\n类型\n大小\n有符号(SIGNED)范围\n无符号(UNSIGNED)范围\n描述\n\n\n\nTINYINT\n1byte\n(-128，127)\n(0，255)\n小整数值\n\n\nSMALLINT\n2bytes\n(-32768，32767)\n(0，65535)\n大整数值\n\n\nMEDIUMINT\n3bytes\n(-8388608，8388607)\n(0，16777215)\n大整数值\n\n\nINT&#x2F;INTEGER\n4bytes\n(-2147483648，2147483647)\n(0，4294967295)\n大整数值\n\n\nBIGINT\n8bytes\n(-2^63，2^63-1)\n(0，2^64-1)\n极大整数值\n\n\nFLOAT\n4bytes\n(-3.402823466 E+38，3.402823466351 E+38)\n0 和 (1.175494351  E-38，3.402823466 E+38)\n单精度浮点数值\n\n\nDOUBLE\n8bytes\n(-1.7976931348623157 E+308，1.7976931348623157 E+308)\n0 和  (2.2250738585072014 E-308，1.7976931348623157 E+308)\n双精度浮点数值\n\n\nDECIMAL\n\n依赖于M(精度)和D(标度)的值\n\n\n\n\n字符串类型\n\n\n\n类型\n大小\n描述\n\n\n\nCHAR\n0-255 bytes\n定长字符串(需要指定长度)\n\n\nVARCHAR\n0-65535 bytes\n变长字符串(需要指定长度)\n\n\nTINYBLOB\n0-255 bytes\n不超过255个字符的二进制数据\n\n\nTINYTEXT\n0-255 bytes\n短文本字符串\n\n\nBLOB\n0-65 535 bytes\n二进制形式的长文本数据\n\n\nTEXT\n0-65 535 bytes\n长文本数据\n\n\nMEDIUMBLOB\n0-16 777 215 bytes\n二进制形式的中等长度文本数据\n\n\nMEDIUMTEXT\n0-16 777 215 bytes\n中等长度文本数据\n\n\nLONGBLOB\n0-4 294 967 295 bytes\n二进制形式的极大文本数据\n\n\nLONGTEXT\n0-4 294 967 295 bytes\n极大文本数据\n\n\n日期时间类型\n\n\n\n类型\n大小\n范围\n格式\n描述\n\n\n\nDATE\n3\n1000-01-01 至  9999-12-31\nYYYY-MM-DD\n日期值\n\n\nTIME\n3\n-838:59:59 至  838:59:59\nHH:MM:SS\n时间值或持续时间\n\n\nYEAR\n1\n1901 至 2155\nYYYY\n年份值\n\n\nDATETIME\n8\n1000-01-01 00:00:00 至 9999-12-31 23:59:59\nYYYY-MM-DD HH:MM:SS\n混合日期和时间值\n\n\nTIMESTAMP\n4\n1970-01-01 00:00:01 至 2038-01-19 03:14:07\nYYYY-MM-DD HH:MM:SS\n\n\n\n3.4.1.4 案例使用SQL创建表：\nsqlcreate table emp (\n  id int unsigned primary key auto_increment comment &#39;ID&#39;,\n  username varchar(20) not null unique comment &#39;用户名&#39;,\n  password varchar(32) default &#39;123456&#39; comment &#39;密码&#39;,\n  name varchar(10) not null comment &#39;姓名&#39;,\n  gender tinyint unsigned not null comment &#39;性别, 说明: 1 男, 2 女&#39;,\n  image varchar(300) comment &#39;图像&#39;,\n  job tinyint unsigned comment &#39;职位, 说明: 1 班主任,2 讲师, 3 学工主管, 4 教研主管&#39;,\n  entrydate date comment &#39;入职时间&#39;,\n  create_time datetime not null comment &#39;创建时间&#39;,\n  update_time datetime not null comment &#39;修改时间&#39;\n) comment &#39;员工表&#39;;除了使用SQL语句创建表外，我们还可以借助于图形化界面来创建表结构，这种创建方式会更加直观、更加方便。\n操作步骤如下：\n\n在指定操作的数据库上，右键New &#x3D;&#x3D;&gt; Table\n\n\n\n编辑表结构的相关信息\n\n\n3.4.1.5 设计表流程通过上面的案例，我们明白了，设计一张表，基本的流程如下：\n\n阅读页面原型及需求文档\n\n基于页面原则和需求文档，确定原型字段(类型、长度限制、约束)\n\n再增加表设计所需要的业务基础字段(id主键、插入时间、修改时间)\n\n\n\n\n\n\n\n\n\n\n\n\n说明：\n\ncreate_time：记录的是当前这条数据插入的时间。 \n\nupdate_time：记录当前这条数据最后更新的时间。\n\n\n3.4.2 查询\n\n\n\n\n\n\n\n\n关于表结构的查询操作，工作中一般都是直接基于图形化界面操作。 \n查询当前数据库所有表\ntxtshow tables;查看指定表结构\ntxtdesc 表名 ;#可以查看指定表的字段、字段的类型、是否可以为NULL、是否存在默认值等信息查询指定表的建表语句\ntxtshow create table 表名 ;3.4.3 修改\n\n\n\n\n\n\n\n\n关于表结构的修改操作，工作中一般都是直接基于图形化界面操作。 \n添加字段\nsqlalter table 表名 add  字段名  类型(长度)  [comment 注释]  [约束];修改数据类型\ntxtalter table 表名 modify  字段名  新数据类型(长度);sqlalter table 表名 change  旧字段名  新字段名  类型(长度)  [comment 注释]  [约束];删除字段\nsqlalter table 表名 drop 字段名;修改表名\nsqlrename table 表名 to  新表名;3.4.4 删除删除表语法：\nsqldrop  table [ if exists ]  表名;\n\n\n\n\n\n\n\n\nif exists ：只有表名存在时才会删除该表，表名不存在，则不执行删除操作(如果不加该参数项，删除一张不存在的表，执行将会报错)。\n4.数据库操作-DMLDML英文全称是Data Manipulation Language(数据操作语言)，用来对数据库中表的数据记录进行增、删、改操作。\n\n添加数据（INSERT）\n修改数据（UPDATE）\n删除数据（DELETE）\n\n4.1 添加（insert）insert语法：\n\n向指定字段添加数据\ntxtinsert into 表名 (字段名1, 字段名2) values (值1, 值2);\n全部字段添加数据\ntxtinsert into 表名 values (值1, 值2, ...);\n批量添加数据（指定字段）\ntxtinsert into 表名 (字段名1, 字段名2) values (值1, 值2), (值1, 值2);\n批量添加数据（全部字段）\ntxtinsert into 表名 values (值1, 值2, ...), (值1, 值2, ...);\n\nInsert操作的注意事项：\n\n插入数据时，指定的字段顺序需要与值的顺序是一一对应的。\n\n字符串和日期型数据应该包含在引号中。\n\n插入的数据大小，应该在字段的规定范围内。\n\n\n4.2 修改（update）update语法：\nsqlupdate 表名 set 字段名1 = 值1 , 字段名2 = 值2 , .... [where 条件] ;\n\n\n\n\n\n\n\n\n注意事项:\n\n修改语句的条件可以有，也可以没有，如果没有条件，则会修改整张表的所有数据。\n\n在修改数据时，一般需要同时修改公共字段update_time，将其修改为当前操作时间。\n\n\n4.3 删除（delete）delete语法：\nsqldelete from 表名  [where  条件] ;\n\n\n\n\n\n\n\n\n注意事项:\n​\t• DELETE 语句的条件可以有，也可以没有，如果没有条件，则会删除整张表的所有数据。\n​\t• DELETE 语句不能删除某一个字段的值(可以使用UPDATE，将该字段值置为NULL即可)。\n​\t• 当进行删除全部数据操作时，会提示询问是否确认删除所有数据，直接点击Execute即可。 \n5.数据库操作-DQL5.1 介绍DQL英文全称是Data Query Language(数据查询语言)，用来查询数据库表中的记录。\n查询关键字：SELECT\n查询操作是所有SQL语句当中最为常见，也是最为重要的操作。在一个正常的业务系统中，查询操作的使用频次是要远高于增删改操作的。当我们打开某个网站或APP所看到的展示信息，都是通过从数据库中查询得到的，而在这个查询过程中，还会涉及到条件、排序、分页等操作。\n5.2 语法DQL查询语句，语法结构如下：\ntxtSELECT\n    字段列表\nFROM\n    表名列表\nWHERE\n    条件列表\nGROUP  BY\n    分组字段列表\nHAVING\n    分组后条件列表\nORDER BY\n    排序字段列表\nLIMIT\n    分页参数5.3 基本查询在基本查询的DQL语句中，不带任何的查询条件，语法如下：\n\n查询多个字段\ntxtselect 字段1, 字段2, 字段3 from  表名;\n查询所有字段（通配符）\ntxtselect *  from  表名;\n设置别名\ntxtselect 字段1 [ as 别名1 ] , 字段2 [ as 别名2 ]  from  表名;\n去除重复记录\ntxtselect distinct 字段列表 from  表名;\n\n5.4 条件查询语法：\nsqlselect  字段列表  from   表名   where   条件列表 ; -- 条件列表：意味着可以有多个条件学习条件查询就是学习条件的构建方式，而在SQL语句当中构造条件的运算符分为两类：\n\n比较运算符\n逻辑运算符\n\n常用的比较运算符如下: \n\n\n\n比较运算符\n功能\n\n\n\n&gt;\n大于\n\n\n&gt;&#x3D;\n大于等于\n\n\n&lt;\n小于\n\n\n&lt;&#x3D;\n小于等于\n\n\n&#x3D;\n等于\n\n\n&lt;&gt; 或 !&#x3D;\n不等于\n\n\nbetween …  and …\n在某个范围之内(含最小、最大值)\n\n\nin(…)\n在in之后的列表中的值，多选一\n\n\nlike 占位符\n模糊匹配(_匹配单个字符, %匹配任意个字符)\n\n\nis null\n是null\n\n\n常用的逻辑运算符如下:\n\n\n\n逻辑运算符\n功能\n\n\n\nand 或 &amp;&amp;\n并且 (多个条件同时成立)\n\n\nor 或 ||\n或者 (多个条件任意一个成立)\n\n\nnot 或 !\n非 , 不是\n\n\ntxtselect id, username, password, name, gender, image, job, entrydate, create_time, update_time\nfrom tb_emp\nwhere id &lt;=5;5.5 聚合函数之前我们做的查询都是横向查询，就是根据条件一行一行的进行判断，而使用聚合函数查询就是纵向查询，它是对一列的值进行计算，然后返回一个结果值。（将一列数据作为一个整体，进行纵向计算）\n语法：\ntxtselect  聚合函数(字段列表)  from  表名 ;\n\n\n\n\n\n\n\n\n注意 : 聚合函数会忽略空值，对NULL值不作为统计。\n常用聚合函数：\n\n\n\n函数\n功能\n\n\n\ncount\n统计数量\n\n\nmax\n最大值\n\n\nmin\n最小值\n\n\navg\n平均值\n\n\nsum\n求和\n\n\n\n\n\n\n\n\n\n\n\ncount ：按照列去统计有多少行数据。\n\n在根据指定的列统计的时候，如果这一列中有null的行，该行不会被统计在其中。\n\nsum ：计算指定列的数值和，如果不是数值类型，那么计算结果为0\nmax ：计算指定列的最大值\nmin ：计算指定列的最小值\navg ：计算指定列的平均值\ntxt# count(字段)\nselect count(id) from tb_emp;-- 结果：29\nselect count(job) from tb_emp;-- 结果：28 （聚合函数对NULL值不做计算）\n\n# count(常量)\nselect count(0) from tb_emp;\nselect count(&#39;A&#39;) from tb_emp;\n\n# count(*)  推荐此写法（MySQL底层进行了优化）\nselect count(*) from tb_emp;5.6 分组查询分组： 按照某一列或者某几列，把相同的数据进行合并输出。\n\n\n\n\n\n\n\n\n\n分组其实就是按列进行分类(指定列下相同的数据归为一类)，然后可以对分类完的数据进行合并计算。\n分组查询通常会使用聚合函数进行计算。\n语法：\ntxtselect  字段列表  from  表名  [where 条件]  group by 分组字段名  [having 分组后过滤条件];\n\n\n\n\n\n\n\n\n注意事项:\n​\t• 分组之后，查询的字段一般为聚合函数和分组字段，查询其他字段无任何意义\n​\t• 执行顺序：where &gt; 聚合函数 &gt; having \nwhere与having区别（面试题）\n\n执行时机不同：where是分组之前进行过滤，不满足where条件，不参与分组；而having是分组之后对结果进行过滤。\n判断条件不同：where不能对聚合函数进行判断，而having可以。\n\ntxtselect job, count(*)\nfrom tb_emp\nwhere entrydate &lt;= &#39;2015-01-01&#39;   -- 分组前条件\ngroup by job                      -- 按照job字段分组\nhaving count(*) &gt;= 2;             -- 分组后条件5.7 排序查询排序在日常开发中是非常常见的一个操作，有升序排序，也有降序排序。\n语法：\ntxtselect  字段列表  \nfrom   表名   \n[where  条件列表] \n[group by  分组字段 ] \norder  by  字段1  排序方式1 , 字段2  排序方式2 … ;\n排序方式：\n\nASC ：升序（默认值）\nDESC：降序\n\n\n\n\n\n\n\n\n\n\n\n\n注意事项：如果是多字段排序，当第一个字段值相同时，才会根据第二个字段进行排序 \ntxtselect id, username, password, name, gender, image, job, entrydate, create_time, update_time\nfrom tb_emp\norder by entrydate DESC; -- 按照entrydate字段下的数据进行降序排序5.8 分页查询分页操作在业务系统开发时，也是非常常见的一个功能，日常我们在网站中看到的各种各样的分页条，后台也都需要借助于数据库的分页操作。\n分页查询语法：\nsqlselect  字段列表  from   表名  limit  起始索引, 查询记录数 ;\n\n\n\n\n\n\n\n\n注意事项:\n\n起始索引从0开始。        计算公式 ：   起始索引 &#x3D; （查询页码 - 1）* 每页显示记录数\n分页查询是数据库的方言，不同的数据库有不同的实现，MySQL中是LIMIT\n如果查询的是第一页数据，起始索引可以省略，直接简写为 limit  条数\n\ntxtselect id, username, password, name, gender, image, job, entrydate, create_time, update_time\nfrom tb_emp\nlimit 0 , 5; -- 从索引0开始，向后取5条记录6.多表设计项目开发中，在进行数据库表结构设计时，会根据业务需求及业务模块之间的关系，分析并设计表结构，由于业务之间相互关联，所以各个表结构之间也存在着各种联系，基本上分为三种：\n\n一对多(多对一)\n\n多对多\n\n一对一\n\n\n6.1 一对多员工表 - 部门表之间的关系：\n\n\n\n\n\n\n\n\n\n\n一对多关系实现：在数据库表中多的一方，添加字段，来关联属于一这方的主键。\n外键约束\n目前上述的两张表(员工表、部门表)，在数据库层面，并未建立关联，所以是无法保证数据的一致性和完整性的\n想解决上述的问题呢，我们就可以通过数据库中的 外键约束 来解决。\n\n\n\n\n\n\n\n\n\n外键约束：让两张表的数据建立连接，保证数据的一致性和完整性。  \n对应的关键字：foreign key\n外键约束的语法：\ntxt-- 创建表时指定\ncreate table 表名(\n    字段名    数据类型,\n    ...\n    [constraint]   [外键名称]  foreign  key (外键字段名)   references   主表 (主表列名)\t\n);\n\n\n-- 建完表后，添加外键\nalter table  表名  add constraint  外键名称  foreign key(外键字段名) references 主表(主表列名);方式1：通过SQL语句操作\ntxt-- 修改表： 添加外键约束\nalter table tb_emp  \nadd  constraint  fk_dept_id  foreign key (dept_id)  references  tb_dept(id);方式2：图形化界面操作\n \n\n\n\n\n\n\n\n\n\n当我们添加外键约束时，我们得保证当前数据库表中的数据是完整的。 所以，我们需要将之前删除掉的数据再添加回来。\n\n\n\n\n\n\n\n\n\n当我们添加了外键之后，再删除ID为1的部门，就会发现，此时数据库报错了，不允许删除。\n\n外键约束（foreign key）：保证了数据的完整性和一致性。\n物理外键和逻辑外键\n\n物理外键\n\n概念：使用foreign key定义外键关联另外一张表。\n缺点：\n影响增、删、改的效率（需要检查外键关系）。\n仅用于单节点数据库，不适用与分布式、集群场景。\n容易引发数据库的死锁问题，消耗性能。\n\n\n\n\n逻辑外键\n\n概念：在业务层逻辑中，解决外键关联。\n通过逻辑外键，就可以很方便的解决上述问题。\n\n\n\n\n\n\n\n\n\n\n\n\n**在现在的企业开发中，很少会使用物理外键，都是使用逻辑外键。 甚至在一些数据库开发规范中，会明确指出禁止使用物理外键 foreign key **\n6.2 一对一一对一关系表在实际开发中应用起来比较简单，通常是用来做单表的拆分，也就是将一张大表拆分成两张小表，将大表中的一些基础字段放在一张表当中，将其他的字段放在另外一张表当中，以此来提高数据的操作效率。\n\n\n\n\n\n\n\n\n\n一对一的应用场景： 用户表(基本信息+身份信息)\n\n\n基本信息：用户的ID、姓名、性别、手机号、学历\n身份信息：民族、生日、身份证号、身份证签发机关，身份证的有效期(开始时间、结束时间)\n\n其实一对一我们可以看成一种特殊的一对多。一对多我们是怎么设计表关系的？是不是在多的一方添加外键。同样我们也可以通过外键来体现一对一之间的关系，我们只需要在任意一方来添加一个外键就可以了。\n\n\n\n\n\n\n\n\n\n\n一对一 ：在任意一方加入外键，关联另外一方的主键，并且设置外键为唯一的(UNIQUE)\n6.3 多对多多对多的关系在开发中属于也比较常见的。比如：学生和老师的关系，一个学生可以有多个授课老师，一个授课老师也可以有多个学生。在比如：学生和课程的关系，一个学生可以选修多门课程，一个课程也可以供多个学生选修。\n案例：学生与课程的关系\n\n关系：一个学生可以选修多门课程，一门课程也可以供多个学生选择\n\n实现关系：建立第三张中间表，中间表至少包含两个外键，分别关联两方主键\n\n\n\n7.多表查询7.1 概述多表查询：查询时从多张表中获取所需数据\n\n\n\n\n\n\n\n\n\n单表查询的SQL语句：select  字段列表  from  表名;\n那么要执行多表查询，只需要使用逗号分隔多张表即可，如： select   字段列表  from  表1, 表2;\n查询用户表和部门表中的数据：\ntxtselect * from  tb_emp , tb_dept;此时,我们看到查询结果中包含了大量的结果集，总共85条记录，而这其实就是员工表所有的记录(17行)与部门表所有记录(5行)的所有组合情况，这种现象称之为笛卡尔积。\n笛卡尔积：笛卡尔乘积是指在数学中，两个集合(A集合和B集合)的所有组合情况。\n\n\n\n\n\n\n\n\n\n\n在多表查询时，需要消除无效的笛卡尔积，只保留表关联部分的数据\n\n在SQL语句中，如何去除无效的笛卡尔积呢？只需要给多表查询加上连接查询的条件即可。\ntxtselect * from tb_emp , tb_dept where tb_emp.dept_id = tb_dept.id ;7.2 内连接\n内连接：相当于查询A、B交集部分数据\n\n \n内连接查询：查询两表或多表中交集部分数据。\n内连接从语法上可以分为：\n\n隐式内连接\n\n显式内连接\n\n\n隐式内连接语法：\ntxtselect  字段列表   from   表1 , 表2   where  条件 ... ;显式内连接语法：\ntxtselect  字段列表   from   表1  [ inner ]  join 表2  on  连接条件 ... ;多表查询时给表起别名：\n\ntableA  as  别名1  ,  tableB  as  别名2 ;\ntableA  别名1  ,  tableB  别名2 ;\n\n\n\n\n\n\n\n\n\n\n注意事项:\n一旦为表起了别名，就不能再使用表名来指定对应的字段了，此时只能够使用别名来指定字段。\n\n隐式内连接实现\n\ntxtselect tb_emp.name , tb_dept.name -- 分别查询两张表中的数据\nfrom tb_emp , tb_dept -- 关联两张表\nwhere tb_emp.dept_id = tb_dept.id; -- 消除笛卡尔积\n显式内连接实现\n\ntxtselect tb_emp.name , tb_dept.name\nfrom tb_emp inner join tb_dept\non tb_emp.dept_id = tb_dept.id;7.3 外连接外连接\n\n左外连接：查询左表所有数据(包括两张表交集部分数据)\n\n右外连接：查询右表所有数据(包括两张表交集部分数据)\n\n\n左外连接语法结构：\ntxtselect  字段列表   from   表1  left  [ outer ]  join 表2  on  连接条件 ... ;\n\n\n\n\n\n\n\n\n左外连接相当于查询表1(左表)的所有数据，当然也包含表1和表2交集部分的数据。\n右外连接语法结构：\ntxtselect  字段列表   from   表1  right  [ outer ]  join 表2  on  连接条件 ... ;\n\n\n\n\n\n\n\n\n右外连接相当于查询表2(右表)的所有数据，当然也包含表1和表2交集部分的数据。\n\n\n\n\n\n\n\n\n\n注意事项：\n左外连接和右外连接是可以相互替换的，只需要调整连接查询时SQL语句中表的先后顺序就可以了。而我们在日常开发使用时，更偏向于左外连接。\ntxt-- 左外连接：以left join关键字左边的表为主表，查询主表中所有数据，以及和主表匹配的右边表中的数据\nselect emp.name , dept.name\nfrom tb_emp AS emp left join tb_dept AS dept \n     on emp.dept_id = dept.id;txt-- 右外连接\nselect dept.name , emp.name\nfrom tb_emp AS emp right join  tb_dept AS dept\n     on emp.dept_id = dept.id;7.4 子查询7.4.1 介绍SQL语句中嵌套select语句，称为嵌套查询，又称子查询。\nsqlSELECT  *  FROM   t1   WHERE  column1 =  ( SELECT  column1  FROM  t2 ... );\n\n\n\n\n\n\n\n\n子查询外部的语句可以是insert &#x2F; update &#x2F; delete &#x2F; select 的任何一个，最常见的是 select。\n根据子查询结果的不同分为：\n\n标量子查询（子查询结果为单个值[一行一列]）\n\n列子查询（子查询结果为一列，但可以是多行）\n\n行子查询（子查询结果为一行，但可以是多列）\n\n表子查询（子查询结果为多行多列[相当于子查询结果是一张表]）\n\n\n子查询可以书写的位置：\n\nwhere之后\nfrom之后\nselect之后\n\n7.4.2 标量子查询子查询返回的结果是单个值(数字、字符串、日期等)，最简单的形式，这种子查询称为标量子查询。\n常用的操作符： &#x3D;   &lt;&gt;   &gt;    &gt;&#x3D;    &lt;   &lt;&#x3D;   \ntxt-- 1.查询&quot;教研部&quot;部门ID\nselect id from tb_dept where name = &#39;教研部&#39;;    #查询结果：2\n-- 2.根据&quot;教研部&quot;部门ID, 查询员工信息\nselect * from tb_emp where dept_id = 2;\n\n-- 合并出上两条SQL语句\nselect * from tb_emp where dept_id = (select id from tb_dept where name = &#39;教研部&#39;);7.4.3 列子查询子查询返回的结果是一列(可以是多行)，这种子查询称为列子查询。\n常用的操作符：\n\n\n\n操作符\n描述\n\n\n\nIN\n在指定的集合范围之内，多选一\n\n\nNOT IN\n不在指定的集合范围之内\n\n\ntxt-- 1.查询&quot;销售部&quot;和&quot;市场部&quot;的部门ID\nselect id from tb_dept where name = &#39;教研部&#39; or name = &#39;咨询部&#39;;    #查询结果：3,2\n-- 2.根据部门ID, 查询员工信息\nselect * from tb_emp where dept_id in (3,2);\n\n-- 合并以上两条SQL语句\nselect * from tb_emp where dept_id in (select id from tb_dept where name = &#39;教研部&#39; or name = &#39;咨询部&#39;);7.4.4 行子查询子查询返回的结果是一行(可以是多列)，这种子查询称为行子查询。\n常用的操作符：&#x3D; 、&lt;&gt; 、IN 、NOT IN\ntxt-- 查询&quot;韦一笑&quot;的入职日期 及 职位\nselect entrydate , job from tb_emp where name = &#39;韦一笑&#39;;  #查询结果： 2007-01-01 , 2\n-- 查询与&quot;韦一笑&quot;的入职日期及职位相同的员工信息\nselect * from tb_emp where (entrydate,job) = (&#39;2007-01-01&#39;,2);\n\n-- 合并以上两条SQL语句\nselect * from tb_emp where (entrydate,job) = (select entrydate , job from tb_emp where name = &#39;韦一笑&#39;);7.4.5 表子查询子查询返回的结果是多行多列，常作为临时表，这种子查询称为表子查询。\ntxtselect * from emp where entrydate &gt; &#39;2006-01-01&#39;;\n\nselect e.*, d.* from (select * from emp where entrydate &gt; &#39;2006-01-01&#39;) e left join dept d on e.dept_id = d.id ;8.事务8.1 介绍在实际的业务开发中，有些业务操作要多次访问数据库。一个业务要发送多条SQL语句给数据库执行。需要将多次访问数据库的操作视为一个整体来执行，要么所有的SQL语句全部执行成功。如果其中有一条SQL语句失败，就进行事务的回滚，所有的SQL语句全部执行失败。\n简而言之：事务是一组操作的集合，它是一个不可分割的工作单位。事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。\n事务作用：保证在一个事务中多次操作数据库表中数据时，要么全都成功,要么全都失败。\n8.2 操作MYSQL中有两种方式进行事务的操作：\n\n自动提交事务：即执行一条sql语句提交一次事务。（默认MySQL的事务是自动提交）\n手动提交事务：先开启，再提交\n\n事务操作有关的SQL语句：\n\n\n\nSQL语句\n描述\n\n\n\nstart transaction;  &#x2F;  begin ;\n开启手动控制事务\n\n\ncommit;\n提交事务\n\n\nrollback;\n回滚事务\n\n\n\n\n\n\n\n\n\n\n\n手动提交事务使用步骤：\n\n第1种情况：开启事务  &#x3D;&gt;  执行SQL语句   &#x3D;&gt;  成功  &#x3D;&gt;  提交事务\n第2种情况：开启事务  &#x3D;&gt;  执行SQL语句   &#x3D;&gt;  失败  &#x3D;&gt;  回滚事务\n\n使用事务控制删除部门和删除该部门下的员工的操作：\nsql-- 开启事务\nstart transaction ;\n\n-- 删除学工部\ndelete from tb_dept where id = 1;\n\n-- 删除学工部的员工\ndelete from tb_emp where dept_id = 1;\n上述的这组SQL语句，如果如果执行成功，则提交事务\n\nsql-- 提交事务 (成功时执行)\ncommit ;\n上述的这组SQL语句，如果如果执行失败，则回滚事务\n\nsql-- 回滚事务 (出错时执行)\nrollback ;8.3 四大特性面试题：事务有哪些特性？\n\n原子性（Atomicity）：事务是不可分割的最小单元，要么全部成功，要么全部失败。\n一致性（Consistency）：事务完成时，必须使所有的数据都保持一致状态。\n隔离性（Isolation）：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行。\n持久性（Durability）：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的。\n\n\n\n\n\n\n\n\n\n\n事务的四大特性简称为：ACID\n\n原子性（Atomicity） ：原子性是指事务包装的一组sql是一个不可分割的工作单元，事务中的操作要么全部成功，要么全部失败。\n\n一致性（Consistency）：一个事务完成之后数据都必须处于一致性状态。\n\n\n​\t\t如果事务成功的完成，那么数据库的所有变化将生效。\n​\t\t如果事务执行出现错误，那么数据库的所有变化将会被回滚(撤销)，返回到原始状态。\n\n隔离性（Isolation）：多个用户并发的访问数据库时，一个用户的事务不能被其他用户的事务干扰，多个并发的事务之间要相互隔离。\n\n​\t\t一个事务的成功或者失败对于其他的事务是没有影响。\n\n持久性（Durability）：一个事务一旦被提交或回滚，它对数据库的改变将是永久性的，哪怕数据库发生异常，重启之后数据亦然存在。\n\n9.索引9.1 介绍索引(index)：是帮助数据库高效获取数据的数据结构 。\n\n简单来讲，就是使用索引可以提高查询的效率。\n\ntxt-- 添加索引\ncreate index idx_sku_sn on tb_sku (sn);  #在添加索引时，也需要消耗时间\n\n-- 查询数据（使用了索引）\nselect * from tb_sku where sn = &#39;100000003145008&#39;;优点：\n\n提高数据查询的效率，降低数据库的IO成本。\n通过索引列对数据进行排序，降低数据排序的成本，降低CPU消耗。\n\n缺点：\n\n索引会占用存储空间。\n索引大大提高了查询效率，同时却也降低了insert、update、delete的效率。\n\n9.2 结构MySQL数据库支持的索引结构有很多，如：Hash索引、B+Tree索引、Full-Text索引等。\n我们平常所说的索引，如果没有特别指明，都是指默认的 B+Tree 结构组织的索引。\n在没有了解B+Tree结构前，我们先回顾下之前所学习的树结构：\n\n\n\n\n\n\n\n\n\n二叉查找树：左边的子节点比父节点小，右边的子节点比父节点大\n \n\n\n\n\n\n\n\n\n\n当我们向二叉查找树保存数据时，是按照从大到小(或从小到大)的顺序保存的，此时就会形成一个单向链表，搜索性能会打折扣。\n \n\n\n\n\n\n\n\n\n\n可以选择平衡二叉树或者是红黑树来解决上述问题。（红黑树也是一棵平衡的二叉树）\n\n\n\n\n\n\n\n\n\n\n但是在Mysql数据库中并没有使用二叉搜索数或二叉平衡数或红黑树来作为索引的结构。\n思考：采用二叉搜索树或者是红黑树来作为索引的结构有什么问题？\n\n    答案\n    最大的问题就是在数据量大的情况下，树的层级比较深，会影响检索速度。因为不管是二叉搜索数还是红黑数，一个节点下面只能有两个子节点。此时在数据量大的情况下，就会造成数的高度比较高，树的高度一旦高了，检索速度就会降低。\n\n\n\n\n\n\n\n\n\n\n\n\n\n说明：如果数据结构是红黑树，那么查询1000万条数据，根据计算树的高度大概是23左右，这样确实比之前的方式快了很多，但是如果高并发访问，那么一个用户有可能需要23次磁盘IO，那么100万用户，那么会造成效率极其低下。所以为了减少红黑树的高度，那么就得增加树的宽度，就是不再像红黑树一样每个节点只能保存一个数据，可以引入另外一种数据结构，一个节点可以保存多个数据，这样宽度就会增加从而降低树的高度。这种数据结构例如BTree就满足。\n下面我们来看看B+Tree(多路平衡搜索树)结构中如何避免这个问题：\n\nB+Tree结构：\n\n每一个节点，可以存储多个key（有n个key，就有n个指针）\n节点分为：叶子节点、非叶子节点\n叶子节点，就是最后一层子节点，所有的数据都存储在叶子节点上\n非叶子节点，不是树结构最下面的节点，用于索引数据，存储的的是：key+指针\n\n\n为了提高范围查询效率，叶子节点形成了一个双向链表，便于数据的排序及区间范围查询\n\n\n\n\n\n\n\n\n\n\n拓展：\n非叶子节点都是由key+指针域组成的，一个key占8字节，一个指针占6字节，而一个节点总共容量是16KB，那么可以计算出一个节点可以存储的元素个数：16*1024字节 &#x2F; (8+6)&#x3D;1170个元素。\n\n查看mysql索引节点大小：show global status like ‘innodb_page_size’;    – 节点大小：16384\n\n当根节点中可以存储1170个元素，那么根据每个元素的地址值又会找到下面的子节点，每个子节点也会存储1170个元素，那么第二层即第二次IO的时候就会找到数据大概是：1170*1170&#x3D;135W。也就是说B+Tree数据结构中只需要经历两次磁盘IO就可以找到135W条数据。\n对于第二层每个元素有指针，那么会找到第三层，第三层由key+数据组成，假设key+数据总大小是1KB，而每个节点一共能存储16KB，所以一个第三层一个节点大概可以存储16个元素(即16条记录)。那么结合第二层每个元素通过指针域找到第三层的节点，第二层一共是135W个元素，那么第三层总元素大小就是：135W*16结果就是2000W+的元素个数。\n结合上述分析B+Tree有如下优点：\n\n千万条数据，B+Tree可以控制在小于等于3的高度\n所有的数据都存储在叶子节点上，并且底层已经实现了按照索引进行排序，还可以支持范围查询，叶子节点是一个双向链表，支持从小到大或者从大到小查找\n\n9.3 语法创建索引\ntxtcreate  [ unique ]  index 索引名 on  表名 (字段名,... ) ;查看索引\ntxtshow  index  from  表名;删除索引\ntxtdrop  index  索引名  on  表名;\n\n\n\n\n\n\n\n\n注意事项：\n\n主键字段，在建表时，会自动创建主键索引\n\n添加唯一约束时，数据库实际上会添加唯一索引\n\n\n","slug":"MySQL学习","date":"2024-02-07T09:58:12.000Z","categories_index":"Study","tags_index":"数据库,MySQL","author_index":"Fioransh"},{"id":"2fe7dc1ca97676d4ef7064386a344643","title":"Maven知识点总结","content":"1.初始Maven1.1 什么是MavenMaven是Apache旗下的一个开源项目，是一款用于管理和构建java项目的工具。\n1.2 Maven的作用使用Maven能够做什么：\n\n依赖管理\n统一项目结构\n项目构建\n\n依赖管理：\n\n方便快捷的管理项目依赖的资源(jar包)，避免版本冲突问题\n\n\n当使用maven进行项目依赖(jar包)管理，则很方便的可以解决这个问题。 我们只需要在maven项目的pom.xml文件中，添加一段如下图所示的配置即可实现。\n\n**统一项目结构 : **\n\n提供标准、统一的项目结构\n\n在项目开发中，当你使用不同的开发工具 (如：Eclipse、Idea)，创建项目工程时：\n\n若我们创建的是一个maven工程，是可以帮我们自动生成统一、标准的项目目录结构：\n\n具体的统一结构如下：\n\n\n\n\n\n\n\n\n\n\n目录说明： \n\nsrc&#x2F;main&#x2F;java: java源代码目录\nsrc&#x2F;main&#x2F;resources:  配置文件信息\nsrc&#x2F;test&#x2F;java: 测试代码\nsrc&#x2F;test&#x2F;resources: 测试配置文件信息\n\n项目构建 : \n\nmaven提供了标准的、跨平台(Linux、Windows、MacOS) 的自动化项目构建方式\n\n代码需要进行编译、测试、打包、发布，这些操作如果需要反复进行就显得特别麻烦，而Maven提供了一套简单的命令来完成项目构建。\n\n2.Maven概述2.1 Maven介绍Apache Maven是一个项目管理和构建工具，它基于项目对象模型(Project Object Model , 简称: POM)的概念，通过一小段描述信息来管理项目的构建、报告和文档。\n官网：https://maven.apache.org/\nMaven的作用： \n\n方便的依赖管理\n统一的项目结构\n标准的项目构建流程\n\n2.2 Maven模型\n项目对象模型 (Project Object Model)\n依赖管理模型(Dependency)\n构建生命周期&#x2F;阶段(Build lifecycle &amp; phases)\n\n\n2.3 Maven仓库仓库：用于存储资源，管理各种jar包\n\n\n\n\n\n\n\n\n\n仓库的本质就是一个目录(文件夹)，这个目录被用来存储开发中所有依赖(就是jar包)和插件\nMaven仓库分为：\n\n本地仓库：自己计算机上的一个目录(用来存储jar包)\n中央仓库：由Maven团队维护的全球唯一的。仓库地址：https://repo1.maven.org/maven2/\n远程仓库(私服)：一般由公司团队搭建的私有仓库\n\n当项目中使用坐标引入对应依赖jar包后，首先会查找本地仓库中是否有对应的jar包\n\n如果有，则在项目直接引用\n\n如果没有，则去中央仓库中下载对应的jar包到本地仓库\n\n\n如果还可以搭建远程仓库(私服)，将来jar包的查找顺序则变为： 本地仓库 –&gt; 远程仓库–&gt; 中央仓库\n2.4 Maven安装下载地址：https://maven.apache.org/download.cgi\nMaven安装配置步骤：\n\n解压安装\n配置仓库\n配置Maven环境变量\n\n1、解压 apache-maven-3.6.1-bin.zip（解压即安装）\n\nbin目录 ： 存放的是可执行命令。（mvn 命令重点关注）\nconf目录 ：存放Maven的配置文件。（settings.xml配置文件后期需要修改）\nlib目录 ：存放Maven依赖的jar包。（Maven也是使用java开发的，所以它也依赖其他的jar包）\n\n2、配置本地仓库\n在自己计算机上新一个目录（本地仓库，用来存储jar包）\n进入到conf目录下修改settings.xml配置文件 \n1). 使用超级记事本软件，打开settings.xml文件，定位到53行\n2). 复制标签，粘贴到注释的外面（55行）\n3). 复制之前新建的用来存储jar包的路径，替换掉标签体内容\n3、配置阿里云私服\n由于中央仓库在国外，所以下载jar包速度可能比较慢，而阿里公司提供了一个远程仓库，里面基本也都有开源项目的jar包。\n进入到conf目录下修改settings.xml配置文件：\n1). 使用超级记事本软件，打开settings.xml文件，定位到160行左右\n2). 在&#x2F;标签下为其添加子标签&#x2F;，内容如下：\nxml&lt;mirror&gt;  \n    &lt;id&gt;alimaven&lt;/id&gt;  \n    &lt;name&gt;aliyun maven&lt;/name&gt;  \n    &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;\n    &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;          \n&lt;/mirror&gt;&#x3D;&#x3D;注:  只可配置一个(另一个要注释!) ，不然两个可能发生冲突，导致jar包无法下载!!!!!!!&#x3D;&#x3D;\n4、配置环境变量\n1). 在系统变量处新建一个变量MAVEN_HOME\n\nMAVEN_HOME环境变量的值，设置为maven的解压安装目录\n\n2). 在Path中进行配置\n\nPATH环境变量的值，设置为：%MAVEN_HOME%\\bin\n\n3). 打开DOS命令提示符进行验证，出现如图所示表示安装成功\ntxtmvn -v3. IDEA集成Maven3.1 配置Maven环境1、选择 IDEA中 File  &#x3D;&gt;  Settings  &#x3D;&gt;  Build,Execution,Deployment  &#x3D;&gt;  Build Tools  &#x3D;&gt;  Maven\n\n2、设置IDEA使用本地安装的Maven，并修改配置文件及本地仓库路径\n\n\n\n\n\n\n\n\n\n\nMaven home path ：指定当前Maven的安装目录\nUser settings file ：指定当前Maven的settings.xml配置文件的存放路径\nLocal repository ：指定Maven的本地仓库的路径 (如果指定了settings.xml, 这个目录会自动读取出来, 可以不用手动指定)\n3、配置工程的编译版本为11\n\nMaven默认使用的编译版本为5（版本过低）\n\n\n3.2 全局设置1、进入到IDEA欢迎页面\n\n选择 IDEA中 File  &#x3D;&gt;  close project\n\n2、打开 All settings , 选择 Build,Execution,Deployment  &#x3D;&gt;  Build Tools  &#x3D;&gt;  Maven\n3、配置工程的编译版本为11\n这里所设置的maven的环境信息，并未指定任何一个project，此时设置的信息就属于全局配置信息。 以后，我们再创建project，默认就是使用我们全局配置的信息。\n3.3 Maven项目1、创建一个空项目 \n\n2、创建模块，选择Maven，点击Next\n\n\n3、填写模块名称，坐标信息，点击finish，创建完成\n\n4、在Maven工程下，创建HelloWorld类\n\n\n5、编写 HelloWorld，并运行\njavapublic class HelloWorld &#123;\n    public static void main(String[] args) &#123;\n        System.out.println(&quot;Hello Maven ...&quot;);\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\nMaven项目的目录结构:\nmaven-project01|—  src  (源代码目录和测试代码目录)        |—  main (源代码目录)                   |— java (源代码java文件目录)                   |— resources (源代码配置文件目录)        |—  test (测试代码目录)                   |— java (测试代码java目录)                   |— resources (测试代码配置文件目录)|— target (编译、打包生成文件存放目录)\n\n\n3.4 POM配置POM (Project Object Model) ：指的是项目对象模型，用来描述当前的maven项目。\n\n使用pom.xml文件来实现\n\npom文件详解：\n\n ：pom文件的根标签，表示当前maven项目\n ：声明项目描述遵循哪一个POM模型版本\n虽然模型本身的版本很少改变，但它仍然是必不可少的。目前POM模型版本是4.0.0\n\n\n坐标 ：、、\n定位项目在本地仓库中的位置，由以上三个标签组成一个坐标\n\n\n ：maven项目的打包方式，通常设置为jar或war（默认值：jar）\n\n3.5 Maven坐标什么是坐标？\n\nMaven中的坐标是&#x3D;&#x3D;资源的唯一标识&#x3D;&#x3D; , 通过该坐标可以唯一定位资源位置\n使用坐标来定义项目或引入项目中需要的依赖\n\nMaven坐标主要组成\n\ngroupId：定义当前Maven项目隶属组织名称（通常是域名反写，例如：com.itheima）\n\nartifactId：定义当前Maven项目名称（通常是模块名称，例如 order-service、goods-service）\n\nversion：定义当前项目版本号\n\n注意：\n\n上面所说的资源可以是插件、依赖、当前项目。\n我们的项目如果被其他的项目依赖时，也是需要坐标来引入的。\n\n\n\n3.6 导入Mavem项目\n方式1：使用Maven面板，快速导入项目\n\n打开IDEA，选择右侧Maven面板，点击 + 号，选中对应项目的pom.xml文件，双击即可\n说明：如果没有Maven面板，选择 View  &#x3D;&gt;  Appearance  &#x3D;&gt;  Tool Window Bars\n\n方式2：使用idea导入模块项目\n\nFile  &#x3D;&gt;  Project Structure  &#x3D;&gt;  Modules  &#x3D;&gt;  +  &#x3D;&gt;  Import Module\n找到要导入工程的pom.xml\n4.依赖管理4.1 依赖配置依赖：指当前项目运行所需要的jar包。一个项目中可以引入多个依赖：\n例如：在当前工程中，我们需要用到logback来记录日志，此时就可以在maven工程的pom.xml文件中，引入logback的依赖。具体步骤如下：\n\n在pom.xml中编写标签\n在标签中使用引入坐标\n定义坐标的 groupId、artifactId、version\n点击刷新按钮，引入最新加入的坐标\n\n\n刷新依赖：保证每一次引入新的依赖，或者修改现有的依赖配置，都可以加入最新的坐标\n\n注意事项：\n\n如果引入的依赖，在本地仓库中不存在，将会连接远程仓库 &#x2F; 中央仓库，然后下载依赖（这个过程会比较耗时，耐心等待）\n如果不知道依赖的坐标信息，可以到mvn的中央仓库（https://mvnrepository.com/）中搜索\n\n添加依赖的几种方式：\n\n利用中央仓库搜索的依赖坐标\n利用IDEA工具搜索依赖\n熟练上手maven后，快速导入依赖\n\n4.2 依赖传递依赖传递可以分为：\n\n直接依赖：在当前项目中通过依赖配置建立的依赖关系\n\n间接依赖：被依赖的资源如果依赖其他资源，当前项目间接依赖其他资源\n\n\n\n比如以上图中：\n\nprojectA依赖了projectB。对于projectA 来说，projectB 就是直接依赖。\n而projectB依赖了projectC及其他jar包。 那么此时，在projectA中也会将projectC的依赖传递下来。对于projectA 来说，projectC就是间接依赖。\n\n在pom.xml文件中只添加了logback-classic依赖，但由于maven的依赖具有传递性，所以会自动把所依赖的其他jar包也一起导入。\n4.3 排除依赖问题：之前我们讲了依赖具有传递性。那么A依赖B，B依赖C，如果A不想将C依赖进来，是否可以做到？ \n答案：在maven项目中，我们可以通过排除依赖来实现。\n什么是排除依赖？\n\n排除依赖：指主动断开依赖的资源。（被排除的资源无需指定版本）\n\nxml&lt;dependency&gt;\n    &lt;groupId&gt;com.itheima&lt;/groupId&gt;\n    &lt;artifactId&gt;maven-projectB&lt;/artifactId&gt;\n    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;\n   \n    &lt;!--排除依赖, 主动断开依赖的资源--&gt;\n    &lt;exclusions&gt;\n        &lt;exclusion&gt;\n            &lt;groupId&gt;junit&lt;/groupId&gt;\n            &lt;artifactId&gt;junit&lt;/artifactId&gt;\n        &lt;/exclusion&gt;\n    &lt;/exclusions&gt;\n&lt;/dependency&gt;4.4 依赖范围在项目中导入依赖的jar包后，默认情况下，可以在任何地方使用。\n\n如果希望限制依赖的使用范围，可以通过标签设置其作用范围。\n\n作用范围：\n\n主程序范围有效（main文件夹范围内）\n\n测试程序范围有效（test文件夹范围内）\n\n是否参与打包运行（package指令范围内）\n\n\nscope标签的取值范围：\n\n\n\nscope值\n主程序\n测试程序\n打包（运行）\n范例\n\n\n\ncompile（默认）\nY\nY\nY\nlog4j\n\n\ntest\n-\nY\n-\njunit\n\n\nprovided\nY\nY\n-\nservlet-api\n\n\nruntime\n-\nY\nY\njdbc驱动\n\n\n4.5 生命周期Maven的生命周期就是为了对所有的构建过程进行抽象和统一。 描述了一次项目构建，经历哪些阶段。\nMaven从大量项目和构建工具中学习和反思，然后总结了一套高度完美的，易扩展的项目构建生命周期。这个生命周期包含了项目的清理，初始化，编译，测试，打包，集成测试，验证，部署和站点生成等几乎所有构建步骤。\nMaven对项目构建的生命周期划分为3套（相互独立）：\n\nclean：清理工作。\n\ndefault：核心工作。如：编译、测试、打包、安装、部署等。\n\nsite：生成报告、发布站点等。\n\n\n\n• clean：移除上一次构建生成的文件\n• compile：编译项目源代码\n• test：使用合适的单元测试框架运行测试(junit)\n• package：将编译后的文件打包，如：jar、war等\n• install：安装项目到本地仓库\nMaven的生命周期是抽象的，这意味着生命周期本身不做任何实际工作。在Maven的设计中，实际任务（如源代码编译）都交由插件来完成。\nIDEA工具为了方便程序员使用maven生命周期，在右侧的maven工具栏中，已给出快速访问通道\n\n生命周期的顺序是：clean –&gt; validate –&gt; compile –&gt; test –&gt; package –&gt; verify –&gt; install –&gt; site –&gt; deploy \n我们需要关注的就是：clean –&gt;  compile –&gt; test –&gt; package  –&gt; install \n4.6 执行\n在日常开发中，当我们要执行指定的生命周期时，有两种执行方式：\n\n在idea工具右侧的maven工具栏中，选择对应的生命周期，双击执行\n在DOS命令行中，通过maven命令执行\n\n方式一：在idea中执行生命周期\n\n选择对应的生命周期，双击执行\n\n\ntest：\n\npackage：\n\ninstall：\n\nclean：\n\n方式二：在命令行中执行生命周期\n\n进入到DOS命令行\n\n\n \n5.其他5.1 更新依赖索引有时候给idea配置完maven仓库信息后，在idea中依然搜索不到仓库中的jar包。这是因为仓库中的jar包索引尚未更新到idea中。这个时候我们就需要更新idea中maven的索引了，具体做法如下：\n 打开设置—-搜索maven—-Repositories—-选中本地仓库—–点击Update\n\n5.2 清理maven仓库初始情况下，我们的本地仓库是没有任何jar包的，此时会从私服去下载（如果没有配置，就直接从中央仓库去下载），可能由于网络的原因，jar包下载不完全，这些不完整的jar包都是以lastUpdated结尾。此时，maven不会再重新帮你下载，需要你删除这些以lastUpdated结尾的文件，然后maven才会再次自动下载这些jar包。\n\n如果本地仓库中有很多这样的以lastUpadted结尾的文件，可以定义一个批处理文件，在其中编写如下脚本来删除： \ntxtset REPOSITORY_PATH=E:\\develop\\apache-maven-3.6.1\\mvn_repo\nrem 正在搜索...\n\ndel /s /q %REPOSITORY_PATH%\\*.lastUpdated\n\nrem 搜索完毕\npause操作步骤如下：\n1). 定义批处理文件del_lastUpdated.bat  (直接创建一个文本文件，命名为del_lastUpdated，后缀名直接改为bat即可 )\n \n2). 在上面的bat文件上右键—》编辑 。修改文件：\n \n修改完毕后，双击运行即可删除maven仓库中的残留文件。\n6.Maven高级Maven高级内容包括:\n\n分模块设计与开发\n继承与聚合\n私服\n\n6.1 分模块设计与开发所谓分模块设计，顾名思义指的就是我们在设计一个 Java 项目的时候，将一个 Java 项目拆分成多个模块进行开发。\n1). 未分模块设计的问题 \n如果项目不分模块，也就意味着所有的业务代码是不是都写在这一个 Java 项目当中。随着这个项目的业务扩张，项目当中的业务功能可能会越来越多。\n总结起来，主要两点问题：不方便项目的维护和管理、项目中的通用组件难以复用。\n2). 分模块设计\n分模块设计我们在进行项目设计阶段，就可以将一个大的项目拆分成若干个模块，每一个模块都是独立的。\n分模块设计就是将项目按照功能&#x2F;结构拆分成若干个子模块，方便项目的管理维护、拓展，也方便模块键的相互调用、资源共享。\n注意：分模块开发需要先针对模块功能进行设计，再进行编码。不会先将工程开发完毕，然后进行拆分。\n例子：\n1.创建maven模块 tlias-pojo，存放实体类\nA. 创建一个正常的Maven模块，模块名tlias-pojo\nB. 然后在tlias-pojo中创建一个包 com.itheima.pojo (和原来案例项目中的pojo包名一致)\nC. 将原来案例项目 tlias-web-management 中的pojo包下的实体类，复制到tlias-pojo模块中\nD. 在 tlias-pojo 模块的pom.xml文件中引入依赖\nE. 删除原有案例项目tlias-web-management的pojo包【直接删除不要犹豫，我们已经将该模块拆分出去了】，然后在pom.xml中引入 tlias-pojo的依赖\n2. 创建Maven模块 tlias-utils，存放相关工具类\nA. 创建一个正常的Maven模块，模块名tlias-utils\nB. 然后在 tlias-utils 中创建一个包 com.itheima.utils (和原来案例项目中的utils包名一致)\nC. 将原来案例项目 tlias-web-management 中的utils包下的实体类，复制到tlias-utils模块中\nD. 在 tlias-utils 模块的pom.xml文件中引入依赖\nE. 删除原有案例项目tlias-web-management的utils包【直接删除不要犹豫，我们已经将该模块拆分出去了】，然后在pom.xml中引入 tlias-utils的依赖\n到此呢，就已经完成了模块的拆分，拆分出了 tlias-pojo、tlias-utils、tlias-web-management ，如果其他项目中需要用到 pojo，或者 utils工具类，就可以直接引入依赖。 \n\n\n\n\n\n\n\n\n\n1). 什么是分模块设计：将项目按照功能拆分成若干个子模块\n\n\n\n\n\n\n\n\n\n2). 为什么要分模块设计：方便项目的管理维护、扩展，也方便模块间的相互调用，资源共享\n\n\n\n\n\n\n\n\n\n3). 注意事项：分模块设计需要先针对模块功能进行设计，再进行编码。不会先将工程开发完毕，然后进行拆分\n6.2 继承\n概念：继承描述的是两个工程间的关系，与java中的继承相似，子工程可以继承父工程中的配置信息，常见于依赖关系的继承。\n\n作用：简化依赖配置、统一管理依赖\n\n实现：\nxml&lt;parent&gt;\n    &lt;groupId&gt;...&lt;/groupId&gt;\n    &lt;artifactId&gt;...&lt;/artifactId&gt;\n    &lt;version&gt;...&lt;/version&gt;\n    &lt;relativePath&gt;....&lt;/relativePath&gt;\n&lt;/parent&gt;\n\n\n1). 创建maven模块 tlias-parent ，该工程为父工程，设置打包方式pom(默认jar)。\n工程结构如下：\n\n父工程tlias-parent的pom.xml文件配置如下：\nxml&lt;parent&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n    &lt;version&gt;2.7.5&lt;/version&gt;\n    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;\n&lt;/parent&gt;\n\n&lt;groupId&gt;com.itheima&lt;/groupId&gt;\n&lt;artifactId&gt;tlias-parent&lt;/artifactId&gt;\n&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;\n&lt;packaging&gt;pom&lt;/packaging&gt;\n\n\n\n\n\n\n\n\nMaven打包方式：\n\njar：普通模块打包，springboot项目基本都是jar包（内嵌tomcat运行）\nwar：普通web程序打包，需要部署在外部的tomcat服务器中运行\npom：父工程或聚合工程，该模块不写代码，仅进行依赖管理\n\n2). 在子工程的pom.xml文件中，配置继承关系。\nxml&lt;parent&gt;\n    &lt;groupId&gt;com.itheima&lt;/groupId&gt;\n    &lt;artifactId&gt;tlias-parent&lt;/artifactId&gt;\n    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;\n    &lt;relativePath&gt;../tlias-parent/pom.xml&lt;/relativePath&gt;\n&lt;/parent&gt;\n\n&lt;artifactId&gt;tlias-utils&lt;/artifactId&gt;\n&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;这里是以 tlias-utils 为例，指定了其父工程。其他的模块，都是相同的配置方式。\n\n\n\n\n\n\n\n\n\n注意：\n\n在子工程中，配置了继承关系之后，坐标中的groupId是可以省略的，因为会自动继承父工程的 。\nrelativePath指定父工程的pom文件的相对位置（如果不指定，将从本地仓库&#x2F;远程仓库查找该工程）。\n..&#x2F; 代表的上一级目录\n\n\n\n3). 在父工程中配置各个工程共有的依赖（子工程会自动继承父工程的依赖）。\nxml&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n        &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n        &lt;version&gt;1.18.24&lt;/version&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;此时，我们已经将各个子工程中共有的依赖（lombok），都定义在了父工程中，子工程中的这一项依赖，就可以直接删除了。删除之后，我们会看到父工程中配置的依赖 lombok，子工程直接继承下来了。\n \n\n\n\n\n\n\n\n\n\n工程结构说明：\n\n我们当前的项目结构为：\n \n因为我们是项目开发完毕之后，给大家基于现有项目拆分的各个模块，tlias-web-management已经存在了，然后再创建各个模块与父工程，所以父工程与模块之间是平级的。\n\n而实际项目中，可能还会见到下面的工程结构：\n \n而在真实的企业开发中，都是先设计好模块之后，再开始创建模块，开发项目。 那此时呢，一般都会先创建父工程 tlias-parent，然后将创建的各个子模块，都放在父工程parent下面。 这样层级结构会更加清晰一些。 \nPS：上面两种工程结构，都是可以正常使用的，没有一点问题。 只不过，第二种结构，看起来，父子工程结构更加清晰、更加直观。\n\n\n版本锁定\n那假如说，我们项目要升级，要使用到jwt最新版本 0.9.2 中的一个新功能，那此时需要将依赖的版本升级到0.9.2，那此时该怎么做呢 ？\n第一步：去找当前项目中所有的模块的pom.xml配置文件，看哪些模块用到了jwt的依赖。\n第二步：找到这个依赖之后，将其版本version，更换为 0.9.2。\n问题：如果项目拆分的模块比较多，每一次更换版本，我们都得找到这个项目中的每一个模块，一个一个的更改。 很容易就会出现，遗漏掉一个模块，忘记更换版本的情况。\n那我们又该如何来解决这个问题，如何来统一管理各个依赖的版本呢？ \n答案：Maven的版本锁定功能。\n在maven中，可以在父工程的pom文件中通过 &lt;dependencyManagement&gt; 来统一管理依赖版本。\n父工程：\nxml&lt;!--统一管理依赖版本--&gt;\n&lt;dependencyManagement&gt;\n    &lt;dependencies&gt;\n        &lt;!--JWT令牌--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;\n            &lt;artifactId&gt;jjwt&lt;/artifactId&gt;\n            &lt;version&gt;0.9.1&lt;/version&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n&lt;/dependencyManagement&gt;子工程：\nxml&lt;dependencies&gt;\n    &lt;!--JWT令牌--&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;\n        &lt;artifactId&gt;jjwt&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;\n\n\n\n\n\n\n\n\n注意：\n\n在父工程中所配置的 &lt;dependencyManagement&gt; 只能统一管理依赖版本，并不会将这个依赖直接引入进来。 这点和 &lt;dependencies&gt; 是不同的。\n\n子工程要使用这个依赖，还是需要引入的，只是此时就无需指定 &lt;version&gt; 版本号了，父工程统一管理。变更依赖版本，只需在父工程中统一变更。\n\n\n接下来，我们就可以将tlias-utils模块中单独配置的依赖，将其版本统一交给 tlias-parent 进行统一管理。\n如果依赖的版本已经在父工程进行了统一管理，所以在子工程中就无需再配置依赖的版本了。\n我们也可以通过自定义属性及属性引用的形式，在父工程中将依赖的版本号进行集中管理维护。 \n版本集中管理之后，我们要想修改依赖的版本，就只需要在父工程中自定义属性的位置，修改对应的属性值即可。\n\n\n\n\n\n\n\n\n\n面试题：&lt;dependencyManagement&gt; 与 &lt;dependencies&gt; 的区别是什么?\n\n&lt;dependencies&gt; 是直接依赖，在父工程配置了依赖，子工程会直接继承下来。 \n&lt;dependencyManagement&gt; 是统一管理依赖版本，不会直接依赖，还需要在子工程中引入所需依赖(无需指定版本)\n\n6.3 聚合分模块设计与开发之后啊，我们的项目被拆分为多个模块，而模块之间的关系，可能错综复杂。 那就比如我们当前的案例项目，结构如下（相对还是比较简单的）：\n\n\n那此时，大家试想一下，如果开发一个大型项目，拆分的模块很多，模块之间的依赖关系错综复杂，那此时要进行项目的打包、安装操作，是非常繁琐的。 而我们接下来，要讲解的maven的聚合就是来解决这个问题的，通过maven的聚合就可以轻松实现项目的一键构建（清理、编译、测试、打包、安装等）。\n \n\n\n聚合：将多个模块组织成一个整体，同时进行项目的构建。\n聚合工程：一个不具有业务功能的“空”工程（有且仅有一个pom文件） 【PS：一般来说，继承关系中的父工程与聚合关系中的聚合工程是同一个】\n作用：快速构建项目（无需根据依赖关系手动构建，直接在聚合工程上构建即可）\n\n在maven中，我们可以在聚合工程中通过 &lt;moudules&gt; 设置当前聚合工程所包含的子模块的名称。我们可以在 tlias-parent中，添加如下配置，来指定当前聚合工程，需要聚合的模块：\njava&lt;!--聚合其他模块--&gt;\n&lt;modules&gt;\n    &lt;module&gt;../tlias-pojo&lt;/module&gt;\n    &lt;module&gt;../tlias-utils&lt;/module&gt;\n    &lt;module&gt;../tlias-web-management&lt;/module&gt;\n&lt;/modules&gt;那此时，我们要进行编译、打包、安装操作，就无需在每一个模块上操作了。只需要在聚合工程上，统一进行操作就可以了。\n继承与聚合对比\n\n作用\n\n聚合用于快速构建项目\n\n继承用于简化依赖配置、统一管理依赖\n\n\n\n相同点：\n\n聚合与继承的pom.xml文件打包方式均为pom，通常将两种关系制作到同一个pom文件中\n\n聚合与继承均属于设计型模块，并无实际的模块内容\n\n\n\n不同点：\n\n聚合是在聚合工程中配置关系，聚合可以感知到参与聚合的模块有哪些\n\n继承是在子模块中配置关系，父模块无法感知哪些子模块继承了自己\n\n\n\n\n6.4 私服私服其实就是架设在公司局域网内部的一台服务器，就是一种特殊的远程仓库。\n有了私服之后，各个团队就可以直接来连接私服了。 A 连接上私服之后，他就可以把jar包直接上传到私服当中。我公司自己内部搭建的服务器，我是不是有权限操作呀，把jar包上传到私服之后，我让 B 团队的所有开发人员也连接同一台私服。连接上这一台私服之后，他就会根据坐标的信息，直接从私服当中将对应的jar包下载到自己的本地仓库，这样就可以使用到依赖当中所提供的一些工具类了。这样我们就可以通过私服来完成资源的共享。\n\n私服：是一种特殊的远程仓库，它是架设在局域网内的仓库服务，用来代理位于外部的中央仓库，用于解决团队内部的资源共享与资源同步问题。\n依赖查找顺序：\n本地仓库\n私服仓库\n中央仓库\n\n\n注意事项：私服在企业项目开发中，一个项目&#x2F;公司，只需要一台即可（无需我们自己搭建，会使用即可）。\n\n资源的上传与下载\n资源上传与下载，我们需要做三步配置，执行一条指令。\n第一步配置：在maven的配置文件中配置访问私服的用户名、密码。\n第二步配置：在maven的配置文件中配置连接私服的地址(url地址)。\n第三步配置：在项目的pom.xml文件中配置上传资源的位置(url地址)。\n配置好了上述三步之后，要上传资源到私服仓库，就执行执行maven生命周期：deploy。\n\n\n\n\n\n\n\n\n\n私服仓库说明：\n\nRELEASE：存储自己开发的RELEASE发布版本的资源。\nSNAPSHOT：存储自己开发的SNAPSHOT发布版本的资源。\nCentral：存储的是从中央仓库下载下来的依赖。\n\n\n\n\n\n\n\n\n\n\n项目版本说明：\n\nRELEASE(发布版本)：功能趋于稳定、当前更新停止，可以用于发行的版本，存储在私服中的RELEASE仓库中。\nSNAPSHOT(快照版本)：功能不稳定、尚处于开发中的版本，即快照版本，存储在私服的SNAPSHOT仓库中。\n\n1.设置私服的访问用户名&#x2F;密码（在自己maven安装目录下的conf&#x2F;settings.xml中的servers中配置）\n2.设置私服依赖下载的仓库组地址（在自己maven安装目录下的conf&#x2F;settings.xml中的mirrors、profiles中配置）\n3.IDEA的maven工程的pom文件中配置上传（发布）地址(直接在tlias-parent中配置发布地址)\n配置完成之后，我们就可以在tlias-parent中执行deploy生命周期，将项目发布到私服仓库中。 \n","slug":"Maven学习","date":"2024-02-05T14:33:12.000Z","categories_index":"Study","tags_index":"Java,Maven","author_index":"Fioransh"},{"id":"186ee7c09be0c58bb704d8a02925d69c","title":"Javaweb前端速通","content":"Javaweb前端速通1.前端开发介绍前端开发，主要的职责就是将数据以好看的样式呈现出来。说白了，就是开发网页程序。\n2.web标准Web标准也称为网页标准，由一系列的标准组成，大部分由W3C（ World Wide Web Consortium，万维网联盟）负责制定。由三个组成部分：\n\nHTML：负责网页的结构（页面元素和内容）。\n\nCSS：负责网页的表现（页面元素的外观、位置等页面样式，如：颜色、大小等）。\n\nJavaScript：负责网页的行为（交互效果）。\n\n\n随着技术的发展，我们为了更加快速的开发，现在也出现了很多前端开发的高级技术。例如：vue、elementui、Axios等等。\n3.HTML&amp;CSSHTML&amp;CSS基本学习同前端知识点总结一文\n**HTML: **HyperText Markup Language，超文本标记语言。\n\n超文本：超越了文本的限制，比普通文本更强大。除了文字信息，还可以定义图片、音频、视频等内容。\n\n标记语言：由标签构成的语言\n\n\nCSS: Cascading Style Sheet，层叠样式表，用于控制页面的样式（表现）。\n盒子模型：\n\n盒子：页面中所有的元素（标签），都可以看做是一个 盒子，由盒子将页面中的元素包含在一个矩形区域内，通过盒子的视角更方便的进行页面布局\n盒子模型组成：内容区域（content）、内边距区域（padding）、边框区域（border）、外边距区域（margin）\n\n4.文档查阅文档地址: https://www.w3school.com.cn/index.html\n5.JavaScript通过代码&#x2F;js效果演示提供资料进行效果演示，通过浏览器打开，我们点击主题5按钮，页面的主题发生了变化，所以js可以让我们的页面更加的智能，让页面和用户进行交互。\n5.1 引入方式第一种方式：内部脚本，将JS代码定义在HTML页面中\n\nJavaScript代码必须位于&lt;script&gt;&lt;&#x2F;script&gt;标签之间\n在HTML文档中，可以在任意地方，放置任意数量的&lt;script&gt;\n一般会把脚本置于&lt;body&gt;元素的底部，可改善显示速度\n\n第二种方式：外部脚本将， JS代码定义在外部 JS文件中，然后引入到 HTML页面中\n\n外部JS文件中，只包含JS代码，不包含&amp;ltscript&gt;标签\n引入外部js的&lt;script&gt;标签，必须是双标签\n\n5.2 语法基础语法：\n\n区分大小写：与 Java 一样，变量名、函数名以及其他一切东西都是区分大小写的\n\n每行结尾的分号可有可无\n\n大括号表示代码块\n\n\n\n\n\napi\n描述\n\n\n\nwindow.alert()\n警告框\n\n\ndocument.write()\n在HTML 输出内容\n\n\nconsole.log()\n写入浏览器控制台\n\n\n\n\n\n关键字\n解释\n\n\n\nvar\n早期ECMAScript5中用于变量声明的关键字\n\n\nlet\nECMAScript6中新增的用于变量声明的关键字，相比较var，let只在代码块内生效\n\n\nconst\n声明常量的，常量一旦声明，不能修改\n\n\n\nJavaScript 是一门弱类型语言，变量可以存放不同类型的值 。\n变量名需要遵循如下规则：\n组成字符可以是任何字母、数字、下划线（_）或美元符号（$）\n数字不能开头\n建议使用驼峰命名\n\n\n\n\n\n\n数据类型\n描述\n\n\n\nnumber\n数字（整数、小数、NaN(Not a Number)）\n\n\nstring\n字符串，单双引皆可\n\n\nboolean\n布尔。true，false\n\n\nnull\n对象为空\n\n\nundefined\n当声明的变量未初始化时，该变量的默认值是 undefined\n\n\n\n\n\n运算规则\n运算符\n\n\n\n算术运算符\n+ , - , * , &#x2F; , % , ++ , –\n\n\n赋值运算符\n&#x3D; , +&#x3D; , -&#x3D; , *&#x3D; , &#x2F;&#x3D; , %&#x3D;\n\n\n比较运算符\n&gt; , &lt; , &gt;&#x3D; , &lt;&#x3D; , !&#x3D; , &#x3D;&#x3D; , &#x3D;&#x3D;&#x3D;   注意     &#x3D;&#x3D; 会进行类型转换，&#x3D;&#x3D;&#x3D; 不会进行类型转换\n\n\n逻辑运算符\n&amp;&amp; , || , !\n\n\n三元运算符\n条件表达式 ? true_value: false_value\n\n\njsfunction 函数名(参数1,参数2..)&#123;\n    要执行的代码\n&#125;因为JavaScript是弱数据类型的语言，所以有如下几点需要注意：\n\n形式参数不需要声明类型，并且JavaScript中不管什么类型都是let或者var去声明，加上也没有意义。\n返回值也不需要声明类型，直接return即可\n\n第二种可以通过let去定义函数的名字，具体格式如下：\njslet functionName = function (参数1,参数2..)&#123;   \n    //要执行的代码\n&#125;接下来我们按照上述的格式，修改代码如下：只需要将第一种定义方式注释掉，替换成第二种定义方式即可，函数的调用不变\n5.3 JS对象基本对象：Array对象\nArray对象时用来定义数组的。常用语法格式有如下2种：\n方式1：\njslet 变量名 = new Array(元素列表); 方式2：\njslet 变量名 = [ 元素列表 ]; 与java中不一样的是，JavaScript中数组相当于java中的集合，数组的长度是可以变化的。而且JavaScript是弱数据类型的语言，所以数组中可以存储任意数据类型的值。接下来我们通过代码来演示上述特点。\n属性：\n\n\n\n属性\n描述\n\n\n\nlength\n设置或返回数组中元素的数量。\n\n\n方法：\n\n\n\n方法方法\n描述\n\n\n\nforEach()\n遍历数组中的每个有值得元素，并调用一次传入的函数\n\n\npush()\n将新元素添加到数组的末尾，并返回新的长度\n\n\nsplice()\n从数组中删除元素\n\n\nforEach()函数\n首先我们学习forEach()方法，顾名思义，这是用来遍历的，那么遍历做什么事呢？所以这个方法的参数，需要传递一个函数，而且这个函数接受一个参数，就是遍历时数组的值。修改之前的遍历代码如下：\npush()函数\npush()函数是用于向数组的末尾添加元素的，其中函数的参数就是需要添加的元素，编写如下代码：向数组的末尾添加3个元素\nsplice()函数\nsplice()函数用来数组中的元素，函数中填入2个参数。\n参数1：表示从哪个索引位置删除\n参数2：表示删除元素的个数\nString对象\nString对象的创建方式有2种：\n方式1：\njslet 变量名 = new String(&quot;…&quot;) ; //方式一方式2：\njslet 变量名 = &quot;…&quot; ; //方式二String对象也提供了一些常用的属性和方法，如下表格所示：\n属性：\n\n\n\n属性\n描述\n\n\n\nlength\n字符串的长度。\n\n\n方法：\n\n\n\n方法\n描述\n\n\n\ncharAt()\n返回在指定位置的字符。\n\n\nindexOf()\n检索字符串。\n\n\ntrim()\n去除字符串两边的空格\n\n\nsubstring()\n提取字符串中两个指定的索引号之间的字符。\n\n\n\ncharAt()函数：\ncharAt()函数用于返回在指定索引位置的字符，函数的参数就是索引。\n\nindexOf()函数：\nindexOf()函数用于检索指定内容在字符串中的索引位置的，返回值是索引，参数是指定的内容。\n\ntrim()函数：\ntrim()函数用于去除字符串两边的空格的。\n\nsubstring()函数：\nsubstring()函数用于截取字符串的，函数有2个参数。\n参数1：表示从那个索引位置开始截取。包含\n参数2：表示到那个索引位置结束。不包含\n\n\nJSON对象\n在 JavaScript 中自定义对象特别简单，其语法格式如下：\njslet 对象名 = &#123;\n    属性名1: 属性值1, \n    属性名2: 属性值2,\n    属性名3: 属性值3,\n    函数名称: function(形参列表)&#123;&#125;\n&#125;;\n我们可以通过如下语法调用属性：\njs对象名.属性名通过如下语法调用函数：\njs对象名.函数名()JSON对象：JavaScript Object Notation，JavaScript对象标记法。是通过JavaScript标记法书写的文本。其格式如下：\njs&#123;\n    &quot;key&quot;:value,\n    &quot;key&quot;:value,\n    &quot;key&quot;:value\n&#125;其中，key必须使用引号并且是双引号标记，value可以是任意数据类型。\n那么json这种数据格式的文本到底应用在企业开发的什么地方呢？– 经常用来作为前后台交互的数据载体\n前后台交互时，我们需要传输数据，但是java中的对象我们该怎么去描述呢？我们可以使用如图所示的xml格式，可以清晰的描述java中需要传递给前端的java对象。\n但是xml格式存在如下问题：\n\n标签需要编写双份，占用带宽，浪费资源\n解析繁琐\n\n所以我们可以使用json来替代。\nBOM对象\nBOM的全称是Browser Object Model,翻译过来是浏览器对象模型。也就是JavaScript将浏览器的各个组成部分封装成了对象。我们要操作浏览器的部分功能，可以通过操作BOM对象的相关属性或者函数来完成。\nBOM中提供了如下5个对象：\n\n\n\n对象名称\n描述\n\n\n\nWindow\n浏览器窗口对象\n\n\nNavigator\n浏览器对象\n\n\nScreen\n屏幕对象\n\n\nHistory\n历史记录对象\n\n\nLocation\nd地址栏对象\n\n\n1.Window对象 \nwindow对象指的是浏览器窗口对象，是JavaScript的全部对象，所以对于window对象，我们可以直接使用，并且对于window对象的方法和属性，我们可以省略window.\nwindow对象提供了获取其他BOM对象的属性：\n\n\n\n属性\n描述\n\n\n\nhistory\n用于获取history对象\n\n\nlocation\n用于获取location对象\n\n\nNavigator\n用于获取Navigator对象\n\n\nScreen\n用于获取Screen对象\n\n\nwindow也提供了一些常用的函数，如下表格所示：\n\n\n\n函数\n描述\n\n\n\nalert()\n显示带有一段消息和一个确认按钮的警告框。\n\n\ncomfirm()\n显示带有一段消息以及确认按钮和取消按钮的对话框。\n\n\nsetInterval()\n按照指定的周期（以毫秒计）来调用函数或计算表达式。\n\n\nsetTimeout()\n在指定的毫秒数后调用函数或计算表达式。\n\n\nsetInterval(fn,毫秒值)：定时器，用于周期性的执行某个功能，并且是循环执行。该函数需要传递2个参数：\nfn:函数，需要周期性执行的功能代码\n毫秒值：间隔时间\nsetTimeout(fn,毫秒值) ：定时器，只会在一段时间后执行一次功能。参数和上述setInterval一致\n2.Location对象\nlocation是指代浏览器的地址栏对象，对于这个对象，我们常用的是href属性，用于获取或者设置浏览器的地址信息。\nDOM对象\nDOM：Document Object Model 文档对象模型。也就是 JavaScript 将 HTML 文档的各个组成部分封装为对象。\nDOM 其实我们并不陌生，之前在学习 XML 就接触过，只不过 XML 文档中的标签需要我们写代码解析，而 HTML 文档是浏览器解析。封装的对象分为\n\nDocument：整个文档对象\nElement：元素对象\nAttribute：属性对象\nText：文本对象\nComment：注释对象\n\n那么我们学习DOM技术有什么用呢？主要作用如下：\n\n改变 HTML 元素的内容\n改变 HTML 元素的样式（CSS）\n对 HTML DOM 事件作出反应\n添加和删除 HTML 元素\n\nHTML中的Element对象可以通过Document对象获取，而Document对象是通过window对象获取的。document对象提供的用于获取Element元素对象的api如下表所示：\n\n\n\n函数\n描述\n\n\n\ndocument.getElementById()\n根据id属性值获取，返回单个Element对象\n\n\ndocument.getElementsByTagName()\n根据标签名称获取，返回Element对象数组\n\n\ndocument.getElementsByName()\n根据name属性值获取，返回Element对象数组\n\n\ndocument.getElementsByClassName()\n根据class属性值获取，返回Element对象数组\n\n\n5.4 JS对象什么是事件呢？HTML事件是发生在HTML元素上的 “事情”，例如：\n\n按钮被点击\n鼠标移到元素上\n输入框失去焦点\n……..\n\n事件绑定 \nJavaScript对于事件的绑定提供了2种方式：\n\n方式1：通过html标签中的事件属性进行绑定\n例如一个按钮，我们对于按钮可以绑定单机事件，可以借助标签的onclick属性，属性值指向一个函数。\n\n方式2：通过DOM中Element元素的事件属性进行绑定\n依据我们学习过得DOM的知识点，我们知道html中的标签被加载成element对象，所以我们也可以通过element对象的属性来操作标签的属性。\n\n\n需要注意的是：事件绑定的函数，只有在事件被触发时，函数才会被调用。\n常见事件\n\n\n\n事件属性名\n说明\n\n\n\nonclick\n鼠标单击事件\n\n\nonblur\n元素失去焦点\n\n\nonfocus\n元素获得焦点\n\n\nonload\n某个页面或图像被完成加载\n\n\nonsubmit\n当表单提交时触发该事件\n\n\nonmouseover\n鼠标被移到某元素之上\n\n\nonmouseout\n鼠标从某元素移开\n\n\n6. Vue一个完整的html页面包括了视图和数据，数据是通过请求 从后台获取的，那么意味着我们需要将后台获取到的数据呈现到页面上，很明显， 这就需要我们使用DOM操作。正因为这种开发流程，所以我们引入了一种叫做MVVM(Model-View-ViewModel)的前端开发思想，即让我们开发者更加关注数据，而非数据绑定到视图这种机械化的操作。\nMVVM:其实是Model-View-ViewModel的缩写，有3个单词，具体释义如下：\n\nModel: 数据模型，特指前端中通过请求从后台获取的数据\nView: 视图，用于展示数据的页面，可以理解成我们的html+css搭建的页面，但是没有数据\nViewModel: 数据绑定到视图，负责将数据（Model）通过JavaScript的DOM技术，将数据展示到视图（View）上\n\nVue.js（读音 &#x2F;vjuː&#x2F;, 类似于 view） 是一套构建用户界面的 渐进式框架。与其他重量级框架不同的是，Vue 采用自底向上增量开发的设计。Vue 的核心库只关注视图层，并且非常容易学习，非常容易与其它库或已有项目整合。Vue.js 的目标是通过尽可能简单的 API 实现响应的数据绑定和组合的视图组件。\n框架即是一个半成品软件，是一套可重用的、通用的、软件基础代码模型。基于框架进行开发，更加快捷、更加高效。\n在创建vue对象时，有几个常用的属性：\n\nel:  用来指定哪儿些标签受 Vue 管理。 该属性取值 #app 中的 app 需要是受管理的标签的id属性值\ndata: 用来定义数据模型\nmethods: 用来定义函数。这个我们在后面就会用到\n\n6.1 常用指令在vue中，通过大量的指令来实现数据绑定到视图的，所以接下来我们需要学习vue的常用指令，如下表所示：\n\n\n\n指令\n作用\n\n\n\nv-bind\n为HTML标签绑定属性值，如设置  href , css样式等\n\n\nv-model\n在表单元素上创建双向数据绑定\n\n\nv-on\n为HTML标签绑定事件\n\n\nv-if\n条件性的渲染某元素，判定为true时渲染,否则不渲染\n\n\nv-else\n\n\n\nv-else-if\n\n\n\nv-show\n根据条件展示某元素，区别在于切换的是display属性的值\n\n\nv-for\n列表渲染，遍历容器的元素或者对象的属性\n\n\nv-bind:  为HTML标签绑定属性值，如设置  href , css样式等。当vue对象中的数据模型发生变化时，标签的属性值会随之发生变化。\nv-model： 在表单元素上创建双向数据绑定。什么是双向？\n\nvue对象的data属性中的数据变化，视图展示会一起变化\n视图数据发生变化，vue对象的data属性中的数据也会随着变化。\n\n双向绑定的作用：可以获取表单的数据的值，然后提交给服务器\nv-on: 用来给html标签绑定事件的。需要注意的是如下2点：\n\nv-on语法给标签的事件绑定的函数，必须是vue对象种声明的函数\nv-on语法绑定事件时，事件名相比较js中的事件名，没有on\n\n6.2 生命周期vue的生命周期：指的是vue对象从创建到销毁的过程。vue的生命周期包含8个阶段：每触发一个生命周期事件，会自动执行一个生命周期方法，这些生命周期方法也被称为钩子方法。其完整的生命周期如下图所示：\n\n\n\n状态\n阶段周期\n\n\n\nbeforeCreate\n创建前\n\n\ncreated\n创建后\n\n\nbeforeMount\n挂载前\n\n\nmounted\n挂载完成\n\n\nbeforeUpdate\n更新前\n\n\nupdated\n更新后\n\n\nbeforeDestroy\n销毁前\n\n\ndestroyed\n销毁后\n\n\nmounted：挂载完成，Vue初始化成功，HTML页面渲染成功。以后我们一般用于页面初始化自动的ajax请求后台数据\n","slug":"Javaweb前端速通","date":"2024-02-05T12:56:12.000Z","categories_index":"Study","tags_index":"Java,前端","author_index":"Fioransh"},{"id":"edf904054aa8b48f1e963a1dfb1f4ee3","title":"算法性能分析","content":"1.时间复杂度1.1 什么是时间复杂度时间复杂度是一个函数，它定性描述该算法的运行时间。\n通常会估算算法的操作单元数量来代表程序消耗的时间，这里默认CPU的每个单元运行消耗的时间都是相同的。假设算法的问题规模为n，那么操作单元数量便用函数f(n)来表示，随着数据规模n的增大，算法执行时间的增长率和f(n)的增长率相同，这称作为算法的渐近时间复杂度，简称时间复杂度，记为 O(f(n))。\n1.2 什么是大O算法导论给出的解释：大O用来表示上界的，当用它作为算法的最坏情况运行时间的上界，就是对任意数据输入的运行时间的上界。\n快速排序是O(nlogn)，但是当数据已经有序情况下，快速排序的时间复杂度是O(n^2) 的，**所以严格从大O的定义来讲，快速排序的时间复杂度应该是O(n^2)**。\n但是我们依然说快速排序是O(nlogn)的时间复杂度，这个就是业内的一个默认规定，这里说的O代表的就是一般情况，而不是严格的上界。\n1.3 不同数据规模的差异大O就是数据量级突破一个点且数据量级非常大的情况下所表现出的时间复杂度，这个数据量也就是常数项系数已经不起决定性作用的数据量。\n我们说的时间复杂度都是省略常数项系数的，是因为一般情况下都是默认数据规模足够的大，基于这样的事实，给出的算法时间复杂的的一个排行如下所示：\nO(1)常数阶 &lt; O(logn)对数阶 &lt; O(n)线性阶 &lt; O(nlogn)线性对数阶 &lt; O(n^2)平方阶 &lt; O(n^3)立方阶 &lt; O(2^n)指数阶\n1.4 例子题目描述：找出n个字符串中相同的两个字符串（假设这里只有两个相同的字符串）。\n1）可能会忽略了字符串比较的时间消耗，这里并不像int 型数字做比较那么简单，除了n^2 次的遍历次数外，字符串比较依然要消耗m次操作（m也就是字母串的长度），所以时间复杂度是O(m × n × n)。\n2）先排对n个字符串按字典序来排序，排序后n个字符串就是有序的，意味着两个相同的字符串就是挨在一起，然后在遍历一遍n个字符串，这样就找到两个相同的字符串了。\n那看看这种算法的时间复杂度，快速排序时间复杂度为O(nlogn)，依然要考虑字符串的长度是m，那么快速排序每次的比较都要有m次的字符比较的操作，就是O(m × n × log n) 。\n之后还要遍历一遍这n个字符串找出两个相同的字符串，别忘了遍历的时候依然要比较字符串，所以总共的时间复杂度是 O(m × n × logn + n × m)。\n我们对O(m × n × log n + n × m) 进行简化操作，把m × n提取出来变成 O(m × n × (logn + 1))，再省略常数项最后的时间复杂度是 O(m × n × log n)。\nps：例子仅用于讲解示范时间复杂度。\n2.算法为什么会超时2.1 超时怎么来程序运行的时间超过了规定的时间，一般OJ（online judge）的超时时间就是1s，也就是用例数据输入后最多要1s内得到结果，暂时还不清楚leetcode的判题规则，下文为了方便讲解，暂定超时时间就是1s。\n如果写出了一个$O(n)$的算法 ，其实可以估算出来n是多大的时候算法的执行时间就会超过1s了。\n如果n的规模已经足够让$O(n)$的算法运行时间超过了1s，就应该考虑log(n)的解法了。\n3.递归算法的时间复杂度面试题：求x的n次方\n最直观的方式应该就是，一个for循环求出结果，代码如下：\ncppint function1(int x, int n) &#123;\n    int result = 1;  // 注意 任何数的0次方等于1\n    for (int i = 0; i &lt; n; i++) &#123;\n        result = result * x;\n    &#125;\n    return result;\n&#125;时间复杂度为O(n)，此时面试官会说，有没有效率更好的算法呢。\n如果此时没有思路，不要说：我不会，我不知道了等等。\n可以和面试官探讨一下，询问：“可不可以给点提示”。面试官提示：“考虑一下递归算法”。\n那么就可以写出了如下这样的一个递归的算法，使用递归解决了这个问题。\ncppint function2(int x, int n) &#123;\n    if (n == 0) &#123;\n        return 1; // return 1 同样是因为0次方是等于1的\n    &#125;\n    return function2(x, n - 1) * x;\n&#125;一些同学可能一看到递归就想到了O(log n)，其实并不是这样，递归算法的时间复杂度本质上是要看: 递归的次数 * 每次递归中的操作次数。\n每次n-1，递归了n次时间复杂度是O(n)，每次进行了一个乘法操作，乘法操作的时间复杂度一个常数项O(1)，所以这份代码的时间复杂度是 n × 1 &#x3D; O(n)。\n这个时间复杂度就没有达到面试官的预期。于是又写出了如下的递归算法的代码：\ncppint function3(int x, int n) &#123;\n    if (n == 0) return 1;\n    if (n == 1) return x;\n\n    if (n % 2 == 1) &#123;\n        return function3(x, n / 2) * function3(x, n / 2)*x;\n    &#125;\n    return function3(x, n / 2) * function3(x, n / 2);\n&#125;**时间复杂度忽略掉常数项-1之后，这个递归算法的时间复杂度依然是O(n)**。对，你没看错，依然是O(n)的时间复杂度！\n于是又写出如下递归算法的代码：\ncppint function4(int x, int n) &#123;\n    if (n == 0) return 1;\n    if (n == 1) return x;\n    int t = function4(x, n / 2);// 这里相对于function3，是把这个递归操作抽取出来\n    if (n % 2 == 1) &#123;\n        return t * t * x;\n    &#125;\n    return t * t;\n&#125;依然还是看他递归了多少次，可以看到这里仅仅有一个递归调用，且每次都是n&#x2F;2 ，所以这里我们一共调用了log以2为底n的对数次。\n**每次递归了做都是一次乘法操作，这也是一个常数项的操作，那么这个递归算法的时间复杂度才是真正的O(logn)**。\n4.空间复杂度分析4.1 什么是空间复杂度是对一个算法在运行过程中占用内存空间大小的量度，记做S(n)&#x3D;O(f(n)。\n空间复杂度(Space Complexity)记作S(n) 依然使用大O来表示。利用程序的空间复杂度，可以对程序运行中需要多少内存有个预先估计。\n关注空间复杂度有两个常见的相关问题\n空间复杂度是考虑程序（可执行文件）的大小么？\n空间复杂度是考虑程序运行时占用内存的大小，而不是可执行文件的大小。\n空间复杂度是准确算出程序运行时所占用的内存么？\n不要以为空间复杂度就已经精准的掌握了程序的内存使用大小，很多因素会影响程序真正内存使用大小，例如编译器的内存对齐，编程语言容器的底层实现等等这些都会影响到程序内存的开销。\n所以空间复杂度是预先大体评估程序内存使用的大小。\n说到空间复杂度，我想同学们在OJ（online judge）上应该遇到过这种错误，就是超出内存限制，一般OJ对程序运行时的所消耗的内存都有一个限制。\n为了避免内存超出限制，这也需要我们对算法占用多大的内存有一个大体的预估。\n同样在工程实践中，计算机的内存空间也不是无限的，需要工程师对软件运行时所使用的内存有一个大体评估，这都需要用到算法空间复杂度的分析。\n4.2 例子什么时候的空间复杂度是$O(1)$呢，C++代码如下：\ncppint j = 0;\nfor (int i = 0; i &lt; n; i++) &#123;\n    j++;\n&#125;第一段代码可以看出，随着n的变化，所需开辟的内存空间并不会随着n的变化而变化。即此算法空间复杂度为一个常量，所以表示为大O(1)。\n什么时候的空间复杂度是O(n)？\n当消耗空间和输入参数n保持线性增长，这样的空间复杂度为O(n)，来看一下这段C++代码\ncppint* a = new int(n);\nfor (int i = 0; i &lt; n; i++) &#123;\n    a[i] = i;\n&#125;我们定义了一个数组出来，这个数组占用的大小为n，虽然有一个for循环，但没有再分配新的空间，因此，这段代码的空间复杂度主要看第一行即可，随着n的增大，开辟的内存大小呈线性增长，即 O(n)。\n5.代码内存消耗5.1 不同语言的内存管理不同的编程语言各自的内存管理方式。\n\nC&#x2F;C++这种内存堆空间的申请和释放完全靠自己管理\nJava 依赖JVM来做内存管理，不了解jvm内存管理的机制，很可能会因一些错误的代码写法而导致内存泄漏或内存溢出\nPython内存管理是由私有堆空间管理的，所有的python对象和数据结构都存储在私有堆空间中。程序员没有访问堆的权限，只有解释器才能操作。\n\n例如Python万物皆对象，并且将内存操作封装的很好，所以python的基本数据类型所用的内存会要远大于存放纯数据类型所占的内存，例如，我们都知道存储int型数据需要四个字节，但是使用Python 申请一个对象来存放数据的话，所用空间要远大于四个字节。\n5.2 内存对齐再介绍一下内存管理中另一个重要的知识点：内存对齐。\n不要以为只有C&#x2F;C++才会有内存对齐，只要可以跨平台的编程语言都需要做内存对齐，Java、Python都是一样的。\n而且这是面试中面试官非常喜欢问到的问题，就是：为什么会有内存对齐？\n主要是两个原因\n\n平台原因：不是所有的硬件平台都能访问任意内存地址上的任意数据，某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。为了同一个程序可以在多平台运行，需要内存对齐。\n硬件原因：经过内存对齐后，CPU访问内存的速度大大提升。\n\n参考学习自代码随想录\n","slug":"算法性能分析","date":"2024-01-28T14:25:12.000Z","categories_index":"Study","tags_index":"学习,算法","author_index":"Fioransh"},{"id":"8844fd48687a754eafe1c7b3d89d9e8e","title":"Hexo+gitee博客搭建流程","content":"写在前面本博客只是讲述安装流程，并不是纯面向小白的安装教程，在b站上有许多hexo的安装教程视频，可以参考b站教程进行安装。Hexo可以算是入门门槛最低的一种博客搭建手段了。这篇博客只是防止我以后忘记安装流程而编写，安装如遇到问题可以wx交流一下，不保证能解决。搭建环境开发项目是一件需要耐心的事情，可能会遇到各种各样的问题，要学会灵活网络搜索，你遇到的问题基本上都能解决，保持耐心，说不定马上你的问题就迎刃而解了。\n\n1.node js的安装和环境配置（由Ryan Dahl开发，是一个基于ChromeV8引擎的JavaScript运行环境，\n使用了一个事件驱动、非阻塞式I&#x2F;O模型，让JavaScript 运行在服务端的开发平台，\n它让JavaScript成为与PHP、Python、Perl、Ruby等服务端语言平起平坐的脚本语言\nnode 安装过程截图 \n\n安装可以无脑下一步，注意安装路径就行，不会有问题，如果不放心的话可以参考原文章的安装过程截图，有详细步骤，由于本文篇幅较长，这里就不再转载了。\n1.1 测试是否安装成功node -v\nnpm -v\n成功截图如下：\n解决npm查询不到版本号，方法一：https://past-taleggio-288.notion.site/node-24b6cf34d5c24186b7ef1ea7028b7fda\n1.2 配置环境变量详细截图在刚才安装nodejs的根目录下，创建node_global，node_cache文件夹以管理员身份打开cmd，配置路径`npm config set prefix \"E:\\develop\\nodejs\\node_global\"``npm config set cache \"E:\\develop\\nodejs\\node_cache\"`修改全局路径 node_global, 修改缓存路径 node_cache内路径需要根据自己实际情况来进行修改修改全局安装路径后，需要在系统环境变量Path中添加该路径，否则之后使用npm install –global xxx，xxx都报错找不到命令。 找到电脑环境配置  win10和win11：右键此电脑-属性-高级系统设置-高级-环境变量win11 还可以：点设置-系统-关于-高级系统设置-高级-环境变量\n完成以上操作后，在用户变量中创建NODE_PATH变量，变量值为node_modeules路径地址在系统变量中选择Path添加如下属性：\n\n2.安装git2.1 下载git官网https://git-scm.com/\n找到首页下方的Downloads\n下载对应系统（MAC、Windows、Linux&#x2F;Unix）安装包\n\n2.2 安装git安装git过程\n\n\n\n3.hexo下载npm install hexo-cli -g #安装hexo\n4.检查已安装各框架的版本git：\ngit --version\nhexo:\nhexo -v\n安装成功效果\n\n5.创建仓库及配置SSH连接5.1  创建gitee仓库（github同理）利用gitee仓库，存放静态网站资源，达到挂载网站的目的\n\n需要注意的是作为网站访问的这个仓库，仓库名称一定是，拥有者名+gitee.io\n5.2  生成ssh keys在博客文件夹根目录下，右键，调用git bash here功能\n\n先输入ssh查看是否已经安装ssh，git默认有安装\n本地生成ssh keys\ntxtssh-keygen -t rsa -C &quot;邮箱地址&quot;\n在本地电脑中找到.ssh文件夹\n\n一般默认都是，C:\\Users\\用户名.ssh.pub文件\n找到秘钥的位置，并用记事本打开**.pub文件**，复制其内容 (ctrl+a全选，ctrl+c复制，ctrl+v粘贴)\n打开gitee，头像下拉选项设置，找到SSH公钥（新建ssh秘钥）\n\n把在本地生成的秘钥内容粘贴至此秘钥处，标题可以随便取。\n测试ssh是否绑定成功（在git里操作）\ntxtssh -T git@gitee.com\n如果问你（yes or no），直接yes就可以得到上面这段话\n6.搭建本地博客创建一个放置博客文件夹的文件，在里面启用Git Bash Here\n\n初始化hexo\ntxthexo init\n\n生成hexo本地页面\n\ntxthexo s\n\n复制粘贴该地址到浏览器中，即可访问本地搭建的博客 http://localhost:4000\n\ntxthexo cl #clean #清理编译文件\nhexo g #generate #编译项目\nhexo s #server #本地预览运行项目7.上传本地博客至gitee7.1 修改配置文件在创建博客文件夹的根目录下修改-config.yml文件\n\n\ntxtdeploy:  \n   type: git  \n   repository: 你的gitee地址  \n   branch: main7.2 安装hexo-deployer-git 自动部署发布工具\ntxtnpm install hexo-deployer-git --save7.3  编译文件生成界面\ntxthexo g7.4  本地文件上传到Gitee\ntxthexo d成功后\n\n可以直接访问仓库名如:\n https://xxx.gitee.io\n\n出现如图画面，恭喜你完成了hexo的博客搭建。\n8.安装Aurora主题本步骤非必须，可以在hexo的官方网站寻找自己喜欢的主题进行安装，安装流程大致相似，每个主题也可能有自己独特的地方需要设置，具体参照对应主题自己的官方文档进行参考\nAurora官方文档参考：https://aurora.tridiamond.tech/zh/guide\n建议直接参照官方文档进行设置，官方文档更加详细。\n8.1  配置txtnpm install hexo-theme-aurora --save #进入hexo初始化目录用git执行\n安装好之后，我们需要自己创建一个配置文件。\n我们可以到 node_modules文件夹 下找到 hexo-theme-aurora文件夹。\n里面将_config.yml 复制一份 F2 重命名为_config.aurora.yml\n\n然后将 _config.aurora.yml 移动到你的博客根目录下\n\n8.2 修改配置打开_comfig.yml\n由默认主题改为Aurora\n\n由于Aurora是vue3项目\n打开根目录下的_config.yml\n修改路由方式\n\n运行\ntxthexo clean &amp; hexo g &amp; hexo server我的习惯是分开来：\ntxthexo cl\nhexo g\nhexo s\n8.3 上传并覆盖gitee仓库txthexo d可以使用\ntxthexo s进行本地预览\n打开你的Gitee网页地址，比如本博客主题配置成功\n9.博客参考[搭建博客-图文教程-Luiyang](https://luiyang08.github.io/post/Build Blog)\nhexo+aurora+github搭建-叁鄉浪子\nhexo官方文档\nAurora官方文档\n写在后面搭建完成后的文章编写也会有许多的问题，后续有空再写一下关于文章编写的问题吧，以及一些aurora主题的各种自定义样式修改例如网站图标，个人头像，文章头图等，各类组件的开关安装，编写博客实在需要很多时间，可以网上搜索参考官方文档和他人的教程，这些问题都能得到解决，最重要的是有坚持不懈的心。\n","slug":"hexo博客创建教程","date":"2024-01-25T09:42:12.000Z","categories_index":"Blog","tags_index":"学习,博客搭建","author_index":"Fioransh"},{"id":"40b4e77513d2dcdb879ae29656ac6237","title":"SCAU2023CSAPP期末知识点总结","content":"CSAPP知识点\n进制数转换：十进制转二进制、二进制转十进制、十进制转十六进制、十六进制转十进制、二进制转十六进制、十六进制转二进制。\n\n布尔运算：&amp;与（0&amp;0&#x3D;0 0&amp;1&#x3D;0 1&amp;1&#x3D;1） |或（0|0&#x3D;0 0|1&#x3D;1 1|1&#x3D;1）~非（取反）^异或（0^0&#x3D;0 0^1&#x3D;1 1^1&#x3D;0）\n\n位及运算：获取最低有效字节的值（&amp;0xFF）\n\n逻辑运算（&amp;&amp; || ！）：非0参数都位true（0x01）、参数0表示false(0x00)\n\n移位运算：左移（丢弃左位在最右端补0）逻辑右移（丢弃右位在最左端补0）算数右移（最高位等于0时候与逻辑右移一样、最高位等于1时则是在最高位补1）有符号数为算数右移、无符号数为逻辑右移。\n\n映射(B2U)有符号数无符号数的编码方式：\n\n补码编码映射(B2T)：\n\n有符号数和无符号数的转换：位模式不变、解释位的方式变化。\n\n强制类型转换、影响关系运算的结果：程序运行有符号数会强转成无符号数运算。较大数据类型转较小会损失。\n\n无符号数的转换更大数据类型-扩展：无符号数末尾带有U\n\n有符号数的转换更大数据类型-扩展：\n\n截断的基本规则：\n\n无符号数加法：\n\n有符号数加法：\n\n补码的加法：\n\n使用移位、加法运算的组合代表乘以常数因子：除法无法除尽时候会向0方向舍入、除法为右移\n\n浮点数的权重：\n\n浮点数格式（符号、阶码、尾数）：符号位s（为0时为正数、为1时为负数）阶码exp、尾数M与frac相关\n\n浮点数规格化的值、非规格化的值、特殊值：阶码exp决定了这个数是哪一类\n\n规格化的值和非规格化的值：阶码域全为0的时候E&#x3D;1-bias。M&#x3D;f。\n\n单精度浮点数的二进制表示：\n\n向上舍入、向下舍入、向0舍入、向偶数舍入：\n\nint转化为float不会溢出可能会被舍入、int&#x2F;float转化为double可以保留、double转化为float类型可能会发生溢出转换后可能被舍入、float&#x2F;double转化为int可能向0舍入也可能溢出。\n\n操作数的寄存器：\n\n操作码和操作数以及内存引用：立即数用$表示、内存引用需要加上括号\n\n操作数：\n\n汇编后缀表示：\n\n数据传送指令mov：后缀不同操作的数大小不同，当movq指令的源操作数为立即数时、该立即数只能是32位的补码表示、然后对该数值进行符号位扩展后、讲得到的64位数传送。\n\n压入和弹出栈：\n\n算数和逻辑指令leaq：\n\n通过leaq指令实现算术运算：\n\n一元操作：\n\n二元操作：\n\n移位运算：\n\n其他运算：\n\n常用条件码：CF-进位标志，当CPU最近执行的一条指令最高位产生了进位时，CF会被置1，可以用来检查无符号数的溢出。ZF-零标志，当最近操作的结果为0时，零标志会被置1。SF-符号标志，当最近的操作结果小于0的时候，符号标志会被置1。OF-溢出标志，最近的操作导致正溢出或负溢出时候会被置1。\n\ncmp指令和test指令：\n\n条件控制分支if-else以及条件传送：\n\n循环指令：循环语句是通过条件测试与跳转的结合来实现的。\n\nswitch语句：\n\n理解过程，理解“过程 P 调用过程 Q，Q 执行后返回到 P”包含的三个机制（传递控制、\n传递数据、分配和释放内存）：\n栈帧：当函数执行所需要的存储空间超出寄存器能够存放的大小时，会借助栈上的存储空间，这部分存储空间就叫做栈帧。\n对于函数P调用函数Q的例子，包括较早的帧、调用函数P的帧、还要正在执行函数Q的帧。\n当函数P调用函数Q时，会把返回地址压入栈中，该地址殖知名了函数Q执行结束返回时要从函数P的哪个位置继续进行。这个返回地址的压栈操作并不是由指令push来执行的，而是由函数调用指令call实现的。\n\n数组的分配与访问： short数组2个字节、int数组4个字节、double数组8个字节、指针数组8个字节\n二维数组（嵌套数组）：Xd表示数组的起始地址、L表示数组T的大小、Cij都是常数。\n\n理解内存越界的引用和缓冲区溢出：缓冲区溢出会导致返回时会随机返回到系统的任意位置。对抗缓冲区溢出攻击的方法：栈随机化（ASLR 栈的位置在每次运行时地址都变化）、栈破坏检测（在缓冲区与栈保存的状态值之间存储一个特殊值，这个值被称为金丝雀值、检测金丝雀值是否变化判断是否遭受攻击）、限制可执行代码区域。\n\n消除循环的低效率：CPE表示每个元素执行所需要的周期数（度量效率）。比较操作和分支操作不直接影响程序的数据流，将两个操作以及寄存器rax删除，只保留循环寄存器以及关键操作。将这个视作一个模板重复n次。\n\n减少过程调用（循环展开）：多路并行，10路时接近吞吐界限。\n\n消除不必要的内存引用（加载操作延迟）：加载操作会受存储引用和计算影响。\n\n动态RAM（DRAM）： 电容充电维持信息存储、每个bit位的存储对应一个电容和晶体管，对干扰十分敏感，内存采用DRAM，不断刷新才能保持数据，使用超单元一词来表示DRAM的存储单元，可以通过类似坐标的方式寻址，寻址所需位数关系2的n次方等于行数&#x2F;列数，n即为寻址位数。\n\n磁盘容量和磁盘访问时间的计算：\n\n局部性（时间局部性、空间局部性）：时间局部性（被引用的内存位置在不远的将来还可能被多次引用）、空间局部性（一个内存被引用了一次，程序很可能在不远的将来引用附近的一个内存位置）如两层嵌套的循环遍历二重数组的例子。\n\n高速缓存的参数：基于SRAM，有效位（valid 长1bit 表示当前cache line存储的信息是否有效 1表示有效0表示无效）、标记（tag 确定目标数据是否存在于当前的cache line中） 、数据块（cache block一小部分内存数据的副本，大小用B表示）\n\n高速缓存的三种地址的映射方式：根据每个set所包含的cache line的行数不同，cache被分为不同的类。\n直接缓存（E&#x3D;1 组选择 行匹配 字抽取 根据偏移量来确定目标数据的确切位置，从什么位置开始抽取数据 命中：不命中：cache需要从存储器层次结构的下一层取出被请求的块)\n例子：S表示有几个set、E表示每个set有几行、B表示每个数据块包含几个字节、其中地址m是多少位\n组相联（E&#x3D;2）：字抽取不命中（随机替换、最不常使用、最近最少使用）\n全相联（E&#x3D;C&#x2F;B）：\n\n编写高速缓存友好代码：\n\n理解符号类型和符号解析：全局符号（由该模块定义、同时能被其他模块引用的全局符号）、外部符号（被其他模块定义、同时被该模块引用的全局符号）、局部符号（只能被该模块定义和引用的局部符号 static）\nCOMMON是未初始化的全局变量，注意和.bss区分\n\n强符号和弱符号：强符号（函数和已初始化的全局变量  连接器不允许有多个同名的强符号一起出现）、弱符号（未初始化的全局变量）。\n\n重定位：重定位条目（告诉链接器在合成可执行文件时候应该如何修改这个引用）链接器合并输入模块，并为每个符号分配运行时地址\n重定位相对引用\n绝对地址引用\n\n异常控制流的分类：中断（异步）、陷阱、故障和终止\n\n并发流：一个逻辑流的执行在时间上和另一个流重叠的情况成为并发流，两个流的执行被成为并发运行。（并行是两个进程在不同的处理器核上同时运行）并发是交替运行的，并行是同时运行的。\n\n进程的状态\n\n进程的创建：创建进程时使用的系统函数-fork。父进程调用fork函数创建一个子进程。fork函数一次调用返回两次。父进程和子进程二者并发执行，它们的输出结果都打印出来。\n\n函数execve：调用加载器，在执行可执行程序的main函数之前。\n\nzombie僵死进程：终止运行但是还未回收的进程称为僵死进程，仍在消耗内存。\n\n子进程的回收：父进程通过函数waitpid来等待它的子进程终止或者停止。当第一个参数pid等于0表示等待的进程是一个单独的子进程，pid&#x3D;-1表示等待的进程是由父进程创建的所有子进程组成的集合。statusp是非空，函数waitpid在status上放上导致返回的子进程的状态信息，status就是statusp的值。正常回收返回true，否则未false。\n\n信号所引发事件：\n\n进程组的概念：每个进程都只属于一个进程组，每个进程组都有自己的ID值来唯一标识，通过函数getpgrp来获取当前进程所属的进程组ID值。setpgrp可以进行更改ID\n\n发送信号的方式：\n发送信号的&#x2F;kill方式：通过&#x2F;bin目录中的kill程序可以向其他的进程发送任意的信号。\n从键盘发送信号：当我们在键盘上输入Ctrl+C键会导致内容发送一个中断信号到前台进程组中的所有进程中。\n调用函数kill：调用函数发送信号给其他进程，也包括给自己发送信号。\n使用函数alarm函数：\n\n接收信号：一个待处理信号最多只能接收一次，一种类型的信号最多只能有一次待处理信号。如果一个类型为k的信号有待处理信号，那接下来这个进程中类型为k的信号都不用排队等待，会被简单地丢弃。\n\n虚拟内存：自动完成内存管理的相关工作，可以创建和释放内存空间，将内存空间映射到磁盘文件的某个部分，共享内存。虚拟内存使用不当会使程序产生错误。\n\n物理寻址：\n\n虚拟寻址：将一个虚拟地址转换成物理地址的任务叫做地址翻译\n\n地址空间：地址空间是一个非负整数的有序集合，如果地址空间中的整数是连续的，那么我们说它是一个线性地址空间，一个地址空间的大小是由标识最大地址所需要的位数来描述的。最大可能的虚拟地址是虚拟地址数-1。\n\n虚拟页（存在于磁盘上）和物理页：\n\n页表：是一个页表条目PTE的数组存在于物理内存之中，将虚拟页地址映射到物理页地址。页表条目PTE&#x3D;2的n-p次方，n为虚拟地址大小、页大小P&#x3D;2的p次方。\n\n页命中：虚拟内存中的一个字存在于物理内存中（即DRAM缓存命中）\n\n缺页：引用虚拟内存中的字，不在物理内存中 (DRAM 缓存不命中)\n\n分配页面：分配一个新的虚拟内存页 (VP 5).内核在磁盘上分配VP5， 并且将PTE5指向这个新的位置\n\n使用SRAM缓存来表示CPU与内存之间的L1L2L3这三级高速缓存。DRAM表示虚拟内存系统的缓存。\n\n地址翻译：\n\nP&#x3D;1K&#x3D;2的10次方可以得到p&#x3D;10。虚拟页偏移量VPO&#x3D;物理页偏移量PPO&#x3D;p。虚拟页号VPN&#x3D;虚拟地址空间-虚拟页偏移量VPO。物理页号PPN&#x3D;物理地址-物理页偏移量PPO。\n\n\n","slug":"CSAPP知识点","date":"2024-01-02T05:28:12.000Z","categories_index":"Study","tags_index":"CSAPP,学习","author_index":"Fioransh"},{"id":"c64df93cb58edc8361b9b55ace6a467f","title":"前端部分知识点","content":"HTML部分1. html结构1.html：根标签\n2.head： 头部标签\n3.body： 主体标签\n4.title：标题标签\n5.DOCTYPE： 声明文档类型\n6.lang &#x3D; “en”：页面的语言类型\n7.charset&#x3D;“UTF-8”编码格式\n2. html标签\n标题标h： &lt;h1&gt; ~ &lt;h6&gt; 不同字号大小\n段落标签p\n水平线标签  &lt;hr&#x2F;&gt; 单标签\n换行标签  &lt;br&#x2F;&gt;\nspan 文字标签：一行上可以放多个 \\ 小盒子\ndiv标签： 一行上只能放一个&lt;div&gt;大盒子 \n加粗标签：&lt;strong&gt; 和  &lt;b&gt; 前者语义更强烈\n倾斜标签：&lt;em&gt; 和 &lt;i&gt; 前者语义更强烈\n删除线：&lt;del&gt; 和  &lt;s&gt;  前者语义更强烈\n下划线：&lt;ins&gt; 和 &lt;u&gt; 前者语义更强烈\n\n3.图片标签&lt;img&gt;\nsrc：当前图片的路径\nalt：当图片错误加载时候显示的文字\ntitle：当鼠标悬停在图片上显示的文字\nheight： 图片的高度\nwidth： 图片的宽度\nborder：图片的边框\n\n4.连接标签&lt;a&gt;\n外部链接  &lt;a href&#x3D;”\\\">http://www.baidu.com&quot;&gt;\\  写完整的 协议  域名   网址\n内部链接 &lt;a href&#x3D;”index.html”&gt;&lt;&#x2F;a&gt;   直接写文件名即可\nhref:指定跳转的页面\ntitle：鼠标悬停显示的文字\ntarget:  _self(默认会覆盖原来的窗口)   _blank(会以新的窗口打开)    窗口的打开方式\n#：会阻止页面跳转但是会刷新页面\n绝对路径：目录下的绝对位置，通常从盘符开始\n相对路径：在同一个文件夹直接找名字、向上一级  ..&#x2F; 、向下 &#x2F;\n\n5.表格\n表格：&lt;table&gt;是用于定义表格的标签。\n行：&lt;tr&gt;标签用于定义表格中的行，必须嵌套在 &lt;table&gt; 标签中。\n单元格：&lt;td&gt; 用于定义表格中的单元格，必须嵌套在&lt;tr&gt;标签中。\n表头&lt;th&gt; 加粗加黑自动居中。\n表格的标题：&lt;caption&gt;表格的标题   写在内部  显示外部  居中\n结构头：&lt;thead&gt; 结构头\n结构底：&lt;tfoot&gt;结构底\n结构体：&lt;tbody&gt;结构体\n表格边框border\n宽度 width\n高度 height\n单元格与单元格之间距离 cellspacing\n单元格与内容之间的距离 cellspadding\n居中 align ： left&#x2F; center&#x2F; right \n列合并 colspan\n行合并 rowspan\n\n6.列表\n无序列表 : &lt;ul&gt; &lt;li&gt;\n有序列表 : &lt;ol&gt;&lt;li&gt;\n自定义列表：&lt;dl&gt; &lt;dt&gt; &lt;dd&gt;\n\n7. 表单1. input属性 &lt;input type &#x3D; “属性值”&gt;\ntext：文本框\npassword：密码框\nradio：单选按钮\ncheckbox：复选框\nbutton：普通按钮\nreset：重置按钮  需要配合form表单才有作用\nsubmit：提交按钮\nimage   属性  src\nfile 文件按钮   上传图片\n\n2.其他属性\nname属性：定义input元素的名称\nvalue：规定input氧元素的值\nchecked：规定input元素首次加载时应当被选中\nmaxlength： 输入字段字符的最大长度\nlabel\ntextarea：用户留言 cols&#x3D;“每行中的字符数” ，rows&#x3D;“显示的行数”\nselect：下拉菜单\nform表单：收集用户信息，action：  提交后台的地址 method&#x3D;”get&#x2F;post”   提交（传输）后台的方式 name &#x3D;“a” 告诉服务器  由哪个表单提交过来的\n\nCSS部分1.css引入方式\n行内样式：&lt;标签 style&#x3D;”属性:属性值;”&gt;&lt;&#x2F;标签&gt;\n内部样式：选择器{属性:属性值;属性：属性值}\n外部样式：通过link引入外部css文件  &lt;link  rel&#x3D;”stylesheet”   href&#x3D;”外部css文件”  &#x2F;&gt;\nhref与src   href 是引用   src下载资源到当前页面\n\n2.选择器\n标签选择器：标签{属性：属性值}\nclass（类选择器）：html：&lt;div class&#x3D;”名字”&gt;  css：  .名字{属性：属性值}  .nav{color: red}\nid选择器：html：&lt;div id&#x3D;”名字”&gt;&lt;&#x2F;div&gt;   css：  #名字{属性：属性值} id与class选择器的区别：  id的名字是唯一的（体现在js里面） class名字可以任意多个  #nav{color： red}\n通配符选择器：选择所有的标签 *{color：red}\n\n3.字体属性\n字体大小：font-size \n字体类型：font-family\n字体粗度：font-weight   normal默认值400（不加粗）bold粗体700（加粗的）\n文本风格：font-style:字体倾斜：italic（倾斜）&#x2F;normal（正常）\n文字阴影： text-shadow  水平距离   垂直距离  模糊程度   阴影颜色   \n字体连写：  font:font-style font-weight font-size&#x2F;line-height font-family\n字体颜色：color\n水平对齐方式：text-align:left&#x2F;center&#x2F;right（注意：1.div  h。。标题会居中   span   em  i。。。。不会居中）\n行高：line-height\n首行缩进：text-indent:  em   1em&#x3D;16px\n去掉a链接默认的下划线 ：text-decoration： none(去掉下划线)&#x2F; undefined(添加下划线)\n\n4.快速生成HTML结构语法\n生成标签 直接输入标签名 按tab键即可   比如  div   然后tab 键， 就可以生成 &lt;div&gt;&lt;&#x2F;div&gt;\n如果想要生成多个相同标签  加上 * 就可以了 比如   div*3  就可以快速生成3个div\n如果有父子级关系的标签，可以用 &gt;  比如   ul &gt; li就可以了\n如果有兄弟关系的标签，用  +  就可以了 比如 div+p  \n如果生成带有类名或者id名字的，  直接写  .demo  或者  #two   tab 键就可以了\n如果生成的div 类名是有顺序的， 可以用 自增符号  $ \n如果想要在生成的标签内部写内容可以用  { }  表示\n\n5.快速生成CSS样式语法CSS 基本采取简写形式即可\n​\t\t比如 w200   按tab  可以 生成  width: 200px;\n​\t\t比如 lh26px   按tab  可以生成  line-height: 26px;‘\n6.复合选择器\n后代选择器：元素1 元素2 {样式}   ul li{color：red} 选择ul里面所有的li标签元素\n子选择器：元素1&gt;元素2 {样式}  div &gt; p {样式声明} 选择div里面所有最近一级的p标签元素\n并集选择器：元素1，元素2 {样式声明}  ul，div{样式}  选择ul和div标签元素\n伪类选择器：     （ :hover）\n链接伪类选择器：给某些选择器增加特殊的效果：\ta:hover\t鼠标经过的那个链接\n:focus 伪类选择器：用于选取获得焦点的表单元素\n\n7.CSS的显示模式\n块元素：&lt;h1&gt;~&lt;h6&gt;、&lt;p&gt;、&lt;div&gt;、&lt;ul&gt;、&lt;ol&gt;、&lt;li&gt;  比较霸道，自己独占一行。高度，宽度、外边距以及内边距都可以控制。宽度默认是容器（父级宽度）的100%。是一个容器及盒子，里面可以放行内或者块级元素。\n行内元素：&lt;a&gt;、&lt;strong&gt;、&lt;b&gt;、&lt;em&gt;、&lt;i&gt;、&lt;del&gt;、&lt;s&gt;、&lt;ins&gt;、&lt;u&gt;、&lt;span&gt; 相邻行内元素在一行上，一行可以显示多个。默认宽度就是它本身内容的宽度。\n行内块元素：&lt;img &#x2F;&gt;、&lt;input &#x2F;&gt;、&lt;td&gt;  同时具有块元素和行内元素的特点。\n元素显示模块转换：转换为块元素：display:block;  转换为行内元素：display:inline;  转换为行内块：display: inline-block;\n让文字的行高等于盒子的高度  就可以让文字在当前盒子内垂直居中\n\n8.CSS的背景\n背景颜色：background-color：颜色值；元素背景颜色默认值是 transparent（透明）\n背景图片：background-image：none | url ；\n背景平铺：background-repeat： repeat在纵向和横向上平铺 | no-repeat不平铺 | repeat-x横向 | repeat-y纵向\n背景图片位置：background-position 属性可以改变图片在背景中的位置\n背景图片固定：\tbackground-attachment    scroll随对象内容滚动  fixed 背景图像固定\n背景样式合写：\tbackground: 背景颜色 背景图片地址 背景平铺 背景图像滚动 背景图片位置;\n背景色半透明：background： rgba（0，0，0，0.3） 最后一个参数是 alpha 透明度，取值范围在 0~1之间\n\n9.优先级\n继承或者* 0，0，0，0\n元素选择器 0，0，0，1\n类选择器，伪类选择器 0，0，1，0\nID选择器  0，1，0，0\n行内样式 style&#x3D;“” 1，0，0，0\n！important 重要的 无穷大\n\n10.盒子模型——边框border\nCSS 盒子模型本质上是一个盒子，封装周围的 HTML 元素，它包括：边框、外边距、内边距、和 实际内容\n定义边框粗细：border-width： 单位是px\n边框的样式：border-style  none：没有边框即忽略所有边框的宽度（默认值）solid：边框为单实线(最为常用的) dashed：边框为虚线   dotted：边框为点线\n表格的细线边框：border-collapse \nborder-collapse: collapse; 表示相邻边框合并在一起\n内边距 padding\n外边距 margin\n圆角边框：border-radius 用于设置元素的外边框圆角。\n盒子阴影： box-shadow: h-shadow水平阴影 v-shadow垂直阴影 blur模糊距离 spread阴影的尺寸 color阴影颜色 inset外部阴影改为内部阴影;\n文字阴影：  text-shadow: h-shadow水平阴影 v-shadow垂直阴影 blur模糊距离 color阴影颜色;\n\n11.浮动\n浮动：float：none不浮动   left向左浮动   right向右浮动\n清除浮动： 选择器{clear:属性值;}   left 不允许左侧有浮动   right 不允许右侧有浮动  both 同时清除左右两侧浮动\n额外标签法清除浮动：例如 &lt;div style&#x3D;”clear:both”&gt;&lt;&#x2F;div&gt;，或者其他标签（如&lt;br &#x2F;&gt;等）。\n父级添加 overflow 属性 （溢出）hidden | auto | scroll\n父级添加after伪元素\n\n12.定位（position）\n边偏移 有 top、bottom、left 和 right  4 个属性。\n\nposition 属性定义元素的定位模式  选择器 { position: 属性值; } static  静态定位 relative  相对定位            absolute  绝对定位fixed  固定定位\n\n静态定位(static) ：无定位\n\n相对定位(relative) ：移动位置的时候相对于自己原来的位置来说的，在原来位置继续占有\n\n绝对定位(absolute)：绝对定位是元素在移动位置的时候，是相对于它祖先元素来说的，完全不占位置，父元素要有定位\n\n子绝父相\n\n固定定位(fixed)：固定于浏览器可视区的位置，不随滚动条滚动，不占位置\n\n粘性定位(sticky) ：相对定位和固定定位的混合，占位置\n\n\n\n定位模式\n是否脱标\n移动位置\n是否常用\n\n\n\nstatic   静态定位\n否\n不能使用边偏移\n很少\n\n\nrelative 相对定位\n否 (占有位置)\n相对于自身位置移动\n基本单独使用\n\n\nabsolute绝对定位\n是（不占有位置）\n带有定位的父级\n要和定位父级元素搭配使用\n\n\nfixed 固定定位\n是（不占有位置）\n浏览器可视区\n单独使用，不需要父级\n\n\nsticky 粘性定位\n否   (占有位置)\n浏览器可视区\n当前阶段少\n\n\n\n堆叠顺序（z-index）：正整数、负整数或 0，默认值是 0，数值越大，盒子越靠上；\n\n绝对定位的盒子居中：left: 50%;  margin-left: -100px;\n\n脱标的盒子不会触发外边距塌陷\n\n绝对定位（固定定位）会完全压住盒子\n\n\n13.元素显示隐藏\n显示display：display: none 隐藏对象  display：block 除了转换为块级元素之外，同时还有显示元素的意思。隐藏后不再占有原本位置\n\n可见性 visibility：visibility：visible ; 　元素可视   visibility：hidden; 　  元素隐藏\n\noverflow 溢出：\n\n\n\n\n属性值\n描述\n\n\n\nvisible\n不剪切内容也不添加滚动条\n\n\nhidden\n不显示超过对象尺寸的内容，超出的部分隐藏掉\n\n\nscroll\n不管超出内容否，总是显示滚动条\n\n\nauto\n超出自动显示滚动条，不超出不显示滚动条\n\n\n\n\n14.精灵图\n精灵技术主要针对于背景图片使用。就是把多个小背景图片整合到一张大图片中。\n这个大图片也称为 sprites  精灵图  或者 雪碧图\n移动背景图片位置， 此时可以使用 background-position 。\n移动的距离就是这个目标图片的 x 和 y 坐标。注意网页中的坐标有所不同\n因为一般情况下都是往上往左移动，所以数值是负值。\n使用精灵图的时候需要精确测量，每个小背景图片的大小和位置。\n\n15.字体应用txt @font-face &#123;\n   font-family: &#39;icomoon&#39;;\n   src:  url(&#39;fonts/icomoon.eot?7kkyc2&#39;);\n   src:  url(&#39;fonts/icomoon.eot?7kkyc2#iefix&#39;) format(&#39;embedded-opentype&#39;),\n     url(&#39;fonts/icomoon.ttf?7kkyc2&#39;) format(&#39;truetype&#39;),\n     url(&#39;fonts/icomoon.woff?7kkyc2&#39;) format(&#39;woff&#39;),\n     url(&#39;fonts/icomoon.svg?7kkyc2#icomoon&#39;) format(&#39;svg&#39;);\n   font-weight: normal;\n   font-style: normal;\n &#125;\n定义字体： span {   font-family: “icomoon”;}\n16.CSS界面样式\n鼠标样式 cursor：default 小白默认 pointer小手 move 移动 text文本 not-allowed禁止\n轮廓线 outline：none 去掉默认蓝色边框\n防止拖拽文本域 resize：none\n文字对齐 vertical-align ：baseline默认，放在父元素基线，top 行中最高元素顶端对齐 middle 放在父元素中部 bottom最低元素的顶端对齐\n单行文本溢出显示省略号：先强制一行内显示文本  white-space: nowrap; 超出的部分隐藏  overflow: hidden;  文字用省略号替代超出的部分  text-overflow: ellipsis;\n\nHTML51.语义化标签\n&lt;header&gt; 头部标签\n&lt;nav&gt; 导航标签\n&lt;article&gt; 内容标签\n&lt;section&gt; 定义文档某个区域\n&lt;aside&gt; 侧边栏标签\n&lt;footer&gt; 尾部标签\n\n2.多媒体标签\n音频 audio 和视频 video 两个标签\nautoplay 视频就绪自动播放\nwidth height\nloop 视频播放完毕是否循环播放\npreload auto预先加载 none不预先\nurl地址\nposter 加载等待的画面图片\nmuted 静音播放\ncontrols 显示控件\n\n3.新增表单元素\nemail  \nurl\ndate\ntime\nmonth\nweek\nnumber\ntel\nsearch\ncolor\n\nCSS31.新增选择器\n\n\n\n\n2.盒子模型\nbox-sizing: content-box  盒子大小为 width + padding + border  （以前默认的）\nbox-sizing: border-box  盒子大小为 width\n如果盒子模型我们改为了box-sizing: border-box  ， 那padding和border就不会撑大盒子了（前提padding和border不会超过width宽度）\n\n3.其他特性\n模糊滤镜filter ：filter:   函数(); –&gt;  例如： filter: blur(5px);  –&gt;  blur模糊处理  数值越大越模糊\n计算盒子宽度 – calc 函数：width: calc(100% - 80px);\n\n4.CSS3过渡\n过渡动画： 是从一个状态 渐渐的过渡到另外一个状态\ntransition: 要过渡的属性  花费时间  运动曲线  何时开始;\n\n5.2D转换\n转换 移动：translate  旋转：rotate  缩放：scale\n旋转 translate：transform：translate（x,y）\n缩放 retate：transform：retate（度数）\n2D转换中心点：transform-origin： x， y；\n缩放 transform：scale（x,y）\n\n6.动画\nkeyframes定义动画  @keyframes动画名称\n\n","slug":"前端部分知识总结","date":"2023-11-23T05:28:12.000Z","categories_index":"Study","tags_index":"学习,前端","author_index":"Fioransh"},{"id":"1a206922638b47b5382f6efd345cd840","title":"校园课表微信小程序接口文档示例","content":"基于uni-app框架开发的微信小程序接口文档一. 关系型数据库设计1.数据列表1.student 表\n\n\nstudent_id\nreal_student_id\nname\ncollege\nmajor\nclassNum\ngrade\n\n\n\n1\n202225220801\n张三\n数信\n软件工程\n5班\n2022\n\n\n2\n202325310802\n李四\n材能\n材料\n1班\n2023\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\n2. courses表\n\n\ncourse_id\nname\nteacher\ntime\nlocation\nday_of_week\n\n\n\n101\n数据库原理\n王老师\n周一1-2节\n4210\n1\n\n\n102\n数据结构\n张老师\n周三1-2节\n3302\n3\n\n\n103\n面向对象程序设计\n宋老师\n周四3-4节\n4502\n4\n\n\n…\n…\n…\n…\n…\n\n\n\n3.enrollments表\n\n\nenrollment_id\nstudent_id\ncourse_id\n\n\n\n1\n1\n101\n\n\n2\n1\n102\n\n\n3\n2\n101\n\n\n4\n2\n103\n\n\n…\n…\n…\n\n\n4.tasks表\n\n\ntask_id\nreal_student_id\ndescription\nstatus\ncreate_time\nupdate_time\n\n\n\n1\n202225220501\n完成作业\n未完成(0)\n…\n…\n\n\n2\n202325310502\n准备考试\n完成(1)\n…\n…\n\n\n3\n202225310702\n提交报告\n未完成(0)\n…\n…\n\n\n…\n…\n…\n…\n\n\n\n\n生成语句txt-- 学生表格\ncreate table students (\n    student_id int unsigned primary key auto_increment comment &#39;主键学生id&#39;,\n    real_student_id varchar(20) not null comment &#39;学号&#39;,\n    name varchar(10) not null comment &#39;名字&#39;,\n    college varchar(20) not null comment &#39;学院&#39;,\n    major varchar(20) not null comment &#39;专业&#39;,\n    class int not null comment &#39;班级&#39;,\n    grade int not null comment &#39;年级&#39;\n)comment &#39;学生表格&#39;;\nCREATE INDEX idx_real_student_id ON students(real_student_id);\n-- 学生表测试数据\ninsert into students(student_id, real_student_id, name, college, major, class, grade) values(1, &#39;202225220503&#39;, &#39;冯焯炫&#39;, &#39;软件学院&#39;, &#39;软件工程&#39;, 5, 2022),\n                                                                                            (2, &#39;202225220504&#39;, &#39;郭文杰&#39;, &#39;软件学院&#39;, &#39;软件工程&#39;, 5, 2022),\n                                                                                            (3, &#39;202225220901&#39;, &#39;张三&#39;, &#39;软件学院&#39;, &#39;软件工程&#39;, 9, 2022),\n                                                                                            (4, &#39;202325220904&#39;, &#39;李四&#39;, &#39;软件学院&#39;, &#39;软件工程&#39;, 9, 2023),\n                                                                                            (5, &#39;202225310902&#39;, &#39;王五&#39;, &#39;数学与信息学院&#39;, &#39;计算机科学与技术&#39;, 9, 2022);\n\n\n-- 课程表格\ncreate table courses(\n    course_id int unsigned primary key auto_increment comment &#39;主键课程id&#39;,\n    name varchar(20) not null comment &#39;课程名字&#39;,\n    teacher varchar(10) not null comment &#39;教师名字&#39;,\n    time varchar(20) not null comment &#39;上课时间&#39;,\n    location varchar(20) not null comment &#39;上课地点&#39;,\n    day_of_week int not null comment &#39;星期几上课&#39;\n)comment &#39;课程表格&#39;;\n-- 课程表测试数据\ninsert into courses(course_id, name, teacher, time, location, day_of_week) values(101, &#39;数据结构&#39;, &#39;张老师&#39;, &#39;周一第1-2节&#39;, &#39;4201&#39;, 1),\n                                                                                 (102, &#39;数据库&#39;, &#39;陈老师&#39;, &#39;周三第1-2节&#39;, &#39;4311&#39;, 3),\n                                                                                 (103, &#39;面向对象程序设计&#39;, &#39;王老师&#39;, &#39;周四第3-4节&#39;, &#39;4403&#39;, 4),\n                                                                                 (104, &#39;C语言程序设计&#39;, &#39;周老师&#39;, &#39;周二第7-8节&#39;, &#39;4402&#39;, 2),\n                                                                                 (105, &#39;高等数学&#39;, &#39;王老师&#39;, &#39;周四第3-4节&#39;, &#39;3201&#39;, 4),\n                                                                                 (106, &#39;大学英语&#39;, &#39;冯老师&#39;, &#39;周一第7-8节&#39;, &#39;3311&#39;, 1),\n                                                                                 (107, &#39;数据结构&#39;, &#39;张老师&#39;, &#39;周三第1-2节&#39;, &#39;4301&#39;, 3),\n                                                                                 (108, &#39;计算机组成原理&#39;, &#39;黄老师&#39;, &#39;周五第5-6节&#39;, &#39;1502&#39;, 5),\n                                                                                 (109, &#39;数字电路&#39;, &#39;王老师&#39;, &#39;周二第1-2节&#39;, &#39;3301&#39;, 2),\n                                                                                 (110, &#39;近代史纲要&#39;, &#39;陈老师&#39;, &#39;周五第5-6节&#39;, &#39;5c501&#39;, 5),\n                                                                                 (111, &#39;离散结构&#39;, &#39;李老师&#39;, &#39;周四第1-2节&#39;, &#39;5a601&#39;, 4);\n\n\n\n\n-- 选课表格\ncreate table enrollments(\n    enrollment_id int unsigned primary key auto_increment comment &#39;主键选课id&#39;,\n    student_id int unsigned not null comment &#39;学生id&#39;,\n    course_id int unsigned not null comment &#39;课程id&#39;,\n    FOREIGN KEY (student_id) REFERENCES students(student_id),\n    FOREIGN KEY (course_id) REFERENCES courses(course_id)\n)comment &#39;选课表格&#39;;\n-- 选课表测试数据\ninsert into enrollments(enrollment_id, student_id, course_id) values(1, 1, 101),\n                                                                    (2, 1, 102),\n                                                                    (3, 1, 103),\n                                                                    (4, 1, 106),\n                                                                    (5, 1, 107),\n                                                                    (6, 1, 109),\n                                                                    (7, 2, 101),\n                                                                    (8, 2, 102),\n                                                                    (9, 2, 103),\n                                                                    (10, 2, 106),\n                                                                    (11, 2, 107),\n                                                                    (12, 2, 109),\n                                                                    (13, 3, 103),\n                                                                    (14, 3, 111),\n                                                                    (15, 3, 101),\n                                                                    (16, 3, 107),\n                                                                    (17, 3, 106),\n                                                                    (18, 3, 102),\n                                                                    (19, 4, 104),\n                                                                    (20, 4, 110),\n                                                                    (21, 4, 109),\n                                                                    (22, 4, 108),\n                                                                    (23, 5, 103),\n                                                                    (24, 5, 108),\n                                                                    (25, 5, 109),\n                                                                    (26, 5, 111),\n                                                                    (27, 5, 106);\n\n\n\n\n\n-- 待办表格\ncreate table tasks(\n    task_id int unsigned primary key auto_increment comment &#39;主键任务id&#39;,\n    real_student_id varchar(20) not null comment &#39;学号&#39;,\n    description varchar(100) not null comment &#39;任务描述&#39;,\n    status tinyint(1) not null comment &#39;任务状态&#39;,\n    create_time datetime not null comment &#39;创建时间&#39;,\n    update_time datetime not null comment &#39;更新时间&#39;,\n    FOREIGN KEY (real_student_id) REFERENCES students(real_student_id)\n)comment &#39;待办表格&#39;;\n-- 待办表测试数据\ninsert into tasks(task_id, real_student_id, description, status, create_time, update_time) values (1, &#39;202225220503&#39;, &#39;完成Java实验任务&#39;, 0, now(), now()),\n                                                                                                  (2, &#39;202225220503&#39;, &#39;完成C语言实验任务&#39;, 1, now(), now()),\n                                                                                                  (3, &#39;202225220504&#39;, &#39;完成数据结构课程设计&#39;, 0, now(), now()),\n                                                                                                  (4, &#39;202225220504&#39;, &#39;完成Java实验任务&#39;, 1, now(), now()),\n                                                                                                  (5, &#39;202225220901&#39;, &#39;完成高等数学周末作业&#39;, 0, now(), now()),\n                                                                                                  (6, &#39;202325220904&#39;, &#39;完成大学英语周末作业&#39;, 0, now(), now()),\n                                                                                                  (7, &#39;202225310902&#39;, &#39;完成数据库实验任务&#39;, 1, now(), now()),\n                                                                                                  (8, &#39;202225310902&#39;, &#39;完成Java实验任务&#39;, 0, now(), now());二.接口文档1.课程管理1.1 课程列表查询1.1.1 基本信息​\t\t| 请求路径：&#x2F;courses&#x2F;{realStudentId}\n​        | 请求方式：GET\n​        | 接口描述：该接口用于根据学号进行学生课表数据查询\n1.1.2 请求参数参数格式：路径参数\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\nrealStudentId\nstring\n必须\n学号\n\n\n请求参数样例：\ntxt/courses/2022252205031.1.3响应数据参数格式： application&#x2F;json\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\ncode\nnumber\n必须\n响应码，1代表成功，0代表失败\n\n\nmsg\nstring\n非必须\n提示信息\n\n\ndata\nobject\n非必须\n返回的数据\n\n\n|- courseId\nnumber\n非必须\n课程id\n\n\n|- name\nstring\n非必须\n课程名称\n\n\n|- teacher\nstring\n非必须\n老师名称\n\n\n|- time\nstring\n非必须\n上课时间\n\n\n|- location\nstring\n非必须\n上课地点\n\n\n|- dayOfWeek\nnumber\n非必须\n上课时间是星期几\n\n\n响应数据样例：\ntxt&#123;\n    &quot;code&quot;: 1,\n    &quot;msg&quot;: &quot;success&quot;,\n    &quot;data&quot;: [\n        &#123;\n            &quot;courseId&quot;: 101,\n            &quot;name&quot;: &quot;数据结构&quot;,\n            &quot;teacher&quot;: &quot;张老师&quot;,\n            &quot;time&quot;: &quot;周一第1-2节&quot;,\n            &quot;location&quot;: &quot;4201&quot;,\n            &quot;dayOfWeek&quot;: 1\n        &#125;,\n        &#123;\n            &quot;courseId&quot;: 102,\n            &quot;name&quot;: &quot;数据库&quot;,\n            &quot;teacher&quot;: &quot;陈老师&quot;,\n            &quot;time&quot;: &quot;周三第1-2节&quot;,\n            &quot;location&quot;: &quot;4311&quot;,\n            &quot;dayOfWeek&quot;: 3\n        &#125;,\n        &#123;\n            &quot;courseId&quot;: 103,\n            &quot;name&quot;: &quot;面向对象程序设计&quot;,\n            &quot;teacher&quot;: &quot;王老师&quot;,\n            &quot;time&quot;: &quot;周四第3-4节&quot;,\n            &quot;location&quot;: &quot;4403&quot;,\n            &quot;dayOfWeek&quot;: 4\n        &#125;,\n        &#123;\n            &quot;courseId&quot;: 106,\n            &quot;name&quot;: &quot;大学英语&quot;,\n            &quot;teacher&quot;: &quot;冯老师&quot;,\n            &quot;time&quot;: &quot;周一第7-8节&quot;,\n            &quot;location&quot;: &quot;3311&quot;,\n            &quot;dayOfWeek&quot;: 1\n        &#125;,\n        &#123;\n            &quot;courseId&quot;: 107,\n            &quot;name&quot;: &quot;数据结构&quot;,\n            &quot;teacher&quot;: &quot;张老师&quot;,\n            &quot;time&quot;: &quot;周三第1-2节&quot;,\n            &quot;location&quot;: &quot;4301&quot;,\n            &quot;dayOfWeek&quot;: 3\n        &#125;,\n        &#123;\n            &quot;courseId&quot;: 109,\n            &quot;name&quot;: &quot;数字电路&quot;,\n            &quot;teacher&quot;: &quot;王老师&quot;,\n            &quot;time&quot;: &quot;周二第1-2节&quot;,\n            &quot;location&quot;: &quot;3301&quot;,\n            &quot;dayOfWeek&quot;: 2\n        &#125;\n    ]\n&#125;2.待办管理1.1查询待办1.1.1基本信息​        | 请求路径：&#x2F;tasks&#x2F;{realStudentId}\n​        | 请求方式：GET\n​        | 接口描述：该接口用于根据学号进行待办事项数据查询\n1.1.2请求参数参数格式：路径参数\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\nrealStudentId\nstring\n必须\n学号\n\n\n请求参数样例：\ntxt/tasks/2022252205031.1.3响应数据参数格式： application&#x2F;json\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\ncode\nnumber\n必须\n响应码，1代表成功，0代表失败\n\n\nmsg\nstring\n非必须\n提示信息\n\n\ndata\nobject\n非必须\n返回的数据\n\n\n|- taskId\nnumber\n非必须\n待办id\n\n\n|- description\nstring\n非必须\n待办内容\n\n\n|- status\nnumber\n非必须\n完成状态，0代表未完成，1代表完成\n\n\n|- createTime\nstring\n非必须\n创建时间\n\n\n|- updateTime\nstring\n非必须\n更新时间\n\n\n响应数据样例：\ntxt&#123;\n    &quot;code&quot;: 1,\n    &quot;msg&quot;: &quot;success&quot;,\n    &quot;data&quot;: [\n        &#123;\n            &quot;taskId&quot;: 1,\n            &quot;description&quot;: &quot;完成Java实验任务&quot;,\n            &quot;status&quot;: 0,\n            &quot;createTime&quot;: &quot;2023-11-05T21:36:43&quot;,\n            &quot;updateTime&quot;: &quot;2023-11-05T21:36:43&quot;\n        &#125;,\n        &#123;\n            &quot;taskId&quot;: 2,\n            &quot;description&quot;: &quot;完成C语言实验任务&quot;,\n            &quot;status&quot;: 1,\n            &quot;createTime&quot;: &quot;2023-11-05T21:36:43&quot;,\n            &quot;updateTime&quot;: &quot;2023-11-05T21:36:43&quot;\n        &#125;\n    ]\n&#125;1.2 删除待办1.2.1 基本信息​\t\t| 请求路径： &#x2F;tasks&#x2F;{taskId}\n​        | 请求方式：DELETE\n​        | 接口描述：该接口用于根据待办事项ID删除待办事项数据\n1.2.2 请求参数参数格式：路径参数\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\ntaskId\nnumber\n必须\n待办事项ID\n\n\n请求参数样例：\ntxt/tasks/91.2.3 响应数据参数格式：application&#x2F;json\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\ncode\nnumber\n必须\n响应码，1代表成功，0代表失败\n\n\nmsg\nstring\n非必须\n提示信息\n\n\ndata\nobject\n非必须\n返回的数据\n\n\n响应数据样例：\ntxt&#123;\n    &quot;code&quot;: 1,\n    &quot;msg&quot;: &quot;success&quot;,\n    &quot;data&quot;: null\n&#125;1.3 添加待办1.3.1 基本信息​\t\t| 请求路径： &#x2F;tasks\n​        | 请求方式：POST\n​        | 接口描述：该接口用于添加待办事项数据\n1.3.2 请求参数参数格式：application&#x2F;json\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\nrealStudentId\nstring\n必须\n学号，必须是student表里有的学号\n\n\ndescription\nstring\n必须\n待办事项\n\n\nstatus\nnumber\n必须\n完成状态，0代表未完成，1代表完成\n\n\n请求参数样例：\ntxt&#123;\n   &quot;realStudentId&quot;: &quot;202225220503&quot;,\n   &quot;description&quot;: &quot;完成Java实验任务&quot;,\n   &quot;status&quot;: 0\n&#125;1.3.3 响应数据参数格式：application&#x2F;json\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\ncode\nnumber\n必须\n响应码，1代表成功，0代表失败\n\n\nmsg\nstring\n非必须\n提示信息\n\n\ndata\nobject\n非必须\n返回的数据\n\n\n响应数据样例：\ntxt&#123;\n    &quot;code&quot;: 1,\n    &quot;msg&quot;: &quot;success&quot;,\n    &quot;data&quot;: null\n&#125;1.4 修改待办1.4.1 基本信息​\t\t| 请求路径： &#x2F;tasks&#x2F;{taskId}\n​        | 请求方式：PUT\n​        | 接口描述：该接口用于修改待办事项数据\n1.4.2 请求参数参数格式：application&#x2F;json\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\nrealStudentId\nstring\n必须\n学号，必须是student表里有的学号\n\n\ndescription\nstring\n必须\n待办事项\n\n\nstatus\nnumber\n必须\n完成状态，0代表未完成，1代表完成\n\n\n请求参数样例：\ntxt&#123;\n   &quot;realStudentId&quot;: &quot;202225220503&quot;,\n   &quot;description&quot;: &quot;完成Java实验任务&quot;,\n   &quot;status&quot;: 0\n&#125;,1.4.3 响应数据参数格式：application&#x2F;json\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\ncode\nnumber\n必须\n响应码，1代表成功，0代表失败\n\n\nmsg\nstring\n非必须\n提示信息\n\n\ndata\nobject\n非必须\n返回的数据\n\n\n响应数据样例：\ntxt&#123;\n    &quot;code&quot;: 1,\n    &quot;msg&quot;: &quot;success&quot;,\n    &quot;data&quot;: null\n&#125;3.学生管理3.1 添加学生3.1.1 基本信息​\t\t| 请求路径： &#x2F;students\n​        | 请求方式：POST\n​        | 接口描述：该接口用于添加待办事项数据\n3.1.2 请求参数参数格式：application&#x2F;json\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\nrealStudentId\nstring\n必须\n学号\n\n\nname\nstring\n必须\n学生姓名\n\n\ncollege\nstring\n必须\n学院\n\n\nmajor\nstring\n必须\n专业\n\n\nclassNum\nnumber\n必须\n班级\n\n\ngrade\nnumber\n必须\n年级\n\n\n请求参数样例：\ntxt&#123;\n   &quot;realStudentId&quot;: &quot;202225220505&quot;,\n   &quot;name&quot;: &quot;何泳泳&quot;,\n   &quot;college&quot;: &quot;软件学院&quot;,\n   &quot;major&quot;: &quot;软件工程&quot;,\n   &quot;classNum&quot;: 5,\n   &quot;grade&quot;: 2022\n&#125;3.1.3响应数据参数格式：application&#x2F;json\n参数说明：\n\n\n\n参数名\n类型\n是否必须\n备注\n\n\n\ncode\nnumber\n必须\n响应码，1代表成功，0代表失败\n\n\nmsg\nstring\n非必须\n提示信息\n\n\ndata\nobject\n非必须\n返回的数据\n\n\n响应数据样例：\ntxt&#123;\n    &quot;code&quot;: 1,\n    &quot;msg&quot;: &quot;success&quot;,\n    &quot;data&quot;: null\n&#125;","slug":"基于uni-app框架开发的校园课表微信小程序","date":"2023-11-06T05:28:12.000Z","categories_index":"Program","tags_index":"学习,Java","author_index":"Fioransh"},{"id":"452d114e7a0301edf39e3da31eb54488","title":"6神，启动！","content":"本文旨在测试博客图片上传功能，为了解决博客上传图片失败问题努力了几个小时后终于发现了问题所在，在hexo中的 hexo-asset-image 图片模块和 hexo-abbrlink 不兼容导致。\n解决方法：在node_modules&#x2F;hexo-asset-image&#x2F;index.js中将代码中的”var endPos &#x3D; link.length - 1”改为”-5”即可解决。\n\n6神，启动！\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"6神，启动！","date":"2023-09-09T16:00:00.000Z","categories_index":"Blog","tags_index":"黄怡慈","author_index":"Fioransh"},{"id":"8f6e64efe3110f584471bcfd49c073a9","title":"Git使用学习","content":"1.引入1.1 版本管理工具概念如果有一个软件能记录我们对文档的所有修改,所有版本,那么上面的问题讲迎刃而解.而这类软件我们一般叫做版本控制工具\n版本管理工具一般具有如下特性:\ntxt1) 能够记录历史版本,回退历史版本\n2) 团队开发,方便代码合并1.2 版本管理工具介绍现在比较流行的版本管理工具是git ,但是实际上git 是近几年才发展起来的,可能有一些老的项目,还在用一些老的软件,比如svn\n\n1.2.1 SVN工作流程\ntxtSVN是集中式版本控制系统，版本库是集中放在中央服务器的.\n工作流程如下:\n    1.从中央服务器远程仓库下载代码\n    2.修改后将代码提交到中央服务器远程仓库优缺点:\ntxt 优点: 简单,易操作\n 缺点:所有代码必须放在中央服务器  \n         1.服务器一旦宕机无法提交代码,即容错性较差\n       2.离线无法提交代码,无法及时记录我们的提交行为svn流程图\n\n1.2.2 Git工作流程\ntxtGit是分布式版本控制系统（Distributed Version Control System，简称 DVCS），分为两种类型的仓库：\n本地仓库和远程仓库\n工作流程如下\n    1．从远程仓库中克隆或拉取代码到本地仓库(clone/pull)\n    2．从本地进行代码修改\n    3．在提交前先将代码提交到暂存区\n    4．提交到本地仓库。本地仓库中保存修改的各个历史版本\n    5．修改完成后，需要和团队成员共享代码时，将代码push到远程仓库\n总结:git和svn的区别\ntxt1. svn 是集中式版本控制工具,git 是分布式版本控制工具\n2. svn 不支持离线提交,git 支持离线提交代码\n命令如下： \n\nclone（克隆）: 从远程仓库中克隆代码到本地仓库 \ncheckout （检出）:从本地仓库中检出一个仓库分支然后进行修订 \nadd（添加）: 在提交前先将代码提交到暂存区 \ncommit（提交）: 提交到本地仓库。本地仓库中保存修改的各个历史版本 \nfetch (抓取) ： 从远程库，抓取到本地仓库，不进行任何的合并动作，一般操作比较少。 \npull (拉取) ： 从远程库拉到本地库，自动进行合并(merge)，然后放到到工作区，相当于 fetch+merge \npush（推送） : 修改完成后，需要和团队成员共享代码时，将代码推送到远程仓库\n\n1.3 Git发展简史Linus  本人 花了10天的时间Git 出来了,一个月之内，Linux系统的源码已经由Git管理了！\n\nGit 出来以后毕竟是一个人做的,开始并不好用(刚开始只能用勉强可以用来形容), 还是很多人抱怨,发展了很多年都没有干过其他软件.\n直到 2008年，GitHub网站上线了，它为开源项目免费提供Git存储，无数开源项目开始迁移至GitHub,从此git 迎来了飞速发展,当下git 已经成为了最流行的版本控制工具\n2.Git 的安装和常用命令本教程里的git命令例子都是在Git Bash中演示的，会用到一些基本的linux命令，在此为大家提前列举：\n\nls&#x2F;ll 查看当前目录 \ncat 查看文件内容 \ntouch 创建文件 \nvi vi编辑器（使用vi编辑器是为了方便展示效果，学员可以记事本、editPlus、notPad++等其它编 辑器）\n\n2.1 Git环境配置2.1.1 下载与安装下载地址： https://git-scm.com/download\n\n下载完成后可以得到如下安装文件：\n\n双击下载的安装文件来安装Git。安装完成后在电脑桌面（也可以是其他目录）点击右键，如果能够看 到如下两个菜单则说明Git安装成功。\n\n备注： \n\nGit GUI：Git提供的图形界面工具 \nGit Bash：Git提供的命令行工具 \n当安装Git后首先要做的事情是设置用户名称和email地址。这是非常重要的，因为每次Git提交都会使用 该用户信息\n\n2.1.2 Git基本配置1.打开Git Bash \n2.设置用户信息 \nshellgit config --global user.name “itcast”    这里是设置用户名shellgit config --global user.email “ hello@itcast.cn”     这里是设置自己的email地址查看配置信息 \nshellgit config --global user.nameshellgit config --global user.email2.1.3 为常用指令配置别名（可选）有些常用的指令参数非常多，每次都要输入好多参数，我们可以使用别名。 \n1.打开用户目录，创建 .bashrc 文件 \n部分windows系统不允许用户创建点号开头的文件，可以打开gitBash,执行  touch ~/.bashrc \n\n2.在 .bashrc 文件中输入如下内容：\nshell#用于输出git提交日志\nalias git-log=&#39;git log --pretty=oneline --all --graph --abbrev-commit&#39;\n#用于输出当前目录所有文件及基本信息\nalias ll=&#39;ls -al3.打开gitBash，执行 source ~/.bashrc\n\n2.1.4 解决GitBash乱码问题1.打开GitBash执行下面命令\nshell git config --global core.quotepath false2.$&#123;git_home&#125;/etc/bash.bashrc\t 文件最后加入下面两行 \nshellexport LANG=&quot;zh_CN.UTF-8&quot; \nexport LC_ALL=&quot;zh_CN.UTF-8&quot; 2.2 获取本地仓库要使用Git对我们的代码进行版本控制，首先需要获得本地仓库 \n1）在电脑的任意位置创建一个空目录（例如test）作为我们的本地Git仓库 \n2）进入这个目录中，点击右键打开Git bash窗口 \n3）执行命令git init \n4）如果创建成功后可在文件夹下看到隐藏的.git目录。\n\n2.3 基础操作指令Git工作目录下对于文件的修改(增加、删除、更新)会存在几个状态，这些修改的状态会随着我们执行Git 的命令而发生变化。\n\n本章节主要讲解如何使用命令来控制这些状态之间的转换： \n\ngit add (工作区 –&gt; 暂存区) \ngit commit (暂存区 –&gt; 本地仓库)\n\n2.3.1 查看修改的状态（status）\n作用：查看的修改的状态（暂存区、工作区）\n命令形式：git status\n\n2.3.2 添加工作区到暂存区（add）\n作用：添加工作区一个或多个文件的修改到暂存区\n命令行事：git add 单个文件名|通配符\n将所有修改加入暂存区：git add .\n\n2.3.3 提交暂存区到本地仓库（commit）\n作用：提交暂存区内容到本地仓库的当前分支\n命令形式：git commit -m ‘注释内容’\n\n2.3.4 查看提交日志（log）\n作用：查看提交记录\n命令形式：git log [option]\noptions\n–all 显示所有分支\n–pretty&#x3D;oneline 将提交信息显示为一行\n–abbrev-commit 使得输出的commitld更简短\n–graph以图的形式显示\n\n\n\n2.3.5 版本回退\n作用：版本切换\n命令形式：git reset –hard commitID\ncommitID 可以使用 git-log 或者 git log指令查看\n\n\n如何查看已经删除的记录？\ngit reflog\n这个指令可以看到已经删除的提交记录\n\n\n\n2.3.6 添加文件至忽略列表一般我们总会有些文件无需纳入Git 的管理，也不希望它们总出现在未跟踪文件列表。 通常都是些自动 生成的文件，比如日志文件，或者编译过程中创建的临时文件等。 在这种情况下，我们可以在工作目录 中创建一个名为 .gitignore 的文件（文件名称固定），列出要忽略的文件模式。下面是一个示例：\nshell# no .a files\n *.a\n # but do track lib.a, even though you&#39;re ignoring .a files above\n !lib.a\n # only ignore the TODO file in the current directory, not subdir/TODO\n /TODO\n # ignore all files in the build/ directory\n build/\n # ignore doc/notes.txt, but not doc/server/arch.txt\n doc/*.txt\n # ignore all .pdf files in the doc/ directory\n doc/**/*.pdf基础操作：\nshell#####################仓库初始化######################\n # 创建目录（git_test01）并在目录下打开gitbash\n略\n# 初始化git仓库\ngit init\n #####################创建文件并提交#####################\n # 目录下创建文件 file01.txt\n略\n# 将修改加入暂存区\ngit add .\n # 将修改提交到本地仓库，提交记录内容为：commit 001\n git commit -m &#39;commit 001&#39;\n # 查看日志\ngit log\n ####################修改文件并提交######################\n # 修改file01的内容为：count=1\n略\n# 将修改加入暂存区\ngit add .\n # # 将修改提交到本地仓库，提交记录内容为：update file01\n git commit --m &#39;update file01&#39;\n # 查看日志\ngit log\n # 以精简的方式显示提交记录\ngit-log\n ####################将最后一次修改还原##################\n # 查看提交记录\ngit-log\n # 找到倒数第2次提交的commitID\n略\n# 版本回退\ngit reset commitID --hard2.4 分支几乎所有的版本控制系统都以某种形式支持分支。 使用分支意味着你可以把你的工作从开发主线上分离 开来进行重大的Bug修改、开发新的功能，以免影响开发主线。\n2.4.1 查看本地分支\n命令：git branch\n\n2.4.2 创建本地分支\n命令：git branch 分支名\n\n2.4.3 切换分支\n命令：git checkout 分支名\n\n我们还可以直接切换到一个不存在的分支（创建并切换）\n\n命令：git checkout -b 分支名\n\n2.4.4 合并分支一个分支上的提交可以合并到另一个分支\n\n命令：git merge 分支名称\n\n2.4.5 删除分支不能删除当前分支，只能删除其他分支\ngit branch -d b1 删除分支时，需要做各种检查\ngit branch -D b1 不做任何检查，强制删除\n2.4.6 解决冲突当两个分支上对文件的修改可能会存在冲突，例如同时修改了同一个文件的同一行，这时就需要手动解 决冲突，解决冲突步骤如下： \n1.处理文件中冲突的地方 \n2.将解决完冲突的文件加入暂存区(add) \n3.提交到仓库(commit) \n冲突部分的内容处理如下所示： \n\n2.4.7 开发中分支使用原则和流程几乎所有的版本控制系统都以某种形式支持分支。 使用分支意味着你可以把你的工作从开发主线上分离 开来进行重大的Bug修改、开发新的功能，以免影响开发主线。 \n在开发中，一般有如下分支使用原则与流程： \n\nmaster （生产） 分支 \n线上分支，主分支，中小规模项目作为线上运行的应用对应的分支； \n\ndevelop（开发）分支 \n是从master创建的分支，一般作为开发部门的主要开发分支，如果没有其他并行开发不同期上线 要求，都可以在此版本进行开发，阶段开发完成后，需要是合并到master分支,准备上线。 \n\nfeature&#x2F;xxxx分支 \n从develop创建的分支，一般是同期并行开发，但不同期上线时创建的分支，分支上的研发任务完 成后合并到develop分支。 \n\nhotfix&#x2F;xxxx分支 \n从master派生的分支，一般作为线上bug修复使用，修复完成后需要合并到master、test、 develop分支。 \n\n还有一些其他分支，在此不再详述，例如test分支（用于代码测试）、pre分支（预上线分支）等 等。 黑马程序员 北京昌\n\n\n\n分支操作：\nshell###########################创建并切换到dev01分支，在dev01分支提交\n# [master]创建分支dev01\n git branch dev01\n # [master]切换到dev01\n git checkout dev01\n # [dev01]创建文件file02.txt\n略\n# [dev01]将修改加入暂存区并提交到仓库,提交记录内容为：add file02 on dev\n git add .\n git commit -m &#39;add file02 on dev&#39;\n # [dev01]以精简的方式显示提交记录\ngit-log\n ###########################切换到master分支，将dev01合并到master分支\n# [dev01]切换到master分支\ngit checkout master\n # [master]合并dev01到master分支\ngit merge dev01\n # [master]以精简的方式显示提交记录\ngit-log\n # [master]查看文件变化(目录下也出现了file02.txt)\n略\n##########################删除dev01分支\n# [master]删除dev01分支\ngit branch -d dev01\n # [master]以精简的方式显示提交记录\ngit-log3.Git远程仓库3.1 常用的托管服务[远程仓库]前面我们已经知道了Git中存在两种类型的仓库，即本地仓库和远程仓库。那么我们如何搭建Git远程仓库 呢？我们可以借助互联网上提供的一些代码托管服务来实现，其中比较常用的有GitHub、码云、GitLab等。 gitHub（ 地址：https://github.com/ ）是一个面向开源及私有软件项目的托管平台，因为只支持 Git 作为唯一的版本库格式进行托管，故名gitHub 码云（地址： https://gitee.com/ ）是国内的一个代码托管平台，由于服务器在国内，所以相比于 GitHub，码云速度会更快 GitLab （地址： https://about.gitlab.com/ ）是一个用于仓库管理系统的开源项目，使用Git作 为代码管理工具，并在此基础上搭建起来的web服务,一般用于在企业、学校等内部网络搭建git私服。\n3.2 注册码云gitee要想使用码云的相关服务，需要注册账号（地址：  https://gitee.com/signup ）\n3.3 创建远程仓库\n仓库创建完成之后就可以看到仓库地址\n\n3.4 配置SSH公钥\n生成SSH公钥\n\nssh-key-gen-t rsa\n不断回车，如果公钥已经存在，则自动覆盖\n\n\nGitee设置账户公钥\n\n获取公钥\ncat ~&#x2F;.ssh&#x2F;id_rsa.pub\n\n\n\n\n\n验证是否配置成功\n\nssh -T &#x67;&#105;&#x74;&#64;&#x67;&#x69;&#116;&#x65;&#x65;&#46;&#x63;&#111;&#109;\n\n\n\n3.5 操作远程仓库3.5.1 添加远程仓库此操作是先初始化本地库，然后与已创建的远程库进行对接。\n\n命令： git remote add &lt;远端名称&gt; &lt;仓库路径&gt; \n远端名称，默认是origin，取决于远端服务器设置 \n仓库路径，从远端服务器获取此URL \n例如: git remote add origin  &#x67;&#x69;&#x74;&#x40;&#x67;&#105;&#x74;&#x65;&#x65;&#x2e;&#x63;&#x6f;&#x6d;:czbk_zhang_meng&#x2F;git_test.git\n\n\n3.5.2 查看远程仓库\n命令：git remote\n\n\n3.5.3 推送到远程仓库\n命令：git push [-f] [–set-upstream] [远端名称 [本地分支名][:远端分支名] ] \n\n如果远程分支名和本地分支名称相同，则可以只写本地分支 \ngit push origin master\n-f 表示强制覆盖\n--set-upstream 推送到远端的同时并且建立起和远端分支的关联关系。 \ngit push --set-upstream origin master \n如果当前分支已经和远端分支关联，则可以省略分支名和远端名。\n git push 将master分支推送到已关联的远端分支。\n\n\n\n\n查询远程仓库\n\n3.5.4 本地分支与远程分支的关联关系\n查看关联关系我们可以使用 git branch -vv命令\n\n3.5.5 从远程仓库克隆如果已经有一个远端仓库，我们可以直接clone到本地。 \n\n命令: git clone &lt;仓库路径&gt; [本地目录] \n本地目录可以省略，会自动生成一个目录\n\n\n3.5.6 从远程仓库中抓取和拉取远程分支和本地的分支一样，我们可以进行merge操作，只是需要先把远端仓库里的更新都下载到本 地，再进行操作。\n\n抓取 命令：git fetch [remote name] [branch name] \n\n抓取指令就是将仓库里的更新都抓取到本地，不会进行合并\n\n如果不指定远端名称和分支名，则抓取所有分支。\n\n拉取 命令：git pull [remote name] [branch name]\n\n拉取指令就是将远端仓库的修改拉到本地并自动进行合并，等同于fetch+merge \n\n如果不指定远端名称和分支名，则抓取所有并更新当前分支。\n\n\n1.在test01这个本地仓库进行一次提交并推送到远程仓库\n\n2.在另一个仓库将远程提交的代码拉取到本地仓库\n\n3.5.7 解决合并冲突在一段时间，A、B用户修改了同一个文件，且修改了同一行位置的代码，此时会发生合并冲突。 \nA用户在本地修改代码后优先推送到远程仓库，此时B用户在本地修订代码，提交到本地仓库后，也需要 推送到远程仓库，此时B用户晚于A用户，故需要先拉取远程仓库的提交，经过合并后才能推送到远端分 支,如下图所示。\n\n在B用户拉取代码时，因为A、B用户同一段时间修改了同一个文件的相同位置代码，故会发生合并冲突。\n远程分支也是分支，所以合并时冲突的解决方式也和解决本地分支冲突相同相同，在此不再赘述。\n远程仓库操作：\nshell##########################1-将本地仓库推送到远程仓库\n# 完成4.1、4.2、4.3、4.4的操作\n略\n# [git_test01]添加远程仓库\ngit remote add origin  git@gitee.com/**/**.git\n # [git_test01]将master分支推送到远程仓库,并与远程仓库的master分支绑定关联关系\ngit push --set-upstream origin master\n ###########################2-将远程仓库克隆到本地\n# 将远程仓库克隆到本地git_test02目录下\ngit clone git@gitee.com/**/**.git  git_test02\n # [git_test02]以精简的方式显示提交记录\ngit-log\n ###########################3-将本地修改推送到远程仓库\n# [git_test01]创建文件file03.txt\n略\n# [git_test01]将修改加入暂存区并提交到仓库,提交记录内容为：add file03\n git add .\n git commit -m &#39;add file03&#39;\n # [git_test01]将master分支的修改推送到远程仓库\ngit push origin master\n ###########################4-将远程仓库的修改更新到本地\n# [git_test02]将远程仓库修改再拉取到本地\ngit pull\n # 以精简的方式显示提交记录\ngit-log\n # 查看文件变化(目录下也出现了file03.txt)\n略4.在Idea中使用Git4.1 在Idea中配置Git安装好IntelliJ IDEA后，如果Git安装在默认路径下，那么idea会自动找到git的位置，如果更改了Git的安 装位置则需要手动配置下Git的路径。选择File→Settings打开设置窗口，找到Version Control下的git选项：\n\n点击Test按钮,现在执行成功，配置完成\n4.2 在Idea中操作Git场景：本地已经有一个项目，但是并不是git项目，我们需要将这个放到码云的仓库里，和其他开发人员继续一起协作开发。\n4.2.1 创建项目远程仓库\n4.2.2 初始化本地仓库\n4.2.3 设置远程仓库\n4.2.4 提交到本地仓库\n4.2.5 推送到远程仓库\n4.2.6 克隆远程仓库到本地\n4.2.7 创建分支\n\n4.2.8 切换分支及其他分支相关操作\n4.2.9 解决冲突1.执行merge或pull操作时，可能发生冲突\n\n2.冲突解决后加入暂存区\n3.提交到本地仓库\n4.推送到远程仓库\n4.3 Idea常用Git操作入口\n\n5.附录5.1 windows下看不到隐藏的文件（.bashrc、.gitignore）\n5.2 windows下无法创建.ignore|.bashrc文件这里以创建 .ignore 文件为例： \n在git目录下打开gitbash \n执行指令 touch .gitignore \n\n5.3 IDEA集成GitBash作为Terminal\n5.4 命令shell#设置用户信息 \n   git config --global user.name “itcast”\n   git config --global user.email “itcast@itcast.cn”\n#查看配置信息\n   git config --list\n   git config user.name\n#通过上面的命令设置的信息会保存在~/.gitconfig文件中\nshell# 初始化仓库带工作区\ngit init\n# 初始化仓库不带工作区\ngit init --bare  shell# 从远程仓库克隆\ngit clone 远程Git仓库地址 \n例如: git clone https://gitee.com/itcast/gittest.gitshell# 查看状态\ngit status \n#查看状态 使输出信息更加简洁\ngit status –s shell# 将未跟踪的文件加入暂存区\ngit add  &lt;文件名&gt;  \n# 将暂存区的文件取消暂存 (取消 add )\ngit reset  &lt;文件名&gt;  \nshell# git commit 将暂存区的文件修改提交到本地仓库\ngit commit -m &quot;日志信息&quot;  &lt;文件名&gt;  \nshell# 从本地工作区 删除文件\ngit rm &lt;文件名&gt;  \n# 如果本工作区库误删, 想要回退\ngit checkout head &lt;文件名&gt;  shell# 查看远程  列出指定的每一个远程服务器的简写\ngit remote \n# 查看远程 , 列出 简称和地址\ngit remote  -v  \n# 查看远程仓库详细地址\ngit remote show  &lt;仓库简称&gt;\nshell# 添加远程仓库\ngit remote add &lt;shortname&gt; &lt;url&gt;\n# 移除远程仓库和本地仓库的关系(只是从本地移除远程仓库的关联关系，并不会真正影响到远程仓库)\ngit remote rm &lt;shortname&gt; shell# 从远程仓库克隆\ngit clone &lt;url&gt; \n# 从远程仓库拉取 (拉取到.git 目录,不会合并到工作区,工作区发生变化)\ngit fetch  &lt;shortname&gt;  &lt;分支名称&gt;\n# 手动合并  把某个版本的某个分支合并到当前工作区\ngit merge &lt;shortname&gt;/&lt;分支名称&gt;\n# 从远程仓库拉取 (拉取到.git 目录,合并到工作区,工作区不发生变化) = fetch+merge\ngit pull  &lt;shortname&gt;  &lt;分支名称&gt;\ngit pull  &lt;shortname&gt;  &lt;分支名称&gt;  --allow-unrelated-histories  #  强制拉取合并shell# 将本地仓库推送至远程仓库的某个分支\ngit push [remote-name] [branch-name]shell# 默认 分支名称为 master\n# 列出所有本地分支\ngit branch\n# 列出所有远程分支\ngit branch -r\n# 列出所有本地分支和远程分支\ngit branch -a\n# 创建分支\ngit branch &lt;分支名&gt;\n# 切换分支 \ngit checkout &lt;分支名&gt;\n# 删除分支(如果分支已经修改过,则不允许删除)\ngit branch -d  &lt;分支名&gt;\n# 强制删除分支\ngit branch -D  &lt;分支名&gt;shell# 提交分支至远程仓库\ngit push &lt;仓库简称&gt; &lt;分支名称&gt;\t\n# 合并分支 将其他分支合并至当前工作区\ngit merge &lt;分支名称&gt;\n# 删除远程仓库分支\ngit push origin –d branchNameshell# 列出所有tag\ngit tag\n# 查看tag详细信息 \ngit show [tagName]\n# 新建一个tag\ngit tag [tagName]\n# 提交指定tag\n$ git push [仓库简称] [tagName]\n# 新建一个分支，指向某个tag\n$ git checkout -b [branch] [tag]\n# 删除本地tag\n$ git tag -d [tag]\n# 删除远程tag (注意 空格)\n$ git push origin :refs/tags/[tag]","slug":"Git使用总结","date":"2023-08-20T02:25:12.000Z","categories_index":"Study","tags_index":"开发工具,Git","author_index":"Fioransh"},{"id":"a5170803adaf724d5767bb183841fa47","title":"SCAU软件工程经济学知识点","content":"SCAU软件工程经济学知识点*有哪些分类，有哪些方法，有哪些特点*\n第一章\n1.软件的定义：它是包括程序、数据及其相关文档的完整集合。\n2.按软件功能分类：系统、支撑、应用。\n3.按规模分类：微型、小型、中型、大型、超大型、极大型。\n4.按标准化程度分类：标准化、半定制、软件服务（定制软件）。\n5.按硬件或软件关联分类：嵌入型、组织型、半独立型。\n6.按工作方式：实时处理、多用户分时处理、交互式、批处理。\n7.软件特点：信息产品、从头开始生产、知识结晶、手工方式生产、无需库存成本、壁垒低、对用户有粘性。\n8.软件产业是指软件产品和软件服务相关的一切经济活动和关系的总称。\n9.软件产业特点：高技术高附加值高效益、高度关联性、国际化、专业化分工、规模化经济效益。\n10.发展模式：“全面领先”技术与服务领导型——美国，“整机带动”嵌入式系统开发型——日韩，“软件集散”生产本地化型——爱尔兰，“外包服务”国际加工服务型——印度。\n11.产业不足：关键核心缺乏、自主创新能力弱、企业规模小、产权保护力度弱。\n12.软件企业：分为软件产品企业和软件服务企业。\n13.软件工程生产过程方法论：技术学、经济学、管理学。 \n14.软件生产周期：从概念形成开始，经过开发、使用和维护，直到最后退役的全过程。\n15.计算题：功能点计算方法\n\nW为加权系数，d为基本信息量。\nwd为题目表格中数据相乘后相加。\nFi环境复杂度参数（题目给出）\n16.衡量产品质量高低的指标：技术性能指标（处理能力）和可靠性指标（持久能力）。\n17.软件的可靠性是关系到系统成败的重要因素。\n18.软件工程经济学四个部分：\n\n第二章\n1.沉没成本：已经发生的不可收回的支出。\n2.任何对软件项目的工程经济分析与研究都必须从实体维、时间维和要素维等三个维度展开。\n3.经济活动分析与评价特征：系统分析的目的是为了提高工程经济活动的经济效果，经济效果大多与“未来”有关，系统分析强调的是在技术可行性基础上的经济分析，系统评价是通过“比较”来完成的，统评价应是各利益主体目标的相互协调与均衡。\n4.投资：实现目标而进行资金投放或运行的经济活动。\n5.投资活动包括：生产性投资（保证生产运行）和非生产性投资（证券投资）。\n6.建设项目投资包括：固定资产投资（设备）、流动资金投资（工资原材料）、无形资产投资（使用权）。\n7.筹资和资金运用、项目可行性、市场调查。\n8.项目的可行性分析：必要性、可实现性、效果性与风险性。\n9.总成本费用：生产成本、管理费用、财务费用和销售费用。\n10.收入：销售收入、劳务收入、使用费收入、股利收入及利息收入。\n11.税金：增值税（增值额）、营业税、企业所得税（生产经营）、城乡维护建设税（维护公共设施）、教育费附加。\n12.所得税：企业所得税与个人所得税。\n13.利润：\n\n14.资金的时间价值：绝对金额随时间转移后其增加或减少的金额部分。\n15.计算题：年利率（本利和）的计算。\n\n16.现金流量图：箭头向上者表示现金流入(或正现金流)，箭头向下者表示现金流出(或负现金流)。注意现金流量图对象！\n17.计算题：初值和本利的计算。\n\n例题：\n\n\n\n\n18.***计算题：等额系列现金流。\n\n\nA为每年等额偿还&#x2F;存储的金额。Sn为最后一年金额。P0为首年金额。\nA&#x3D;P0 × CRF（偿还）\nA&#x3D;Sn × SFF （存储）\n例题：\n\n\n19.招标与投标的特征：组织性（招标特有）、公开性、一次性决定、公平性。\n20.招标类型：按公开程度和参加人数的限制条件分类，可划分为竞争性招标（公开招标）和有限招标（邀请招标），按合同的条件分类，可分为自动条件招标、随机条件招标、谈判招标。\n 第三章\n1.成本的经济内容：劳动资料方面的消耗、劳动对象方面的消耗、人工方面的消费的消耗。\n2.成本的特点：消耗性、补偿性、目的性、综合性、代偿性。\n3.成本的分类：按企业主要经营活动——研究与开发成本、采购成本、生产成本、经营成本、管理费用。按成本与产量的对应关系——变动成本与固定成本。按成本的确定时间——预测成本、定额成本、计划成本、实际成本。\n4.软件成本构成：硬件购置费用、网络通信费用、软件购置费用、基建费用、人力资源费用、硬件生产测试费、软件开发&#x2F;测试费用、水、电、运输费用、消耗材料及废品损失费用、培训费用、系统营销费用、管理费用、其他费用。\n5.减少成本测算误差的策略。\n6.计算题：功能分解法（不考大题）\n最小可能值ai、最大可能值bi、最可能值mi、平均规模Ej\n\n成本费用Coi、劳动生产率Eoi、各子系统模块成本Ci、各子系统工作量Mi\n软件总成本Cs、总工作量Es（Ms）\n\n\n例题：习题三第3题\n7.计算题：影响因子法与COCOMO模型\nU为综合影响要素\n\n\nCs软件开发成本、a工时费用率、Ms修正工作量、Mo基本工作量\nL软件开发规模、Td工期、rkhd形式参数（根据类型判断）。\n组织性：程序规模较小；嵌入型：硬件软件限制条件下运行；半独立型：规模较大。\n例题：\n\n\n8.计算题：类比法估计目标软件成本\n改变调整系数AAF、原软件开发规模La、新软件开发规模Lb\nDM设计修改百分比、CM代码修改百分比、IM集成修改百分比\n\nW1 &#x3D; 0.4、 W2 &#x3D; W3 &#x3D; 0.3\n\n9.ABC分类法\n\n\n成本控制的重点研究对象：ABC分类（从大到小排序）\n10.计算题：挣值管理法\n四个关键指标：总预算成本TBC、累计预算成本CBC、累计实现成本CAC、累计实现价值CEV。\n四个绩效评价参数：成本偏差CV：CV&#x3D;CEV-CAC、成本绩效CPI：CPI&#x3D;CEV&#x2F;CAC、进度偏差SV：SV&#x3D;CEV-CBC、进度绩效SPI：SPI&#x3D;CEV&#x2F;CBC。\n完工预测成本FCAC：FCAC&#x3D;TBC&#x2F;CPI、FCAC&#x3D;CAC+(TBC-CEV)、FCAC&#x3D;CAC+重估剩余工程预算。\n11.软件产品的定价和营销是软件生存周期中的两项重要工程经济活动。\n12.产品价格是由其价值所决定的。\n13.软件价格的影响因素：用户需求、产品成本、市场竞争和垄断及环境因素。\n14.软件的定价目标：利润导向、收益导向、销售导向、竞争导向、品牌导向、维持生存导向。\n15.软件的定价方法：成本导向定价法、需求导向定价法、竞争导向定价法。\n16.软件的定价策略：撇脂和渗透定价策略，捆绑定价策略，免费使用策略，歧视定价策略。\n17.软件的市场营销过程一般包括： ① 目标市场定位 ② 确定产品策略③ 确定定价策略④ 确定(销售)渠道策略 ⑤ 确定促销策略⑥ 确定服务策略。\n第四章\n1.项目评价：净现值法、内部收益率法和投资回收期法。\n2.计算题：净现值法NPV\n\nBt寿命期内收益、Ct支出（成本）、Dt残值、Kt投资额、i基准贴现率、N使用年限\nNPV&gt;0 投资可行 NPV&lt;&#x3D;0投资不可行\n3.计算题：内部收益法（不要求计算）了解原理：求NPV(IRR)（对分法）。\n4.计算题：投资回收期法\n\n5.计算题：净现值法进行多方案比较\n\n6.计算题：净年值法进行多方案比较\nCRF资金回收系数\n\n7.计算题：研究期法（是否承认未使用价值）\n\n8.计算题：费用现值法\n\n9.计算题：年费用现值法\n\n10.效益的分类：成本与支出费用的节省、社会财富的增加、服务水平的提高、管理水平的提高。\n11.对软件项目实际效益与预测效益评价常采用系统运行前后对比法和参数估计法。\n12.软件的社会效益评价：系统评价以定性分析为主、社会评价无通用方法、对社会的贡献以间接效益、无形效果和外部效果为主。\n13.软件项目的风险：\n\n第五章（略）\n第六章\n1.软件的开发的产品目标：质量、成本、进度和团队。\n2.计划网络图与关键路径！！！\n特征：有向性和不可逆转性、连通性、封闭性。\n当计划网络出现多个起始结点或多个终止结点时，应引入虚活动。\n\n\n\n\n3.软件开发团队的组织建设\n\n\n\n","slug":"SCAU软件工程经济学","date":"2023-06-28T18:28:12.000Z","categories_index":"Study","tags_index":"学习","author_index":"Fioransh"},{"id":"bc926e4a66038b5c73c00f3880f05287","title":"响应状态码","content":"一、状态码大类\n\n\n状态码分类\n说明\n\n\n\n1xx\n响应中——临时状态码，表示请求已经接受，告诉客户端应该继续请求或者如果它已经完成则忽略它\n\n\n2xx\n成功——表示请求已经被成功接收，处理已完成\n\n\n3xx\n重定向——重定向到其它地方：它让客户端再发起一个请求以完成整个处理。\n\n\n4xx\n客户端错误——处理发生错误，责任在客户端，如：客户端的请求一个不存在的资源，客户端未被授权，禁止访问等\n\n\n5xx\n服务器端错误——处理发生错误，责任在服务端，如：服务端抛出异常，路由出错，HTTP版本不支持等\n\n\n二、常见的响应状态码\n\n\n状态码\n英文描述\n解释\n\n\n\n&#x3D;&#x3D;200&#x3D;&#x3D;\nOK\n客户端请求成功，即处理成功，这是我们最想看到的状态码\n\n\n302\nFound\n指示所请求的资源已移动到由Location响应头给定的 URL，浏览器会自动重新访问到这个页面\n\n\n304\nNot Modified\n告诉客户端，你请求的资源至上次取得后，服务端并未更改，你直接用你本地缓存吧。隐式重定向\n\n\n400\nBad Request\n客户端请求有语法错误，不能被服务器所理解\n\n\n403\nForbidden\n服务器收到请求，但是拒绝提供服务，比如：没有权限访问相关资源\n\n\n&#x3D;&#x3D;404&#x3D;&#x3D;\nNot Found\n请求资源不存在，一般是URL输入有误，或者网站资源被删除了\n\n\n405\nMethod Not Allowed\n请求方式有误，比如应该用GET请求方式的资源，用了POST\n\n\n428\nPrecondition Required\n服务器要求有条件的请求，告诉客户端要想访问该资源，必须携带特定的请求头\n\n\n429\nToo Many Requests\n指示用户在给定时间内发送了太多请求（“限速”），配合 Retry-After(多长时间后可以请求)响应头一起使用\n\n\n431\n Request Header Fields Too Large\n请求头太大，服务器不愿意处理请求，因为它的头部字段太大。请求可以在减少请求头域的大小后重新提交。\n\n\n&#x3D;&#x3D;500&#x3D;&#x3D;\nInternal Server Error\n服务器发生不可预期的错误。服务器出异常了，赶紧看日志去吧\n\n\n503\nService Unavailable\n服务器尚未准备好处理请求，服务器刚刚启动，还未初始化好\n\n\n状态码大全：https://cloud.tencent.com/developer/chapter/13553 \n","slug":"响应状态码","date":"2023-03-14T05:28:12.000Z","categories_index":"Study","tags_index":"学习,计算机网络","author_index":"Fioransh"}]